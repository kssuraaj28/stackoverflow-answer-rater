Id,Body,CommentCount,Score,Reputation,UpVotes,DownVotes,Views,QId,QAcceptedAnswerId
"60026924","<p>You might simplify your piece to make it more efficient:</p>

<pre><code>leaves = set()
leaves.update(*graph.values())
leaves -= graph.keys()
</code></pre>
","2","0","1678","131","50","109","60012940","60026924"
"60013028","<p>Use <a href=""https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html"" rel=""nofollow noreferrer"">Pandas</a>.</p>

<p>Like this,</p>

<pre><code>import pandas as pd
</code></pre>

<p>I made a file from your provided data and imported,</p>

<pre><code>df = pd.read_csv('rcsv.csv')

print(df.head())
</code></pre>

<p>It looks like this,</p>

<pre><code>Time  Data1  Data2  Data3
0     0     10     25    100
1     1     20     30    120
2     2     25     35    125
3     3     30     50    150
</code></pre>

<p>You get a specific element like this (second element in second column, zero indexed)</p>

<pre><code>print(df.iloc[1][1])

20
</code></pre>

<p>If you have a <a href=""https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.to_datetime.html"" rel=""nofollow noreferrer"">date and/or time</a> axis then we could approach it differently.  </p>
","0","0","423","27","14","87","60012972","60013072"
"60013049","<p>Solution without <code>pandas</code>:</p>

<pre><code>import csv

dataFile = 'data.csv'

with open(dataFile) as inputData:
    csv_input = csv.reader(inputData)
    i = zip(next(csv_input), zip(*csv_input))
    data, (_, times) = {}, next(i)
    for k, line in i:
        for t, l in zip(times, line):
            data.setdefault(k, {}).setdefault(t, {})
            data[k][int(t)] = l

print(data['Data1'][1])
</code></pre>

<p>Prints:</p>

<pre><code>20
</code></pre>
","0","0","67907","1966","35","5948","60012972","60013072"
"60013070","<p>You do not need to load the immense Panda library to read a CSV file.Python provides modules for this:</p>

<pre class=""lang-py prettyprint-override""><code>
import csv
import collections

filename = ""data_80.csv""


def read_csv(filename):
    columns = collections.defaultdict(list)
    with open(filename, 'rt') as file:
        rows = csv.DictReader(file)
        for row in rows:
            for key, val in row.items():
                columns[key].append(val)
    return dict(columns)  

data = read_csv(filename)

print(data) # data is a dictionary of list
{
'Time': ['0', '1', '2', '3'], 
'Data1': ['10', '20', '25', '30'], 
'Data2': ['25', '30', '35', '50'], 
'Data3': ['100', '120', '125', '150']
}

# You just can do 
print(data['Data1'][0])
</code></pre>
","0","2","695","55","5","87","60012972","60013072"
"60013072","<p>Keeping part posters original software</p>

<pre><code>import csv

dataFile = 'data.csv'

with open(dataFile) as inputData:
    csv_input = csv.reader(inputData)
    headers = next(csv_input)
    data = list(zip(*[map(int, row) for row in csv_input]))
</code></pre>

<p>Modification, dicitonary is simply:</p>

<pre><code>my_dictionary = dict(zip(headers, data))

print(my_dictionary ['Data1'][1])
&gt;&gt;&gt; 20
</code></pre>
","0","1","10876","714","1","925","60012972","60013072"
"60013091","<p>You may use</p>

<pre><code>\b(by|per)\s+(.*?)(?=\s*(?:\b(?:by|per)\b|$))
</code></pre>

<p>See the <a href=""https://regex101.com/r/RIF5X1/1"" rel=""nofollow noreferrer"">regex demo</a></p>

<p><strong>Details</strong></p>

<ul>
<li><code>\b</code> - a word boundary</li>
<li><code>(by|per)</code> - Group 1: <code>by</code> or <code>per</code> words</li>
<li><code>\s+</code> - 1+ whitespaces</li>
<li><code>(.*?)</code> - Group 2: any zero or more chars other than line break chars, as few as possible up to the first occurrence of...</li>
<li><code>(?=\s*(?:\b(?:by|per)\b|$))</code> - a sequence of

<ul>
<li><code>\s*</code> - 0+ whitespaces</li>
<li><code>(?:\b(?:by|per)\b|$)</code> - either of

<ul>
<li><code>\b(?:by|per)\b</code> - <code>by</code> or <code>per</code> whole words</li>
<li><code>|</code> - or</li>
<li><code>$</code> - end of string.</li>
</ul></li>
</ul></li>
</ul>
","0","0","477916","18508","53879","62572","60013016","60013091"
"60013126","<p>I believe it is because some diacritic characters in Unicode have duplicates. That is, while some characters appear identical, they may be different characters with different codes. Try <code>'á'.encode()</code> once by writing <code>á</code> and once again by copy-pasting as you did. If the bytes look different, that's because they are different characters that look identical.</p>
","2","1","1525","43","4","59","60013043","60016032"
"60016032","<p>You can normalize the file list before comparing them.</p>

<pre class=""lang-py prettyprint-override""><code>from unicodedata import normalize
ls = [normalize('NFC', f) for f in os.listdir(path)]
# compare
normalize('NFC', 'á.csv') in ls
# or just 'á.csv' in ls
</code></pre>
","1","1","23288","1366","13","1990","60013043","60016032"
"60014046","<p>Can you provide the <code>model.fit</code> call? Here is a working set of code. Working, meaning it does not raise errors using tensorflow 2.0 or 2.1.</p>

<pre class=""lang-py prettyprint-override""><code>import numpy as np
import tensorflow as tf

model = tf.keras.models.Sequential([
  #tf.keras.layers.Flatten(input_shape=(10, 1)),
  tf.keras.layers.Dense(128, activation='relu'),
  tf.keras.layers.Dropout(0.2),
  tf.keras.layers.Dense(2, activation='softmax')
])

model.compile(
    optimizer='adam',
    loss='categorical_crossentropy',
    metrics=['accuracy'])

# Generate fake data.
x = np.ones([10, 1], dtype=np.float32)
y = np.ones([10, 2], dtype=np.float32)

# Train the model, providing features and labels.
model.fit(x, y)
</code></pre>

<p>The error you are getting could be because you are not providing <code>y</code> to <code>model.fit</code>.</p>
","0","0","10363","2079","274","1014","60013061","60014046"
"60013154","<p>I'm not sure if I understood correctly, but if youwant to return multiple variables you can do:</p>

<pre><code>def foo():
    return a, b

c, d = foo()
</code></pre>

<p>Based on the sample code you gave, you're calling the function incorrectly. Try this:</p>

<pre><code>def main():
    M = Mandelbrot(-2.025,0.6,-1.125,1.125,255,200)  
    #setting parameters for the iteration
    generated_set, counts = M.parameters()  #storing  the list of mandelbrot set coordinates in complex plane
    M.display(generated_set)  #graphically 
displaying the generated mandelbrot set 

main()      
</code></pre>

<p>The reason is that <code>M</code> is an instance of the Mendelbrot class. You don't pass M to the function, you use it to call it instead.</p>
","3","3","3322","293","58","422","60013125","60013154"
"60013327","<p>Although I have accepted an answer, I think this code is in a more OOP style</p>

<p>The code for the display method should be:</p>

<pre><code>def display(np_full_grid,counts):  #creating method to graphically display mandelbrot set       
        f, ax = plt.subplots()
        points = ax.scatter(np_full_grid.real, np_full_grid.imag, c=counts, s=1, cmap=""viridis"")  #displaying filtered grid
        f.colorbar(points)  #generating colour bar from 
</code></pre>

<p>The test code should be:</p>

<pre><code>def main():
    M = Mandelbrot(-2.025,0.6,-1.125,1.125,255,100)  #setting parameters for the iteration
    generated_set,counts = Mandelbrot.parameters(M)  #storing the list of mandelbrot set coordinates in complex plane and their corresponding count
    Mandelbrot.display(generated_set,counts)  #graphically displaying the generated mandelbrot set 
main()      
</code></pre>
","2","0","217","20","0","22","60013125","60013154"
"60031662","<p>Look in the API docs for <a href=""https://discordpy.readthedocs.io/en/latest/ext/commands/api.html?highlight=has_permissions#discord.ext.commands.has_role"" rel=""nofollow noreferrer"">discord.ext.commands.has_role()</a> and <a href=""https://discordpy.readthedocs.io/en/latest/ext/commands/api.html?highlight=has_permissions#discord.ext.commands.cooldown"" rel=""nofollow noreferrer"">discord.ext.commands.cooldown()</a><br>
Both can be used as <a href=""https://wiki.python.org/moin/PythonDecorators"" rel=""nofollow noreferrer"">decorators</a></p>
","0","0","593","66","0","48","60013135","60031662"
"60013793","<p>In your TodoList model you do not have due_Date field thats why you are getting this error: The value of 'list_display[2]' refers to 'due_date', which is not a callable.
list_display in admin takes your model's field name only.
I dont know why you are using due_date which is not present in your model.</p>
","1","2","393","34","1","45","60013141","60013793"
"60014051","<p>You can use a <strong>waiter</strong>:</p>

<pre class=""lang-py prettyprint-override""><code>waiter = client.get_waiter('db_cluster_snapshot_available')
</code></pre>

<blockquote>
  <p>Polls <code>RDS.Client.describe_db_cluster_snapshots()</code> every 30 seconds until a successful state is reached. An error is returned after 60 failed checks.</p>
</blockquote>

<p>See: <a href=""https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/rds.html#RDS.Waiter.DBClusterSnapshotAvailable"" rel=""nofollow noreferrer"">class RDS.Waiter.DBClusterSnapshotAvailable</a></p>
","0","2","161426","2680","33","15860","60013146","60014051"
"60013609","<p>You are creating an oval one pixel wide and one pixel tall. What you see is the color of the oval outline. With only one pixel there isn't enough space to draw both the outline and an interior. </p>

<p>You can either set the <code>outline</code> attribute to the same color as the fill color, or set the outline width (<code>width</code> attribute) to zero. </p>

<p>Here is an example that shows two different blocks of 1-pixel ovals. One has the default outline width of one, and the other explicitly sets the outline width to zero. Notice in the first you're seeing the outline color, and in the second you're seeing the fill color.</p>

<pre><code>import tkinter as tk
root = tk.Tk()
canvas = tk.Canvas(root, width=200, height=200, background=""black"")
canvas.pack(fill=""both"", expand=True)

for x in range(100):
    for y in range(100):
        canvas.create_oval(x, y, x, y, outline=""red"", fill=""green"")

for x in range(100, 200):
    for y in range(100, 200):
        canvas.create_oval(x, y, x, y, outline=""red"", fill=""green"", width=0)

root.mainloop()
</code></pre>

<p><a href=""https://i.stack.imgur.com/xD63h.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/xD63h.png"" alt=""enter image description here""></a></p>
","3","1","304622","14209","14165","34310","60013156","60013609"
"60013333","<p>At first glance it looks like because your <code>location=i</code> is not indented inside your if statement so it is getting set to the latest <code>i</code> on each iteration of the for loop. Let me know if this helps.</p>

<pre><code>def search_query(person_infos):
  if answer == '3':
    search_query = input('Who would you like to find: ')
    they_are_found = False
    location = None
    for i, each_employee in enumerate(person_infos):
      if each_employee['name'] == search_query:
        they_are_found = True
        location = i
    if they_are_found:
      print('Found: ', person_infos[location]['name'], person_infos[location]['job position'], person_infos[location]['date hired'], person_infos[location]['pay per hour'])
  else:
      print('Sorry, your search query is non-existent.')
</code></pre>
","0","0","510","6","3","40","60013290","60013333"
"60013364","<blockquote>
  <p>if 'word' is in 'minor_words' join the 'minor_words' </p>
</blockquote>

<p>No, that's not what it means.</p>

<p><code>word if word in minor_words</code> means that if <code>word</code> is in <code>minor_words</code>, we join <code>word</code> (which is a word from <code>title</code>).</p>

<p><code>else word.capitalize()</code> means that if <code>word</code> is <em>not</em> in <code>minor_words</code>, we join the capitalized word.</p>

<blockquote>
  <p>why is there <code>=''</code>?</p>
</blockquote>

<p>That provides a default value to the <code>minor_words</code> parameter. In the last example, where you call the function with only one argument:</p>

<pre><code>title_case('the quick brown fox')
</code></pre>

<p>it's equivalent to:</p>

<pre><code>title_case('the quick brown fox', '')
</code></pre>

<p>Without the default value you would get an error that not enough arguments were provided.</p>
","0","1","586865","7069","3864","89361","60013332","60013364"
"60013406","<p><strong>You might also like pandas.</strong></p>

<p>If you do a lot of stuff like this, you should check into <a href=""https://pandas.pydata.org/pandas-docs/stable/index.html"" rel=""nofollow noreferrer"">pandas</a> and its <a href=""https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.apply.html"" rel=""nofollow noreferrer"">apply functionality</a>. It can make these sorts of things as quick as: </p>

<pre class=""lang-py prettyprint-override""><code>df = df.apply(your_func)
</code></pre>

<p>It's a really powerful tool and you can sometimes make some slick and handy one-liners if that's your kind of thing. </p>
","0","0","81","3","0","20","60013385","60013434"
"60013434","<p>Using <a href=""https://docs.python.org/3/library/functions.html#map"" rel=""nofollow noreferrer""><code>map()</code></a>, you can make your transformation function accept a key to transform and return a lambda, which acts as the mapping method. By using the previously passed key (<code>k</code>) and the passed in dictionary (<code>d</code>), you can return a new dictionary with the dictionary's value converted to uppercase:</p>

<pre><code>arr_of_dicts = ({""st"" : ""il""}, {""st"" : ""IL""}, {""st"" : ""Il""})

upper = lambda k: lambda d: {k: d[k].upper()} # your func
res = map(upper('st'), arr_of_dicts) # mapping method

print(list(res))
</code></pre>

<p><strong>Result:</strong></p>

<pre><code>[{'st': 'IL'}, {'st': 'IL'}, {'st': 'IL'}]
</code></pre>

<hr>

<p>If your dictionaries have additional keys, then you can first spread the original dictionary into your new dictionary, and then overwrite the key propery you want to transform with the uppercase version like so:</p>

<pre><code>arr_of_dicts = [{""a"": 5, ""st"" : ""il""}, {""a"": 7, ""st"" : ""IL""}, {""a"": 8, ""st"" : ""Il""}]

upper = lambda k: lambda d: {**d, k: d[k].upper()}
res = map(upper('st'), arr_of_dicts) # mapping method

print(list(res))
</code></pre>

<p><strong>Result:</strong></p>

<pre><code>[{'a': 5, 'st': 'IL'}, {'a': 7, 'st': 'IL'}, {'a': 8, 'st': 'IL'}]
</code></pre>
","3","2","30684","4111","819","2869","60013385","60013434"
"60013596","<p>Using <code>pandas</code> library, we can use subsetting technique for a <code>DataFrame</code>.</p>

<p>Firstly, for testing purpose, I recreate the data frame with only 2 columns: <code>Borough</code> and <code>Neighbourhood</code>. I also add another row, since none of the provided data meet the condition.</p>

<pre><code>borough = [""Not assigned"", ""Not assigned"", ""Not assigned"", ""Not assigned"", ""Etobicoke"", ""Etobicoke"", ""Etobicoke"", ""Etobicoke"", ""Etobicoke"", ""Not assigned"", ""Etobicoke""]
neighbourhood = [""Not assigned"", ""Not assigned"", ""Not assigned"", ""Not assigned"", ""Kingsway Park South West"", ""Mimico NW"", ""The Queensway West"", ""Royal York South West"", ""South of Bloor"", ""Not assigned"", ""Not assigned""]

df = pd.DataFrame({""Borough"": borough,
                   ""Neighbourhood"": neighbourhood})
print(df)
</code></pre>

<p>Then we create the conditional statement of: <strong>If a cell has a valid Borough location (can be anything) and the Neighbourhood is ""Not assigned"" then the Neighborhood will be set to equal the same as the Borough.</strong></p>

<pre><code>condition = (df[""Borough""] != ""Not assigned"") &amp; (df[""Neighbourhood""] == ""Not assigned"")
print(condition)
</code></pre>

<p><code>condition</code> is a <code>boolean Series</code> which contains only <code>True</code> and <code>False</code>, useful for subsetting the dataframe.</p>

<p>Lastly, we replace the value in <code>Neighbourhood</code> column with the value in <code>Borough</code> column if the row met the <code>condition</code>.</p>

<pre><code>df.loc[condition, ""Neighbourhood""] = df.loc[condition, ""Borough""]
print(df)
</code></pre>

<p><strong>Alternatively</strong>, you can also do looping, but it's not a good practice since the computation could be slower for bigger data:</p>

<pre><code>for idx, row in df.iterrows():
    condition = (row[""Borough""] != ""Not assigned"") &amp; (row[""Neighbourhood""] == ""Not assigned"")
    if condition:
        row[""Neighbourhood""] = row[""Borough""]
</code></pre>
","0","1","61","0","0","3","60013459","60013596"
"60013500","<p>It seems like you're setting <code>[toggleLogger = false]</code>, but not the bool to false. 
<code>[isToggled  = false]</code>. Your code is checking whether <code>isToggled == false</code>, not <code>toggleLogger</code>.</p>

<p>if you print <code>toggleLogger</code> and <code>isToggled</code> before and after you will see the difference.</p>

<p>Try something like:
<code>isToggled = !isToggled</code>     or
<code>isToggled = False</code></p>
","0","0","16","2","0","1","60013461","60013500"
"60013827","<p>You can use <code>PyAstronomy</code> in python:</p>

<pre><code>from PyAstronomy import pyas

jd = 2440000.0
print(""HJD (ra=100 deg, dec=37 deg): "", pyas.helio_jd(jd-2.4e6, 100.0, 37.0))
</code></pre>

<p>Output:</p>

<pre><code>HJD (ra=100 deg, dec=37 deg):  39999.99536863883
</code></pre>
","1","0","484","430","29","54","60013462","60013827"
"60013741","<p>I think you want to use drop_duplicates(). Here's a simplified example:</p>

<pre><code>import pandas as pd

df = pd.DataFrame([[""foo"", ""bar""],[""foo2"", ""bar2""],[""foo3"", ""bar3""]], columns=[""first_column"", ""second_column""])
df2 = pd.DataFrame([[""foo3"", ""bar4""],[""foo4"", ""bar5""],[""foo5"", ""bar6""]], columns=[""first_column"", ""second_column""])

print(pd.concat([df, df2], ignore_index=True).drop_duplicates(subset=""first_column""))
</code></pre>

<p>Output:</p>

<pre><code>  first_column second_column
0          foo           bar
1         foo2          bar2
2         foo3          bar3
4         foo4          bar5
5         foo5          bar6
</code></pre>

<p>As you can see, the ""foo3"" row from the second dataframe gets filtered out because it is already contained in the first dataframe.</p>

<p>In your case you would use something like:</p>

<pre><code>pd.concat([stats, stats2], ignore_index=True).drop_duplicates(subset=""Player""))
</code></pre>
","0","0","145","19","0","9","60013509","60078626"
"60078626","<p>Your doing a ton of work to put a <code>&lt;table&gt;</code> tag into a table. Let pandas do that for you (it uses BeautifulSoup under the hood). Then to merge, there's 2 ways you can do it:</p>

<p>1) Make one of the dataframes only have what is not contained in the other (However, keep columns that you will do the merge on).</p>

<p>2) Drop columns from the second dataframe that are in the dataframe (again, make sure to not drop the columns you will do the merge on.</p>

<pre><code>import pandas as pd

def scrape_data(url):
    stats = pd.read_html(url)[0]
    return stats


df1 = scrape_data(""https://basketball-reference.com/leagues/NBA_2020_advanced.html"")
df1 = df1[df1['Rk'] != 'Rk']

df2 = scrape_data(""https://basketball-reference.com/leagues/NBA_2020_per_poss.html"")
df2 = df2[df2['Rk'] != 'Rk']

uniqueCols = [ col for col in df2.columns if col not in df1.columns ]

# Below will do the same as above line
#uniqueCols = list(df2.columns.difference(df1.columns))

df2 = df2[uniqueCols + ['Player', 'Tm']]

df = df1.merge(df2, how='left', on=['Player', 'Tm'])
</code></pre>

<p>OR</p>

<pre><code>import pandas as pd

def scrape_data(url):
    stats = pd.read_html(url)[0]
    return stats


df1 = scrape_data(""https://basketball-reference.com/leagues/NBA_2020_advanced.html"")
df1 = df1[df1['Rk'] != 'Rk']

df2 = scrape_data(""https://basketball-reference.com/leagues/NBA_2020_per_poss.html"")
df2 = df2[df2['Rk'] != 'Rk']

dropCols = [ col for col in df1.columns if col in df2.columns and col not in ['Player','Tm']]
df2 = df2.drop(dropCols, axis=1)

df = df1.merge(df2, how='left', on=['Player', 'Tm'])
</code></pre>
","0","0","16881","862","128","1314","60013509","60078626"
"60013923","<p>I tried to <em>stay true</em> to your attempt.  Not sure I got the <em>empty lines</em> logic correct.</p>

<p>Iterate over the file till you find a line that has <code>'TIP4P'</code> in it; get the next line, split it and grab the eighth and ninth item.</p>

<pre><code>empty = False
with open(iFileName,""r"") as ifile:
    while not empty:   # keep looping till too many empty lines
        empties = 0
        line = next(ifile).strip()
        while line[13:18] != 'TIP4P':
            line = next(ifile).strip()
            #print(line)
            if not line:
               empties += 1 
            if empties &gt;= 10:
                empty = True
                break
        if empty: break
        line = next(ifile).strip()
        line = line.split()
        #print(list(enumerate(line)))
        val = line[8][:-1]
        units = line[9][1:-2]
        val = float(val)
        print('val: {} - {}'.format(val,units))
</code></pre>

<hr>

<p>It probably isn't the way I would do it. I would probably rely on the structure and find what I wanted with a regular expression.</p>

<pre><code>import re
pattern = r'TIP4P.*$\s+.*?(\d+\.\d+)\)\s\[(mol/kg)'
tip4p = re.compile(pattern,flags=re.MULTILINE)

with open(iFileName,""r"") as ifile:
    s = ifile.read()

for match in tip4p.finditer(s):
    #print(match.groups())
    val,units = match.groups()
    val = float(val)
    print('val: {} - {}'.format(val,units))
</code></pre>
","12","0","19459","1049","1547","4170","60013524","60013923"
"60021612","<p>Your debug output helpfully contains the following trace:</p>

<pre><code>-&gt; 1-23-0-2-0-1-0-23-0-1-2-0-1-55-131
&lt;- 1-151-1-143-240
</code></pre>

<p>Consider the following:</p>

<ul>
<li>The second byte is 23, so the correct function code was sent.</li>
<li>You actually got an ""illegal function code"" on the wire, which must have been generated by the device on purpose. You don't get a CRC error or ""illegal address"" or ""illegal value"".</li>
<li>It's possible (but I guess somewhat unlikely) that the device supports code 23, but only for some addresses.</li>
</ul>

<p>The only thing left that could have been wrong on <em>your</em> side is that the library botched the encoding of the actual request. I haven't checked the other bytes, but as <a href=""https://stackoverflow.com/questions/60013544/modbus-tk-for-modbus-rtu-read-write-multiple-registers-fn-code-23-returns-ex/60021612#comment106139591_60013544"">commented by Brits</a>, there might be a bug in modbus-tk with the encoding. It's possible that the person implementing the slave decided to respond with ""illegal function code"" to a malformed request.</p>

<p>It seems also plausible to me that they just didn't bother to implement this function code. For example, <a href=""http://www.simplymodbus.ca/FAQ.htm#FC"" rel=""nofollow noreferrer"">simplymodbus</a> doesn't even list it.</p>
","0","2","3903","717","12","232","60013544","60022248"
"60022248","<p>Further to the answer from @maxy; the <a href=""http://www.modbus.org/docs/Modbus_Application_Protocol_V1_1b3.pdf"" rel=""nofollow noreferrer"">modbus spec</a> states that exception code 1 (ILLEGAL FUNCTION) means:</p>

<blockquote>
  <p>The function code received in the query is not an allowable action for
  the server (or slave). This may be because the function code is only
  applicable to newer devices, and was not implemented in the unit
  selected. It could also indicate that the server (or slave) is in the
  wrong state to process a request of this type, for example because it
  is unconfigured and is being asked to return register values.</p>
</blockquote>

<p>So, in this case, I'd say that the device does not support this command.</p>

<p>However given that another user has reported an issue with this command I thought it was worth checking the encoding:</p>

<pre class=""lang-none prettyprint-override""><code>1- Slave ID
23- Function Code
0, 2- Read Starting Address
0, 1- Quantity to Read
0, 23- Write Starting Address
0, 1 - Quantity to write
2, Write Byte Count
0,1, - Write Registers value
55,131 - CRC (have not checked)
</code></pre>

<p>This looks correct to me with one exception; it's not clear where the ""Write Starting Address"" comes from (and suspicious that it's the same as the function code). Looking at the <a href=""https://github.com/ljean/modbus-tk/blob/master/modbus_tk/modbus.py#L262"" rel=""nofollow noreferrer"">source</a>:</p>

<pre class=""lang-py prettyprint-override""><code>pdu = struct.pack(
    ""&gt;BHHHHB"",
    function_code, starting_address, quantity_of_x, defines.READ_WRITE_MULTIPLE_REGISTERS,
    len(output_value), byte_count
)
</code></pre>

<p>This looks wrong to me (<code>defines.READ_WRITE_MULTIPLE_REGISTERS</code> will always be 23). The code was changed to this in commit <a href=""https://github.com/ljean/modbus-tk/commit/dcb0a2f115d7a9d63930c9b4466c4501039880a3"" rel=""nofollow noreferrer"">dcb0a2f115d7a9d63930c9b4466c4501039880a3</a>; previously it was:</p>

<pre class=""lang-py prettyprint-override""><code>pdu = struct.pack(
    ""&gt;BHHHHB"",
    function_code, starting_address, quantity_of_x, starting_addressW_FC23,
    len(output_value), byte_count
)
</code></pre>

<p>This makes more sense to me (you need a way to pass in the address to start writing and the current interface does not seem to provide this). I have added a note re this to the <a href=""https://github.com/ljean/modbus-tk/issues/121"" rel=""nofollow noreferrer"">github issue</a>.</p>

<p>So in conclusion your issue is probably due to the device but even if the device supported the command I don't think it would work due to a bug in modbus-tk.</p>
","0","3","3512","49","44","215","60013544","60022248"
"60049315","<p>Based on the rigor of @maxy's answer, then on @Brits's answer, I decided to investigate further.  The goal was to identify if the root cause was a <code>modbus-tk</code> bug, or if my device doesn't support function code 23.</p>

<p>In <a href=""https://github.com/ljean/modbus-tk/issues/121"" rel=""nofollow noreferrer"">modbus-tk Issue #121</a>, the OP mentions that <code>pymodbus</code> worked with function code 23, read/write multiple registers.</p>

<hr>

<p>So I installed <code>pymodbus==2.3.0</code>, and then gave it a whirl.  Here is the code I used:</p>

<p>Input</p>

<pre class=""lang-py prettyprint-override""><code>#!/usr/bin/env python3


import sys
import logging
from collections import namedtuple

from pymodbus.pdu import ModbusResponse, ExceptionResponse
from pymodbus.client.sync import ModbusSerialClient
from pymodbus.register_read_message import ReadWriteMultipleRegistersResponse


log = logging.getLogger()
log.addHandler(logging.StreamHandler(sys.stdout))
log.setLevel(logging.DEBUG)


ModbusHoldingReg = namedtuple(
    ""ModbusHoldingRegister"", [""name"", ""address"", ""last_read_value"", ""to_write_value""]
)

sensor_mode = ModbusHoldingReg(""sensor on, off, and standby enum"", 0, None, None)


PORT = ""COM3""
SLAVE_NUM = 1
BAUD_RATE = 9600


with ModbusSerialClient(
    method=""rtu"", port=PORT, baudrate=BAUD_RATE, strict=False
) as modbus_client:
    regs_to_write = [0, 1, 3]
    response = modbus_client.readwrite_registers(
        read_address=sensor_mode.address,
        read_count=len(regs_to_write),
        write_address=sensor_mode.address,
        write_registers=regs_to_write,
        unit=SLAVE_NUM,
    )  # type: ModbusResponse

    if response.isError():
        response: ExceptionResponse
        print(
            f""Exception!  Original function code = {response.original_code}, ""
            f""exception_code = {response.exception_code}.""
        )
    else:
        response: ReadWriteMultipleRegistersResponse
        print(f""Success!  response.registers = {response.registers}."")
</code></pre>

<p>Output</p>

<pre class=""lang-none prettyprint-override""><code>Current transaction state - IDLE
Running transaction 1
SEND: 0x1 0x17 0x0 0x0 0x0 0x3 0x0 0x0 0x0 0x3 0x6 0x0 0x0 0x0 0x1 0x0 0x3 0x5d 0xce
New Transaction state 'SENDING'
Changing transaction state from 'SENDING' to 'WAITING FOR REPLY'
Changing transaction state from 'WAITING FOR REPLY' to 'PROCESSING REPLY'
RECV: 0x1 0x97 0x1 0x8f 0xf0
Getting Frame - 0x97 0x1
Factory Response[151]
Frame advanced, resetting header!!
Adding transaction 1
Getting transaction 1
Changing transaction state from 'PROCESSING REPLY' to 'TRANSACTION_COMPLETE'
Original function code = 23, exception code = 1.
</code></pre>

<hr>

<p><strong>Conclusion</strong></p>

<p>One can see that the device responded with exception code 1, <code>Illegal Function</code>.  So I believe this device does not support function code 23.</p>

<p>I will circle back if I ever find a device that supports fn code 23.</p>
","0","2","692","525","5","335","60013544","60022248"
"60073266","<p>I have the same problem but I know that my slave is compliant with Function Code 23, it is a wago 750-362.
I can read the datas but it seems the function writes to the wrong address. I do not have function code error.</p>

<p>This is the command I send:</p>

<pre><code>inputExt = master.execute(1, cst.READ_WRITE_MULTIPLE_REGISTERS, 0, 5, output_value=[32767,32767,32767,32767,0x00ff])
</code></pre>

<p>This is what I see with a wireshark capture:</p>

<pre><code>Modbus/TCP
    Transaction Identifier: 35394
    Protocol Identifier: 0
    Length: 21
    Unit Identifier: 1
Modbus
    .001 0111 = Function Code: Read Write Register (23)
    Read Reference Number: 0
    Read Word Count: 5
    Write Reference Number: 23
    Write Word Count: 5
    Byte Count: 10
    Data: 7fff7fff7fff7fff00ff
</code></pre>

<p>Why the Write reference Number, supposed to be the address where we write and the same as we read, is 23 and not 0? The read reference is OK.</p>
","2","1","11","0","0","3","60013544","60022248"
"60013737","<pre><code>cols = ['date_crawled', 'ad_created', 'last_seen']
[print (autos[v].value_counts(normalize=True, dropna=False).describe()) for v in cols]
</code></pre>

<p>Does this work for you?</p>
","0","0","800","54","1","57","60013547","60013737"
"60013635","<p>Try this basically, what it does it add the rows to a list as they are processed. This allows you to go back to the previous row if you need to update it. It only writes the output after the full input file is processed. <strong>This would not be an ideal solution if this csv is very large as this approach would use a lot of memory</strong>. </p>

<p>This will update the previous rows based on what the <code>Measurement Period</code> is. It checks to make sure that the update falls within the range of the list. For example if the second row has a <code>Measurement Period</code> of 4 you should only update the first row right not 4 rows? </p>

<p>This has the possibility of updating two rows twice aswell, for example. What if row two has a <code>Measurement Period</code> of 2 and row 3 has a <code>Measurement Period</code> of 4. The third rows <code>Rainfall Value</code> will overwrite rows 1 and 2. Does that make sense? </p>

<p>Make sure and test this out to see if it covers your scenrios. </p>

<pre><code>import csv

path = ""Sample.csv""
fields = ['Product code','Year','Month','Measurement period','Rainfall amount']
output2 = ""Sample2.csv""


with open(path,'r') as x, open(output2, 'w', newline='') as output:
    reader = csv.DictReader(x, fieldnames=fields)
    writer= csv.DictWriter(output, fieldnames=fields)
    rows = []
    for row in reader:

    try:
        if int(row['Measurement period']) &gt; 1:
            for i in range(int(row['Measurement period'])):
                if len(rows)-(i+1) &lt;= len(rows)-1 and len(rows)-(i+1) &gt;= 0:
                    rows[len(rows)-(i+1)]['Rainfall amount'] = row['Rainfall amount']
        rows.append(row)
    except ValueError:
        pass
writer.writerows(rows)`enter code here`
</code></pre>
","2","0","510","6","3","40","60013552","60013635"
"60013726","<p>You should assign it back and switch</p>

<pre><code>df = df.sort_values(by=['name', 'values'], ascending=[True, False])
</code></pre>
","0","0","252249","5881","962","22297","60013707","60013730"
"60013730","<p>Just change the order on how we sort the values:</p>

<pre><code>df.sort_values(by=['name', 'values'], ascending=[True, False])
</code></pre>

<p>We have to sort it by <code>name</code> first, and then <code>values</code>. Not the other way.</p>
","0","1","61","0","0","3","60013707","60013730"
"60014118","<p>use <code>pd.set_option('max_colwidth', &lt;width&gt;)</code> for column width &amp; <code>pd.set_option('max_rows', &lt;rows&gt;)</code> for number of rows.<br>
see <a href=""https://pandas.pydata.org/pandas-docs/stable/user_guide/options.html"" rel=""noreferrer"">https://pandas.pydata.org/pandas-docs/stable/user_guide/options.html</a></p>

<pre><code>[] pd.set_option('max_rows', 99999)
[] pd.set_option('max_colwidth', 400)
[] pd.describe_option('max_colwidth')

display.max_colwidth : int
    The maximum width in characters of a column in the repr of
    a pandas data structure. When the column overflows, a ""...""
    placeholder is embedded in the output.
    [default: 50] [currently: 400]

[] df = pd.DataFrame(d)
[] df

  name                                                                                     degree   score
0   a1  We explained to customer how correct fees (100) were charged. Account balance was too low   90
1   b2  customer was late in paying fees and we have to charge fine                                 40
2   c2  customer's credit score was too low and we have to charge higher interest rate              80
3   d3  customer complained a lot and didnt listen to our explanation. I had to escalate the call   98
</code></pre>
","0","9","1132","71","34","145","60013721","60014118"
"60015918","<p>Another way to display more content is to use <code>DataTable</code> to display pandas dataframe.</p>

<pre class=""lang-py prettyprint-override""><code>%load_ext google.colab.data_table
df = pd.DataFrame(dict) 
df
</code></pre>

<p>This seems to pack the data more densely and display a lot in each cell.</p>
","0","1","23288","1366","13","1990","60013721","60014118"
"60013814","<p><code>def avg(*args)</code> means that your function takes several arguments, but calling <code>avg(pkt)</code> passes a <em>list</em> to the function. You need to unpack that list with <code>avg(*pkt)</code> so its contents are passed individually to the function - or of course define the function as <code>def avg(args)</code> so it accepts a list as its only argument.</p>
","1","1","247","20","0","20","60013785","60013814"
"60013842","<p>I think an example is the best way to showcase <code>args</code> and <code>kwargs</code>. Notice the following:</p>

<pre class=""lang-py prettyprint-override""><code>def foo(*args):
    print(args)

foo(1, 2, 3)
</code></pre>

<p>outputs:</p>

<pre><code>(1, 2, 3)
</code></pre>

<hr>

<pre class=""lang-py prettyprint-override""><code>def bar(**kwargs):
    print(kwargs)

bar(a=1, b=2, c=3)
</code></pre>

<p>outputs:</p>

<pre><code>{'a': 1, 'b': 2, 'c': 3}
</code></pre>

<hr>

<pre class=""lang-py prettyprint-override""><code>def foobar(*args, **kwargs):
    print('args', args)
    print('kwargs', kwargs)

foobar(1, 2, 3, d=4, e=5, f=6)
</code></pre>

<p>outputs:</p>

<pre><code>args (1, 2, 3)
kwargs {'d': 4, 'e': 5, 'f': 6}
</code></pre>

<hr>

<p>In short, <code>args</code> allows functions to take any unnamed variables and <code>kwargs</code> allows functions to take any named variables. However, it is not the name <code>args</code> and <code>kwargs</code> that give them this special property, but rather the explicit definition of each with <code>*</code> and <code>**</code>:</p>

<pre class=""lang-py prettyprint-override""><code>def foo(*lol):
    print(lol)

foo(1, 2, 3)
</code></pre>

<p>outputs:</p>

<pre><code>(1, 2, 3)
</code></pre>

<p>Checkout the Python documentation on them <a href=""https://docs.python.org/3/tutorial/controlflow.html#arbitrary-argument-lists"" rel=""nofollow noreferrer"">here</a>.</p>

<hr>

<p>The concept above also works for unpacking other objects, such as <code>list</code> and <code>set</code>. Notice:</p>

<pre class=""lang-py prettyprint-override""><code>print([1, 2, 3])  # &gt;&gt;&gt; [1, 2, 3]
</code></pre>

<p>where</p>

<pre class=""lang-py prettyprint-override""><code>print(*[1, 2, 3]) # &gt;&gt;&gt; 1 2 3
</code></pre>

<p>The above is the equivalent of passing three separate arguments to the <code>print</code> function, so it is the same as doing:</p>

<pre class=""lang-py prettyprint-override""><code>print(1, 2, 3)
</code></pre>
","0","2","4588","211","39","464","60013785","60013814"
"60013826","<p>You can do </p>

<pre><code>s = df.groupby(['Place','zoneid','Id']).head(1)
df = df.drop(s.index[s['Event']=='Out'])
</code></pre>
","1","3","252249","5881","962","22297","60013789","60013826"
"60013997","<p>Router provides argument <a href=""https://www.django-rest-framework.org/api-guide/routers/#usage"" rel=""nofollow noreferrer""><code>basename</code></a> which is using to reverse url.</p>

<pre><code>router = routers.DefaultRouter()
router.register(r'genres', GenreViewSet, basename='genres')

urlpatterns = [
    url(r'^api/',include(router.urls)),
    path('', views.index, name='index'),
</code></pre>

<p>Note that DRF's viewset has multiple urls. So you need to specify which one you want to use by adding specific suffix <code>-list</code> or <code>-detail</code>. First one will give you url of viewset <code>list()</code> and <code>create()</code> actions. And second using for <code>retrieve()</code> and <code>update()</code>.</p>

<p>So in template it would be something like this:</p>

<pre><code>&lt;a href=""{% url 'genres-list' %}""&gt;api&lt;/a&gt;
</code></pre>
","1","2","37572","2148","0","2444","60013944","60013997"
"60014125","<p>This will do:</p>

<pre><code>    if str(submit_button[""state""]) == ""disabled"":
        submit_button[""state""] = ""normal""
        browse_button[""state""] = ""disabled""
        show_fig[""state""] = ""disabled""

    elif str(browse_button[""state""]) == ""disabled"":
        submit_button[""state""] = ""disabled""
        browse_button[""state""] = ""normal""
        save_button[""state""] = ""disabled""
        show_button[""state""] = ""disabled""
</code></pre>

<p>Just replace your <code>switch1()</code> function with this.</p>
","0","1","953","1008","3023","498","60013965","60014125"
"60014116","<p>Install Virtual Environment so you can use many and different versions of Python.</p>
","1","0","39","0","0","5","60014044","60014195"
"60014185","<p>use anaconda python distribution which better for python.</p>
","1","1","531","88","20","94","60014044","60014195"
"60014195","<p>Use <code>$ type python</code> to see where it points to. Use <code>brew info</code> command to list the info on installed python. </p>

<pre><code>$ brew info python
python: stable 3.7.6 (bottled), HEAD
Interpreted, interactive, object-oriented programming language
https://www.python.org/
/usr/local/Cellar/python/3.7.5 (4,032 files, 61.8MB) *
  Poured from bottle on 2019-11-04 at 22:34:01
From: https://github.com/Homebrew/homebrew-core/blob/master/Formula/python.rb
==&gt; Dependencies
Build: pkg-config ✔
Required: gdbm ✔, openssl@1.1 ✔, readline ✔, sqlite ✔, xz ✔
==&gt; Options
--HEAD
    Install HEAD version
==&gt; Caveats
Python has been installed as
  /usr/local/bin/python3

Unversioned symlinks `python`, `python-config`, `pip` etc. pointing to
`python3`, `python3-config`, `pip3` etc., respectively, have been installed into
  /usr/local/opt/python/libexec/bin

If you need Homebrew's Python 2.7 run
  brew install python@2

You can install Python packages with
  pip3 install &lt;package&gt;
They will install into the site-package directory
  /usr/local/lib/python3.7/site-packages

See: https://docs.brew.sh/Homebrew-and-Python

</code></pre>

<p>See the lines under <code>Caveats</code></p>

<blockquote>
  <p><code>Python has been installed as</code><br>
  <code>/usr/local/bin/python3</code></p>
</blockquote>

<p>that's your python3 alias path. you can safely symlink <code>python</code> to point to it in <code>~/.bash_profile</code></p>

<pre><code>$ echo 'alias python=/usr/local/bin/python' &gt; ~/.bash_profile
$ cat ~/.bash_profile
###########################
# you'll probably see these kind of lines before your alias
###########################

export PATH=/usr/local/bin:/usr/local/Cellar:$PATH
export ARCHFLAGS=""-arch x86_64""
export LC_ALL=""en_US.UTF-8""
export LANG=""en_US.UTF-8""
alias python=/usr/local/bin/python

</code></pre>

<p>restart your terminal for it to take effect</p>

<pre><code>$ type python
python is aliased to `python3'
$ python
Python 3.7.5 (default, Nov  1 2019, 02:16:32) 
[Clang 11.0.0 (clang-1100.0.33.8)] on darwin
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
&gt;&gt;&gt; 
</code></pre>
","6","1","1132","71","34","145","60014044","60014195"
"60056648","<p><a href=""https://i.stack.imgur.com/0u7cB.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/0u7cB.png"" alt=""enter image description here""></a></p>

<blockquote>
  <p>It seems I have entered wrong inputs, hence the reason I had this
  error. Below is the snapshot of the code results. </p>
  
  <p>These are case sensitive inputs. That was the reason why I had this
  issue.</p>
</blockquote>

<p><a href=""https://i.stack.imgur.com/BofoJ.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/BofoJ.png"" alt=""enter image description here""></a></p>
","0","0","913","25","5","91","60014108","60056648"
"60014270","<p>If you really want to read the entire file into a single list, where each element of the list is a line from the file, then use <code>.readlines()</code> instead of <code>.read()</code>.</p>

<p>However, if your file is large, then you may not want to load it all into memory at once.  You can process a file one line at a time like this:</p>

<pre><code>stroke = open('2018cut.txt', 'r')
for line in stroke:
    # do stuff with line
</code></pre>
","0","0","1318","121","13","64","60014218","60014270"
"60015067","<p>Here you go, description in code.</p>

<pre><code>from tkinter import *
import Image, ImageTk

# create canvas
canvas = Canvas(width=300, height=200, bg='black')
canvas.pack()
# create image object
img = Image.new('RGB', (60, 30), color='red')
new_image = ImageTk.PhotoImage(img)
# load into canvas
canvas.create_image(50, 10, image=new_image, anchor=NW)
mainloop()
</code></pre>

<p>Output:</p>

<p><a href=""https://i.stack.imgur.com/NiPv5.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/NiPv5.png"" alt=""enter image description here""></a></p>

<p>To update canvas create function, and update root after changes to the object are made.</p>

<pre><code>from tkinter import *
import Image, ImageTk
import time


def update_position():
    while True:
        canvas.move(rectangle, 30, 10)
        time.sleep(1)
        root.update()


root = Tk()
# create canvas
canvas = Canvas(root, width=300, height=200, bg='black')
canvas.pack()
# create image object
img = Image.new('RGB', (60, 30), color='red')
new_image = ImageTk.PhotoImage(img)
# load into canvas
rectangle = canvas.create_image(50, 10, image=new_image, anchor=NW)
update_position()
root.mainloop()
</code></pre>
","3","1","4584","259","83","602","60014234","60015067"
"60014926","<p>Simply add theta variable to title string</p>

<pre><code>theta = 1
ax.set_title(""Θ = %.i"" % theta, fontsize=25)
</code></pre>

<p>By saving file do the same</p>

<pre><code>fig.savefig('Θ = ' + str(theta) +'.png')
</code></pre>
","6","1","4584","259","83","602","60014260","60014926"
"60015456","<p>You are not using the <code>host</code> variable in <code>for host in keys:</code> loop at all.</p>

<p>And you can actually use the data as you read them straight away. It does not look like you need to collect the data to <code>keys</code> at all.</p>

<pre><code>for row in reader:
    host = row[1]
    ms_key = row[2]
    rm_key = row[3]

    i = 1

    while True:
        print (""\nTrying to connect to %s (%i/2)"" % (host, i))

        try:
           ssh = paramiko.SSHClient()
           ssh.set_missing_host_key_policy(paramiko.AutoAddPolicy())
           ssh.connect(
               host, username=username, password=password, look_for_keys=False, timeout= 5)
           print (""\nConnected to %s"" % host )
           connection_state = 1
           break

    if connection_state == 1:
        client_shell = ssh.invoke_shell()
        time.sleep(.4)
        client_shell.send(multi_site + ""\n"")
        time.sleep(.4)
        client_shell.send(remote_monitor + ""\n"")
</code></pre>

<p><em>(btw, the <code>i</code> is never changed from its initial value of <code>1</code>)</em></p>
","1","0","144036","8283","6276","21385","60014311","60015456"
"60014721","<p>If tag is <code>Name</code> in loop then set to variable and last add to <code>dictionary</code> values:</p>

<pre><code>import xml.etree.cElementTree as ET
def read_xml(xml_file):

   etree = ET.parse(xml_file)
   root = etree.getroot()
   items = []
   for item in root.findall('LIST/'):
       values = {}
       if (item.tag == 'Name'):
           name = item.text
           continue
       for it in item:
           values[it.tag] = it.text
       values['Name'] = name
       items.append(values)

   columns = ['Name','Mode', 'LEVELS','Group','Type']
   df = pd.DataFrame(items, columns = columns)

   return df

xml_file = 'xml.xml'
print(read_xml(xml_file))
         Name    Mode LEVELS Group Type
0       ALICE    Hole      1    11    0
1       ALICE   BEWEL      2    22    0
2  WONDERLAND    Mole      1    11    0
3  WONDERLAND  Matrix      6    66    0
</code></pre>
","0","1","615041","23439","1483","126104","60014315","60014721"
"60018412","<p>The variable Name needs to be <code>""PRD""</code> (the string itself must contain double quotes). Python considers <code>Name = """"""PRD""""""</code> the same as <code>Name = ""PRD""</code> so it's incorrect because the variable Name will just contain <code>PRD</code> (missing double quotes).</p>

<p>Hence, need to use string backslash (<code>Name = ""\""PRD\""""</code> or other possibilities mentioned <a href=""https://stackoverflow.com/a/6717689/9150270"">here</a>) to maintain the double quote in the variable Name.</p>

<p>Complete code:</p>

<pre><code>from subprocess import call
import win32com.client
import time
import os

GUIPath = 'C:/Program Files (x86)/SAP/FrontEnd/SAPgui/'
WinTitle = 'SAP'
Name = ""\""PRD\""""
SID = 'PRD'
InstanceNo = '01'

shell = win32com.client.Dispatch(""WScript.Shell"")
call(os.path.join(GUIPath, 'SAPgui.exe') + "" "" + Name + "" "" + InstanceNo)
</code></pre>
","4","3","33","3","0","3","60014378","60018412"
"60023371","<p>Use this simple one-liner for connecting:</p>

<pre><code>import subprocess
subprocess.check_call(['C:\Program Files (x86)\SAP\FrontEnd\SAPgui\\sapshcut.exe', '-system=DCG210', '-client=100', '-user=USERNAME', '-pw=PASSWORD'])
</code></pre>

<p>You should use <code>subprocess</code> module instead of <code>os.call</code>, it is <a href=""https://stackoverflow.com/a/17094488/911419"">preferred</a> now.</p>
","0","1","8255","2572","121","1571","60014378","60018412"
"60014455","<p>Your file is called <code>email.py</code>. A standard Python library module with the same name is used by <code>smtplib</code>. As a result, <code>smtplib</code> imports <em>your</em> file instead of the standard module. Solution: rename your file.</p>
","0","1","44660","2964","3976","8780","60014386","60014455"
"60014443","<p>I think you need remove <code>[]</code> because <code>ALTJ_genes</code> is list and <code>[ALTJ_genes]</code> is nested list:</p>

<pre><code>df1.drop(df1.columns.difference(ALTJ_genes), axis=1, inplace=True)
</code></pre>

<p>But simplier is select columns by list:</p>

<pre><code>df1 = df1[ALTJ_genes]
</code></pre>

<p>EDIT:</p>

<p>I think problem is with defined columns with nested list, so get one level non standard MultiIndex:</p>

<pre><code>df1 = pd.DataFrame([[1,2,3,4]])
#nested list
df1.columns = [['APEX1', 'ASF1A', 'CDKN2D', 'AAA']]
print (df1) 
  APEX1 ASF1A CDKN2D AAA
0     1     2      3   4

print (df1.columns)
MultiIndex([( 'APEX1',),
            ( 'ASF1A',),
            ('CDKN2D',),
            (   'AAA',)],
           )
</code></pre>

<p>If pass non nested list:</p>

<pre><code>df1 = pd.DataFrame([[1,2,3,4]])
#not nested list
df1.columns = ['APEX1', 'ASF1A', 'CDKN2D', 'AAA']
print (df1) 
   APEX1  ASF1A  CDKN2D  AAA
0      1      2       3    4

print (df1.columns)
Index(['APEX1', 'ASF1A', 'CDKN2D', 'AAA'], dtype='object')
</code></pre>
","16","2","615041","23439","1483","126104","60014438","60014443"
"60014796","<h2>Simplification of the code</h2>

<p>If we define a helper function which returns cyclically the data from the tuple:</p>

<pre class=""lang-py prettyprint-override""><code>def cyclic_iter(values):
    while True:
        for v in values:
            yield v
</code></pre>

<p>then the code could simply become:</p>

<pre class=""lang-py prettyprint-override""><code>def multiple_writer(self, val:tuple):
    with open(self.file_path, 'wb+') as file:
        generator = cyclic_iter(val)
        for _ in range(self.file_size):
            file.write(next(generator))
</code></pre>

<p>or one could exploit the <code>zip</code> function:</p>

<pre class=""lang-py prettyprint-override""><code>def multiple_writer(self, val:tuple):
    with open(self.file_path, 'wb+') as file:
        for _, value in zip(range(self.file_size), cyclic_iter(val)):
            file.write(value)
</code></pre>

<h2>Edit: Simplest way</h2>

<p>Since you mentioned that you just started with python I'll add the simplest way I know.</p>

<pre class=""lang-py prettyprint-override""><code>def multiple_writer(self, val:tuple):
    with open(self.file_path, 'wb+') as file:
        for i in range(self.file_size):
            file.write(val[i % len(val))
</code></pre>
","3","-1","629","93","2","56","60014448","60014796"
"60015849","<p>Try this:</p>

<pre><code>%run another.ipynb
</code></pre>

<p>You may need to mount drive to access your <code>drive/My Drive/Colab Notebooks/</code></p>
","2","2","23288","1366","13","1990","60014501","60015849"
"60014521","<p>Get all object columns by <a href=""http://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.select_dtypes.html"" rel=""nofollow noreferrer""><code>DataFrame.select_dtypes</code></a>, convert to dict and pass to <a href=""http://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.astype.html"" rel=""nofollow noreferrer""><code>DataFrame.astype</code></a>:</p>

<pre><code>train = train.astype(dict.fromkeys(train.select_dtypes('object').columns, 'category'))
</code></pre>
","0","1","615041","23439","1483","126104","60014502","60014521"
"60014737","<p>You have used <code>predict = model.predict_classes(encode)</code> which overwrites any function definition of predict and replace with an array.</p>

<p>So Predict is an array which is not callable.
If you just to see the predicted class for <code>encode[0]</code> you can use: <code>print(predict[0])</code></p>
","0","1","61","37","0","2","60014565","60014737"
"60029126","<p>The issue is that Pillow loads the image in greyscale mode, because it can, but then Pygame can’t recognise this. To fix it, you need to <code>convert()</code> the image to a format Pygame understands, by changing your third line to this:</p>

<pre class=""lang-py prettyprint-override""><code>image = Image.open(""./QR/test.png"").convert(""RGB"")
</code></pre>

<p>If you need an alpha channel, change <code>""RGB""</code> to <code>""RGBA""</code>.</p>

<p>Note that if you don’t intend to use the image in Pillow, you can just use</p>

<pre class=""lang-py prettyprint-override""><code>py_image = pygame.image.load(""./QR/test.png"")
</code></pre>

<p>which is much faster and shorter.</p>
","0","1","1272","52","4","65","60014571","60029126"
"60014697","<pre><code>import os
import platform

path = os.path.basename(__file__)
run_on=platform.system()
if run_on=='Windows': path=f'.\\{path}'
elif run_on=='Linux': path=f'./{path}'

print(f'path is {path}')
</code></pre>
","1","1","373","4","1","27","60014652","60014697"
"60014789","<p>Why not simply let <code>os</code> handle that for you?</p>

<pre><code>path = os.path.normcase(os.path.join('.', os.path.relpath(__file__)))
</code></pre>
","4","0","972","24","5","77","60014652","60014697"
"60015032","<p>You can do this in Loop, while changing input arguments of function. This is one way of doing it inside you Windows. You can define your locations (x,y) on plan. it will keep on doing things inside your VM.</p>

<pre><code>import win32api, win32con
def click(x,y):
    win32api.SetCursorPos((x,y))
    win32api.mouse_event(win32con.MOUSEEVENTF_RIGHTDOWN,x,y,0,0)
    win32api.mouse_event(win32con.MOUSEEVENTF_RIGHTUP,x,y,0,0)
click(100,100)
</code></pre>
","0","2","107","9","0","16","60014869","60015032"
"60017217","<p>This should work:</p>

<pre class=""lang-py prettyprint-override""><code>cur.execute(
  ""INSERT INTO engagement.geospatial_countries (name, code, polygon) VALUES (%s, %s, %s)"",
  geometry_to_insert
)
</code></pre>

<p>please read in the docs <a href=""https://www.psycopg.org/docs/usage.html#passing-parameters-to-sql-queries"" rel=""nofollow noreferrer"">how to pass parameters to the query</a> and, if you want to insert several objects at time, <a href=""https://www.psycopg.org/docs/extras.html#psycopg2.extras.execute_values"" rel=""nofollow noreferrer"">the <code>execute_values()</code> function</a>.</p>
","1","1","11617","147","36","778","60014973","60030831"
"60028730","<p>A postgres/redshift geometry is not a GeoJSON, you need to use JSON column type:</p>

<pre><code>...
cur.execute(""CREATE TABLE engagement.geospatial_countries (id INTEGER PRIMARY KEY, name VARCHAR(25), code VARCHAR(10), polygon JSON)"")
country = countries[0]
geometry_to_insert = (
    country[""properties""][""ADMIN""],
    country[""properties""][""ISO_A3""],
    Json.dumps(country[""geometry""])
)
cur.execute(
      ""INSERT INTO engagement.geospatial_countries (name, code, polygon) VALUES (%s, %s, %s)"", geometry_to_insert
)
</code></pre>
","1","1","11727","812","303","942","60014973","60030831"
"60030831","<p>Here I give the steps that worked to insert it into the DB.</p>

<p>First, a minor correction in creating a table for the geometries, using IDENTITY to have an auto-incrementing ID:</p>

<pre><code>conn = psycopg2.connect(...connection params)
cur = conn.cursor()
cur.execute(""CREATE TABLE engagement.geospatial_countries (id INTEGER IDENTITY(0,1) PRIMARY KEY, name VARCHAR(25), code VARCHAR(10), polygon GEOMETRY);"")
</code></pre>

<p>Onto the Geometries. To insert the value, use a WKT value:</p>

<pre><code>import geojson
from shapely.geometry import shape
...
# exact same steps as in question to read file, then
country = countries[0]
geom = shape(country[""geometry""])
geometry_to_insert = (
    country[""properties""][""ADMIN""],
    country[""properties""][""ISO_A3""],
    geom.wkt
)
</code></pre>

<p>Then the following command to insert the value:</p>

<pre><code>cur.execute(
  ""INSERT INTO engagement.geospatial_countries (name, code, polygon) VALUES (%s, %s, ST_GeomFromText(%s))"",
  geometry_to_insert
)
</code></pre>

<p>Answers from both @Maurice Meyer and @piro guided me to this answer.</p>
","0","2","753","255","1","68","60014973","60030831"
"60015697","<p>Just create two plots, in which case axes will be a list of 2 elements and use those plot.</p>

<p>Refer the <a href=""https://matplotlib.org/api/_as_gen/matplotlib.pyplot.subplots.html#matplotlib.pyplot.subplots"" rel=""nofollow noreferrer"">documentation</a>.</p>

<pre><code>f, axes = plt.subplots(2, figsize = (14,10))
sns.boxplot(x='Heating QC',y='SalePrice',hue='Central Air',  data=df, ax=axes[0])
sns.boxplot(x='Heating',y='SalePrice',hue='Central Air',  data=df, ax=axes[1])
</code></pre>
","0","1","1151","33","3","71","60015020","60015697"
"60015336","<p>You need to create new twix axis on host and shrink subplot to create space for additional axis on right side. Then move new axis at right position. Some descriptions in code.   </p>

<pre><code>import matplotlib.pyplot as plt
import numpy as np

fig, host = plt.subplots()
# shrink subplot
fig.subplots_adjust(right=0.75)

# create new axis on host
par1 = host.twinx()
par2 = host.twinx()
# place second axis at far right position
par2.spines[""right""].set_position((""axes"", 1.2))


# define plot functions
def function_sin(x):
    return np.sin(x)


def function_parabola(x):
    return x**2


def function_line(x):
    return x+1

# plot data
x = np.linspace(0, 10, 100)
y_sin = function_sin(x)
y_parabola = function_parabola(x)
y_line = function_line(x)
host.plot(x, y_sin, ""b-"")
par1.plot(x, y_parabola, ""r-"")
par2.plot(x, y_line, ""g-"")

# set labels for each axis
host.set_xlabel(""VAV 16"")
host.set_ylabel(""Temperature"")
par1.set_ylabel(""Temperature"")
par2.set_ylabel(""Air Flow"")

plt.show()
</code></pre>

<p>Output:</p>

<p><a href=""https://i.stack.imgur.com/yctiy.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/yctiy.png"" alt=""enter image description here""></a></p>
","3","3","4584","259","83","602","60015071","60015336"
"60015615","<p>if you use Ubuntu add ""sh"" and ""-c"":</p>

<pre><code> String[] cmd = {
                            ""sh"",
                            ""-c"",
                            ""python"",
                            ""/Users/rasheenruwisha/final-year-proj/build.py"",
                            ""ARG 1"",
                            ""ARG 2"",
                        };
                        try {
                                Runtime.getRuntime().exec(cmd);
                             } catch (IOException e) {
                                e.printStackTrace();
                             }
</code></pre>
","0","2","326","37","2","20","60015120","60015615"
"60020115","<p>1.You can also use org.python.util.PythonInterpreter</p>

<pre><code>    PythonInterpreter interpreter = new PythonInterpreter();
    try {
     interpreter.execfile(""/Users/rasheenruwisha/final-year-proj/build.py"",""ARG 1,""ARG 
     2"");
    } catch (Exception e) {
        e.printStackTrace();
    }
</code></pre>
","0","1","476","63","7","46","60015120","60015615"
"60015184","<p>Idea is use <a href=""http://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.pivot_table.html"" rel=""nofollow noreferrer""><code>pivot_table</code></a> for reshape and then found index values if only one value is non missing per rows:</p>

<pre><code>df1 = df.pivot_table(index='Site', columns='Segment', aggfunc='size')
print (df1)
Segment   groupa  groupb  groupc
Site                            
cnn.com      NaN     1.0     NaN
dc.com       NaN     NaN     1.0
espn.com     1.0     1.0     NaN
news.com     1.0     NaN     NaN

print (df1.notna().sum(axis=1))
Site
cnn.com     1
dc.com      1
espn.com    2
news.com    1
dtype: int64

a = df1.index[df1.notna().sum(axis=1).eq(1)].tolist()
print (a)
['cnn.com', 'dc.com', 'news.com']
</code></pre>
","0","2","615041","23439","1483","126104","60015157","60015184"
"60086640","<p>If you need just the normal <code>ppf</code>, it is indeed puzzling that it is so slow, but you can use <code>scipy.special.erfinv</code> instead:</p>

<pre><code>x = np.random.uniform(0,1,100)
np.allclose(special.erfinv(2*x-1)*np.sqrt(2),stats.norm().ppf(x))
# True
timeit(lambda:stats.norm().ppf(x),number=1000)
# 0.7717257660115138
timeit(lambda:special.erfinv(2*x-1)*np.sqrt(2),number=1000)
# 0.015020604943856597
</code></pre>

<p>EDIT:</p>

<p><code>lognormal</code> and <code>triangle</code> are also straight forward:</p>

<pre><code>c = np.random.uniform()

np.allclose(np.exp(c*special.erfinv(2*x-1)*np.sqrt(2)),stats.lognorm(c).ppf(x))
# True

np.allclose(((1-np.sqrt(1-(x-c)/((x&gt;c)-c)))*((x&gt;c)-c))+c,stats.triang(c).ppf(x))
# True
</code></pre>

<p>skew normal I'm not familiar enough, unfortunately.</p>
","2","3","46998","848","1","8605","60015261","60497749"
"60497749","<p>Ultimately, this issue was caused by my use of the <a href=""https://en.wikipedia.org/wiki/Skew_normal_distribution"" rel=""nofollow noreferrer"">skew-normal</a> distribution. The ppf of the skew-normal actually does not have a closed-form analytic definition, so in order to compute the ppf, it fell back to <code>scipy.continuous_rv</code>'s numeric approximation, which involved iteratively computing the cdf and using that to zero in on the ppf value. The skew-normal pdf is the product of the normal pdf and normal cdf, so this numeric approximation called the normal's pdf and cdf many many times. This is why when I profiled the code, it <em>looked</em> like the normal distribution was the problem, not the SKU normal. The other answer to this question was able to achieve time savings by skipping type-checking, but didn't actually make a difference on the run-time growth, just a difference on small-n runtimes.  </p>

<p>To solve this problem, I have replaced the skew-normal distribution with the <a href=""https://en.wikipedia.org/wiki/Johnson%27s_SU-distribution"" rel=""nofollow noreferrer"">Johnson SU</a> distribution. It has 2 more free parameters than a normal distribution so it can fit different types of skew and kurtosis effectively. It's supported for all real numbers, and it has a closed-form ppf definition with a fast implementation in SciPy. Below you can see example Johnson SU distributions I've been fitting from the 10th, 50th, and 90th percentiles.</p>

<p><a href=""https://i.stack.imgur.com/Lrk9q.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/Lrk9q.png"" alt=""Example distributions""></a></p>
","0","0","792","159","5","95","60015261","60497749"
"60015515","<p>If you override the <code>__init__</code> method of the superclass, then the <code>__init__</code> method of the subclass needs to explicitly call it if that is the intended behavior, yes.</p>

<p>Your mental model of <code>__init__</code> is incorrect; it is not the constructor method, it is a hook which the constructor method calls to let you customize object initialization easily. (The actual constructor is called <code>__new__</code> but you don't need to know this, and will probably never need to interact with it directly, let alone change it.)</p>
","0","5","136497","9042","39241","29487","60015319","60015515"
"60015466","<p>change your url pattern to</p>

<pre><code>urlpatterns = [
    # ex: /polls/
    path('', views.index, name='index'),
    # ex: /polls/5/
    path('&lt;int:question_id&gt;/detail/', views.detail, name='detail'),
    # ex: /polls/5/results/
    path('&lt;int:question_id&gt;/results/', views.results, name='results'),
    # ex: /polls/5/vote/
    path('&lt;int:question_id&gt;/vote/', views.vote, name='vote'),
]
</code></pre>

<p>Instead of curly brackets you have to use square brackets and make pattern in such a way that it should not <strong>overlap</strong> </p>
","1","0","3084","21","48","293","60015326","60015466"
"60015358","<p>Use <a href=""https://docs.scipy.org/doc/numpy/reference/generated/numpy.where.html"" rel=""nofollow noreferrer"">where</a> with <a href=""https://docs.scipy.org/doc/numpy/reference/generated/numpy.amax.html"" rel=""nofollow noreferrer"">amax</a>, <a href=""https://docs.scipy.org/doc/numpy/reference/generated/numpy.amin.html"" rel=""nofollow noreferrer"">amin</a>.</p>

<pre><code>import numpy as np

arr = np.array([[2, 3, 9], [1,6,7], [4, 5, 8]])

max_value_index = np.where(arr == np.amax(arr))
min_value_index = np.where(arr == np.amin(arr))
</code></pre>

<p>Output:</p>

<pre><code>(array([0]), array([2]))
(array([1]), array([0]))
</code></pre>
","2","2","4584","259","83","602","60015349","60015358"
"60017260","<p>According to the comment, I use repr() to check where the difference is. </p>

<pre><code>repr(d.find('div', 'date').string.lstrip()) == repr(date)
# ' 2/01' '2/01'
</code></pre>

<p>So I need to remove the blank</p>

<pre><code>d.find('div', 'date').string.lstrip() == date
# '2/01' '2/01'
</code></pre>

<p>Then the condition is true.</p>
","0","1","9","0","0","2","60015354","60017260"
"60015444","<p><code>x1_change</code>, <code>y1_change</code> are local variables in scope of <code>nextMove</code>. Variables with the same name exists in scope of <code>gameLoop</code>. This are different variables, they have just the same name. 
When you change <code>x1_change</code>, <code>y1_change</code> in <code>nextMove</code>, then do not change then identically named variables in <code>gameLoop</code>.</p>

<p>Add arguments to <code>nextMove</code> and return the changed values of <code>x1_change</code> and <code>y1_change</code>:</p>

<pre class=""lang-py prettyprint-override""><code>def nextMove(snake_head, x_ch, y_ch):
    x1_change, y1_change = x_ch, y_ch

    # chang x1_change, y1_change
    # [...]

    return x1_change, y1_change
</code></pre>

<p>Pass <code>x1_change</code> and <code>y1_change</code> to and get the new values from <code>nextMove</code> in <code>gameLoop</code>:</p>

<pre class=""lang-py prettyprint-override""><code>def gameLoop():

    # [...]

    while not game_over:

        # [...]

        our_snake(snake_block, snake_List)

        x1_change, y1_change = nextMove(snake_Head, x1_change, y1_change)

        Your_score(Length_of_snake - 1)
        pygame.display.update()
</code></pre>

<hr>

<p>If the length of the snake grows, it will hit itself, when it changes the direction to the opposite.<br>
I recommend to change the direction to the left or right instead:</p>

<pre class=""lang-py prettyprint-override""><code>def nextMove(snake_head, x_ch, y_ch):

    x1_change, y1_change = x_ch, y_ch
    x1, y1 = snake_head
    next_x, next_y = x1 + x1_change, y1 + y1_change

    if next_x &lt; 0 or next_x &gt;= dis_width:
        x1_change = 0
        y1_change = 10 if y1 &lt; dis_height // 2 else -10
    if next_y &lt; 0 or next_y &gt;= dis_height:
        x1_change = 10 if x1 &lt; dis_width // 2 else -10
        y1_change = 0

    return x1_change, y1_change
</code></pre>
","7","0","136140","16645","626","8521","60015363","60015444"
"60015388","<p>You don't need to use <code>global</code></p>

<p>And you're <a href=""https://stackoverflow.com/questions/59996634/how-do-i-print-multiple-variables-in-a-line-of-code"">missing a formatted string</a> </p>

<pre><code>#!/usr/bin/env python3

import os

print ('Ping Of Death')
os.system(""clear"")
print() 
ipdeath = input(""ip:"")
packetsize = input(""size:"")
os.system(f""ping {ipdeath} -s {packetsize} "")
</code></pre>

<p>You're not capturing the output of the ping command, so that's why nothing would be printed for it (hint: use subprocess module instead of <code>os</code></p>
","9","1","124322","2234","5803","53684","60015364","60015388"
"60028764","<h2>Make use of pairwise distances from sklearn</h2>

<ul>
<li>Pairwise distances of sparse matrices are supported (no dense temporary array needed)</li>
<li>This algorithm uses a algebraic reformulation like <a href=""https://stackoverflow.com/a/42994680/4045774"">in this answer</a></li>
<li>It can be a lot faster on high dimensional problems like yours (20k) since most of the calculation is done within a highly optimized matrix-matrix product.</li>
<li>Check if this method is precise enough, it is less numerically stable
than a ""naive"" approach pdist uses</li>
</ul>

<p><strong>Example</strong></p>

<pre><code>import numpy as np
from scipy import sparse
from sklearn import metrics
from scipy.spatial import distance

matrix=sparse.random(1_000, 20_000, density=0.05, format='csr', dtype=np.float64)

%%timeit
dist_2=distance.squareform(distance.pdist(matrix.todense()))
dist_2.sort(axis=1)
dist_2=dist_2[:,1:3]
#10.1 s ± 23.1 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)

%%timeit
dist=metrics.pairwise.euclidean_distances(matrix,squared=True)
dist.sort(axis=1)
dist=np.sqrt(dist[:,1:3])
#401 ms ± 13.1 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)
</code></pre>
","0","0","5188","591","6","1183","60015409","60028764"
"60015603","<p>You can use <a href=""https://www.regular-expressions.info/lookaround.html"" rel=""nofollow noreferrer"">positive lookahead</a> expression and transform your pattern into <a href=""https://regex101.com/r/MjGtDC/3"" rel=""nofollow noreferrer""><code>(?=(aaa))</code></a>:</p>

<pre><code>for m in re.finditer('(?=(aaa))', 'aaaaaa'):
    print(m.start())
</code></pre>

<p>To get match text you need to use <code>m.group(1)</code>.</p>
","1","1","4972","166","141","1029","60015417","60015603"
"60015499","<p>Manipulate the generator manually </p>

<pre><code>gen = iter(range(15)) 
while True:
    try:
        i = next(gen) 
        if i ==2:
            next(gen) 
            continue 
        else:
            pass
    except: StopIteration
        break 
</code></pre>
","2","1","124322","2234","5803","53684","60015478","60015499"
"60015543","<p>You are missing brackets in your <code>student</code>'s class constructor:</p>

<pre class=""lang-py prettyprint-override""><code>self.Lap=self.Laptop()
</code></pre>
","2","0","9474","543","121","728","60015491","60015543"
"60015808","<p>You need to get dipper in dictionary tree to get some data like latitude. Results are collected into collection of lists then loaded into data frame and saved as csv file.</p>

<pre><code>import requests
import pandas as pd

r=requests.get('https://data.police.uk/api/crimes-street/all-crime?poly=51.169,-0.633:51.186,-0.5436:51.226,-0.6224&amp;date=2019-12')
r_json=r.json()

# collect data into list of lists
collected_data = []
for data in r_json:
    category = data.get('category')
    month = data.get('month')
    latitude = ''
    longitude = ''
    street = ''
    for key, value in data.items():
        if key == 'location':
            latitude = value.get('latitude')
            longitude = value.get('longitude')
            street = value.get('street').get('name')
    collected_data.append([category, latitude, longitude, street, month])

# load data into data frame
df = pd.DataFrame(collected_data, columns = ['Category' , 'Latitude', 'Longitude', 'Street', 'Month'])
# save data frame into csv
df.to_csv('data.csv')
</code></pre>
","3","0","4584","259","83","602","60015529","60015808"
"60016707","<p>Hi let me know if this works for you or not,</p>

<p>Just For example I have created the data frame</p>

<pre><code>import pandas as pd

data1={'A':[1,2,3,43],
    'B':[11,22,3,53],
    'C':[21,23,3,433],
    'D':[131,223,3,54]}

df=pd.DataFrame(data1)
df.index.names=['index']
print(df)
</code></pre>

<p><strong>DataFrame</strong></p>

<pre><code>       A    B   C   D
index               
0      1    11  21  131
1      2    22  23  223
2      3    3   3   3
3      43   53  433 54

ind=df[df['A']+df['B'] == df['C']+df['D']].index # get the index where values are similar. Here i have done the addition of the values from first two columns and same with next two columns, if both sums are equal then get the index.

df.drop(ind,inplace=True)  #drop row (ind=2) and save the dataframe 
print(df)
</code></pre>

<p><strong>Final output</strong></p>

<pre><code>       A    B   C   D
index               
0      1    11  21  131
1      2    22  23  223
3      43   53  433 54
</code></pre>

<p>Note: index 2 row is removed.</p>
","2","0","366","68","7","34","60015596","60016707"
"60015803","<p>By typing:</p>

<pre class=""lang-py prettyprint-override""><code>example_tuple[0[:-1]]
</code></pre>

<p>Python tries to compute what's inside the bracket first, that is <code>0[:-1]</code>. That explains the error:</p>

<pre class=""lang-py prettyprint-override""><code>TypeError: 'int' object is not subscriptable
</code></pre>

<p>You are trying to access <code>0</code> as an array.</p>

<p>As @ShubhamShaswat said, to access an array within an array, you need to get the first one, and access the value you want in it:</p>

<pre class=""lang-py prettyprint-override""><code>example_tuple = [[5.7, 2.9, 7.9], [0.1, 4.2], [1.2]]

### Using 2 steps ###
# temp_var equals [5.7, 2.9, 7.9]
temp_var = example_tuple[0]
# output: [5.7, 2.9]
print(temp_var[:-1])

### Which can be shortened in Python by assembling array access ###
# output: [5.7, 2.9]
print(example_tuple[0][:-1])
</code></pre>
","0","2","61","0","0","2","60015606","60015803"
"60028526","<p>Downgrading JRE version to 8 and installing the <code>language-check</code> package as <code>root</code> user did the trick for me.</p>
","0","0","4486","291","5","855","60015613","60028526"
"60015729","<p>You need to unpack the params list:</p>

<pre><code>out += '({:.4f},{:.4f})'.format(x,f(x, *params ))  # * == splat operator, unpacks list
</code></pre>

<p>to get</p>

<pre><code>\draw[thick] (0.0000,0.0000) -- (1.0000,1.0000) -- (2.0000,2.0000);
\draw[thick] (0.0000,0.1000) -- (1.0000,1.1000) -- (2.0000,2.1000);
\draw[thick] (0.0000,2.0000) -- (1.0000,2.3000) -- (2.0000,2.6000);
</code></pre>
","0","2","42762","4753","7949","7626","60015678","60015729"
"60015917","<p>One of the alternate ways is to extract the groups first, then replace like in below, your looping method is still better. </p>

<p>We need to alter the regex_dict a bit, </p>

<pre><code>regex_dict = {
 r'mcdonalds|mcdonald_s':""McDonalds"",
 r'lidl|lidi':""Lidl"",
 r'wallmart': ""Wallmart"",
 r'kfc':""KFC"" ,
 r'aldi|aldi':""Aldi""
}

df.str.extract(r'('+ '|'.join(regex_dict.keys())+')',expand=False).replace(regex_dict,regex=True)
0    McDonalds
1         Lidl
2         Lidl
3          KFC
4         Lidl
</code></pre>
","1","2","26658","1663","208","2991","60015726","60238126"
"60238126","<p>I managed to reduced the time needed by 40% using this. Best I could do</p>

<p>I create an empty dataframe called <code>fixed_df</code> to append new standardized rows, then delete the same rows in the original dataframe at the end of each loop. The search space is reduced for each loop as each shop is standardized, and the <code>fixed_df</code> increases in size with each loop. In the end, <code>fixed_df</code> should have all the original rows, now standardized, and the original df should be empty. </p>

<pre><code># create empty df to store new results
fixed_df = pd.DataFrame()

# loop through dictionary
for regname, regex_formula in regex_dict.items(): 

    # search for regex formula, add standardized name into standard column
    df.loc[df['term_location'].str.contains(regex_formula,na=False,flags=re.I), 'standard'] = regname

    # get index of where names were fixed
    ind = df[df['standard']==regname].index

    # append fixed data to new df
    fixed_df.append(df[df.index.isin(ind)].copy())

    # remove processed stuff from original df
    df = df[~df.index.isin(ind)].copy()
</code></pre>
","0","1","2167","119","1","235","60015726","60238126"
"60015871","<p>First create groups by test non missing values with cumulative sum and pass to <a href=""http://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.core.groupby.GroupBy.apply.html"" rel=""nofollow noreferrer""><code>GroupBy.apply</code></a> with lambda function with <a href=""https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.ffill.html"" rel=""nofollow noreferrer""><code>Series.ffill</code></a> with limit by first value of <code>times</code> per groups:</p>

<pre><code>#if necessary convert strings t onumeric and NaNs
#df['amount'] = pd.to_numeric(df['amount'], errors='coerce')

print (df['amount'].dtype)
float64

g = df['amount'].notna().cumsum()

f = lambda x: x['amount'].ffill(limit=x['times'].iat[0])
df['amount'] = df.groupby(g, group_keys=False).apply(f)
print (df)
       amount  times
0   2800000.0      6
1   2800000.0      0
2   2800000.0      0
3   2800000.0      0
4   2800000.0      0
5   2800000.0      0
6   2800000.0      0
7   4750000.0      4
8   4750000.0      0
9   4750000.0      0
10  4750000.0      0
11  4750000.0      0
12        NaN      0
13        NaN      0
</code></pre>
","1","2","615041","23439","1483","126104","60015834","60015871"
"60016037","<p>Assuming that you don't want to use the straight forward solution by iterating the indices list instead:</p>

<p>The problem is that one of the variables you're depending on (the index) is not included in your call to <code>map</code>. You'll have to insert that into the map call in some way, for example by using <code>enumerate</code> - which will emit a <code>(idx, value)</code> tuple for each element in your list.</p>

<pre><code>nums = [123, 456, 1, 0, -2, 13, 15, 29, 47, 48]
indices = [0, 1, 2, 3]

result = list(
    map(
        lambda x: x[1] + 10 if x[0] in indices else x[1],
        enumerate(nums)
    )
)

print(result)
</code></pre>

<p>Be aware that the <code>if x[0] in indices</code> part will search the indices list linearly, and will make the whole operation <code>O(n * m)</code>. This can be optimised by using a set (which has O(1) lookup as the common case) or a dictionary instead.  </p>

<pre><code>&gt; [133, 466, 11, 10, -2, 13, 15, 29, 47, 48]
</code></pre>
","0","1","37257","1432","259","3476","60015884","60016037"
"60021414","<p>With cx_Oracle 7.3, you can access <a href=""https://cx-oracle.readthedocs.io/en/latest/api_manual/cursor.html#Cursor.lastrowid"" rel=""nofollow noreferrer""><code>Cursor.lastRowid</code></a> after executing the INSERT.  See the cx_Oracle example <a href=""https://github.com/oracle/python-cx_Oracle/blob/master/samples/LastRowid.py"" rel=""nofollow noreferrer""><code>LastRowid.py</code></a>:</p>

<pre><code>cursor = connection.cursor()
cursor.execute(""insert into mytab (id, data) values (:1, :2)"", [1, ""First""])
print(""Rowid 1:"", cursor.lastrowid)
</code></pre>

<p>Otherwise use the RETURNING INTO clause you were looking at.  There is a RETURNING INTO example at <a href=""https://cx-oracle.readthedocs.io/en/latest/user_guide/bind.html#dml-returning-bind-variables"" rel=""nofollow noreferrer"">https://cx-oracle.readthedocs.io/en/latest/user_guide/bind.html#dml-returning-bind-variables</a>.</p>
","0","1","5893","301","67","1035","60015903","60021414"
"60047300","<p>Chris has given an excellent generic answer. If you are looking for the specific answer to your question, you need to do the following:</p>

<pre><code>self.__cursor.execute(SqlQry, parm + [idvar])
</code></pre>

<p>In other words, you need to ensure that only one set of parameters is passed, not multiple!</p>
","0","1","4845","20","3","677","60015903","60021414"
"60016212","<p>you should write like this</p>

<pre><code>idx= -1
for i in range(len(transmisiones)):
        if transmisiones[i] == 1:
            idx = i
        transmisiones[i] = 0

transmisiones[idx] = 1

</code></pre>

<p>the <code>idx</code> always keep the last index where the value is equal to 1</p>

<p>if you want all the indices to be saved append them in the a list</p>
","1","2","1054","33","16","194","60015929","60016212"
"60016125","<p>I've run into bugs like this before. I don't know if Kivy is working as intended with this or how to fix it. Anyone with more knowledge than me, I'd be glad to hear the reasoning to this.</p>

<pre><code>class CustomDropDown(DropDown):

    def __init__(self, **kwargs):
        super(CustomDropDown, self).__init__(**kwargs)
        self.add_buttons()

    def add_buttons(self):
        for index in range(10):

            #btn = Button(text='Value %d' % index, size_hint_y=None, height=44)
            btn = Button(text='Value %d' % index)
            btn.size_hint_y = None
            btn.height = 44


            btn.bind(on_release=lambda btn: self.select(btn.text))

            self.add_widget(btn)
</code></pre>

<p>These kind of things cause me nothing but frustration.</p>
","5","1","66","2","0","9","60015941","60016125"
"60018431","<p>Pygame is built on SDL2 which has some rules regarding in which threads certain functions can be called. For example, for functions in the event module, (<em><a href=""https://wiki.libsdl.org/SDL_PollEvent"" rel=""nofollow noreferrer"">""you can only call this function in the thread that set the video mode.""</a></em>).</p>

<p>You should almost always avoid using threads unless they are absolutely necessary! They make your program non-deterministic, harder to debug, harder to test, harder to maintain and often slower (unless you use them effectively). In your program, there are no reasons to use threads. In your case, they are unnecessary. You should do this instead:</p>

<pre><code>import pygame
import ctypes

class Game:
    def __init__(self):
        self.init = pygame.init()
        self.screen = pygame.display.set_mode((800, 500))
        self.runGame()

    def runGame(self):
        self.running = True
        while self.running:
            for event in pygame.event.get():
                if event.type == pygame.QUIT:
                    ctypes.windll.user32.MessageBoxW(0, 'Thank you for Playing!', 'Thank You', 0)
                    self.running = False

            self.screen.fill((255, 255, 255))
            pygame.draw.circle(self.screen, (0, 0, 255), (250, 250), 75)

            pygame.display.flip()  # Don't forget to call this to update the screen!



if __name__ == '__main__':
    ins = Game()
</code></pre>

<p>Less code, deterministic, and most likely faster and using less memory.</p>
","0","2","7215","573","1024","1156","60016180","60018431"
"60016567","<p>What do you want to achieve - get/print the text of each element? Because <code>Get Webelements</code> does just what its name says - returns you a list of matching elements - selenium element objects. 
Having that, if you want to print the text of each one, just iterate over the list and call <code>Get Text</code> on each member:</p>

<pre><code>FOR    ${el}    IN    @{get_t3}
    ${txt}=    Get Text    ${el}
    Log    ${txt}
END
</code></pre>
","4","5","14399","689","156","1239","60016277","60016567"
"60022398","<p>You cannot modify the airflow image that runs in Cloud Composer; however, you can use the <a href=""https://cloud.google.com/composer/docs/how-to/using/using-kubernetes-pod-operator"" rel=""nofollow noreferrer"">KubernetesPodOperator</a> to launch a new pod with pg_dump, execute it and upload the file to Cloud Storage. </p>
","0","1","2117","150","7","242","60016322","60022398"
"60016385","<p>In the second for-loop you are appending the <em>same</em> list to <code>List</code> n-times over. </p>

<pre><code>for i in range(n):
    List.append(listx)
</code></pre>

<p>You need to make copies of <code>listx</code> &amp; use those inside <code>List</code>. Like this:</p>

<pre><code>for i in range(n):
    List.append(listx[::])
</code></pre>

<p><code>listx[::]</code> makes a copy of <code>listx</code> to use. </p>
","0","1","15185","371","2705","1878","60016360","60016389"
"60016389","<p>This bit:</p>

<pre><code>for i in range(n):
    List.append(listx)
</code></pre>

<p>Adds the same list (<code>listx</code>) to <code>List</code> three times. So when you change it one place, all references change, because they are all pointing to the same list.</p>

<p>Also, as a side note: don't name variables <code>List</code> with a capital, because that makes others (and software) think it's a class. And the name <code>list</code> is of course even worse, because that would be shadowing the type <code>list</code>. Come up with names that are meaningful and not overly generic - like <code>playground</code>.</p>

<p>A more efficient way of creating an <code>n</code> x <code>m</code> list:</p>

<pre><code>playground = [[0] * m for _ in range(n)]
</code></pre>

<p>The bit <code>[0] * m</code> creates a list with <code>m</code> zeroes; this works because a number isn't referenced like a list and the zeroes won't be copies of the same variable.</p>

<p>The <code>for _ in range(n)</code> causes the resulting list to be filled with <code>n</code> of those lists. The <code>_</code> just means you're not doing anything with the number from the <code>range()</code>, it's only there for a number of repetitions and the <code>for</code> loop needs something in that place, either a variable or the <code>_</code> ""don't care"".</p>
","0","3","12065","76","218","1202","60016360","60016389"
"60016459","<p>In your second for loop you are appending the same list many times, you are appending a ""view/reference"" not the actual list, so in your second four you have to append a copy of the <code>listx</code>, for this you can use : </p>

<ul>
<li><code>list(listx)</code></li>
<li><code>listx[::]</code></li>
<li><code>listx.copy()</code></li>
</ul>

<p>Is like you want to buy apples, but you have only one and other 3 pictures of the first apple, you can' say you have 4 apples </p>
","0","0","15189","2120","120","950","60016360","60016389"
"60035820","<p><a href=""https://pytorch.org/docs/stable/nn.html#conv1d"" rel=""nofollow noreferrer"">Conv1D</a> takes as input a tensor with 3 dimensions <code>(N, C, L)</code> where <code>N</code> is the batchsize, <code>C</code> is the number of channels and <code>L</code> size of the 1D data. In your case it seems like one sample has 20 entries and you have one channel. You have a <code>batch_size</code> variable but it is not used in the code posted.</p>

<pre><code> nn.Conv1d(20,40,kernel_size=5,stride=1,padding=2)
</code></pre>

<p>This lines creates a convolution which takes a input with 20 channels (you have 1) and outputs 40 channels. So you have to change the 20 to a 1 and you might wanna change the 40 to something smaller. Since convolutions are applied to the whole input (controlled by stride, patting and kernel size), there is no need to specify the size of a sample.</p>

<p>Also you might wanna add some logic to build minibatches. Right now it seems like you just want to input every sample by itself. Maybe read a bit about dataset classes and data loaders in pytorch.</p>
","0","1","1178","13","20","45","60016597","60035820"
"60022133","<p>In TensorFlow 2.x, the recommended method of creating reusable neural network layers is to create a new <code>tf.keras.layers.Layer</code> subclass. TensorFlow provides a <a href=""https://www.tensorflow.org/guide/keras/custom_layers_and_models"" rel=""nofollow noreferrer"">great tutorial on this</a>. You can reuse the vast majority of the code in your posted example in a <code>tf.keras</code> layer class. You might also be able to inherit from <code>tensorflow.python.keras.layers.convolutional.Conv</code> to reduce the amount of boilerplate code.</p>

<p>As for the some modules not being found, you should use the aliases that TensorFlow exposes. Here is an incomplete list:</p>

<ul>
<li><code>array_ops.reshape</code> -> <code>tf.reshape</code></li>
<li><code>init_ops.constant_initializer</code> -> <code>tf.initializers.constant</code></li>
<li><code>tensor_shape</code> -> <code>tf.TensorShape</code></li>
<li><code>nn_ops.Convolution</code> -> <code>tf.nn.convolution</code> or <code>tf.keras.layers.Conv?D</code></li>
</ul>
","1","1","10363","2079","274","1014","60016635","60022133"
"60016905","<p>Here is a solution involving <code>lxml.html</code>:</p>

<p>We extract all <code>div</code>s between the <em>first</em> and <em>last</em> <code>div</code>s which contain an <code>h2</code> tag:</p>

<pre class=""lang-py prettyprint-override""><code>import lxml.html


# HTML file saved as ""file.html""
file_name = ""file.html""
with open(file_name, 'r') as f:
    tree = lxml.html.fromstring(f.read())

# all_div = tree.findall('div')
all_div = tree.find_class('foo-bar-details')[0].findall('div')
start, stop = None, None
for k, div in enumerate(all_div):
    if div.findall('h2') and start is None:
        print(""Range starts at %d"" % k)
        start = k
        continue
    if div.findall('h2') and start is not None:
        print(""Range stops at %d"" % k)
        stop = k + 1  # add one as range stops at k - 1
        continue

# div_list = all_div[start:stop]
img_list = [_.xpath('.//img') for _ in all_div[start:stop]]
print(img_list)
# [[], [&lt;Element img at 0x20b58d73f40&gt;], [&lt;Element img at 0x20b58d73f90&gt;], []]

# Or
img_list = [_.xpath('.//img/@src') for _ in all_div[start:stop]]
print(img_list)
# [[], ['../../images/123456_thumb.jpg'], ['../../images/67890_thumb.JPG'], []]
</code></pre>
","5","2","4391","311","4","409","60016647","60016905"
"60022477","<p>Another solution involving SimplifiedDoc:</p>

<pre><code>from simplified_scrapy.simplified_doc import SimplifiedDoc
html ='''
&lt;div class=""foo-bar-details""&gt;
    &lt;div class=""element-header mystic-bg padding-y-10 padding-x-20"" id=""elem-4""&gt;
        &lt;h2 class=""h3 margin-bottom-5""&gt;
            Foo 
        &lt;/h2&gt;
        &lt;ul class=""list-inline margin-0""&gt;
            &lt;li&gt; &lt;a href=""#foo-feat-4-1""&gt;Foo feature&lt;/a&gt; &lt;/li&gt;
            ... 
        &lt;/ul&gt;
    &lt;/div&gt;
    &lt;div id=""info-panel-header"" class=""padding-y-10 padding-x-40""&gt;Test 1&lt;/div&gt;
    &lt;div class=""padding-y-10 padding-x-40 gray-wild-sand-bg"" id=""foo-feat-4-1""&gt;Test 2&lt;/div&gt;
    &lt;div class=""padding-y-10 padding-x-40 "" id=""foo-feat-4-2""&gt;Test 3&lt;/div&gt;
    &lt;div class=""padding-y-10 padding-x-40 gray-wild-sand-bg"" id=""foo-feat-4-3""&gt;Test 4&lt;/div&gt;
    &lt;div class=""element-header mystic-bg padding-y-10 padding-x-20"" id=""elem-5""&gt;
        &lt;h2 class=""h3 margin-bottom-5""&gt;
            Bar 
        &lt;/h2&gt;
        &lt;ul class=""list-inline margin-0""&gt;
            &lt;li&gt; &lt;a href=""#foo-feat-5-1""&gt;Bar feature&lt;/a&gt; &lt;/li&gt;
            ... 
        &lt;/ul&gt;
    &lt;/div&gt;
&lt;/div&gt;
'''
doc = SimplifiedDoc(html)
divs = doc.select('div.foo-bar-details').divs.contains('&lt;h2')
print ([div.id for div in divs])
divs = doc.select('div.foo-bar-details').divs.notContains('&lt;h2')
print ([div.id for div in divs])
</code></pre>

<p>Result:</p>

<pre><code>['elem-4', 'elem-5']
['info-panel-header', 'foo-feat-4-1', 'foo-feat-4-2', 'foo-feat-4-3']
</code></pre>

<p>Simplifieddoc library does not rely on the third-party library, which is lighter and faster, perfect for beginners.
Here are more examples <a href=""https://github.com/yiyedata/simplified-scrapy-demo/tree/master/doc_examples"" rel=""nofollow noreferrer"">here</a></p>
","0","0","2231","56","0","189","60016647","60016905"
"60027428","<p>If I understand you correctly, you want to find <code>&lt;img&gt;</code> tags and corresponding <code>&lt;h2&gt;</code> to which the images belong to.</p>

<p>This example (<code>txt</code> variable contains the HTML snippet from your question):</p>

<pre><code>from bs4 import BeautifulSoup

soup = BeautifulSoup(txt, 'html.parser')

out = {}
for img in soup.select('div:has(h2) ~ div img'):
    out.setdefault(img.find_previous('h2').get_text(strip=True), []).append(img['src'])

from pprint import pprint
pprint(out)
</code></pre>

<p>Prints:</p>

<pre><code>{'Bar': ['../../images/39826_thumb.JPG', '../../images/209876_thumb.JPG'],
 'Foo': ['../../images/123456_thumb.jpg', '../../images/67890_thumb.JPG']}
</code></pre>
","0","0","67907","1966","35","5948","60016647","60016905"
"60017714","<p>I don't have an exact solution but you could create a pivot table: ids on the index and datetimes on the columns. Then you just have to select the columns you want. </p>

<pre><code>import pandas as pd
import numpy as np

df = pd.DataFrame(
{
    ""date_time"": [
        ""2018-10-16 23:00:00"",
        ""2018-10-16 23:10:00"",
        ""2018-10-16 23:20:00"",
        ""2018-10-16 23:30:00"",
        ""2018-10-16 23:40:00"",
        ""2018-10-16 23:50:00"",
        ""2018-10-17 00:00:00"",
        ""2018-10-17 00:10:00"",
        ""2018-10-17 00:20:00"",
    ],
    ""uids"": [
        ""1000,1321,7654,1321"",
        ""7654"",
        np.nan,
        ""7654,1000,7654,1321,1000"",
        ""691,3974,3974,323"",
        np.nan,
        np.nan,
        np.nan,
        ""27,33,3974,3974,7665,27"",
    ],
}
)

df[""date_time""] = pd.to_datetime(df[""date_time""])

df = (
    df.set_index(""date_time"") #do not use set_index if date_time is current index
    .loc[:, ""uids""]
    .str.extractall(r""(?P&lt;uids&gt;\d+)"")
    .droplevel(level=1)
) # separate all the ids

df[""number""] = df.index.minute.astype(float) / 10 + 1 # get the number 1 to 6 depending on the minutes

df_pivot = df.pivot_table(
    values=""number"", 
    index=""uids"", 
    columns=[""date_time""], 
) #dataframe with all the uids on the index and all the datetimes in columns. 
</code></pre>

<p>You can apply this to the whole dataframe or just a subset containing 6 rows. Then you rename your columns.</p>
","1","2","377","38","0","12","60016683","60017714"
"60018108","<p>You can use the function <code>crosstab</code>:</p>

<pre><code>df['uids'] = df['uids'].str.split(',')
df = df.explode('uids')
df['date_time'] = df['date_time'].dt.minute.floordiv(10).add(1)
pd.crosstab(df['uids'], df['date_time'], dropna=False)
</code></pre>

<p>Output:</p>

<pre><code>date_time  1  2  3  4  5  6
uids                       
1000       1  0  0  2  0  0
1321       2  0  0  1  0  0
27         0  0  2  0  0  0
323        0  0  0  0  1  0
33         0  0  1  0  0  0
3974       0  0  2  0  2  0
691        0  0  0  0  1  0
7654       1  1  0  2  0  0
7665       0  0  1  0  0  0
</code></pre>
","0","1","8392","1681","353","792","60016683","60017714"
"60020367","<p>We can achieve this with extracting the minutes from your datetime column. Then using <code>pivot_table</code> to get your wide format:</p>

<pre><code>df['date_time'] = pd.to_datetime(df['date_time'])

df['minute'] = df['date_time'].dt.minute // 10

piv = (df.assign(uids=df['uids'].str.split(','))
         .explode('uids')
         .pivot_table(index='uids', columns='minute', values='minute', aggfunc='size')
      )
</code></pre>

<pre><code>minute    0    1    2    3    4
uids                           
1000    1.0  NaN  NaN  2.0  NaN
1321    2.0  NaN  NaN  1.0  NaN
27      NaN  NaN  2.0  NaN  NaN
323     NaN  NaN  NaN  NaN  1.0
33      NaN  NaN  1.0  NaN  NaN
3974    NaN  NaN  2.0  NaN  2.0
691     NaN  NaN  NaN  NaN  1.0
7654    1.0  1.0  NaN  2.0  NaN
7665    NaN  NaN  1.0  NaN  NaN
</code></pre>
","0","1","31021","2441","310","2308","60016683","60017714"
"60017010","<p>In your program, you have this line  <code>del store_1[y]</code>. This is an O(n) operation according to <a href=""https://wiki.python.org/moin/TimeComplexity"" rel=""nofollow noreferrer"">here</a>. So, your code works in O(n<sup>2</sup>). That is why you are getting <strong>CPU Time Exceeded</strong>.</p>

<p>Maintain 2 counters , <code>b=0</code> and <code>m=0</code>. Iterate through the given string and find if the given index is part of the set, If yes, don't do anything. Else check if it is <code>B</code> or <code>M</code>. Accordingly, increment the counters and do the necessary check in the end. </p>

<p>Also, instead of generating Fibonacci series multiple times, you can actually generate it once and use the results again and again for the test cases.</p>
","3","0","1997","716","58","334","60016724","60017010"
"60017413","<p>There are several things that slow down your code:</p>

<ul>
<li>You start with <em>x</em> from 0 to reproduce the same Fibonacci numbers which you already generated for the previous test case. You should only generate those you did not have yet.</li>
<li>Because of the previous point, you have duplicates which you need to get rid of by applying <code>set</code>, and then you have to sort that set. If you would only generate unique Fibonacci numbers, you would not have to perform those actions.</li>
<li><code>del</code> is not a constant time operation. You should not need to delete list elements at all. All you <em>really</em> need to do, is counting</li>
<li>You potentially call the <code>count</code> method four times in a test case, while it should be enough to only perform a count once.  </li>
</ul>

<p>You can save more:</p>

<ul>
<li>Don't actually store the Fibonacci numbers in a list, but just keep the last two values in memory, and produce the next one once your index reaches the current Fibonacci number</li>
<li>Keep track of <em>one</em> count, a balance, which will go positive when Madrid scores more, or negative when Barcelona scores more.</li>
</ul>

<p>Here is how that could look:</p>

<pre><code>num_of_testcase = int(input())
for i in range(num_of_testcase):
    goals = input()
    balance = 0
    # Fibonacci pair
    a = 3
    b = 5
    # Don't bother looking at index 0-3: they are to be ignored
    for j in range(4, len(goals)):
        if j &lt; b:
            balance += 1 if goals[j] == ""M"" else -1
        else:
            a, b = b, a+b # Up to next Fibonacci number
    if balance &lt; 0:
        print(""Case #{}: Aaj Kemon Bodh Korcho"".format(i+1))
    elif balance &gt; 0:
        print(""Case #{}: Hala Madrid"".format(i+1))
    else:
        print(""Case #{}: Meh :\\"".format(i+1))
</code></pre>
","8","-1","204854","1897","2832","18633","60016724","60017010"
"60016863","<p>You can do this:</p>

<pre><code>def on_release(key):
    print('{0} released'.format(key))
    #Add your code to stop motor
    if key == keyboard.Key.esc:
        # Stop listener
        # Stop the Robot Code
        return False
    if 'char' in dir(key):     #check if char method exists,
        if key.char == 'q':    #check if it is 'q' key
            print(""fviokbhvxfb"")
</code></pre>
","1","1","3276","1384","197","432","60016734","60016863"
"60023072","<p>If you are using virtual environments, depending how you run your script, <code>'python'</code> might refer to the system Python. Using <code>sys.executable</code> instead of <code>'python'</code> might help.</p>

<p>Note that if you are using WSGI, <code>sys.executable</code> is probably not set correctly, so you might want to set it explicitly in your WSGI entry point script.</p>
","0","0","3579","482","206","406","60016929","60023072"
"60041049","<p>views.py</p>

<p>def datatest(request):<br>
   subprocess.call([sys.executable, ""-c"", ""import dbtest2""])<br>
   return HttpResponse('Call python...')</p>
","0","0","33","0","0","3","60016929","60023072"
"60017112","<p>since your column datatype is timestamp you can not use str <code>'2020-02-01'</code> to compare with your column so you need also a timestamp value: <code>pd.Timestamp(2020, 2,1)</code></p>

<p>you can use <a href=""https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.map.html"" rel=""nofollow noreferrer"">pandas.Series.map</a>:</p>

<pre><code>df_main['month_1'] = df_main['month_1'].map(lambda x: 0 if x &gt;= pd.Timestamp(2020, 2,1) else x)
</code></pre>

<p>or you can filter and assign: </p>

<pre><code>df_main['month_1'][ df_main['month_1'] &gt;= pd.Timestamp(2020, 2,1)] = 0 
</code></pre>
","2","1","15189","2120","120","950","60017006","60017112"
"60047191","<p>QPainter supports floating point coordinates, but has to be done using an implicit QPointF statement:</p>

<p><code>qp.drawPoint(QPointF(10.5, 10))</code> </p>

<p><a href=""https://i.stack.imgur.com/w4fFo.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/w4fFo.png"" alt=""parameters""></a></p>
","0","0","270","287","9","98","60017009","60047191"
"60104107","<p>What is it you are really trying to do? There are many float/real methods to choose from so it doesn't sound like you are asking the correct question.</p>

<p><a href=""https://doc.qt.io/qt-5/qgraphicsview.html#mapFromScene-5"" rel=""nofollow noreferrer"">mapFromScene()</a>
<a href=""https://doc.qt.io/qt-5/qgraphicsview.html#centerOn"" rel=""nofollow noreferrer"">centerOn()</a></p>

<p>In C++ when you <a href=""https://doc.qt.io/qt-5/qgraphicsscene.html#addWidget"" rel=""nofollow noreferrer"">addWidget()</a> you get back QGraphicsProxyWidget *. and it just so happens that QGraphicsProxyWidget has <a href=""https://doc.qt.io/qt-5/qgraphicsitem.html#setPos-1"" rel=""nofollow noreferrer"">setPos(qreal x, qreal y)</a></p>

<p>I'm certain you can find something similar in the Python interface. If you cannot, convert your QWidget to a QGraphicsItem which also has a setPos(qreal x, qreal y)</p>
","2","1","159","7","2","35","60017009","60047191"
"60017551","<p>Before you go down this route, you should evaluate if that is even neccessary. One important limit is the <a href=""https://www.rabbitmq.com/blog/2012/04/25/rabbitmq-performance-measurements-part-2/"" rel=""nofollow noreferrer"">rabbitmq bandwidth</a>.</p>

<p>Build a single-threaded app, and start feeding it synthetic rabbitmq messages. Increase the msg/s rate until it cannot keep up anymore.</p>

<p>If that rate is much higher than is likely to occur in practice, you are done. :-)</p>

<p>If not, then you start <em>profiling</em> your application to find which parts of it take the most time. Those are your bottlenecks.
Only when you know what the bottlenecks are, you can look at the relevant code and think about how to improve them.</p>

<p>Note that <code>multiprocessing</code> and <code>threading</code> do different things and have different applications. If your application is limited by the amount of calculations that it can do then <code>multiprocessing</code> can help by spreading out the calculations over multiple CPU cores. Note that this only works well if the calculations are <em>independant</em> of each other. If your application spends a lot of time waiting for I/O, <code>threading</code> can help you with doing calculations in one thread while the other is waiting for I/O.</p>

<p>But neither are free in terms of complexity. For example with <code>threading</code> you have to protect reading and writing of your dataframes with locks so that only one thread at a time can read or modify said dataframe. With <code>multiprocessing</code> you have to send data from the worker processes back to the parent process.</p>

<p>In this case, I think that <code>multiprocessing</code> would be most useful. You could set up a number of processes, each responsible for part of the beds/patients. If rabbitmq can have multiple listeners, you can have each worker process only handle the messages from patients that it is responsible for. Otherwise you have to distribute the messages to the appropriate process. Each worker process now processes the messages (and keeps the dataframes) for a number of patients. When an alert is triggered based on the calcutations done on the data, the worker only has to send a message detailing the identifier of the patient and the nature of the alert to the parent process.</p>
","1","0","35699","643","139","2437","60017013","60017551"
"60017956","<p>Plotting 3d images in <code>matplotlib</code> is a little tricky. Generally you plot whole surfaces at once instead of plotting one line at a time. You do so by passing three 2d arrays, one for each position dimension (x, y, z). But you can't just pass any old 2d arrays either; the points themselves have to be in a precise order!</p>

<p>Sometimes you can do something that just works, but I find it easier to explicitly parameterize plots using <code>u</code> and <code>v</code> dimensions. Here's what I was able to get working here:</p>

<pre><code># Abstract u and v parameters describing surface coordinates
u_plt = np.arange(x.shape[1])
v_plt = np.arange(x.shape[0])

# The outer products here produce 2d arrays. We multiply by
# ones in this case for an identity transformation, but in 
# general, you could use any broadcasted operation on `u`
# and `v`.
x_plt = np.outer(np.ones(np.size(v_plt)), u_plt)
y_plt = np.outer(v_plt, np.ones(np.size(u_plt)))

# In this case, our `x` array gives the `z` values directly.
z_plt = x

fig = plt.figure(figsize=(16, 10))
ax = fig.add_subplot(111, projection='3d')

ax.set_zmargin(1)  # Add a bit more space around the plot.
ax.plot_wireframe(x_plt, y_plt, z_plt,
                  rstride=1, cstride=1,  # ""Resolution"" of the plot
                  color='blue', linewidth=1.0,
                  alpha=0.7, antialiased=True)

# Tilt the view to match the example.
ax.view_init(elev = 45, azim = -45)

plt.xlabel('i')
plt.ylabel('x')
plt.title('test')
plt.show()
</code></pre>

<p>And here's the resulting image. I had to reduce <code>n</code> to 80 to make this comprehensible at all, and I have no idea what I am looking at, so I am not sure it's correct. But I think it looks broadly similar to the example you gave.</p>

<p><a href=""https://i.stack.imgur.com/ObOTm.jpg"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/ObOTm.jpg"" alt=""wireframe plot""></a></p>

<p>Just to illustrate the power of this approach, here's a nautilus shell. It uses a two-stage parameterization, which could be compressed, but which I find conceptually clearer:</p>

<pre><code>n_ticks = 100

# Abstract u and v parameters describing surface coordinates
u_plt = np.arange(n_ticks // 2) * 2
v_plt = np.arange(n_ticks)

# theta is the angle along the leading edge of the shell
# phi is the angle along the spiral of the shell
# r is the distance of the edge from the origin
theta_plt = np.pi * ((u_plt / n_ticks) * 0.99 + 0.005)
phi_plt = np.pi * v_plt / (n_ticks / 5)
r_plt = v_plt / (n_ticks / 5)

# These formulas are based on the formulas for rendering
# a sphere parameterized by theta and phi. The only difference
# is that r is variable here too.
x_plt = r_plt[:, None] * np.cos(phi_plt[:, None]) * np.sin(theta_plt[None, :])
y_plt = r_plt[:, None] * np.sin(phi_plt[:, None]) * np.sin(theta_plt[None, :])
z_plt = r_plt[:, None] * \ 
    (np.ones(np.shape(phi_plt[:, None])) * np.cos(theta_plt[None, :]))

# This varies the color along phi
colors = cm.inferno(1 - (v_plt[:, None] / max(v_plt))) * \
    np.ones(np.shape(u_plt[None, :, None])) 

fig = plt.figure(figsize=(8, 8))
ax = fig.add_subplot(111, projection='3d')

ax.set_zmargin(1)
ax.plot_surface(x_plt, y_plt, z_plt,
                rstride=1, cstride=1,
                facecolors=colors, linewidth=1.0,
                alpha=0.3, antialiased=True)
ax.view_init(elev = 45, azim = -45)

plt.show()
</code></pre>

<p><a href=""https://i.stack.imgur.com/a4oJN.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/a4oJN.png"" alt=""plot of a nautilus shell""></a></p>
","1","1","123320","2200","152","5846","60017049","60017956"
"60024424","<p>To resolve this problem, I have executed sort_index and the code above worked</p>

<pre><code>df.sort_index(inplace= True)
</code></pre>
","0","0","107","7","0","9","60017052","63252466"
"63252466","<p>Having the same ValueError, this is just the result of some testing and little research on my own, without the claim to be complete or professional about it. Please comment or answer whoever finds something wrong.</p>
<p>Of course, your data should be in the right order of the index values, which you would assure with <code>df.sort_index(inplace=True)</code>, as you state it in your answer. This is not wrong as such, though the error message is not about the sort order, and I have checked this: the error does not go away in my case when I sort the index of a huge dataset I have at hand. It is true, I also have to sort the df.index, but the decompose() can handle unsorted data as well where items jump here and there in time: then you simply get a lot of blue lines from left to the right and back, until the whole graph is full of it. What is more, usually, the sorting is already in the right order anyway. In my case, sorting does not help fixing the error. Thus I also doubt that index sorting has fixed the error in your case, because: what does the error actually say?</p>
<p><strong>ValueError: You must specify:</strong></p>
<ol>
<li><strong>[either] a period</strong></li>
<li><strong>or x must be a pandas object with a DatetimeIndex with a freq not set to None</strong></li>
</ol>
<p>Before all, in case you have a <em>list column</em> so that your time series is nested up to now, see <a href=""https://stackoverflow.com/questions/63246938/convert-pandas-df-with-data-in-a-list-column-into-a-time-series-in-long-format"">Convert pandas df with data in a &quot;list column&quot; into a time series in long format. Use three columns: [list of data] + [timestamp] + [duration]</a> for details how to unnest a <em>list column</em>. This would be needed for both 1.) and 2.).</p>
<p><em>Details of 1.:</em></p>
<p><em>Definition of period</em></p>
<p>&quot;period, int, optional&quot; from <a href=""https://www.statsmodels.org/stable/generated/statsmodels.tsa.seasonal.seasonal_decompose.html"" rel=""noreferrer"">https://www.statsmodels.org/stable/generated/statsmodels.tsa.seasonal.seasonal_decompose.html</a>:</p>
<blockquote>
<p>Period of the series. Must be used if x is not a pandas object or if
the index of x does not have a frequency. Overrides default
periodicity of x if x is a pandas object with a timeseries index.</p>
</blockquote>
<p>The period parameter that is set with an integer means the number of cycles which you expect to be in the data. If you have a df with 1000 rows with a <em>list column</em> in it (call it df_nested), and each list with for example 100 elements, then you will have 100 elements per cycle. It is probably smart taking <code>period = len(df_nested)</code> (= number of cycles) in order to get the best split of seasonality and trend. If your elements per cycle vary over time, other values may be better.</p>
<p>The &quot;period&quot; parameter of option 1.) has a big advantage over option 2.). Though it uses the time index (DatetimeIndex) for its x-axis, it does not require an item to hit the frequency exactly, in contrast to option 2.). Instead, it just joins together whatever is in a row, with the advantage that you do not need to fill any gaps: the last value of the previous event is just joined with the next value of the following event, whether it is already in the next second or on the next day.</p>
<p>What is the max possible &quot;period&quot; value? In case you have a <em>list column</em> (call the df &quot;df_nested&quot; again), you should first <em>unnest</em> the <em>list column</em> to a <em>normal column</em>. The max period is <code>len(df_unnested)/2</code>.</p>
<p>Example1: 20 items in x (x is the amount of all items of df_unnested) can maximally have a <code>period = 10</code>.</p>
<p>Example2: Having the 20 items and taking <code>period=20</code> instead, this throws the following error:</p>
<blockquote>
<p>ValueError: x must have 2 complete cycles requires 40
observations. x only has 20 observation(s)</p>
</blockquote>
<p>Another side-note:
To get rid of the error in question, <code>period = 1</code> should already take it away, but for time series analysis, &quot;=1&quot; does not reveal anything new, every cycle is just 1 item then, the trend is the same as the original data, the seasonality is 0, and the residuals are always 0.</p>
<p>####</p>
<p><em>Example borrowed from <a href=""https://stackoverflow.com/questions/63246938/convert-pandas-dataframe-with-a-nested-list-in-the-data-column-timestamp-and-du:"">Convert pandas df with data in a &quot;list column&quot; into a time series in long format. Use three columns: [list of data] + [timestamp] + [duration]</a></em></p>
<pre><code>df_test = pd.DataFrame({'timestamp': [1462352000000000000, 1462352100000000000, 1462352200000000000, 1462352300000000000],
                'listData': [[1,2,1,9], [2,2,3,0], [1,3,3,0], [1,1,3,9]],
                'duration_sec': [3.0, 3.0, 3.0, 3.0]})
tdi = pd.DatetimeIndex(df_test.timestamp)
df_test.set_index(tdi, inplace=True)
df_test.drop(columns='timestamp', inplace=True)
df_test.index.name = 'datetimeindex'

df_test = df_test.explode('listData') 
sizes = df_test.groupby(level=0)['listData'].transform('size').sub(1)
duration = df_test['duration_sec'].div(sizes)
df_test.index += pd.to_timedelta(df_test.groupby(level=0).cumcount() * duration, unit='s') 
</code></pre>
<p>The resulting df_test['listData'] looks as follows:</p>
<pre><code>2016-05-04 08:53:20    1
2016-05-04 08:53:21    2
2016-05-04 08:53:22    1
2016-05-04 08:53:23    9
2016-05-04 08:55:00    2
2016-05-04 08:55:01    2
2016-05-04 08:55:02    3
2016-05-04 08:55:03    0
2016-05-04 08:56:40    1
2016-05-04 08:56:41    3
2016-05-04 08:56:42    3
2016-05-04 08:56:43    0
2016-05-04 08:58:20    1
2016-05-04 08:58:21    1
2016-05-04 08:58:22    3
2016-05-04 08:58:23    9
</code></pre>
<p><strong>Now have a look at different period's integer values.</strong></p>
<p><code>period = 1</code>:</p>
<pre><code>result_add = seasonal_decompose(x=df_test['listData'], model='additive', extrapolate_trend='freq', period=1)
plt.rcParams.update({'figure.figsize': (5,5)})
result_add.plot().suptitle('Additive Decompose', fontsize=22)
plt.show()
</code></pre>
<p><a href=""https://i.stack.imgur.com/r0Hlz.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/r0Hlz.png"" alt=""enter image description here"" /></a></p>
<p><code>period = 2</code>:</p>
<pre><code>result_add = seasonal_decompose(x=df_test['listData'], model='additive', extrapolate_trend='freq', period=2)
plt.rcParams.update({'figure.figsize': (5,5)})
result_add.plot().suptitle('Additive Decompose', fontsize=22)
plt.show()
</code></pre>
<p><a href=""https://i.stack.imgur.com/cPzwP.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/cPzwP.png"" alt=""enter image description here"" /></a></p>
<p>If you take a quarter of all items as one cycle which is 4 (out of 16 items) here.</p>
<p><code>period = 4</code>:</p>
<pre><code>result_add = seasonal_decompose(x=df_test['listData'], model='additive', extrapolate_trend='freq', period=int(len(df_test)/4))
plt.rcParams.update({'figure.figsize': (5,5)})
result_add.plot().suptitle('Additive Decompose', fontsize=22)
plt.show()
</code></pre>
<p><a href=""https://i.stack.imgur.com/ZjLxG.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/ZjLxG.png"" alt=""enter image description here"" /></a></p>
<p>Or if you take the max possible size of a cycle which is 8 (out of 16 items) here.</p>
<p><code>period = 8</code>:</p>
<pre><code>result_add = seasonal_decompose(x=df_test['listData'], model='additive', extrapolate_trend='freq', period=int(len(df_test)/2))
plt.rcParams.update({'figure.figsize': (5,5)})
result_add.plot().suptitle('Additive Decompose', fontsize=22)
plt.show()
</code></pre>
<p><a href=""https://i.stack.imgur.com/WedRI.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/WedRI.png"" alt=""enter image description here"" /></a></p>
<p>Have a look at how the y-axes change their scale.</p>
<p>####</p>
<p>You will increase the period integer according to your needs. The max in your case of the question:</p>
<pre><code>sm.tsa.seasonal_decompose(df, model = 'additive', period = int(len(df)/2))
</code></pre>
<p><em>Details of 2.:</em></p>
<p>To get x to be a DatetimeIndex with a freq not set to None, you need to assign the freq of the DatetimeIndex using .asfreq('?') with ? being your choice among a wide range of offset aliases from <a href=""https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#offset-aliases"" rel=""noreferrer"">https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#offset-aliases</a>.</p>
<p>In your case, this option 2. is the better suited as you seem to have a list without gaps. Your monthly data then should probably be introduced as &quot;month start frequency&quot; --&gt; &quot;MS&quot; as offset alias:</p>
<pre><code>sm.tsa.seasonal_decompose(df.asfreq('MS'), model = 'additive')
</code></pre>
<p>See <a href=""https://stackoverflow.com/questions/54630027/how-to-set-frequency-with-pd-to-datetime?rq=1"">How to set frequency with pd.to_datetime()?</a> for more details, also about how you would deal with gaps.</p>
<p>If you have data that is highly scattered in time so that you have too many gaps to fill or if gaps in time are nothing important, option 1 of using &quot;period&quot; is probably the better choice.</p>
<p>In my example case of df_test, option 2. is not good. The data is totally scattered in time, and if I take a minute as the frequency, you get this:</p>
<p>Output of <code>df_test.asfreq('s')</code> (=frequency in seconds):</p>
<pre><code>2016-05-04 08:53:20      1
2016-05-04 08:53:21      2
2016-05-04 08:53:22      1
2016-05-04 08:53:23      9
2016-05-04 08:53:24    NaN
                      ...
2016-05-04 08:58:19    NaN
2016-05-04 08:58:20      1
2016-05-04 08:58:21      1
2016-05-04 08:58:22      3
2016-05-04 08:58:23      9
Freq: S, Name: listData, Length: 304, dtype: object
</code></pre>
<p>You see here that although my data is only 16 rows, introducing a frequency in seconds forces the df to be 304 rows only to reach out from &quot;08:53:20&quot; till &quot;08:58:23&quot;, 288 gaps are caused here. What is more, here you have to hit the exact time. If you have 0.1 or even 0.12314 seconds as your real frequency instead, you will not hit most of the items with your index.</p>
<p>Here an example with min as the offset alias, <code>df_test.asfreq('min')</code>:</p>
<pre><code>2016-05-04 08:53:20      1
2016-05-04 08:54:20    NaN
2016-05-04 08:55:20    NaN
2016-05-04 08:56:20    NaN
2016-05-04 08:57:20    NaN
2016-05-04 08:58:20      1
</code></pre>
<p>We see that only the first and the last minute are filled at all, the rest is not hit.</p>
<p>Taking the day as as the offset alias, <code>df_test.asfreq('d')</code>:</p>
<pre><code>2016-05-04 08:53:20    1
</code></pre>
<p>We see that you get only the first row as the resulting df, since there is only one day covered. It will give you the first item found, the rest is dropped.</p>
<p>The end of it all:</p>
<p>Putting together all of this, in your case, take option 2., while in my example case of df_test, option 1 is needed.</p>
","1","8","1200","1262","12","429","60017052","63252466"
"65295170","<p>I've had the same issue and it eventually turned out (in my case at lease) to be an issue of missing data points in my dataset. In example I have hourly data for a certain period of time and there where 2 separate hourly data points missing (in the middle of the dataset). So I got the same error. When testing on a different dataset with no missing data points, it worked without any error messages. Hope this helps. It's not exactly a solution.</p>
","0","2","43","5","0","2","60017052","63252466"
"60017183","<p>You can try <a href=""https://docs.python.org/3/library/itertools.html#itertools.groupby"" rel=""nofollow noreferrer""><code>itertools.groupby</code></a>:</p>

<pre><code>&gt;&gt;&gt; from itertools import groupby
&gt;&gt;&gt; x = [4, 4, 1, 6, 6, 6, 1, 1, 1, 1]
&gt;&gt;&gt; new_list = [list(group) for _, group in groupby(x)]
&gt;&gt;&gt; new_list
[[4, 4], [1], [6, 6, 6], [1, 1, 1, 1]]
&gt;&gt;&gt;
</code></pre>

<p>Another way would be:</p>

<pre><code>&gt;&gt;&gt; master_list, new_list = [], []
&gt;&gt;&gt; for elem in x:
...     if not new_list:
...             new_list.append(elem)
...     elif elem == new_list[-1]:
...             new_list.append(elem)
...     else:
...             master_list.append(new_list)
...             new_list = [elem]
&gt;&gt;&gt; master_list.append(new_list)
&gt;&gt;&gt; master_list
[[4, 4], [1], [6, 6, 6], [1, 1, 1, 1]]
</code></pre>
","0","3","12268","1175","288","837","60017135","60017183"
"60017192","<p>Try this:</p>

<pre><code>from itertools import groupby

a = [4, 4, 1, 6, 6, 6, 1, 1, 1, 1]
new_list=[] 
for k,g in groupby(a): 
    new_list.append(list(g))
</code></pre>

<p><code>new_list</code> will be your expected result.</p>
","0","1","9243","1210","839","1256","60017135","60017183"
"60017278","<p>Originally my answer only worked for one test case, this is quick (not the prettiest) but works for both:</p>

<pre><code>def delete_nth(x, e):
    x = x[::-1]
    for i in x:
        while x.count(i) &gt; e:
            x.remove(i)
    return x[::-1]
</code></pre>
","1","-1","385","178","16","78","60017186","60017284"
"60017284","<p>Your assertions fails, because the order is not preserved. Here is a simple example of how this could be done without doing redundant internal loops to count the occurrences for each number:</p>

<pre><code>def delete_nth(order, max_e):
    # Get a new list that we will return
    result = []

    # Get a dictionary to count the occurences
    occurrences = {}

    # Loop through all provided numbers
    for n in order:

        # Get the count of the current number, or assign it to 0
        count = occurrences.setdefault(n, 0)

        # If we reached the max occurence for that number, skip it
        if count &gt;= max_e:
            continue

        # Add the current number to the list
        result.append(n)

        # Increase the 
        occurrences[n] += 1

    # We are done, return the list
    return result

assert delete_nth([20,37,20,21], 1) == [20, 37, 21]
assert delete_nth([1, 1, 1, 1], 2) == [1, 1]
assert delete_nth([1, 1, 3, 3, 7, 2, 2, 2, 2], 3) == [1, 1, 3, 3, 7, 2, 2, 2]
assert delete_nth([1, 1, 2, 2], 1) == [1, 2]
</code></pre>
","0","2","972","24","5","77","60017186","60017284"
"60017371","<p>A version which maintains the order:</p>

<pre><code>from collections import defaultdict

def delete_nth(order, max_e):
    count = defaultdict(int)
    delet = []
    for i, v in enumerate(order):
        count[v] += 1
        if  count[v] &gt; max_e:
            delet.append(i)
    for i in reversed(delet): # start deleting from the end
        order.pop(i)
    return order

print(delete_nth([1,1,2,2], 1))
print(delete_nth([20,37,20,21], 1))
print(delete_nth([1,1,3,3,7,2,2,2,2], 3))
</code></pre>
","0","1","7655","73","3","374","60017186","60017284"
"60017872","<p>This should do the trick:</p>

<pre class=""lang-py prettyprint-override""><code>from itertools import groupby
import numpy as np

def delete_nth(order, max_e):
    if(len(order)&lt;=max_e):
        return order
    elif(max_e&lt;=0):
        return []
    return np.array(
          sorted(
              np.concatenate(
                [list(v)[:max_e] 
                    for k,v in groupby(
                       sorted(
                          zip(order, list(range(len(order)))), 
                       key=lambda k: k[0]), 
                    key=lambda k: k[0])
                ]
              ), 
           key=lambda k: k[1])
         )[:,0].tolist()
</code></pre>

<p>Outputs:</p>

<pre class=""lang-py prettyprint-override""><code>
print(delete_nth([2,3,4,5,3,2,3,2,1], 2))
[2, 3, 4, 5, 3, 2, 1]

print(delete_nth([2,3,4,5,5,3,2,3,2,1], 1))
[2, 3, 4, 5, 1]

print(delete_nth([2,3,4,5,3,2,3,2,1], 3))
[2, 3, 4, 5, 3, 2, 3, 2, 1]

print(delete_nth([2,2,1,1], 1))
[2, 1]
</code></pre>
","4","1","11365","152","50","745","60017186","60017284"
"60017369","<p>You can use nested list comprehension:</p>

<pre><code>l=[int(el) for s in li for el in s.split()]
print(l)
</code></pre>

<p>Output:</p>

<pre><code>[192, 245, 3, 881250949]
</code></pre>
","0","1","37572","2148","0","2444","60017274","60017375"
"60017375","<p>You are getting <code>ValueError</code> because <code>int()</code> can't convert a string which contains non-digit characters. Here, the string contains <code>'\t'</code>, so raising the error. </p>

<p>A simple way to convert it into list of integers will be to do this(the string contains numbers separated by <code>'\t'</code> then use <code>'\t'</code> instead of <code>' '</code> inside <code>split()</code>):</p>

<pre><code>lst = list(map(int, li[0].split(' ')))
</code></pre>

<p>If you have more than one such string in the list <code>li</code>, then you can use a loop to do the job. Let me know if I am able to answer your query.</p>
","5","1","290","305","0","67","60017274","60017375"
"60017398","<p>this code can help you.
first you must split the string with <code>split()</code> </p>

<p>then you can use <code>map</code> or <code>for loop</code> for convert string to int</p>

<pre><code># with map

li=['192 245 3 881250949']
a=li[0].split(' ')

a = list(map(int,a))


# with for loop

li=['192 245 3 881250949']
a=li[0].split(' ')

for i in range (len(a)):
    a[i] = int(a[i])
</code></pre>
","0","1","91","11","0","19","60017274","60017375"
"60017414","<pre><code>li=['192 245 3 881250949']

print(li)
</code></pre>
","0","0","85","7","0","79","60017274","60017375"
"60017417","<p>The solution for this is to use:</p>

<pre><code>g.add_argument('--start', metavar='&lt;instance-id&gt;')
</code></pre>
","0","1","4996","389","69","364","60017342","60017417"
"60018150","<p>What I can see is that the screens folder is on the root but not inside the accounts folder it's self. 
For that you have to explicitly mention in the templates configurations within settings. You have to mention the ""BASE_DIR, 'name of the folder where the templates are'"". Here how it has to be written.</p>

<pre><code>TEMPLATES = [
    {
        'BACKEND': 'django.template.backends.django.DjangoTemplates',
        'DIRS': [os.path.join(BASE_DIR,'screens')],
        'APP_DIRS': True,
        'OPTIONS': {
            'context_processors': [
                'django.template.context_processors.debug',
                'django.template.context_processors.request',
                'django.contrib.auth.context_processors.auth',
                'django.contrib.messages.context_processors.messages',
            ],
        },
    },
]
</code></pre>

<p>Secondly, you have to give the path of the file within in the views in such manner.</p>

<pre><code>    return render(request, 'screens/login_screen.dart', context)

</code></pre>

<p>Hope that helps.</p>
","0","1","138","68","0","43","60017343","60018150"
"60017381","<p>It deletes the variables:</p>

<pre><code>&gt;&gt;&gt; lid, tym = 1, 2
&gt;&gt;&gt; del (lid, tym)
&gt;&gt;&gt; lid
Traceback (most recent call last):
  File ""&lt;stdin&gt;"", line 1, in &lt;module&gt;
NameError: name 'lid' is not defined
&gt;&gt;&gt; tym
Traceback (most recent call last):
  File ""&lt;stdin&gt;"", line 1, in &lt;module&gt;
NameError: name 'tym' is not defined
</code></pre>

<p>From <a href=""https://docs.python.org/3/reference/simple_stmts.html#the-del-statement"" rel=""nofollow noreferrer"">the docs</a>:</p>

<blockquote>
  <h3>7.5. The <code>del</code> statement</h3>
  
  <p><code>del_stmt ::=  ""del"" target_list</code></p>
  
  <p>...</p>
  
  <p>Deletion of a target list recursively deletes each target, from left to right.</p>
</blockquote>
","0","3","15664","4545","3291","2151","60017363","60017381"
"60017391","<p>Using the <code>del (a, b)</code> will delete the variables.</p>

<pre class=""lang-py prettyprint-override""><code>&gt;&gt;&gt; a, b = 1, 2
&gt;&gt;&gt; t = (a, b)
&gt;&gt;&gt; del (a, b)
&gt;&gt;&gt; t
(1, 2)
&gt;&gt;&gt; a
Traceback (most recent call last):
  File ""&lt;stdin&gt;"", line 1, in &lt;module&gt;
NameError: name 'a' is not defined
&gt;&gt;&gt; b
Traceback (most recent call last):
  File ""&lt;stdin&gt;"", line 1, in &lt;module&gt;
NameError: name 'b' is not defined
&gt;&gt;&gt;
</code></pre>
","0","0","1311","634","303","98","60017363","60017381"
"60017484","<p>You need to add the following code at the end to actually write the replacement to the file:</p>

<pre><code>fin = open(""dates1.csv"", ""wt"")
fin.write(data)
fin.close()
</code></pre>
","0","1","321","7","0","24","60017376","60017484"
"60018323","<p>The data is actually present in the page source. See <code>view-source:https://www.smogon.com/dex/ss/pokemon/</code> (It is present inside on the script tag as a javascript variable).</p>

<pre><code>import requests
import re
import json


response = requests.get('https://www.smogon.com/dex/ss/pokemon/')

# The following regex will help you take the json string from the response text
data = """".join(re.findall(r'dexSettings = (\{.*\})', response.text))

# the above will only return a string, we need to parse that to json in order to process it as a regular json object using `json.loads()`
data = json.loads(data)

# now we can query json string like below.
data = data.get('injectRpcs', [])[1][1].get('items', [])

for row in data:
  print(row.get('name', ''))
  print(row.get('description', ''))

</code></pre>

<p>See it in action <a href=""https://repl.it/repls/AcademicRelevantSource"" rel=""nofollow noreferrer"">here</a></p>
","1","3","2829","595","337","500","60017438","60018323"
"60017804","<p>If you have declared column ID with Integer and Primary key then it will automatically auto increment using ROWID. Refer: <a href=""https://www.sqlite.org/faq.html#q1"" rel=""nofollow noreferrer"">https://www.sqlite.org/faq.html#q1</a></p>

<pre><code>CREATE TABLE login (
   id INTEGER PRIMARY KEY,
   username text NOT NULL,
   password text NOT NULL
);
</code></pre>

<p>And Insert by specifying the column names.</p>

<pre><code>INSERT INTO login (username, password) VALUES (?, ?);
</code></pre>
","0","0","1893","10","1","120","60017441","60017804"
"60021575","<p>May be this should work.</p>

<pre><code>#!/usr/bin/env python

import pandas as pd
import numpy as np
from numpy.linalg import inv

#%% Function

def PlaneFit(x, y, z):

    Mat1 = np.array([ [x.sum(),          y.sum(), x.size],
                      [(x**2).sum(), (x*y).sum(), x.sum()],
                      [(z*x).sum(),  (z*y).sum(), z.sum()],
                     ])

    Mat2 = np.array([ [z.sum()],  [(x*z).sum()], [(z**2).sum()] ])

    Mat = np.dot( inv(Mat1), Mat2 )

    m, n, d = float(Mat[0]), float(Mat[1]), float(Mat[2])

    return m, n, d

#%% values of z

df = pd.read_csv('output.csv', usecols=range(0, 31), header = None)
df_1 = df[0:31]

z = np.array(df_1)

#%% x and y

x = np.linspace(0, 1, 31)
y = np.linspace(0, 1, 31)

x, y = np.meshgrid(x, y)

#%% call function and make plane

m, n, d = PlaneFit(x, y, z)

Zplane = m* x + n* y + d

#%% Plotting

from mpl_toolkits.mplot3d import axes3d;
import matplotlib.pyplot as plt

fig = plt.figure()
ax = fig.add_subplot(111, projection='3d')
ax.plot_surface(x, y, z, edgecolor='k', cmap='viridis', alpha = 0.99 ,linewidth=0, rstride=1, cstride=1, 
                       antialiased=True, shade=False )
ax.plot_surface(x, y, Zplane, edgecolor='k', color='cyan' )
plt.show()
</code></pre>
","0","1","158","52","0","21","60017450","60021575"
"60018053","<p>Seems you have a file in your codebase that interferes with python's own modules, this file is <code>code.py</code> and is being imported inside a system file (<code>pdb.py</code>), rename your <code>code.py</code> to something else and it will probably solve the issue.</p>
","0","1","49475","2189","1361","6044","60017503","60018053"
"60024854","<p>You are probably simply running the code by using the green arrow or any equivalent way of doing so. The problem is that this runs the script as a separate process and once it finishes, nothing remains from its environment.</p>
<hr />
<p>If you want to run like in IDLE, where you execute the script and then can access and modify the environment (variables and functions defined) - you want to <a href=""https://www.jetbrains.com/help/pycharm/loading-code-from-editor-into-console.html"" rel=""nofollow noreferrer""><strong><em>execute in console</em></strong></a>. You have a few ways to do that:</p>
<ol>
<li><p><code>Execute Selection in Console</code> - This will execute any highlighted code in the console:</p>
<p><a href=""https://i.stack.imgur.com/Wn7K2.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/Wn7K2.png"" alt=""enter image description here"" /></a>
<strong>Note</strong> that if no code is highlighted, this option will become <code>Execute Line in Console</code>.</p>
</li>
<li><p>One option below that is the <code>Run File in Console</code>. This will, obviously, run the whole script in the console:</p>
<p><a href=""https://i.stack.imgur.com/p2w82.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/p2w82.png"" alt=""enter image description here"" /></a></p>
<p><strong>Notice</strong> how now you have all the variables defined in the script available in the variables view on the right side.</p>
</li>
<li><p>The last way is to enable this in the Run configurations:</p>
<ul>
<li><p>Open the <code>Edit Configurations...</code>:</p>
<p><a href=""https://i.stack.imgur.com/uwESC.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/uwESC.png"" alt=""enter image description here"" /></a></p>
</li>
<li><p>Then, under <code>Execution</code>, mark the <code>Run with Python console</code> option:</p>
<p><a href=""https://i.stack.imgur.com/8c8xU.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/8c8xU.png"" alt=""enter image description here"" /></a></p>
</li>
<li><p>Now you can run the file regularly, by selecting <code>Run File</code> or using the green triangle.</p>
</li>
</ul>
</li>
</ol>
<p><strong>Note:</strong> using method <code>(2)</code> will <strong>automatically enable</strong> the configuration described in method <code>(3)</code>. So basically after running the file once in the console (as described in method <code>(2)</code>), you can go back to running the file regularly and all future runs will be in the console as well (until you un-check the box in the run configuration).</p>
","0","4","11641","812","4462","4469","60017510","60024854"
"60017915","<p>Somewhere (in code you haven't included, <code>views.py</code> most likely) you are trying to filter or query the <code>User</code> model over the field <code>is_active</code>. However that field doesn't exist on the model, it's a <code>property</code> of the model, and so can't be resolved.</p>

<p>Read the error message and it tells you exactly this:</p>

<pre><code>Cannot resolve keyword 'is_active' into field.
Choices are: active, admin, email, full_name, id, image, last_login, logentry, password, post, staff, timestamp
</code></pre>

<p>Those are the fields on <code>User</code> and consequently those are the fields available for querying over that model.</p>

<p>So, make sure the in arguments being passed to the query (wherever that is happening) uses <code>active</code> instead of <code>is_active</code> and it should succeed.</p>
","0","0","1118","442","6","186","60017537","60017915"
"60017708","<p><code>inputs.shape</code> is not a list, hence it is throwing error. It gives you shape with type <code>tensorflow.python.framework.tensor_shape.TensorShape</code> which has a list of each dimension with type <code>Dimension</code></p>

<pre><code>print(inputs.shape)
# output TensorShape([Dimension(None), Dimension(256), Dimension(256), Dimension(1)])
</code></pre>

<p>You can use <code>as_list()</code> to get shapes as list:</p>

<pre><code># inputs.shape.as_list()
# output [None, 256, 256, 1]

x = InceptionV3(include_top = False, weights = None, input_shape=inputs.shape.as_list()[1:])(x)
</code></pre>
","1","0","2224","522","191","151","60017583","60017708"
"60017725","<p>It looks like when you open linkedin, the page is scrolled down a little bit. Try scrolling up <a href=""https://stackoverflow.com/questions/36647785/scroll-up-the-page-to-the-top-in-selenium"">to the top</a> or more precise - <a href=""https://stackoverflow.com/questions/3401343/scroll-element-into-view-with-selenium"">scrolling to the element</a></p>

<p>You could also just copy the link that 'sign in' button points to and go there straight away.</p>

<p>If signing in is not the whole point, you can also sign in manually and tell selenium to use your <a href=""https://stackoverflow.com/questions/14480717/load-chrome-profile-using-selenium-webdriver-using-java"">profile</a>, so you're already signed in when the script starts.</p>

<p><a href=""https://stackoverflow.com/questions/15058462/how-to-save-and-load-cookies-using-python-selenium-webdriver"">Exporting cookies</a> might also do the trick.</p>

<p>EDIT: closing the pop-up window solved it.</p>
","3","0","3326","325","54","147","60017620","60017725"
"66017887","<p>I automated the login using Python 3 and Selenium 3.141.0 today (I don't know how long it will work) and I found a way to do it using <code>find_element_by_class_name</code> with the <code>sign-in-form__submit-button</code> class name:</p>
<pre><code>def run(email, password):
#Open Chrome web
driver = webdriver.Chrome()
driver.get('https://www.linkedin.com/')

#Login username/password
email_box = driver.find_element_by_id('session_key')
email_box.send_keys(email)
pass_box = driver.find_element_by_id('session_password')
pass_box.send_keys(password)
submit_button = driver.find_element_by_class_name('sign-in-form__submit-button')
submit_button.click()
</code></pre>
<p>I'm using Chrome Version 88.0.4324.96 (Official Build) (x86_64) on MacOS.</p>
","0","0","382","110","2","32","60017620","60017725"
"60018586","<p>Added some permissions using pywin32 module.</p>

<pre><code>import win32security
import ntsecuritycon as con
from win32 import win32api

for f,bArr in depickle_.items():
        full_path = os.path.join(r""S:\test"", f) 
        # with open(full_path, ""wb+"") as fWr:
        fd = os.open(full_path, os.O_CREAT | os.O_WRONLY, 0o777) # will probably work for linux
        with open(fd, 'wb') as fWr:
            fWr.write(bytearray(bArr))
            fWr.close()

    # user, domain, type = win32security.LookupAccountName ("""", win32api.GetUserName())
    user, domain, type = win32security.LookupAccountName ("""", ""Everyone"")
    sd = win32security.GetFileSecurity(full_path, win32security.DACL_SECURITY_INFORMATION)
    dacl = sd.GetSecurityDescriptorDacl()

    # Delete all existing permissions        
    for index in range(0, dacl.GetAceCount()):
        dacl.DeleteAce(0)

    dacl.AddAccessAllowedAce(win32security.ACL_REVISION, con.FILE_ALL_ACCESS, user)
    sd.SetSecurityDescriptorDacl(1, dacl, 0) 
    win32security.SetFileSecurity(full_path, win32security.DACL_SECURITY_INFORMATION, sd)
</code></pre>
","0","0","674","48","29","112","60017630","60018586"
"60017759","<p>Here's a variant that makes sure the substrings all match the given pattern:</p>

<pre><code>input_ = ""121212121212121212""
x = ""12""
res = []
while input_.startswith(x):
    res.append(x)
    input_ = input_[len(x):]
</code></pre>
","0","0","306","34","9","20","60017683","60017781"
"60017781","<p>To decode this string you need 'n' and X anyway.
Why not build it directly with:</p>

<pre><code>li = [X] * n
</code></pre>

<p>Edit:
If you don't have 'n', you could get it easily from the given string.
(Under the condition that givenString only consist of X)</p>

<pre><code>n = len(givenString) / len(str(X))
li = [X] * n
</code></pre>
","1","2","36","2","0","1","60017683","60017781"
"60017834","<p>You can use regular expressions:</p>

<pre><code>import re 

x = input('Enter Your X : ')
mystr = input('Enter Your Input String : ')

result = re.findall(x, mystr) 
print(result)
</code></pre>

<p>This outputs:</p>

<pre><code>Enter Your X : 12
Enter Your Input String : 121212121212
['12', '12', '12', '12', '12', '12']
</code></pre>
","0","1","1623","53","47","157","60017683","60017781"
"60018063","<p>If <code>X</code> is also unknown, you can use this:</p>

<pre><code>import textwrap

def find_shortest_pattern(input_):
     for len_ in range(1, int(len(input_) / 2) + 1):
          patterns = textwrap.wrap(input_, len_)
          if all(pattern == patterns[0] for pattern in patterns):
               return patterns[0]

find_shortest_pattern(""123123123"")
</code></pre>
","0","0","306","34","9","20","60017683","60017781"
"60018785","<p>The result of <em>value_counts()</em> is in this case a <em>Series</em> with:</p>

<ul>
<li>index - original <em>ID</em> values,</li>
<li>values - how many times this <em>ID</em> occurs in the source <em>Series</em>.</li>
</ul>

<p>A bit tricky detail is that the name of this Series (<em>ID</em>) refers actually
to (the only) column, containg the <strong>number of occurrences</strong> of particular
value it the original <em>ID</em> column.</p>

<p>So your task is to:</p>

<ul>
<li>Rename the index to <em>ID</em> (in place).</li>
<li>Rename the Series itself to <em>numberOfMonths</em> or whatever your name of choice
(also in place).</li>
<li>Reset the index, saving the result in a target variable. As <em>drop</em>
parameter is left with its default value (<em>False</em>), the so far
existing index becomes an ""ordinary"" column, keeping its name.</li>
</ul>

<p>The code to do it is:</p>

<pre><code>number_of_months.index.rename('ID', inplace=True)
number_of_months.rename('numberOfMonths', inplace=True)
df1 = number_of_months.reset_index()
</code></pre>

<p>The result, for your sample data, is:</p>

<pre><code>    ID  numberOfMonths
0  564              30
1  133              30
2  156              30
3  153              30
</code></pre>

<p>Now <em>ID</em> name pertains to original <em>ID</em> values and you can merge it with
another DataFrame just on <em>ID</em> column.</p>

<h1>Alternative solution</h1>

<p>If your intention is to add <em>numberOfMonths</em> column to <em>df</em>,
containing information how many times particular <em>ID</em> occurs
in this DataFrame, a quicker and simpler solution is:</p>

<pre><code>df['numberOfMonths'] = df.groupby('ID').transform('count')
</code></pre>
","0","0","23982","8","2","1103","60017748","60018785"
"60019165","<p>One possible solution is to create another QGraphicsPathItem that is the child of the item so the relative coordinates will not change and the parent's QPen will not affect him.</p>

<pre class=""lang-py prettyprint-override""><code>def drawSymbol(self):
    path = QtGui.QPainterPath()
    path.moveTo(0, 40)
    path.lineTo(20, 40)
    path.addRect(QtCore.QRectF(20, 30, 40, 20))
    path.moveTo(60, 40)
    path.lineTo(80, 40)
    self.setPath(path)

    text_item = QtWidgets.QGraphicsPathItem(self)
    text_item.setBrush(QtGui.QColor(""black""))
    child_path = QtGui.QPainterPath()
    child_path.addText(20, 25, QtGui.QFont(""Times"", 20), self.__partName)
    text_item.setPath(child_path)
</code></pre>
","2","1","184341","3940","32065","41961","60017848","60019165"
"60017993","<p>Get slice for each year with contract langth and then sum <code>palyer_value</code>.</p>

<pre><code>import pandas as pd

df1 = pd.DataFrame({'player': ['AB','AB','AB'], 'contract_length':[2,3,1], 'year': [1998,2000,2003]})
df2 = pd.DataFrame({'player': ['AB','AB','AB','AB','AB','AB'], 'year':[1998,1999,2000,2001,2002,2003],'player_value': [4,3,7,10,9,2]})

data = []
for index, row in df1.iterrows():
    contract_data = df2[(df2['year'] &gt;= row['year']) &amp; (df2['year'] &lt;= row['year']+row['contract_length']-1)]
    sum = contract_data['player_value'].sum()
    data.append(sum)

df1['contract_value'] = data
</code></pre>

<p>Output:</p>

<pre><code>  player  contract_length  year  contract_value
0     AB                2  1998               7
1     AB                3  2000              26
2     AB                1  2003               2
</code></pre>
","0","2","4584","259","83","602","60017866","60017993"
"60018448","<p>Consider <a href=""https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Index.repeat.html"" rel=""nofollow noreferrer""><code>repeating</code></a> the dataframe according to <code>contract_length</code> then <a href=""https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.assign.html"" rel=""nofollow noreferrer""><code>assigning</code></a> another column which <a href=""https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.core.groupby.GroupBy.cumcount.html"" rel=""nofollow noreferrer""><code>adds</code></a> the years based on the group and then merging with the second:</p>

<pre><code>final = (df1.loc[df1.index.repeat(df1['contract_length'])]
        .assign(year1 = lambda x: x['year']+x.groupby('year').cumcount())
        .merge(df2, left_on = ['player','year1'],right_on = ['player','year']
        ,suffixes = ('','_y')).groupby(['player','contract_length','year']
        ,sort=False,as_index=False)['player_value'].sum())
</code></pre>

<hr>

<pre><code>  player  contract_length  year  player_value
0     AB                2  1998             7
1     AB                3  2000            26
2     AB                1  2003             2
</code></pre>

<p>breaking this down to 2 steps:</p>

<pre><code>m = df1.loc[df1.index.repeat(df1['contract_length'])].assign(year1 = lambda x:
             x['year']+x.groupby('year').cumcount())
final1 = (m.merge(df2,left_on = ['player','year1'],right_on=['player','year']
         ,suffixes=('','_y').groupby(['player','contract_length','year']
          ,sort=False,as_index=False)['player_value'].sum())
</code></pre>

<hr>

<pre><code>   player  contract_length  year  player_value
0     AB                2  1998             7
1     AB                3  2000            26
2     AB                1  2003             2
</code></pre>

<p>Just so you know what we are merging the second dataframe with:</p>

<pre><code>print(m)

  player  contract_length  year  year1
0     AB                2  1998   1998
0     AB                2  1998   1999
1     AB                3  2000   2000
1     AB                3  2000   2001
1     AB                3  2000   2002
2     AB                1  2003   2003
</code></pre>
","0","1","60867","6713","624","4957","60017866","60017993"
"60018564","<p>Another attempt, using <code>.explode()</code>:</p>

<pre><code>df1['contract_value'] = pd.merge(
        df1.assign(years=df1.apply(lambda x: [*range(x['year'], x['year'] + x['contract_length'])] ,axis=1)).explode('years'),
        df2, left_on=['player', 'years'], right_on=['player', 'year']
    ).groupby(['player', 'year_x'], as_index=False)['player_value'].sum()['player_value']

print(df1)
</code></pre>

<p>Prints:</p>

<pre><code>  player  contract_length  year  contract_value
0     AB                2  1998               7
1     AB                3  2000              26
2     AB                1  2003               2
</code></pre>
","0","0","67907","1966","35","5948","60017866","60017993"
"60018364","<p>Chew on this until you figure it out lol.</p>

<pre class=""lang-py prettyprint-override""><code>import numpy as np
from numpy import cos,sin,pi
import matplotlib.pyplot as plt

# Convert data into floats, for 
sensor_data = tuple(map(lambda x: float(x),[10,0,5,1,10,1,20,1,20,1,15]))

# Start at 0,0 in a 2D plane and start out in x-Direction
Starting_Position = np.array((0.,0.))
Starting_Direction = np.array((1.,0.))



def Rotation_Matrix(direction):

    '''Can be expanded for any angle of rotation in a 2D plane. Google rotation matrix in 2D space.'''

    a = {'left':pi/2,'right':-pi/2}[direction]

    matrix = np.array(((round(cos(a),7),round(-sin(a),7)),
                       (round(sin(a),7),round(cos(a),7))))

    return matrix



def DronePosition(Number_input,Current_Position,Current_Direction):

    if Number_input == 1.:
        New_Direction = Current_Direction.dot(Rotation_Matrix('left'))
        New_Position = Current_Position
    elif Number_input == 0.:
        New_Direction = Current_Direction.dot(Rotation_Matrix('right'))
        New_Position = Current_Position
    else:
        New_Position = Current_Position + Current_Direction*Number_input
        New_Direction = Current_Direction


    return New_Position,New_Direction

Drone_Path = np.zeros(shape=(len(sensor_data),2))

for step in range(len(sensor_data)):
    Drone_Path[step,0] = Starting_Position[0] 
    Drone_Path[step,1] = Starting_Position[1] 
    Starting_Position, Starting_Direction = DronePosition(sensor_data[step],Starting_Position,Starting_Direction)


fig, ax = plt.subplots(figsize=(6,6))

ax.plot(Drone_Path[:,0],Drone_Path[:,1])
plt.show()
</code></pre>
","1","1","133","29","0","71","60017943","60018364"
"60018510","<p>If you have two <code>pd.Series</code>, where <code>dtype('bool')</code>. You can compare them in the following way. <em>Without knowing what your data looks like, I've created two <code>pd.Series</code> with either <code>True</code> or <code>False</code></em>. </p>

<pre><code>import pandas as pd
import numpy as np

condition1= pd.Series(np.random.choice([True, False], 100)) 
condition2= pd.Series(np.random.choice([True, False], 100)) 
</code></pre>

<p>Then you can compare by doing the following.</p>

<pre><code>(condition1) &amp; (condition2) # which returns a `pd.Series` where each row is either `True` or `False`.
</code></pre>

<p>To find any index position from each <code>pd.Series</code> where both values are <code>True</code>.</p>

<pre><code>((condition1) &amp; (condition2)).any() # Which returns either `True` or `False`
</code></pre>

<p>From your code, I would guess this line is the issue.</p>

<pre><code>if ((condition1).bool()&amp;(condition2).any()):
</code></pre>

<p>which should be</p>

<pre><code>if ((condition1) &amp; (condition2)).any():
</code></pre>
","2","0","1378","466","12","86","60017982","60018510"
"60019847","<p>This is called <strong><a href=""https://en.wikipedia.org/wiki/Inverse_transform_sampling"" rel=""nofollow noreferrer"">inverse transform sampling</a></strong>:</p>

<blockquote>
  <p>is a basic method for pseudo-random number sampling, i.e., for
  generating sample numbers at random from any probability distribution
  given its <a href=""https://en.wikipedia.org/wiki/Cumulative_distribution_function"" rel=""nofollow noreferrer"">cumulative distribution function</a>.</p>
</blockquote>

<p>The best explanation I found is <a href=""https://matlabtricks.com/post-44/generate-random-numbers-with-a-given-distribution"" rel=""nofollow noreferrer"">this one</a>. Also discussed <a href=""https://stats.stackexchange.com/questions/321542/how-can-i-draw-a-value-randomly-from-a-kernel-density-estimate"">here</a>.</p>
","8","-1","5121","178","13","664","60017994","60019847"
"60018033","<p>You didn't assign the return value in your function.</p>

<pre><code>        get_random_word(max_length)

    return word
</code></pre>

<p>should be:</p>

<pre><code>    if len(word) &gt; max_length:
        word = get_random_word(max_length)

    return word
</code></pre>
","0","0","1619","93","3","128","60017995","60018295"
"60018043","<p>In the if statement you need return the value </p>

<pre><code>if len(word) &gt; max_length:
        return get_random_word(max_length)
</code></pre>

<p>the last <code>return word</code> will return the last word in memory in this case is the first recursion case of you don't have coincidences because you never return from the base case.</p>
","0","0","23","3","0","22","60017995","60018295"
"60018060","<p>This is a simple recursion error. The value of the variable word is not retained through recursive calls. You have to assign the return value.</p>

<pre><code>word = get_random_word(max_length)
</code></pre>
","0","0","1","0","0","1","60017995","60018295"
"60018088","<p>I think your code works, you don't need at all this line <code>return word</code> and also you don't need to call <code>get_random_word</code> inside print (if you do).</p>
","0","0","672","30","0","17","60017995","60018295"
"60018295","<p>Recursion in Python is inefficient, due to repeated calls to user-defined functions, and limited, in that you will eventually overflow the stack if you don't terminate the recursion soon enough. As such, while the fix to your problem is trivial (return the return value of the recursive call), it's a moot point because recursion is the wrong approach to begin with.</p>

<p>Instead, use a <code>while</code> loop to call <code>random.choice</code> until you get a word that fits your condition.</p>

<pre><code>import random

word_file = ""/usr/share/dict/words""
WORDS = open(word_file).read().splitlines()


def get_random_word(max_length=None):
    while True:
        word = random.choice(WORDS)
        if max_length is None or len(word) &lt;= max_length:
            return word
</code></pre>
","0","0","383179","18330","5892","20227","60017995","60018295"
"60018092","<p>Try:</p>

<pre><code>df.groupby(['out'])['out'].count()
</code></pre>
","2","0","1421","369","4","94","60017998","60018092"
"60041067","<p>Thanks everyone. Looks like the best way to do it is this in case anyone stumbles across my post:</p>

<pre><code>p = model.get_prediction(pd.DataFrame([{""lotsize"":20000,""sqrft"": 2500, ""bdrms"": 4}]))
p.summary_frame()
</code></pre>
","0","0","1","0","0","3","60018011","60041067"
"60126370","<p>I figured it out CrawlerRunner was not able to access settings file of my scrapy project that could enable pipelines.py of scrapy which in turn would save the data in Django MOdels file.The modified code of views.py file of django which calls spider is:</p>

<pre><code>import os
import sys
from newscrawler.spiders import news_spider
from newscrawler.pipelines import NewscrawlerPipeline
from scrapy import signals
from twisted.internet import reactor
from scrapy.crawler import Crawler,CrawlerRunner
from scrapy.settings import Settings
from scrapy.utils.project import get_project_settings
from newscrawler import settings as my_settings 
from scrapy.utils.log import configure_logging
from crochet import setup

@csrf_exempt
@require_http_methods(['POST', 'GET'])
def scrape(request):
    Headline.objects.all().delete()
    crawler_settings = Settings()

    setup()
    configure_logging()
    crawler_settings.setmodule(my_settings)
    runner= CrawlerRunner(settings=crawler_settings)
    d=runner.crawl(news_spider.NewsSpider)
    time.sleep(8)
    return redirect(""../getnews/"")
</code></pre>

<p>Hope this helps anyone wanting to call scrapy spider from within the django views.py file and save the scraped data in Django Models.Thank You</p>
","0","1","11","0","0","3","60018191","60126370"
"60048617","<p>Instead of trying to find horizontal/vertical lines to detect the text document, a simple contour filtering approach should work here. The idea is to threshold the image to obtain a binary image then find contours and sort using contour area. The largest contour should be the text document. We can then apply a <a href=""https://www.pyimagesearch.com/2014/08/25/4-point-opencv-getperspective-transform-example/"" rel=""nofollow noreferrer"">four point perspective transform</a> to obtain a birds eye view of the image. Here's the results:</p>

<p>Input image:</p>

<p><img src=""https://i.stack.imgur.com/UL5MB.jpg"" height=""700""></p>

<p>Output:</p>

<p><img src=""https://i.stack.imgur.com/NVLFl.jpg"" height=""700""></p>

<p>Notice how the output image only has the desired text document and is aligned without a skewed angle.</p>

<p>Code</p>

<pre><code>from imutils.perspective import four_point_transform
import cv2
import numpy

# Load image, grayscale, Gaussian blur, Otsu's threshold
image = cv2.imread(""1.jpg"")
gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
blur = cv2.GaussianBlur(gray, (3,3), 0)
thresh = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]

# Find contours and sort for largest contour
cnts = cv2.findContours(thresh, cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)
cnts = cnts[0] if len(cnts) == 2 else cnts[1]
cnts = sorted(cnts, key=cv2.contourArea, reverse=True)
displayCnt = None

for c in cnts:
    # Perform contour approximation
    peri = cv2.arcLength(c, True)
    approx = cv2.approxPolyDP(c, 0.02 * peri, True)
    if len(approx) == 4:
        displayCnt = approx
        break

# Obtain birds' eye view of image
warped = four_point_transform(image, displayCnt.reshape(4, 2))

cv2.imshow(""thresh"", thresh)
cv2.imshow(""warped"", warped)
cv2.imshow(""image"", image)
cv2.waitKey()
</code></pre>
","2","0","25600","1364","21","7558","60018244","60048617"
"60018909","<blockquote>
<p>QWidget::adjustSize()</p>
<p>Adjusts the size of the widget to fit its contents.</p>
</blockquote>
<pre><code>import sys
from PyQt5.QtWidgets import QApplication, QWidget, QLabel, QFileDialog, QPushButton
from PyQt5.QtGui import QIcon, QPixmap
from PyQt5.QtCore import pyqtSlot
#import TurkceOcr as ocr

class App(QWidget):

    def __init__(self):
        super().__init__()
        self.title = 'Resimden Texte'
        self.left = 50
        self.top = 50
        self.width = 640
        self.height = 480
        self.initUI()

    def initUI(self):
        self.setWindowTitle(self.title)
        self.setGeometry(self.left, self.top, self.width, self.height)

        # Create widget

        button = QPushButton('Resim Yükle', self)
        button.setToolTip('This is load picture button')
        button.move(10, 10)
        button.clicked.connect(self.on_click)

        self.label = QLabel(self)
        self.label.move(10,50)


        #self.resize(pixmap.width(), pixmap.height())

        self.show()

    @pyqtSlot()
    def on_click(self):
        print('PyQt5 button click')
        image = QFileDialog.getOpenFileName(None, 'OpenFile', '', &quot;Image file(*.jpg)&quot;)
        imagePath = image[0]
        pixmap = QPixmap(imagePath)
        self.label.setPixmap(pixmap)
        
        self.label.adjustSize()                       # &lt;---
        
        #print(ocr.resimden_yaziya(imagePath))
        print(imagePath)


if __name__ == '__main__':
    app = QApplication(sys.argv)
    ex = App()
    sys.exit(app.exec_())
</code></pre>
<p><a href=""https://i.stack.imgur.com/GR6M9.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/GR6M9.png"" alt=""enter image description here"" /></a></p>
","0","0","10346","2781","297","1100","60018299","60018909"
"60022391","<p>If both databases located on a same computer, <code>asyncio</code> won't speedup a process: there's no network overhead to parallelize. Quite opposite: overhead for using coroutines will make program a bit slower.</p>

<p>Please, read <a href=""https://stackoverflow.com/a/51180506/1113207"">this answer</a> for detailed explanation.</p>
","0","0","26899","1876","27","2057","60018305","60022391"
"60018427","<p>I believe you're only missing an indent, try this:</p>

<pre class=""lang-py prettyprint-override""><code>def wordcounts():
word_frequencies = dict()
totaal = dict()
for bestand in glob.glob('*.txt'):
    word_list = clean_text(bestand)
    for i in word_list:
        if i in word_frequencies:
            word_frequencies[i] += 1
        else:
            word_frequencies[i] = 1
    totaal[bestand] = word_frequencies  # &lt; Added an indent here
return totaal
</code></pre>
","1","0","329","26","2","18","60018389","60018465"
"60018465","<p>In your code, you have the result dictionary (totaal) sitting outside of the for loop</p>

<pre><code>def wordcounts():
    word_frequencies = dict()
    totaal = dict()
    for bestand in glob.glob('*.txt'):
        word_list = clean_text(bestand)
        for i in word_list:
            if i in word_frequencies:
                word_frequencies[i] += 1
            else:
                word_frequencies[i] = 1
    totaal[bestand] = word_frequencies
    return totaal
</code></pre>

<p>So what's happening is you're loading totaal with one key (the final bestand) and loading it with all the word_frequencies.</p>

<p>If you indent the totaal line to be included in the for loop, it will populate the dictionary with a key for each bestand, like you expected.</p>

<p>You'll also want to move word_frequencies inside the loop, so that you only get the frequencies for each bestand:</p>

<pre><code>def wordcounts():
    totaal = dict()
    for bestand in glob.glob('*.txt'):
        # MOVED WORD_FREQUENCIES HERE
        word_frequencies = dict()
        word_list = clean_text(bestand)
        for i in word_list:
            if i in word_frequencies:
                word_frequencies[i] += 1
            else: 
                word_frequencies[i] = 1
         # NOTE THAT THIS IS NOW PROPERLY INDENTED
         totaal[bestand] = word_frequencies
    return totaal
</code></pre>
","0","0","20","3","0","5","60018389","60018465"
"60018818","<p>This seems to do what you want - replace this one line (swap y and x in for loops):</p>

<pre><code>grid_points = [ shapely.geometry.Point(x,y) for y in range(100) for x in range(100)]
</code></pre>

<hr>

<p>Couple of notes:</p>

<p>My installation of shapely has this module name (geometry spelled differently so you may need to change name in above line):</p>

<pre><code>  import shapely.geometry
</code></pre>

<p>And thanks for adding the second plot command - that helped a bunch.</p>

<p>Something along the way has differing major orders (row-vs-column) so the above line changes to column-major.</p>

<p>And it may be you'd want to compensate by doing the inverse on the exterior plot.</p>

<p>(original (with new random shape), updated, with exterior)</p>

<p><a href=""https://i.stack.imgur.com/pSt07.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/pSt07.png"" alt=""enter image description here""></a> 
<a href=""https://i.stack.imgur.com/B0gk0.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/B0gk0.png"" alt=""enter image description here""></a> 
<a href=""https://i.stack.imgur.com/YVPBl.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/YVPBl.png"" alt=""enter image description here""></a></p>
","1","0","3071","627","340","535","60018423","60018818"
"60021170","<p>(<em>Spyder maintainer here</em>) Sorry, that's not possible.</p>
","0","0","26479","1538","48","6624","60018449","60021170"
"60018531","<p>You can use ""eval"" to evaluate expressions given as strings.</p>

<pre><code>a = ""/""
res = eval(""10"" + a + ""5"")
print(res)
</code></pre>
","2","-2","300","6","2","11","60018472","60018531"
"60018602","<p>There are multiple ways to do this.</p>

<p>The most common way, I guess, is using the operator module and a map (dictionary) to turn your strings into operators, as the next example.</p>

<pre><code>import operator

run_ops = {
  '+' : operator.add,
  '-' : operator.sub,
  '*' : operator.mul,
  '/' : operator.truediv,
  '%' : operator.mod,
  '^' : operator.xor,
}.get

print(run_ops('/')(10, 5))
</code></pre>

<p>Or go with lambdas:</p>

<pre><code>run_ops= {'+': lambda x, y: x + y,
    '-': lambda x, y: x - y,
    # ...
    '/': lambda x, y: x / y
}

run_ops['/'] (10,5)
</code></pre>

<p>Cheers</p>
","0","1","29","1","0","7","60018472","60018531"
"60018813","<p>A nice method has been posted by epap. </p>

<p>However if you want to stick to the order of the expression where the ""/"", comes between the two numbers then one of the ways you can do it, is as below. </p>

<p>You can wrap (Number_1, ""/"", Number_2) and send it to a class and then print it. Something like below.</p>

<pre class=""lang-py prettyprint-override""><code>class Divide(object):

    def __new__(cls, a, symbol, b):
        result = None
        if symbol == ""/"":
            result = a/b        
        return result


print(Divide(5,""/"",2))
</code></pre>

<p>This yields the below output</p>

<pre class=""lang-py prettyprint-override""><code>2.5
</code></pre>
","0","0","1809","104","9","372","60018472","60018531"
"60018489","<p>If <code>NaN</code>s are missing values you can pass columns names like <code>list</code>:</p>

<pre><code>cols = ['Col1','Col2','Col3']
df[cols]=df[cols].bfill()
</code></pre>

<p>If <code>NaN</code>s are strings first replace strings to numeric with missing values for non numbers:</p>

<pre><code>cols = ['Col1','Col2','Col3']
df[cols]=df[cols].apply(lambda x: pd.to_numeric(x, errors='coerce')).bfill()
</code></pre>

<p>If want use your solution:</p>

<pre><code>for col in ['Col1','Col2','Col3']:
    df[col]= pd.to_numeric(df[col], errors='coerce').bfill()

print (df)
     Criteria  Col1  Col2  Col3
0  Jan10Sales  12.0  13.0   4.0
1  Feb10Sales   1.0   3.0   4.0
2  Mar10Sales   5.0  13.0  14.0
3  Apr10Sales   5.0  18.0  12.0
4  May10Sales   6.0  18.0  19.0
</code></pre>

<p>But if last rows has missing values, back filling not repalce them, because not exist next non missing value:</p>

<pre><code>print (df)
     Criteria Col1 Col2 Col3
0  Jan10Sales   12   13  NAN
1  Feb10Sales    1    3    4
2  Mar10Sales  NAN   13   14
3  Apr10Sales    5  NAN   12
4  May10Sales    6   18  NaN

cols = ['Col1','Col2','Col3']
df[cols]=df[cols].apply(lambda x: pd.to_numeric(x, errors='coerce')).bfill()
print (df)

     Criteria  Col1  Col2  Col3
0  Jan10Sales  12.0  13.0   4.0
1  Feb10Sales   1.0   3.0   4.0
2  Mar10Sales   5.0  13.0  14.0
3  Apr10Sales   5.0  18.0  12.0
4  May10Sales   6.0  18.0   NaN
</code></pre>

<p>Then is possible chain <code>bfill</code> and <code>ffill</code>:</p>

<pre><code>df[cols]=df[cols].apply(lambda x: pd.to_numeric(x, errors='coerce')).bfill().ffill()
print (df)
     Criteria  Col1  Col2  Col3
0  Jan10Sales  12.0  13.0   4.0
1  Feb10Sales   1.0   3.0   4.0
2  Mar10Sales   5.0  13.0  14.0
3  Apr10Sales   5.0  18.0  12.0
4  May10Sales   6.0  18.0  12.0
</code></pre>
","8","4","615041","23439","1483","126104","60018473","60018489"
"60018588","<p>You may try this:</p>

<pre><code>for cols in ['Col1','Col2','Col3']:
    df[cols].fillna(method='bfill', inplace=True)
</code></pre>

<p><a href=""https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.fillna.html"" rel=""nofollow noreferrer"">pandas.DataFrame.fillna</a></p>
","0","1","667","321","50","200","60018473","60018489"
"60018647","<blockquote>
<pre><code>I guess string 'NAN' does not mean Non-Value Nan, you already got the solution, you can check my code too
</code></pre>
</blockquote>

<pre><code>df = df[df.ne('NAN')].bfill()

     Criteria Col1 Col2 Col3
0  Jan10Sales   12   13    4
1  Feb10Sales    1    3    4
2  Mar10Sales    5   13   14
3  Apr10Sales    5   18   12
4  May10Sales    6   18   19
</code></pre>
","0","1","444","28","5","38","60018473","60018489"
"60018540","<p>You can use <a href=""https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.isin.html"" rel=""nofollow noreferrer"">pandas.DataFrame.isin</a> followed by <a href=""https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.any.html"" rel=""nofollow noreferrer"">pandas.DataFrame.any</a>:</p>

<pre><code>df[df.isin([10]).any(axis = 1)]

   A    B   C   D   F
0   abc 10  24  32  54
1   cdf 9   10  34  98
3   fgd 1   9   2   10
</code></pre>
","0","1","4004","1850","24","762","60018478","60018546"
"60018546","<p>Use <a href=""http://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.eq.html"" rel=""nofollow noreferrer""><code>DataFrame.eq</code></a> with <a href=""http://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.any.html"" rel=""nofollow noreferrer""><code>DataFrame.any</code></a> for test if at least one <code>True</code> per rows:</p>

<pre><code>df = pd.read_excel('file.xlsx')

df1 = df[df.eq(10).any(axis=1)]
</code></pre>

<p>Or:</p>

<pre><code>df1 = df[(df == 10).any(axis=1)]

print (df1)
     A   B   C   D   F
0  abc  10  24  32  54
1  cdf   9  10  34  98
3  fgd   1   9   2  10
</code></pre>
","14","2","615041","23439","1483","126104","60018478","60018546"
"60020092","<p>add a file called <code>__init__.py</code> to you folder</p>

<p>this tells python that the folder is importable</p>
","0","1","131","8","1","37","60018518","60020092"
"60018643","<p>I believe you can use a Poisson distribution:</p>

<pre><code>from numpy.random import poisson
index = poisson()
return sample[min(len(sample, index)]
</code></pre>

<p>See <a href=""https://en.wikipedia.org/wiki/Poisson_distribution"" rel=""nofollow noreferrer"">Wikipedia</a> for more details on this distribution.</p>

<p>Note: This is valid only if you don't have any requirements for how the prioritization is done.</p>
","0","0","88","4","0","9","60018532","60018908"
"60018908","<p>This is a simple solution but should solve your problem:</p>

<pre><code>sample = ['a', 'b', 'c', 'd', 'e', 'f']
probability = [0.1, 0.15, 0.6, 0.05, 0.03, 0.07]
np.random.choice(a=sample, p=probability)

</code></pre>

<p>Solution 1:</p>

<pre><code>inverse_probability = [(1-x) for x in probability]
inverse_probability = [x/sum(inverse_probability) for x in inverse_probability]
np.random.choice(a=sample, p=inverse_probability)
</code></pre>

<p>Solution 2:</p>

<pre><code>inverse_probability = [1/x for x in probability]
inverse_probability = [x/sum(inverse_probability) for x in inverse_probability]
np.random.choice(a=sample, p=inverse_probability)
</code></pre>
","0","0","1821","28","5","119","60018532","60018908"
"60018985","<p><strong>Here's a simple modification of your code that handles part 1 &amp; 2</strong></p>

<p>Mods based upon the following</p>

<ol>
<li>Use Python variable naming convention <a href=""https://www.python.org/dev/peps/pep-0008/#naming-conventions"" rel=""nofollow noreferrer"">Pep
8</a></li>
<li>Use tab delimited line to avoid having to work with fixed field
widths</li>
<li>Use <a href=""https://www.programiz.com/python-programming/methods/string/lower"" rel=""nofollow noreferrer"">lower()</a> to provide case insensitive comparison</li>
<li>Use string <a href=""https://www.geeksforgeeks.org/title-in-python/"" rel=""nofollow noreferrer"">title()</a>
to ensure the first letter of each word is capitalized for author
and book name</li>
</ol>

<p><strong>Refactored Code</strong></p>

<pre><code>while True:
  menu = input(""1. Add a new book\n2. Search for a new book by a given author\n3. End\n"")
  if menu in ('1', '2', '3'):
    menu = int(menu)
  else:
    print('Error -- Menu needs to be 1, 2, or 3')
    continue

  if menu == 1:
      author = input(""Author: "")
      book = input(""Book: "")
      price = input(""Price: "")
      copies = input(""Copies: "")

      line = '\t'.join([author.title(), book.title(), price, copies])
      with  open(""BOOKS.txt"",""a"") as books:
        print(line)
        books.write(line + ""\n"")

  elif menu == 2:
      author_search = input(""Author name for search: "")
      if not author_search:
        print(""Need author's name"")
        continue  # quit on blank line for author

      author_search = author_search.lower()
      with open(""BOOKS.txt"",""r"") as books:
        found = False
        for line in books:
          # Will print all books by this author
          book_info = line.rstrip().split(""\t"")

          if author_search == book_info[0].lower(): # use lower to make case insensitive match
            found = True
            print('&gt;&gt;&gt; Found Author')
            author, bookname, price, copies = book_info
            print(f'Author name: {author.title()}') # capitable firs letter of each name
            print(f'Book: {bookname.title()}')
            print(f'Price: {price}')
            print(f'Copies: {copies}')
        if not found:
          print('Author not found')
  else:
    break
</code></pre>
","2","0","10876","714","1","925","60018556","60018985"
"60018731","<p><code>model.eval()</code> is a kind of switch for some specific layers/parts of the model that behave differently during training and inference (evaluating) time. For example, Dropouts Layers, BatchNorm Layers etc. You need to turn off them during model evaluation, and <code>.eval()</code> will do it for you. In addition, the common practice for evaluating/validation is using <code>torch.no_grad()</code> in pair with <code>model.eval()</code> to turn off gradients computation:</p>

<pre class=""lang-py prettyprint-override""><code># evaluate model:
model.eval()

with torch.no_grad():
    ...
    out_data = model(data)
    ...
</code></pre>

<p>BUT, don't forget to turn back to <code>training</code> mode after eval step:</p>

<pre class=""lang-py prettyprint-override""><code># training step
...
model.train()
...
</code></pre>
","8","101","4203","546","8","215","60018578","60018731"
"63970021","<p><a href=""https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.eval"" rel=""nofollow noreferrer""><code>model.eval</code></a> is a method of <a href=""https://pytorch.org/docs/stable/generated/torch.nn.Module.html"" rel=""nofollow noreferrer""><code>torch.nn.Module</code></a>:</p>
<blockquote>
<h3><code>eval()</code></h3>
<p>Sets the module in evaluation mode.</p>
<p>This has any effect only on certain modules. See documentations of particular modules for details of their behaviors in training/evaluation mode, if they are affected, e.g. <a href=""https://pytorch.org/docs/stable/generated/torch.nn.Dropout.html#torch.nn.Dropout"" rel=""nofollow noreferrer""><code>Dropout</code></a>, <code>BatchNorm</code>, etc.</p>
<p>This is equivalent with <a href=""https://pytorch.org/docs/stable/generated/torch.nn.Module.html?highlight=eval#torch.nn.Module.train"" rel=""nofollow noreferrer""><code>self.train(False)</code></a>.</p>
</blockquote>
<p>The opposite method is <a href=""https://stackoverflow.com/a/51433411/5884955"">model.train</a> explained nicely by Umang Gupta.</p>
","0","6","25764","1013","177","3051","60018578","60018731"
"65762803","<p>An extra addition to the above answers:</p>
<p>I recently started working with <a href=""https://pypi.org/project/pytorch-lightning/"" rel=""nofollow noreferrer"">Pytorch-lightning</a>, which wraps much of the boilerplate in the training-validation-testing pipelines.</p>
<p>Among other things, it makes <code>model.eval()</code> and <code>model.train()</code> near redundant by allowing the <code>train_step</code> and <code>validation_step</code> callbacks which wrap the <code>eval</code> and <code>train</code> so you never forget to.</p>
","2","1","8768","1847","39","1003","60018578","60018731"
"66843176","<h3><a href=""https://stackoverflow.com/a/66526891/9067615""><code>model.train()</code></a></h3>
<p>Sets your model in <strong>train</strong>ing mode:</p>
<ul>
<li>makes Normalisation layers use per-batch statistics (e.g. <code>BatchNorm</code>, <code>InstanceNorm</code>)</li>
<li>activates <code>Dropout</code> layers (including sub-modules of RNN modules <a href=""https://stackoverflow.com/questions/66534762/which-pytorch-modules-are-affected-by-model-eval-and-model-train"">etc</a>)</li>
</ul>
<h3><code>model.eval()</code></h3>
<p>Sets your model in <strong>eval</strong>uation (inference) mode:</p>
<ul>
<li>makes Normalisation layers use running statistics</li>
<li>de-activates <code>Dropout</code> layers</li>
</ul>
<p>Equivalent to <code>model.train(False)</code>.</p>
<hr />
<p>You can turn off evaluation mode by running <code>model.train()</code>. You should use it when running your model as an inference engine - i.e. when testing, validating, and predicting (though practically it will make no difference if your model does not include any of the <a href=""https://stackoverflow.com/a/66526891/9067615"">differently behaving layers</a>).</p>
","0","0","6005","1870","96","595","60018578","60018731"
"60018962","<p>They have the same hame since all the processes are forked from the same master process. </p>

<p>You need to use dedicated system tools to rename process name. E.g. <code>setproctitle</code> module:
<code>pip install setproctitle</code></p>

<p>Then in in the process function call <code>setproctitle.setproctitle(""new child process name"")</code>.</p>

<p>Here is a small example:</p>

<pre><code>from multiprocessing import Process
import setproctitle
import time

def a_worker():
    setproctitle.setproctitle(""procA"")
    time.sleep(10)

def b_worker():
    setproctitle.setproctitle(""procB"")
    time.sleep(10)

if __name__ == ""__main__"":
    print(""Master process title:"", setproctitle.getproctitle())

    a_proc = Process(target=a_worker)
    b_proc = Process(target=b_worker)

    # Spawn processes
    a_proc.start() 
    b_proc.start()

    # Wait for processes to terminate
    a_proc.join()
    b_proc.join()

    print(""Master process title after kids:"", setproctitle.getproctitle())
</code></pre>

<p>Output of <code>ps -fu</code>:</p>

<pre><code>363  5.2  0.1  29736 10524 tty1     S    01:25   0:00  \_ python3 ab.py
370  0.0  0.0  29736  4424 tty1     S    01:25   0:00      \_ procA
371  0.2  0.0  29736  4216 tty1     S    01:25   0:00      \_ procB
</code></pre>
","0","0","1405","93","2","60","60018603","60018962"
"60018712","<p><code>sum(foo)</code> simply uses the definition of <code>+</code> for the initial value. By default, the initial value is <code>0</code>, so <code>sum(g)</code> would fail for a list since addition of lists and ints isn't defined. By passing an explicit initial value of <code>[]</code>, this forces <code>sum(foo, [])</code> to be equal to <code>foo[0] + foo[1] + ... + foo[n-1] + []</code>, as observed.</p>

<pre><code>&gt;&gt;&gt; sum([[1], [2]])
Traceback (most recent call last):
  File ""&lt;stdin&gt;"", line 1, in &lt;module&gt;
TypeError: unsupported operand type(s) for +: 'int' and 'list'
&gt;&gt;&gt; sum([[1], [2]], [])
[1, 2]
</code></pre>

<p>The exception to this definition is that you cannot use <code>sum</code> with a list of <code>str</code> values, even if you specify <code>""""</code> as the initial value. This is a hard-coded exception, resulting in a <code>TypeError</code> with a suggestion to use <code>str.join</code> instead.</p>

<pre><code>&gt;&gt;&gt; sum([""foo"", ""bar""])
Traceback (most recent call last):
  File ""&lt;stdin&gt;"", line 1, in &lt;module&gt;
TypeError: unsupported operand type(s) for +: 'int' and 'str'
&gt;&gt;&gt; sum([""foo"", ""bar""], """")
Traceback (most recent call last):
  File ""&lt;stdin&gt;"", line 1, in &lt;module&gt;
TypeError: sum() can't sum strings [use ''.join(seq) instead]
</code></pre>
","0","3","383179","18330","5892","20227","60018656","60022923"
"60022923","<h2>Short-answer</h2>

<p>The given code-fragment runs successive list concatenations.</p>

<h2>How it works</h2>

<p>Roughly the built-in <a href=""https://docs.python.org/3/library/functions.html#sum"" rel=""nofollow noreferrer""><em>sum()</em></a> function works like this:</p>

<pre><code>def sum(iterable, /, start=0):
    total = start
    for x in iterable:
        total = total + x
    return total
</code></pre>

<p>The <code>+</code> operator calls <code>__add__</code> on the left-hand operand so that <code>3 + 4</code> runs as <code>(3).__add__(4)</code>, an addition operation on integers.  Likewise, <code>[10, 20] + [30, 40, 50]</code> runs as <code>[10, 20].__add__([30, 40, 50])</code>, a concatenation operation on lists.</p>

<p>Here's how it plays out in the given example:</p>

<pre><code>&gt;&gt;&gt; nums = [1,2,3,4]
&gt;&gt;&gt; g = ([b] * a for a, b in zip(nums[::2], nums[1::2]))
&gt;&gt;&gt; result = []
&gt;&gt;&gt; x = next(g)
&gt;&gt;&gt; result = result + x
&gt;&gt;&gt; result
[2]
&gt;&gt;&gt; x = next(g)
&gt;&gt;&gt; result = result + x
&gt;&gt;&gt; result
[2, 4, 4, 4]
</code></pre>

<h2>Why it is not a good idea</h2>

<p>Successive list concatenations make next list after each addition, so they run at <a href=""https://en.wikipedia.org/wiki/Big_O_notation#Orders_of_common_functions"" rel=""nofollow noreferrer""><code>O(n**2)</code></a> speed, meaning that this a quadratic algorithm that runs excessively slow when given large inputs.</p>

<h2>Better way</h2>

<p>Instead of building new lists at each step, just <a href=""https://docs.python.org/3/library/stdtypes.html#mutable-sequence-types"" rel=""nofollow noreferrer"">extend</a> the base list in-place.  This runs at <a href=""https://en.wikipedia.org/wiki/Big_O_notation#Orders_of_common_functions"" rel=""nofollow noreferrer""><code>O(n)</code></a> linear speed:</p>

<pre><code>&gt;&gt;&gt; nums = [1,2,3,4]
&gt;&gt;&gt; g = ([b] * a for a, b in zip(nums[::2], nums[1::2]))
&gt;&gt;&gt; result = []                 # new list
&gt;&gt;&gt; for x in g:
        result.extend(x)        # extend in-place

&gt;&gt;&gt; result
[2, 4, 4, 4]
</code></pre>

<h2>Even better way</h2>

<p>The <a href=""https://docs.python.org/3/library/itertools.html"" rel=""nofollow noreferrer"">itertools module</a> provides <a href=""https://docs.python.org/3/library/itertools.html#itertools.chain.from_iterable"" rel=""nofollow noreferrer"">a tool for chaining together iterators</a>.  This makes short-work of the problem:</p>

<pre><code>&gt;&gt;&gt; nums = [1,2,3,4]
&gt;&gt;&gt; g = ([b] * a for a, b in zip(nums[::2], nums[1::2]))
&gt;&gt;&gt; list(chain.from_iterable(g))
[2, 4, 4, 4]
</code></pre>

<p>This solution is short, fast and works well even with large inputs.</p>
","0","4","180179","2778","395","33067","60018656","60022923"
"60076165","<p>The problem was my windows defender firewall. I had to disable it for ""Guest or public networks"" I guess somehow the Ethernet cable connection was classified as public network. </p>
","0","0","304","35","0","94","60018734","60076165"
"60018761","<p>Do not include the parentheses in the function passed to:</p>

<pre><code>schedule.every(interval).minutes.do()
</code></pre>

<p>So,  this this line:</p>

<pre><code>schedule.every(interval).minutes.do(self.trigger_testsuite())
</code></pre>

<p>Should be:</p>

<pre><code>schedule.every(interval).minutes.do(self.trigger_testsuite)
</code></pre>

<p>And same for all the others. Final code becomes:</p>

<pre><code>import schedule
    import time


class Scheduler():

    def trigger_testsuite(self):
        print(""I am working as expected."")

    def scheule_a_job(self, type=""Secs"", interval=5):

        if (type == ""Mins""):
            schedule.every(interval).minutes.do(self.trigger_testsuite)

        if (type == ""Secs""):
            schedule.every(interval).seconds.do(self.trigger_testsuite)

        if (interval == ""Hrs""):
            schedule.every().hour.do(self.trigger_testsuite)

        if (interval == ""Daily""):
            schedule.every().day.at(""10:00"").do(self.trigger_testsuite)

        while True:
            schedule.run_pending()
            time.sleep(1)


if __name__ == ""__main__"":
    run = Scheduler()
    run.scheule_a_job()
</code></pre>
","0","1","3981","1105","97","457","60018745","60018761"
"60019013","<p>Avoid <code>DataFrame.apply</code> (which is usually run as a <a href=""https://github.com/pandas-dev/pandas/blob/master/pandas/core/apply.py"" rel=""nofollow noreferrer"">hidden loop</a>) and instead consider nested conditional logic with <a href=""https://docs.scipy.org/doc/numpy/reference/generated/numpy.where.html"" rel=""nofollow noreferrer""><code>numpy.where</code></a> on columns:</p>

<pre><code>match['Winning Team'] = np.where(match['home_team_goal'] &gt; match['away_team_goal'],
                                 match['Home Team'],
                                 np.where(match['home_team_goal'] &lt; match['away_team_goal'],
                                          match['Away Team'],
                                          np.nan
                                         )
                                )
</code></pre>
","2","1","86379","5219","102","7124","60018771","60019016"
"60019016","<p>Use <a href=""https://docs.scipy.org/doc/numpy/reference/generated/numpy.select.html"" rel=""nofollow noreferrer""><code>numpy.select</code></a> instead <code>apply</code>, which should be not good idea here (loops under the hood):</p>

<pre><code>match = pd.DataFrame({
        'Home Team':list('abcdef'),
        'Away Team':list('ghijkl'),
         'home_team_goal':[14,5,4,5,5,4],
         'away_team_goal':[7,8,2,4,8,4],
})

m1 = match.home_team_goal&gt;match.away_team_goal
m2 = match.home_team_goal&lt;match.away_team_goal
match['winner'] = np.select([m1, m2], [match['Home Team'],  match['Away Team']], default=None)
print (match)
  Home Team Away Team  home_team_goal  away_team_goal winner
0         a         g              14               7      a
1         b         h               5               8      h
2         c         i               4               2      c
3         d         j               5               4      d
4         e         k               5               8      k
5         f         l               4               4   None
</code></pre>
","1","2","615041","23439","1483","126104","60018771","60019016"
"60019174","<p>Here's another way: </p>

<p>Creating dataframe with the teams: </p>

<pre><code>results_di = {
    ""Home Team"": [
        ""KV Mechelen"",
        ""KSV Cercle Brugge"",
        ""RSC Anderlecht"",
        ""KV Mechelen"",
        ""SV Zulte-Waregem"",
        ""FC Zürich"",
        ""FC St. Gallen"",
        ""FC Vaduz"",
        ""Grasshopper Club Zürich"",
        ""BSC Young Boys"",
    ],
    ""Away Team"": [
        ""KRC Genk"",
        ""Club Brugge KV"",
        ""SV Zulte-Waregem"",
        ""RSC Anderlecht"",
        ""KSV Roeselare"",
        ""FC Thun"",
        ""FC Thun"",
        ""FC Luzern"",
        ""FC Sion"",
        ""FC Basel"",
    ],
    ""home_team_goal"": [2, 1, 2, 2, 0, 3, 1, 1, 2, 4],
    ""away_team_goal"": [1, 3, 0, 1, 0, 3, 0, 2, 0, 3],
}

df = pd.DataFrame(results_di)
df['winner'] = 'none'
home_win = df['home_team_goal'] - df[""away_team_goal""] &gt; 0
away_win = df[""away_team_goal""] - df['home_team_goal'] &gt; 0

df.loc[home_win, ""winner""] = df.loc[home_win, 'Home Team']
df.loc[away_win, ""winner""] = df.loc[away_win, 'Away Team']
</code></pre>

<p>print(df)</p>

<pre><code>                 Home Team         Away Team  home_team_goal  away_team_goal  \
0              KV Mechelen          KRC Genk               2               1   
1        KSV Cercle Brugge    Club Brugge KV               1               3   
2           RSC Anderlecht  SV Zulte-Waregem               2               0   
3              KV Mechelen    RSC Anderlecht               2               1   
4         SV Zulte-Waregem     KSV Roeselare               0               0   
5                FC Zürich           FC Thun               3               3   
6            FC St. Gallen           FC Thun               1               0   
7                 FC Vaduz         FC Luzern               1               2   
8  Grasshopper Club Zürich           FC Sion               2               0   
9           BSC Young Boys          FC Basel               4               3   

                    winner  
0              KV Mechelen  
1           Club Brugge KV  
2           RSC Anderlecht  
3              KV Mechelen  
4                     none  
5                     none  
6            FC St. Gallen  
7                FC Luzern  
8  Grasshopper Club Zürich  
9           BSC Young Boys  
</code></pre>
","0","1","2736","261","24","281","60018771","60019016"
"60018965","<p>Overriding functions in that way is not suggested, especially for what are considered protected functions in Qt, which is the case of any <code>*Event()</code> function of QObjects and QWidgets.  </p>

<p>Also, in your case you're just overwriting the method with the same signature, which would never allow you to get the source of the function call.<br>
A possible solution would be to use a lambda with the source as a keyword argument:</p>

<pre><code>self.label_ligne_1_1.mousePressEvent = lambda ev, label=self.label_ligne_1_1: self.label_click(label)
</code></pre>

<p>But I wouldn't suggest you to do that.
A better approach, instead, would be to install an <a href=""https://doc.qt.io/qt-5/qobject.html#eventFilter"" rel=""nofollow noreferrer"">event filter</a> on each label, and then set the pixmap each time a mouse press event is captured:</p>

<pre><code>class Squares(QtWidgets.QWidget):
    def __init__(self):
        super().__init__()
        layout = QtWidgets.QGridLayout(self)
        layout.setSpacing(0)

        for row in range(4):
            for col in range(4):
                square = QtWidgets.QLabel()
                square.setPixmap(QtGui.QPixmap('tab.png'))
                layout.addWidget(square, row, col)
                setattr(self, 'label_ligne_{}_{}'.format(row + 1, col + 1), square)
                square.installEventFilter(self)

    def eventFilter(self, source, event):
        if event.type() == QtCore.QEvent.MouseButtonPress:
            source.setPixmap(QtGui.QPixmap('tabx.png'))
        return super().eventFilter(source, event)
</code></pre>
","4","1","18223","101","602","1897","60018773","60018965"
"60020752","<p>Solved:</p>

<p>Here is the working code simplified with notation. Hopefully others will find it instructive. This example uses the model of College Program>Terms>Courses</p>

<pre><code>#import tkinter and ttk modules
from tkinter import *
from tkinter import ttk

#Make the root widget
root = Tk()

#Make the first notebook
program = ttk.Notebook(root) #Create the program notebook
program.pack()

#Make the terms frames for the program notebook
for r in range(1,4):
    termName = 'Term'+str(r) #concatenate term name(will come from dict)
    term = Frame(program)   #create frame widget to go in program nb
    program.add(term, text=termName)# add the newly created frame widget to the program notebook
    nbName=termName+'courses'#concatenate notebook name for each iter
    nbName = ttk.Notebook(term)#Create the notebooks to go in each of the terms frames
    nbName.pack()#pack the notebook

    for a in range (1,6):
        courseName = termName+""Course""+str(a)#concatenate coursename(will come from dict)
        course = Frame(nbName) #Create a course frame for the newly created term frame for each iter
        nbName.add(course, text=courseName)#add the course frame to the new notebook 

root.mainloop()
</code></pre>
","4","1","23","0","0","4","60018778","60020752"
"60019059","<p>TLDR; Make all green pixels white with Numpy:</p>

<pre><code>import numpy as np

pixels[np.all(pixels == (0, 255, 0), axis=-1)] = (255,255,255)
</code></pre>

<hr>

<p>I have made some examples of other ways of changing colours here. First I'll cover exact, specific RGB values like you asked in your question, using this image. It has three big blocks of exactly red, exactly green and exactly blue on the left and three gradual transitions between those colours on the right:</p>

<p><a href=""https://i.stack.imgur.com/D1kEY.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/D1kEY.png"" alt=""enter image description here""></a></p>

<p>Here's the initial answer as above again:</p>

<pre><code>#!/usr/bin/env python3

import cv2
import numpy as np

# Load image
im = cv2.imread('image.png')

# Make all perfectly green pixels white
im[np.all(im == (0, 255, 0), axis=-1)] = (255,255,255)

# Save result
cv2.imwrite('result1.png',im)
</code></pre>

<p><a href=""https://i.stack.imgur.com/huzrN.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/huzrN.png"" alt=""enter image description here""></a></p>

<hr>

<p>This time I define the colour names for extra readability and maintainability. The final line is the important point:</p>

<pre><code># Define some colours for readability - these are in OpenCV **BGR** order - reverse them for PIL
red   = [0,0,255]
green = [0,255,0]
blue  = [255,0,0]
white = [255,255,255]
black = [0,0,0]

# Make all perfectly green pixels white
im[np.all(im == green, axis=-1)] = white
</code></pre>

<p>Same result.</p>

<hr>

<p>This time I make a re-usable mask of red pixels which I can use in subsequent operations. The final line with the assignment <code>im[Rmask] = black</code> is now particularly easy to read :</p>

<pre><code># Define some colours for readability - these are in OpenCV **BGR** order - reverse them for PIL
red   = [0,0,255]
green = [0,255,0]
blue  = [255,0,0]
white = [255,255,255]
black = [0,0,0]

# Make mask of all perfectly red pixels
Rmask = np.all(im == red, axis=-1)

# Make all red pixels black
im[Rmask] = black
</code></pre>

<p><a href=""https://i.stack.imgur.com/cdGUf.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/cdGUf.png"" alt=""enter image description here""></a></p>

<hr>

<p>This time I <strong>combine</strong> a mask of red and blue pixels so you can see the power of masks. The final line is the important point:</p>

<pre><code># Define some colours for readability - these are in OpenCV **BGR** order - reverse them for PIL
red   = [0,0,255]
green = [0,255,0]
blue  = [255,0,0]
white = [255,255,255]
black = [0,0,0]

# Make mask of all perfectly red pixels and all perfectly blue pixels
Rmask = np.all(im == red,  axis=-1)
Bmask = np.all(im == blue, axis=-1)

# Make all red or blue pixels black
im[Rmask | Bmask] = black
</code></pre>

<p><a href=""https://i.stack.imgur.com/8qcLL.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/8qcLL.png"" alt=""enter image description here""></a></p>

<hr>

<p>And this time I make all non-red pixels into black - hopefully you are appreciating the power of masks now. The final line is the important point:</p>

<pre><code># Define some colours for readability - these are in OpenCV **BGR** order - reverse them for PIL
red   = [0,0,255]
green = [0,255,0]
blue  = [255,0,0]
white = [255,255,255]
black = [0,0,0]

# Make mask of all perfectly red pixels
Rmask = np.all(im == red,  axis=-1)

# Make all non-red pixels black
im[~Rmask] = black
</code></pre>

<p><a href=""https://i.stack.imgur.com/p3bYg.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/p3bYg.png"" alt=""enter image description here""></a></p>

<hr>

<p>Up till now, we have only made some selection of pixels into a single new colour. What if we want to make some pixels one colour and all other pixels a different colour in a single pass? The final line is the important point:</p>

<pre><code># Define some colours for readability - these are in OpenCV **BGR** order - reverse them for PIL
red   = [0,0,255]
green = [0,255,0]
blue  = [255,0,0]
white = [255,255,255]
black = [0,0,0]

# Make mask of all perfectly red pixels
Rmask = np.all(im == red,  axis=-1)

# Make all red pixels white AND at same time everything else black
im = np.where(np.all(im == red, axis=-1, keepdims=True), white, black)
</code></pre>

<p><a href=""https://i.stack.imgur.com/po4K8.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/po4K8.png"" alt=""enter image description here""></a></p>

<hr>

<p>If you want to affect a whole <strong>range</strong> of colours, rather than a specific RGB value, have a look <a href=""https://stackoverflow.com/a/50215020/2836621"">here</a> and <a href=""https://stackoverflow.com/a/52183666/2836621"">here</a>.</p>

<p><strong>Keywords</strong>: Image processing, Python, prime, change colour, change color, prime.</p>
","3","7","143615","5750","44","11812","60018903","60019059"
"60019010","<p>I would use <code>sklearn</code> framework.</p>

<p>It isn't a part of python base packages, so you will need to install it (<code>pip install sklearn</code>). </p>

<p>than, import the <code>CountVectorizer</code>:</p>

<pre><code>from sklearn.feature_extraction.text import CountVectorizer
</code></pre>

<p>read you files and store them in a list.
let's say you will call it <code>my_corpus</code>. now  you have a list named <code>my_corpus</code> with 4 members.</p>

<p>just use:</p>

<pre><code>vectorizer =  CountVectorizer()    
matrix = vectorizer.fit_transform(my_corpus)
</code></pre>

<p>Alternativly, if you wouldn't like to use a oter packages, just do:
corpus = [""I like dogs"", ""I like cats"", ""cats like milk"", ""You likes me""]<br>
token_corpus = [s.split() for s in corpus]                                           </p>

<pre><code>vocabulary = {}                                                                      
for i, f in enumerate(token_corpus):                                                 
    for t in f:                                                                      
        if t not in vocabulary:                                                      
             vocabulary[t] = [0]*len(corpus)                                         
        vocabulary[t][i]+=1                                                          

vocabulary
{'I': [1, 1, 0, 0], 'like': [1, 1, 1, 0], 'dogs': [1, 0, 0, 0], 'cats': [0, 1, 1, 0], 'milk': [0, 0, 1, 0], 'You': [0, 0, 0, 1], 'likes': [0, 0, 0, 1], 'me': [0, 0, 0, 1]}
</code></pre>

<p>if you want to save it in a list just use:</p>

<pre><code>list(map(list, vocabulary.items()))
[['I', [1, 1, 0, 0]], ['like', [1, 1, 1, 0]], ['dogs', [1, 0, 0, 0]], ['cats', [0, 1, 1, 0]], ['milk', [0, 0, 1, 0]], ['You', [0, 0, 0, 1]], ['likes', [0, 0, 0, 1]], ['me', [0, 0, 0, 1]]]
</code></pre>
","1","2","1805","1172","161","335","60018917","60019010"
"60019132","<p>A naive sieve implementation would have a <code>is_prime</code> array that represents all <code>n</code> numbers we want to check. So its size would be <code>n</code>. Then for each <code>p</code>, we start at <code>2*p</code> and mark it as ""not prime"" then go to <code>3*p</code>, <code>4*p</code>, <code>5*p</code>, etc, marking each one as ""not prime"". So for example, when <code>p = 2</code>, we mark 4, 6, 8, 10, 12, etc as ""not prime"". Then when <code>p = 3</code> we mark 6, 9, 12, 15 as ""not prime"". </p>

<p>I suggest that you implement this algorithm yourself to understand how it works before moving on to implementations. The code you are looking at uses some tricks to reduce the work done. But to understand those tricks, you need to understand the base algorithm.</p>

<blockquote>
  <p>how did they come up with the formula for the size</p>
</blockquote>

<p>This comes from solving the formula <code>n = i * 2 + 3</code> for <code>i</code> where <code>n</code> is the largest number we will check for primeness. It gives an upper bound for the value of <code>i</code> for all of the numbers we want to test.</p>

<blockquote>
  <p>how did they get p = i * 2 + 3</p>
</blockquote>

<p>This allows us to test only odd numbers starting at 3. Note that even numbers are <strong>not</strong> prime, so we can easily skip them with this formula.</p>

<blockquote>
  <p>what does the following mean Sieving from p^2, where p^2 = (4i^2 + 12i + 9). The index in is_prime is (2i^2 + 6i + 3) because is_prime[i] represents 2i + 3</p>
</blockquote>

<p>Notice how in our naive algorithm, we marked 6 and 12 as ""not prime"" twice. We clearly do some extra work here. We can avoid this extra work by realizing that for <code>p</code>, we have already marked all composite numbers less than <code>p^2</code> as ""not prime"" when we determined each prime less than <code>p</code>.</p>

<p>So we only have to start at <code>p^2</code> instead of at <code>p</code>. Now for <code>p = 2</code>, we mark 4, 6, 8, 10, 12, etc as before. But then for <code>p = 3</code>, we mark 9, 12, 15, 18, etc, avoiding the double work of marking 6 as ""not prime"". For these two examples, the amount of double-marking avoided is pretty small, but as <code>p</code> gets larger, this technique adds up to a significant performance increase.</p>

<p>As for the formula <code>p^2 = (4i^2 + 12i + 9)</code>, you can derive this from what we call the FOIL method when multiplying <code>(2*i+3)*(2*i+3)</code>. For your code, this doesn't really matter, because if you do <code>p = 2*i + 3</code>, then you can calculate <code>p*p</code> directly without worrying about the underlying algebraic manipulations.</p>

<blockquote>
  <p>why does the range of j begin with 2 * i**2 + 6 * i + 3</p>
</blockquote>

<p>We have <code>p^2 = (4i^2 + 12i + 9)</code> and we need to find the index <code>j</code> in <code>is_prime</code> where <code>p^2 = j * 2 + 3</code>. We set these equal and solve for <code>j</code>.</p>
","0","2","68812","12541","1216","18431","60018974","60019268"
"60019268","<p>There are two key tricks which are simultaneously done here. That, I believe, is the main reason behind your confusion. The first is a mathematical fact about the progression about the sieve algorithm. (i.e., starting to update from <code>p<sup>2</sup></code>) The other is a trick employed to use less space by not storing any <code>is_prime</code> data for even numbers)</p>

<p>Let's start with your first two questions. The <code>(2 * i + 3)</code> mapping used in <code>is_prime[i]</code> seems to be a spatial optimization to reduce the space used to half. (i.e., no even number is represented in <code>is_prime</code> list) The mapping helps iterate only the list of odd numbers starting from 3, up to <code>size</code>. If you actually replace the <code>i</code> variable in <code>(2i + 3)</code> with the initial value of <code>size</code>, you will see that you end up with <code>n</code>. (or <code>n-1</code>, depending on whether <code>n</code> is even or odd)</p>

<p>Your third question is relatively more straightforward. In the outer loop, <code>i</code> iterates over the space of odd integers up to <code>n</code>. As there is a mapping of <code>(2i + 3)</code> in <code>is_prime</code>, <code>p</code> is assigned that value. From that point on, <code>p</code> represents the actual prime value which is to be used in the inner loop.</p>

<p>The comment in your fourth question simply further explains the mathematical idea of starting to iterate from <code>p<sup>2</sup></code>. As the loop constitutes <code>i</code> to be part of a mapping (to actual values) the <code>p<sup>2</sup></code> is further expressed in terms of that variable <code>i</code>. I think that comment attempts to express the use of <code>2 * i**2 + 6 * i + 3</code> to initialize the range of <code>j</code>, but is quite unclear.</p>

<p>To answer your final question, we should consider what <code>j</code> actually represents. <code>j</code> represents the space of odd numbers to be updated. Similar with the loop for <code>i</code>, <strong><code>j</code> iterates not over the actual values, but on the odd numbers</strong>. The initial value of <code>j</code> is <code>2 * i**2 + 6 * i + 3</code>, because when you replace that value with the <code>i</code> variable in <code>(2*i + 3)</code> (i.e., the mapping from the odd numbers' space to the set of actual values), you obtain <code>4 * i**2 + 12 * i + 9</code>, which is <code>p<sup>2</sup></code>.</p>

<p>The inner loop is basically assigning <code>is_prime[j]=False</code> to <strong>all the cells that represent the multiples of the actual prime value <code>p</code></strong>, starting from the one representing the value <code>p<sup>2</sup></code>.</p>
","0","2","4154","135","752","1342","60018974","60019268"
"60822995","<p>I'm not clear on what data you're looking for, so I've provided two potential solutions:</p>

<h3>Backend:</h3>

<p>The auth will be present in the header of the request object in your backend.</p>

<pre class=""lang-py prettyprint-override""><code>b64user_pass = request.headers.get(""Authorization"")
</code></pre>

<h3>Frontend:</h3>

<p>If your endpoint is expecting <code>json</code> be sure to make the request with the <code>Content-Type</code> header</p>

<pre class=""lang-py prettyprint-override""><code>request = requests.post(url, data=payload, headers={""Content-Type"": ""application/json"", auth=(user, pass))

# Or even better:
request = requests.post(url, json=payload, auth=(user, pass))
</code></pre>
","0","0","2068","476","17","358","60018992","60822995"
"60021397","<p>Altair features an <a href=""https://altair-viz.github.io/user_guide/marks.html#image-mark"" rel=""noreferrer"">image mark</a> that can be used if you want to plot images that are available at a URL; for example:</p>

<pre><code>import altair as alt
import pandas as pd

source = pd.DataFrame.from_records([
      {""x"": 0.5, ""y"": 0.5, ""img"": ""https://vega.github.io/vega-datasets/data/ffox.png""},
      {""x"": 1.5, ""y"": 1.5, ""img"": ""https://vega.github.io/vega-datasets/data/gimp.png""},
      {""x"": 2.5, ""y"": 2.5, ""img"": ""https://vega.github.io/vega-datasets/data/7zip.png""}
])

alt.Chart(source).mark_image(
    width=50,
    height=50
).encode(
    x='x',
    y='y',
    url='img'
)
</code></pre>

<p><a href=""https://i.stack.imgur.com/KUffc.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/KUffc.png"" alt=""enter image description here""></a></p>

<p>Altair is not as well suited to displaying 2-dimensional data arrays as images, because the grammar is primarily designed to work with structured tabular data. However, it is possible to do using a combination of <a href=""https://altair-viz.github.io/user_guide/transform/flatten.html"" rel=""noreferrer"">flatten transforms</a> and <a href=""https://altair-viz.github.io/user_guide/transform/window.html"" rel=""noreferrer"">window transforms</a>.</p>

<p>Here is an example using the data from the page you linked to:</p>

<pre><code>import altair as alt
import pandas as pd
from sklearn.datasets import fetch_lfw_people
faces = fetch_lfw_people(min_faces_per_person=60)

data = pd.DataFrame({
    'image': list(faces.images[:12])  # list of 2D arrays
})

alt.Chart(data).transform_window(
    index='count()'           # number each of the images
).transform_flatten(
    ['image']                 # extract rows from each image
).transform_window(
    row='count()',            # number the rows...
    groupby=['index']         # ...within each image
).transform_flatten(
    ['image']                 # extract the values from each row
).transform_window(
    column='count()',         # number the columns...
    groupby=['index', 'row']  # ...within each row &amp; image
).mark_rect().encode(
    alt.X('column:O', axis=None),
    alt.Y('row:O', axis=None),
    alt.Color('image:Q',
        scale=alt.Scale(scheme=alt.SchemeParams('greys', extent=[1, 0])),
        legend=None
    ),
    alt.Facet('index:N', columns=4)
).properties(
    width=100,
    height=120
)
</code></pre>

<p><a href=""https://i.stack.imgur.com/ekbPI.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/ekbPI.png"" alt=""enter image description here""></a></p>
","2","17","51859","797","15","8125","60019006","60021397"
"60019107","<p>Something like this will work:</p>

<p>I have assumed your json object is one large string named 'data'.</p>

<pre><code>import pandas as pd    
import json

# json object:
json_string = """""" { ""PlanCoverages"": [ { ""PlanId"": 65860, ... """"""

# 1) load json object as python variable:
data = json.loads(json_string)

# 2) convert to dataframe:
plan_coverages = pd.DataFrame(data['PlanCoverages'])
</code></pre>
","0","1","1842","112","6","198","60019043","60019107"
"60019394","<p>I think you need something like this    </p>

<pre><code>import pandas as pd    
import json


convert json to python dictionary:
my_dict = json.loads(json_string)

convert a dictionary my_dict to dataframe df:
df = pd.concat({k: pd.DataFrame(v).T for k, v in my_dict.items()}, axis=0)

#reset the index
df = df.reset_index()
</code></pre>
","0","0","504","24","3","56","60019043","60019107"
"60020100","<p>One approach is to only give a label to scatter the first time in the loop:</p>

<pre class=""lang-py prettyprint-override""><code>for x, y, z, l, m in zip([data_ax, data_bx, data_cx], [data_ay, data_by, data_cy], [data_az, data_bz, data_cz], [lab_a, lab_b, lab_c], [mrk_a, mrk_b, mrk_c]):
    for ind, (x2, y2, z2) in enumerate(zip(x, y, z)):
        sc = ax.scatter(x2, y2, c=z2, label=l if ind == 0 else None,
                        marker=m, cmap=cm, norm=mplcol.Normalize(vmin=0, vmax=1))
</code></pre>

<p>Another approach is to convert all data to np.arrays (data_cx etc. is now a list of np.arrays), and then use <code>ravel</code> (or <code>flatten</code>) from numpy.</p>

<pre><code>import numpy as np
import matplotlib.pyplot as plt
import matplotlib.colors as mplcol

data_ax = np.random.rand(10,4)
data_bx = np.random.rand(7, 1)
data_cx = np.concatenate([np.random.rand(6,1), np.random.rand(5,1), np.random.rand(8,1)])

data_ay = np.random.rand(10,4)
data_by = np.random.rand(7, 1)
data_cy = np.concatenate( [np.random.rand(6,1), np.random.rand(5,1), np.random.rand(8,1)])

data_az = np.random.rand(10,4)
data_bz = np.random.rand(7, 1)
data_cz = np.concatenate( [np.random.rand(6,1), np.random.rand(5,1), np.random.rand(8,1)])

lab_a = 'Data A'
lab_b = 'Data B'
lab_c = 'Data C'

mrk_a = 'o'
mrk_b = 's'
mrk_c = 'D'

cm = plt.cm.get_cmap('viridis')

fig, ax = plt.subplots()

for x, y, z, l, m in zip([data_ax, data_bx, data_cx], [data_ay, data_by, data_cy], [data_az, data_bz, data_cz], [lab_a, lab_b, lab_c], [mrk_a, mrk_b, mrk_c]):
    sc = ax.scatter(x.ravel(), y.ravel(), c=z.ravel(), label=l, marker=m, cmap=cm, norm=mplcol.Normalize(vmin=0, vmax=1))
ax.legend()

cb = plt.colorbar(sc)

plt.show()
</code></pre>
","0","1","34973","1481","136","1951","60019050","60020100"
"60020130","<p>I have found that your problem is equivalent to</p>

<pre><code>[np.any(arr[i]==values[i]) for i in range(len(values))]
</code></pre>

<p>I agree this is time consuming. Elementwise comparison can't be avoided here so <code>np.any(arr[i]==values[i])</code> or <code>values[i] in arr[i]</code> is must-do here. What about vectorizations, I found it quite difficult to replace list comprehension used here too. This is my way using <a href=""https://docs.scipy.org/doc/numpy/reference/generated/numpy.vectorize.html"" rel=""nofollow noreferrer""><code>np.vectorize</code></a>:</p>

<pre><code>def myfunc(i): return np.any(arr[i]==values[i])
vfunc = np.vectorize(myfunc)
vfunc(np.arange(len(values)))
# output: array([False, False,  True])
</code></pre>
","1","1","3747","281","19","426","60019133","60020269"
"60020269","<p>using <a href=""https://docs.scipy.org/doc/numpy/user/basics.broadcasting.html"" rel=""nofollow noreferrer"">broadcasting</a> might help:</p>

<pre><code>np.any(values[:,None,None] == arr, axis=(1,2))
</code></pre>

<p>is a one liner that gives <code>[False,False,True]</code>.  note that if you're storing <code>arr</code> then storing a similar <code>bool</code> array shouldn't be too bad</p>

<p>note that it's the <code>values[:,None,None] == arr</code> that's doing the broasting, strange <a href=""https://docs.scipy.org/doc/numpy/reference/arrays.indexing.html"" rel=""nofollow noreferrer"">indexing with <code>None</code></a> being equivalent to your <code>reshape</code> (but feels more idiomatic to me)</p>
","0","2","10718","971","119","1114","60019133","60020269"
"60020857","<p>You've basically identified the two options:</p>

<pre><code>In [35]: timeit [(i==a).any() for i,a in zip(values, arr)]                                     
29 µs ± 543 ns per loop (mean ± std. dev. of 7 runs, 10000 loops each)
In [36]: timeit (values[:,None,None]==arr).any(axis=(1,2))                                     
11.4 µs ± 10.5 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)
</code></pre>

<p>In this small case the big array approach is faster.  But for a larger case, the iteration might be better.  Memory management with the larger arrays may cancel out the time savings.  It's often the case that a few iterations on a complex problem are better than the fully 'vectorized' version.</p>

<p>If it's something you do repeatedly, you could take the time craft a hybrid solution, one that iterates on blocks.  But you'd have to judge that yourself.</p>

<p><code>isin</code> and related code either <code>ors</code> some tests, or using <code>sort</code> of some sort to put like values next to each other for easy comparison.  </p>

<p>The other approach is to write a fully iterative solution, and let <code>numba</code> compile it for you.</p>
","1","1","172516","3363","73","13055","60019133","60020269"
"60029255","<p>As hpaulj already mentioned <code>numba</code> can be an option here.</p>

<p><strong>Example</strong></p>

<pre><code>import numpy as np
import numba as nb

#Turn off parallelization for tiny problems
@nb.njit(parallel=True)
def example(values,arr):
    #Make sure that the first dimension is the same
    assert arr.shape[0]==values.shape[0]
    out=np.empty(values.shape[0],dtype=nb.bool_)

    for i in nb.prange(arr.shape[0]):
        out[i]=False
        for j in range(arr.shape[1]):
            if arr[i,j]==values[i]:
                out[i]=True
                break
    return out
</code></pre>

<p><strong>Timings (small arrays)</strong></p>

<pre><code>#your input data
%timeit example(values,arr.reshape(arr.shape[0],-1))# #parallel=True
#10.7 µs ± 34.5 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)
%timeit example(values,arr.reshape(arr.shape[0],-1))# #parallel=False
#2.15 µs ± 49.9 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)

#Methods from other answers
%timeit (values[:,None,None]==arr).any(axis=(1,2))
#9.52 µs ± 323 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)
%timeit [(i==a).any() for i,a in zip(values, arr)]
#23.9 µs ± 435 ns per loop (mean ± std. dev. of 7 runs, 10000 loops each)
</code></pre>

<p><strong>Timings (larger arrays)</strong></p>

<pre><code>values=np.random.randint(low=1,high=100_000,size=1_000_000)
arr=np.random.randint(low=1,high=10_00,size=1_000_000*100).reshape(1_000_000,10,10)

%timeit example(values,arr.reshape(arr.shape[0],-1)) #parallel=True
#48.2 ms ± 5.02 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)
%timeit example(values,arr.reshape(arr.shape[0],-1)) #parallel=False
#90.5 ms ± 618 µs per loop (mean ± std. dev. of 7 runs, 1 loop each)

#Methods from other answers
%timeit (values[:,None,None]==arr).any(axis=(1,2))
#186 ms ± 5.47 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)
%timeit [(i==a).any() for i,a in zip(values, arr)]
#6.63 s ± 69 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)
</code></pre>
","0","1","5188","591","6","1183","60019133","60020269"
"60019312","<p>You could first select a subset of your dataframe containing the rows for which the <code>Return</code> is maximum and then use <code>idxmin()</code> to return the index of the first occurrence of the minimum <code>Volatility</code>. </p>

<p>Here is a dataframe example:</p>

<pre><code>import pandas as pd
mydict = {'Return': [99999,1,1,99999, 809],
    'Volatility': [1, 2, 3, 4, 7]
    }

 df = pd.DataFrame(mydict, columns = ['Return', 'Volatility'])
</code></pre>

<p>For this example, <code>df[df.Return==df.Return.max()]</code> yields:</p>

<blockquote>
  <p>Return  Volatility<br>
  0    99999           1<br>
  3    99999           4</p>
</blockquote>

<p>And <code>df[df.Return==df.Return.max()].Volatility.idxmin()</code> returns:</p>

<blockquote>
  <p>0</p>
</blockquote>

<p>Which is the index associated with the <code>Volatility</code> of 1.</p>
","0","0","1706","160","3","188","60019146","60019312"
"60019278","<p>If no missing data in original DataFrame solution should be simplify a bit.</p>

<p>Also I think <code>inplace</code> is not good practice, check <a href=""https://www.dataschool.io/future-of-pandas/#inplace"" rel=""nofollow noreferrer"">this</a> and <a href=""https://github.com/pandas-dev/pandas/issues/16529"" rel=""nofollow noreferrer"">this</a>.</p>

<p>Also combine of all columns is nice solution, one of fastest, check <a href=""https://stackoverflow.com/a/36911306/2901002"">this</a>.</p>

<pre><code>df = pd.read_sql_query(""SELECT * FROM firstline_srs"", cnx)
df['Open_Date'] = pd.to_datetime(df['Open_Date'])

df['day'] = df['Open_Date'].dt.day
df['month'] = df['Open_Date'].dt.month

df['Product_Name'] = df['Product_Name'].replace('', 'N')
df['product_Type'] = df['product_Type'].replace('', 'A')


df['full_path'] = df['Type'] + ""/"" + df['Area'] + ""/"" + df['Sub_Area'] + ""/"" + df['product_Type'] + ""/"" + df['Product_Name']
</code></pre>

<p>If missing values:</p>

<pre><code>df = pd.read_sql_query(""SELECT * FROM firstline_srs"", cnx)
df['Open_Date'] = pd.to_datetime(df['Open_Date'])

df['day'] = df['Open_Date'].dt.day
df['month'] = df['Open_Date'].dt.month

df['Product_Name'] = df['Product_Name'].replace('', np.nan).fillna(""N"")
df['product_Type'] = df['product_Type'].replace('', np.nan).fillna(""A"")


df['full_path'] = df['Type'] + ""/"" + df['Area'] + ""/"" + df['Sub_Area'] + ""/"" + df['product_Type'] + ""/"" + df['Product_Name']
</code></pre>
","0","0","615041","23439","1483","126104","60019224","60019278"
"60019402","<p>You can use np.ix_() for this to create a map of which values you want by location. </p>

<pre><code>&gt;&gt;&gt; a = np.arange(1,10).reshape(3,3)
&gt;&gt;&gt; a
array([[1, 2, 3],
       [4, 5, 6],
       [7, 8, 9]])

&gt;&gt;&gt; b=np.ix_([0,2],[0, 2])
&gt;&gt;&gt; a[b]
array([[1, 3],
       [7, 9]])
</code></pre>
","0","2","1323","92","59","106","60019225","60019402"
"60019355","<p>Try this on for size</p>

<pre><code>print([[30*y + 10*x for x in range(3)] for y in range(3)])
</code></pre>

<p>What this does is swaps out the <code>0</code> you were using with <code>30*y + 10*x</code> which is exactly what you need to generate your array. For a more general solution that lets you scale to n by n matrices you can use</p>

<pre><code>n = k
print([[10*k*y + 10*x for x in range(k)] for y in range(k)])
</code></pre>

<p>For different rows and columns you can use</p>

<pre><code>rows = k
cols = j
print([[10*cols*y + 10*x for x in range(cols)] for y in range(rows)])
</code></pre>
","0","1","239","7","0","9","60019226","60019355"
"60019372","<p>The code is not very compact but it gets the job done:</p>

<pre><code>matrix = []
bar = []
foo = 10
  for i in range(3):
    for i in range(3):
  bar.append(foo)
  foo = foo + 10
matrix.append(bar)
bar = []
print(matrix)
</code></pre>
","0","0","148","4","2","12","60019226","60019355"
"60019374","<p><code>numpy</code> package is quite flexible for things you want:</p>

<pre><code>import numpy as np
m = np.arange(10, 100, 10) #array [10, 20, 30, 40, 50, 60, 70, 80, 90]
m = m.reshape(3,3) # array [[10, 20, 30], [40, 50, 60], [70, 80, 90]]
print(m.tolist()) # array converted to list if you need
</code></pre>

<h3>Output:</h3>

<pre><code>[[10, 20, 30], [40, 50, 60], [70, 80, 90]]
</code></pre>
","0","1","3747","281","19","426","60019226","60019355"
"60019420","<pre><code>import numpy as np
x = np.array(range(10,100,10)).reshape(3,3)
print(x)

[[10 20 30]
 [40 50 60]
 [70 80 90]]
</code></pre>
","0","0","444","28","5","38","60019226","60019355"
"60031624","<p>Check <a href=""https://discordpy.readthedocs.io/en/latest/api.html#discord.on_error"" rel=""nofollow noreferrer"">discord.py Event Reference</a> and <a href=""https://discordpy.readthedocs.io/en/latest/ext/commands/api.html#event-reference"" rel=""nofollow noreferrer"">Event Command Reference</a>, it allows you to create error handlers</p>
<p>An example for a <code>on_error</code> event handler which sends the traceback to it's owner:</p>
<pre><code>import discord

import traceback
import datetime

@bot.event
async def on_error(event, *args, **kwargs):
    embed = discord.Embed(title=':x: Event Error', colour=0xe74c3c) #Red
    embed.add_field(name='Event', value=event)
    embed.description = '```py\n%s\n```' % traceback.format_exc()
    embed.timestamp = datetime.datetime.utcnow()
    await bot.AppInfo.owner.send(embed=embed)
</code></pre>
","0","0","593","66","0","48","60019371","60031624"
"60019748","<p>How about using a periodic function like sine?</p>

<pre><code>import numpy as np
import matplotlib.pyplot as plt
from numpy import sin

n_points = 10000
n_classes = 2

x = np.random.uniform(-10,10, size=(n_points, n_classes))
mask = np.logical_or(np.logical_and(sin(x[:,0]) &gt; 0.0, sin(x[:,1]) &gt; 0.0), \
np.logical_and(sin(x[:,0]) &lt; 0.0, sin(x[:,1]) &lt; 0.0))
y = np.eye(n_classes)[1*mask]

plt.scatter(x[:,0], x[:,1], c=y[:,0], cmap=""bwr"", alpha=0.5)
plt.show()
</code></pre>
","2","5","1401","28","42","95","60019462","60019748"
"60019577","<p>you can't instantiate a <code>dict</code> with 3 arguments, the problem is the fact that you have 3 variables in the <code>zip</code>: <code>zip(number, name, position)</code> with which  you want to instantiate a <code>dict</code>, you should give only 2 arguments at a time, the key and the value</p>

<p>I've rewritten your las part of the code:</p>

<pre><code>from collections import defaultdict
data = {}
players = defaultdict(list)

for team_name, team_link in team.items():
    player_page = requests.get(team_link)
    cont = soup(player_page.text, 'lxml')
    clud_ele = cont.find_all('span', attrs={'class' : 'playerCardInfo'})
    for i in clud_ele:
        num = i.select('span.number')[0].get_text(strip=True)
        number = 100 if num == '-' else num
        name = i.select('h4.name')[0].get_text(strip=True)
        position = i.select('span.position')[0].get_text(strip=True)
        players[team_name].append({'number': number, 'position': position, 'name': name})
</code></pre>

<p><strong>output:</strong></p>

<pre><code>defaultdict(list,
            {'Arsenal': [{'number': '1',
               'position': 'Goalkeeper',
               'name': 'Bernd Leno'},
              {'number': '26',
               'position': 'Goalkeeper',
               'name': 'Emiliano Martínez'},
              {'number': '33', 'position': 'Goalkeeper', 'name': 'Matt Macey'},
              {'number': '2',
               'position': 'Defender',
               'name': 'Héctor Bellerín'},
                 .......................
</code></pre>
","10","1","15189","2120","120","950","60019478","60020019"
"60020019","<p>There are many problems in your code. The one causing the error is that you are trying to instantiate a dictionary with a 3-items tuple in list which is not possible. See <a href=""https://docs.python.org/3/library/stdtypes.html?highlight=dict#dict"" rel=""nofollow noreferrer"">the dict doc</a> for details.</p>

<hr>

<p>That said, I would suggest to rework the whole nested loop.</p>

<p>First, you have in <code>clud_ele</code> a list of player info, each player info concerns only one player and provides only one position, only one name and only one number. So there is no need to store those informations in lists, you could use simple variables:</p>

<pre class=""lang-py prettyprint-override""><code>for player_info in clud_ele:
    number = player_info.select('span.number')[0].get_text(strip=True)
    if number == '-':
        number = 100
    name = player_info.select('h4.name')[0].get_text(strip=True)
    position = player_info.select('span.position')[0].get_text(strip=True)
</code></pre>

<p>Here, usage of <code>select</code> method returns a list but since you know that the list contains only one item, it's ok to get this item to call <code>get_text</code> on. But you could check that the <code>player_info.select('span.number')</code> length is actually 1 before continuing to work if you want to be sure...</p>

<p>This way, you get scalar data type which will be much easier to manipulate.
Also note that I renamed the <code>i</code> to <code>player_info</code> which is much more explicit.</p>

<p>Then you can easily add your player data to your <code>players</code> dict:</p>

<pre class=""lang-py prettyprint-override""><code>players[team_name].append({'name': name,
                           'position': position
                           'number': number})
</code></pre>

<p>This assume that you create the <code>players[team_name]</code> before the nested loop with <code>players[team_name] = []</code>.</p>

<p><em>Edit: as stated in the <a href=""https://stackoverflow.com/a/60019577/2696355"">@kederrac's answer</a>, usage of a <code>defaultdict</code> is a smart and convenient way to avoid the manual creation of each <code>players[team_name]</code> list</em></p>

<p>Finally, this will give you:</p>

<ul>
<li>a dictionary containing values for <code>name</code>, <code>position</code> and <code>number</code> keys for each player</li>
<li>a team list containg player dictionaries for each team</li>
<li>a players dictionary associating a team list for each <code>team_name</code></li>
</ul>

<hr>

<p>It is the data structure you seems to want, but other structures are possible. Remember to think about your data structure to make it logical AND easily manipulable.</p>
","2","1","4899","456","27","210","60019478","60020019"
"60047954","<p>So the solution I ended up landing one involved a loop to create attributes for the form and a loop on the route for flask to capture the values.  The code looks like this:</p>

<pre><code>def map_csv():
    possible_columns = session['potential_columns']
    missing_columns = session['missing_columns']

    class MappingForm(FlaskForm):
        submit = SubmitField('Submit new mapping')
        pass

    possible_columns = [(x, x) for x in possible_columns]
    if missing_columns is not None:
        for name in missing_columns:
            setattr(MappingForm, name, SelectField(name, choices=possible_columns))

    form = MappingForm()
    if request.method == 'POST':
        if form.validate_on_submit:
            mapping = {}
            for x in missing_columns:
                column = getattr(form, x)
                mapping[column.data] = x
            session['mapping'] = mapping
            return redirect(url_for('main.upload'))
    return render_template('map_csv.html', form=form)

</code></pre>
","0","0","117","14","0","14","60019479","60047954"
"60019587","<p>This part of code <code>datetime.now().strftime(""%Y-%m-%d"")</code> return formated datetime <strong>string</strong>. You can find <code>strftime()</code> description <a href=""https://docs.python.org/3/library/datetime.html#datetime.date.strftime"" rel=""nofollow noreferrer"">here</a>. 
You need to substract timedelta first and then apply formatting to the result:</p>

<pre><code>yesterday = (datetime.now() -  timedelta(days=1)).strftime(""%Y-%m-%d"")
</code></pre>
","0","1","37572","2148","0","2444","60019548","60019587"
"60019650","<p>Convert the number to a string, then use a list comprehension to extract each digit as a character.  This gives you the list of digit strings, e.g. <code>['2', '3', '5']</code>.</p>

<p>Use <code>permutations</code> to get the different arrangements, joining the result and converting them back to integers.</p>

<pre><code>from itertools import permutations

integer = 235
numbers = [i for i in str(integer)]  # ['2', '3', '5']

&gt;&gt;&gt; list(int(''.join(p)) for p in permutations(numbers))
[235, 253, 325, 352, 523, 532]

# Or just simply (no need for `numbers`):
# list(int(''.join(p)) for p in permutations(str(integer)))
</code></pre>
","0","2","86106","1691","794","4699","60019549","60019685"
"60019678","<p>Convert number into list of string numbers then do permutations.</p>

<pre><code>import itertools
number = 235
results = [int("""".join(x)) for x in list(itertools.permutations(list(str(number))))]
</code></pre>

<p>Output:</p>

<pre><code>[235, 253, 325, 352, 523, 532]
</code></pre>
","1","3","4584","259","83","602","60019549","60019685"
"60019685","<p>Use <code>itertools.permutation</code>, one-liners are good to show that you know python very well, but what actually matters is the maintainability. Here is a maintainable code, where every function is doing a single work and after reading the code we can get the logic(wherein the case of a one-liner, we need to spend time understanding the code):</p>

<pre><code>from itertools import permutations as perm

def to_int(p):
    return int(''.join(map(str, p)))

def all_perms(n):
    digits = list(map(int, str(n)))
    perms = []
    for p in perm(digits, len(digits)):
        perms.append(to_int(p))
    return perms

n = 235
print(all_perms(n))
</code></pre>
","0","0","290","305","0","67","60019549","60019685"
"60019798","<p>If I understand your issue, in your main routine</p>

<pre><code>error_tracker.track_func(transformation_with_error(app1='AA', app2='BB'), silent=True)
</code></pre>

<p>calls <code>transformation_with_error</code> before entering <code>error_tracker.track_func</code>. This happens just because you indeed are calling <code>transformation_with_error</code>. If you want your <code>error_tracker.track_func</code> to call <code>transformation_with_error</code>, you have to pass the later as an argument, like you would do for a callback.</p>

<p>For example:</p>

<pre><code>def test(var1, var2):
    print(""{} {}"".format(var1, var2))

def callFn(func, *vars):
    func(*vars)

callFn(test, ""foo"", ""bar"")
</code></pre>

<p>outputs <code>foo bar</code></p>
","0","1","79","3","0","8","60019591","60019798"
"60020884","<p>Thx VincentRG<br>
That was it<br>
Just for the record, below are the changes I did:<br>
(side note: I added the **kwargs, too, to be able to deal with default values)</p>

<p>thx mate</p>

<p><strong>class changes</strong></p>

<pre><code>class ErrorTracker:
    def __init__(self):
        self.list = list()

    def track_func(self, func, silent=False, *args, **kwargs):
        try:
            self.list.append('...in trying')
            print('....trying.....')
            return func(*args, **kwargs)
        except Exception as e:
            self.list.append('...in except')
            self.list.append(e)   # important line - here the error gets ""logged""
            if not silent:
                raise e
</code></pre>

<p><strong>change in call</strong></p>

<pre><code>if __name__ == ""__main__"":
    error_tracker = ErrorTracker()

    print('-- start transformation')
    error_tracker.track_func(transformation_with_error, silent=True, app1='AA', app2='BB')
    print('-- end transformation')

    print(error_tracker.list)
</code></pre>
","0","0","27","1","0","7","60019591","60019798"
"60020140","<p>The argument to the constructor <a href=""https://wxpython.org/Phoenix/docs/html/wx.adv.Animation.html"" rel=""nofollow noreferrer""><code>wx.adv.Animation</code></a> is the filename. So it has to be:</p>

<pre class=""lang-py prettyprint-override""><code>anim = wx.adv.Animation()
anim.LoadFile(r'C:\Users\yuval\PycharmProjects\MultiTyping\pictures\back_gif.gif')
</code></pre>

<p>or</p>

<pre class=""lang-py prettyprint-override""><code>anim = wx.adv.Animation(r'C:\Users\yuval\PycharmProjects\MultiTyping\pictures\back_gif.gif')
</code></pre>

<p>Furthermore, I recommend to add a <a href=""https://wxpython.org/Phoenix/docs/html/wx.BoxSizer.html"" rel=""nofollow noreferrer""><code>wx.BoxSizer</code></a> to the frame:</p>

<pre class=""lang-py prettyprint-override""><code>sizer = wx.BoxSizer(wx.VERTICAL)
sizer.Add(anim_ctrl)
frame.SetSizerAndFit(sizer)
</code></pre>

<p>See the example:</p>

<pre class=""lang-py prettyprint-override""><code>import wx
from wx.adv import AnimationCtrl, Animation

app=wx.App()
frame = wx.Frame(None, -1, title='2', pos=(0, 0), size=(200, 200))
app.SetTopWindow(frame)
anim = Animation(r'C:\Users\yuval\PycharmProjects\MultiTyping\pictures\back_gif.gif')
anim_ctrl = AnimationCtrl(frame, -1, anim)

sizer = wx.BoxSizer(wx.VERTICAL)
sizer.Add(anim_ctrl)
frame.SetSizerAndFit(sizer)

frame.Show()
anim_ctrl.Play()

app.MainLoop()
</code></pre>
","6","1","136140","16645","626","8521","60019621","60020140"
"60025340","<p>I see nothing wrong with the answer given by @Rabbid76, I suggest that you run the code from the command line, rather than from within some ide.<br>
Here is another take on your problem, it's as concise as I can make it and assumes a <code>local</code> file called <code>scan.gif</code>.    </p>

<pre><code>import wx
from wx.adv import AnimationCtrl

class Animate(wx.Frame):
    def __init__(self, parent, id, title):
        wx.Frame.__init__(self, parent, -1, title)
        self.animation = AnimationCtrl(self)
        self.animation.LoadFile('scan.gif')
        self.animation.Play()
        self.Show()

app = wx.App()
frame = Animate(None, -1, 'Animation')
app.MainLoop()
</code></pre>
","5","1","16833","416","37","1242","60019621","60020140"
"60021390","<p>It's almost certainly an adjustment for numerical error. To see why this might be necessary, look what happens when you take the <code>svd</code> of a rank-one 2x2 matrix. We can create a rank-one matrix by taking the outer product of a vector like so:</p>

<pre><code>&gt;&gt;&gt; a = numpy.arange(2) + 1
&gt;&gt;&gt; A = a[:, None] * a[None, :]
&gt;&gt;&gt; A
array([[1, 2],
       [2, 4]])
</code></pre>

<p>Although this is a 2x2 matrix, it only has one linearly independent column, and so its <a href=""https://en.wikipedia.org/wiki/Rank_(linear_algebra)"" rel=""nofollow noreferrer"">rank</a> is one instead of two. So we should expect that when we pass it to <code>svd</code>, one of the singular values will be zero. But look what happens:</p>

<pre><code>&gt;&gt;&gt; U, s, V = numpy.linalg.svd(A)
&gt;&gt;&gt; s
array([5.00000000e+00, 1.98602732e-16])
</code></pre>

<p>What we actually get is a singular value that is <em>not quite</em> zero. This result is inevitable in many cases given that we are working with finite-precision floating point numbers. So although the problem you have identified is a real one, we will not be able to tell in practice the difference between a matrix that really has a very small singular value and a matrix that ought to have a zero singular value but doesn't. Setting small values to zero is the safest practical way to handle that problem.</p>
","0","2","123320","2200","152","5846","60019708","60021390"
"60020046","<p>You are check to see if a list exists in an array of arrays. Convert your list to an array and it should work. </p>

<pre><code>&gt;&gt;&gt; x=np.array([np.array([5, 5, 5]), np.array([6, 6, 6])])
&gt;&gt;&gt; np.array([5, 5, 5]) in x
True
</code></pre>
","0","2","1323","92","59","106","60019782","60020046"
"60020854","<p>I was able to solve this issue by using <a href=""https://docs.scipy.org/doc/scipy/reference/generated/scipy.io.savemat.html"" rel=""nofollow noreferrer"">scipy.io.savemat()</a> and <a href=""https://docs.scipy.org/doc/scipy/reference/generated/scipy.io.loadmat.html"" rel=""nofollow noreferrer"">scipy.io.loadmat()</a>. I was using np.savz() and np.load() before and that was taking too much memory. </p>
","3","0","549","0","0","70","60019795","60021116"
"60021116","<p>Make a sparse matrix:</p>

<pre><code>In [38]: M = sparse.random(1000,1000,.2,'csr')                                                 
</code></pre>

<p>save it 3 different ways:</p>

<pre><code>In [39]: from scipy import io                                                                  
In [40]: np.savez('Msparse.npz', M=M)                                                          
In [41]: sparse.save_npz('M1sparse',M)                                                         

In [43]: io.savemat('Msparse.mat', {'M':M})                                                    
</code></pre>

<p>file sizes:</p>

<pre><code>In [47]: ll M1spa* Mspar*                                                                      
-rw-rw-r-- 1 paul 1773523 Feb  1 12:40 M1sparse.npz
-rw-rw-r-- 1 paul 2404208 Feb  1 12:41 Msparse.mat
-rw-rw-r-- 1 paul 2404801 Feb  1 12:39 Msparse.npz
</code></pre>

<p>Load the 3 matrices:</p>

<pre><code>In [48]: M1=sparse.load_npz('M1sparse.npz')                                                    
In [49]: M2=np.load('Msparse.npz',allow_pickle=True)['M']                                      
In [50]: M3=io.loadmat('Msparse.mat')['M']                                                     
In [51]: M1                                                                                    
Out[51]: 
&lt;1000x1000 sparse matrix of type '&lt;class 'numpy.float64'&gt;'
    with 200000 stored elements in Compressed Sparse Row format&gt;
In [52]: M2                                                                                    
Out[52]: 
array(&lt;1000x1000 sparse matrix of type '&lt;class 'numpy.float64'&gt;'
    with 200000 stored elements in Compressed Sparse Row format&gt;,
      dtype=object)
In [53]: M3                                                                                    
Out[53]: 
&lt;1000x1000 sparse matrix of type '&lt;class 'numpy.float64'&gt;'
    with 200000 stored elements in Compressed Sparse Column format&gt;
</code></pre>

<p><code>M1</code> and <code>M3</code> are the same - <code>csr</code> like <code>M</code> for <code>save_npz</code>, <code>csc</code> (the MATLAB format) for <code>.mat</code>.</p>

<p><code>M2</code> is has an object dtype wrapper.</p>

<pre><code>In [54]: (M1*np.ones((1000,1))).shape                                                          
Out[54]: (1000, 1)
In [55]: (M3*np.ones((1000,1))).shape                                                          
Out[55]: (1000, 1)
</code></pre>

<p>This took a lot longer; and I almost don't dare look at the result.</p>

<pre><code>In [56]: (M2*np.ones((1000,1))).shape                                                          
Out[56]: (1000, 1)
</code></pre>

<p>If I extract the matrix from the object array, the multiplication is fast</p>

<pre><code>In [57]: (M2.item()*np.ones((1000,1))).shape                                                   
Out[57]: (1000, 1)
In [58]: (M2.item()*np.ones((1000,1))).dtype                                                   
Out[58]: dtype('float64')
In [59]: (M3*np.ones((1000,1))).dtype                                                          
Out[59]: dtype('float64')
</code></pre>

<p>Looking more closely at the <code>M2</code> multiplication:</p>

<pre><code>In [60]: (M2*np.ones((1000,1))).dtype                                                          
Out[60]: dtype('O')
In [61]: (M2*np.ones((1000,1)))[:2,:]                                                          
Out[61]: 
array([[&lt;1000x1000 sparse matrix of type '&lt;class 'numpy.float64'&gt;'
    with 200000 stored elements in Compressed Sparse Row format&gt;],
       [&lt;1000x1000 sparse matrix of type '&lt;class 'numpy.float64'&gt;'
    with 200000 stored elements in Compressed Sparse Row format&gt;]],
      dtype=object)
</code></pre>

<p>It's performing a <code>M*1</code> multiplication for each element of <code>ones</code> - making 1000 sparse matrices.  That's where your memory consumption is going.</p>

<p>In sum, when using <code>savez</code> it wraps each sparse matrix in an object dtype array, and does the pickle.  So you shouldn't use `data['Dx'] directly</p>

<pre><code>Dx = data['Dx']  # wrong
Dx = data['Dx'].item()    # right
</code></pre>
","0","1","172516","3363","73","13055","60019795","60021116"
"60021136","<p>The calculation would be well-suited for in-place operations:</p>

<pre><code>np.multiply(data['Dx'], u, out=data['Dx']
np.multiply(data['Dy'], v, out=data['Dy']
np.multiply(data['Dz'], w, out=data['Dz']
numpy.add(data['Dx'], data['Dy'], out=data['Dx'])
numpy.add(data['Dx'], data['Dz'], out=data['Dx'])
</code></pre>

<p>which creates no additional temporary arrays. If you also avoid loading the other variables that are not required for this specific computation, you will save additional memory. Doing the work inside a function is a good way to ensure you clean-up / free memory once the work is done. In your case it is possibly better to pay a read penalty and just read in the specific data you need for each such calculation. Though like hpaulj said, there's not much more magic you can find; it's a large dataset and will require lots of memory. Any way to reduce the size / resolution of the problem, or work it in smaller blocks?</p>
","0","0","10399","969","364","1560","60019795","60021116"
"60029327","<p>(MongoEngine contributor here) MongoEngine indeed adds some metadata to the lists , it uses a subclass of the builtin <code>list</code> class behind the scene. Those aren't stored in MongoDB, they allow MongoEngine to deal with  auto de-referencing or track changes that are applied on the document instance. They should be harmless to your application since they can be manipulated as standard python lists.</p>

<p>Trying to get around it isn't a good idea as its part of the internals of MongoEngine.</p>
","0","0","2992","486","22","162","60019803","60029327"
"60021322","<p>Here are steps that is possible for you to do here:</p>

<ol>
<li>Get the tuples of ids of objects you have created on <code>canvas</code>. You can do it using <code>canvas.find_all()</code> method.</li>
<li>Get coordinates of these objects using <code>canvas.coords(id)</code>.</li>
</ol>

<p>I have checked out standard <code>find_overlapping</code> method of <code>canvas</code>. It helps to determine which object are overlapped with specific rectangle only and I guess you need to solve problem you mentioned using some mathematics with a help of this method. Although, I have found a nice alternative, not based on <code>find_overlapping</code>:</p>

<pre><code>def find_overlaps(self):
    r = 5
    X = []
    tags = self.canvas.find_all() #finds tags of all the object created
    for tag in tags:
        x0, y0, x1, y1 = self.canvas.coords(tag) # corresponding coordinates
        center = [(x0+x1)/2, (y0+y1)/2] #centers of objects
        X.append(center)

    tree = cKDTree(X)
    print(tree.query_pairs(2*r))
</code></pre>

<h3>Output</h3>

<p>This is a set of couples of tags:</p>

<pre><code>{(2, 63), (10, 93), (70, 82), (8, 45)}
</code></pre>

<h3>Note</h3>

<p><code>from scipy.spatial import cKDTree</code> is required</p>
","3","1","3747","281","19","426","60019822","60021322"
"60020120","<p>There's a couple issues here. First, you cannot read the file because you're opening it with <code>a+</code> and so you read from the last line, so instead you have to add:</p>

<pre><code>info.seek(0)
</code></pre>

<p>I'd also suggest adding a <code>,</code> to ensure the names don't mix:</p>

<pre><code>info.write(f""{user_name},"") 
</code></pre>

<p>Lastly, I'd suggest opening the file with a <code>with</code> statement so you don't accidentily leave it open:</p>

<pre><code>with open(""user_info.txt"", ""a+"") as info:
</code></pre>

<p>Putting it all together:</p>

<pre><code>with open(""user_info.txt"", ""a+"") as info:
    info.seek(0)
    user_status = input(""Are you a new user (Y)es or (N)o"")
    if user_status.lower() == (""y""):
        print(""Welcome To Login Master 1000"")
        user_name = input(""Type in user name"")
        if str(user_name) in info.read().split(','):
            print(""That Name Is Taken"")
        info.write(f""{user_name},"")
</code></pre>
","1","1","3322","293","58","422","60019908","60020120"
"60020293","<p>Great start to your program.  Couple things here... when you are manually opening files for modification, you have to manually close the file at the end of your program with <code>info.close()</code>. </p>

<p>The decision for how to store your data in a file has been changed since the beginning of computers.  For simplicity and learning sake, you may just want to store your usernames and passwords in a comma separated file, <code>.csv</code> Or space separated file.  This will allow you to read a line and then split the line into their individual strings for testing.</p>

<p>When writing to file I believe you can append strings with the <code>+</code> operator.  So to create a space separated file you could <code>info.write(user_name+“,”+”password”+”\n”)</code>. Now you have an comma to split off of and only one user and password saved in your file per line.</p>

<p>Your file may be reading already.  To see if the file is being read, before the if statement try <code>print(“Current line is -&gt; “,info.readline())</code> as readline will read only one line.  </p>

<p>If the file is not being read or there is no content in that print or you get an error, then it could be the permission on your file or its a simple option in your <code>a+</code> option needs to be changed.</p>

<p>Next, the keyword <code>in</code> is not checking the content as you intend although this is a good idea.<br>
<code>in</code> is better used to iterate every line of the file <code>for line in info:</code>
<code>Print(info.readline())</code>
The advantage to this method is you can split each line username and password into a list with split. So -></p>

<pre><code>For line in info:
    Print(line)
    Tokens = line.split(“,”) # if comma separated
    If user_name == tokens[0]:
        #Matched input username with file content
</code></pre>

<p>Now when you print tokens you will have a comma separated list looking like <code>[“Username”,”password”]</code> and then you can access <code>”Username”</code> with <code>Tokens[0]</code> and you can access <code>”password”</code> with <code>Tokens[1]</code> because list indexing starts with 0.  </p>
","1","0","127","34","0","65","60019908","60020120"
"60020000","<p>When the second argument is <code>-1</code>, it calculates the modular inverse of <code>a (mod c)</code>. Using other negative powers <code>-n</code> will return the modular inverse to the <code>n</code>-th power <code>(mod c)</code>.</p>

<p><a href=""https://en.wikipedia.org/wiki/Modular_multiplicative_inverse"" rel=""nofollow noreferrer"">https://en.wikipedia.org/wiki/Modular_multiplicative_inverse</a></p>
","0","0","491","19","2","29","60019932","60020038"
"60020038","<p>From the python built-in functions documentation:</p>

<blockquote>
  <p>For int operands base and exp, if mod is present, mod must also be of integer type and mod must be nonzero. If mod is present and exp is negative, base must be relatively prime to mod. In that case, pow(inv_base, -exp, mod) is returned, where inv_base is an inverse to base modulo mod.</p>
</blockquote>

<p>which means that in your example, python calculates the inverse of 6 (so that <code>6 * inverse = 1</code>) and calculates <code>pow(inverse, 2, 13)</code>. In this case the inverse of 6 mod 13 is 11 (<code>6 * 11 = 66 = 1 mod 13</code>) and you calculate <code>11 ** 2 = 121 = 4 mod 13</code>.</p>
","0","1","88","4","0","9","60019932","60020038"
"60020074","<p>Have you tried to check it out for yourself? Python used to not support negative exponents when the third argument was supplied, something they changed in version 3.8.x, and now what it does is allow you to compute the modular inverse (as opposed to the 'standard' inverse when dealing with the reals).</p>

<p>So, if example pow(2, -1, 3) would tell you the inverse in mod 3 which would be 2, because 2*2 =4 = 1 mod 3 </p>
","0","0","23","4","0","3","60019932","60020038"
"60020122","<pre><code>pow(base, exp) =  base**exp
pow(12,2) = 144 = 12**2
</code></pre>

<p>Now computation of modular inverses in supported 3.8 afterwards. Before that they denied to inverse to base modulu</p>
","0","0","1606","27","10","326","60019932","60020038"
"60020309","<p>Use this:</p>

<p><code>id_of_first_artist = result['artist-list'][0]['id']</code></p>
","0","0","306","34","9","20","60019966","60020309"
"60020316","<p>This is how tkinter is designed to work. When you destroy a window, all of its children are destroyed. Since everything is a child of the root window or one of its children, when you destroy the root window all other widgets are destroyed along with it. </p>
","0","0","304622","14209","14165","34310","60019993","60020316"
"60020856","<p>You are passing values to the method in the wrong way. The first parameter is <code>xs</code> and should contain all the <strong><em>x</em></strong> series, but <em>not</em> any of the <strong><em>y</em></strong> series. Howefer you are passing <code>[x, y1]</code> for <code>xs</code>, which will plot the <code>y1</code> values as the x-coordinates for the second line. You probably intend this:</p>

<pre><code>p.multi_line([x, x], [y1, y2], ...)
</code></pre>
","0","1","29791","466","194","3548","60020047","60020856"
"60020095","<p>If you just want a list of sets you can do:</p>

<pre><code>[set() for i in range(12)]
</code></pre>

<hr>

<p>In your code you're both looping through <code>roll</code> and modifying the elements. </p>

<p>Also <code>{}</code> makes a <code>dict</code> not a <code>set</code>.</p>
","1","0","2489","54","19","236","60020057","60020216"
"60020129","<pre><code>roll = [i for i in range(12)]
</code></pre>

<p><code>roll</code> is a list of integers, from 0 - 11 inclusive.</p>

<pre><code>for i in roll:
</code></pre>

<p>For every integer in the list...</p>

<pre><code>roll[i] = {} 
</code></pre>

<p>Treat the current integer as an index to the list, and replace the integer at that index with a dictionary (The literal <code>{}</code> is not a set). This happens to work the way you intended because the integers in the list happen to be the same values as the indices at which they appear in the list.</p>

<p>The whole thing is redundant to begin with - you don't need to create 12 integers to ""allocate"" space for the sets later on, just create the sets in the list comprehension:</p>

<pre><code>roll = [set() for _ in range(12)]
</code></pre>
","1","1","6892","83","2","671","60020057","60020216"
"60020216","<ul>
<li><p>you can define an empty set in the following way: <code>set()</code></p></li>
<li><p><code>{}</code> it is used for an empty dictionary</p></li>
</ul>

<p>you can use in your example:</p>

<pre><code>roll = [i for i in range(12)]   
for i in roll:  
   roll[i] = set()
print(roll)
</code></pre>
","2","0","15189","2120","120","950","60020057","60020216"
"60020454","<p>IIUC, you want to map the values in commentID_parentID with the values of usernameChannelId associated to the same Id. You can try:</p>

<pre><code>#create the mapper
s_map = df.loc[df.Id.ne('NULL'), :].set_index(['Id'])['usernameChannelId']

# create the column by mapping the values where comment_parentID is not NULL, otherwise channelID
df['userChannelId_Target'] = np.where( df['commentID_parentID'].ne('NULL'), 
                                       df['commentID_parentID'].map(s_map), df['channelId'])

# see result
print (df[['usernameChannelId', 'userChannelId_Target' ]])
  usernameChannelId userChannelId_Target
0                 a                    g
1                 b                    k
2                 a                    a
3                 c                    a
4                 d                    h
5                 g                    b
</code></pre>
","0","0","21768","2176","28","1062","60020141","60020454"
"60020272","<p>You can use <a href=""https://docs.python.org/3/library/functions.html#ord"" rel=""nofollow noreferrer""><code>ord(c)</code></a> to get the ordinary number, that represents a character. e.g:</p>

<pre class=""lang-py prettyprint-override""><code>ch = 'a'

while True:

    for event in pygame.event.get():
        if event.type == pygame.KEYDOWN:

            if event.key == ord(ch):
                # [...]

</code></pre>

<p>But note, <code>if event.unicode == ch:</code>, would do the same.  </p>
","0","1","136140","16645","626","8521","60020192","60020272"
"60020303","<p>You need to create <a href=""https://matplotlib.org/api/colors_api.html#module-matplotlib.colors"" rel=""nofollow noreferrer"">valid colors</a>. </p>

<p>Your <code>colors</code> looks like this <code>[0.005 0.005 0.005 0.2   0.2   0.2  ]</code>.</p>

<p>For example:</p>

<pre><code>colors = np.asarray(['r'] * len(listeAlpha) + ['b'] * len(listeBeta))
</code></pre>

<p>creates <code>colors</code> with <code>['r' 'r' 'r' 'b' 'b' 'b']</code> and gives blue and red dots in your plot:</p>

<p><a href=""https://i.stack.imgur.com/UPXfS.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/UPXfS.png"" alt=""enter image description here""></a></p>
","0","2","71005","1633","51","3469","60020203","60020303"
"60020422","<p>It's not very elegant but it do his job.</p>

<pre><code>data = {'test1.txt': {'apple': 1, 'banana': 1, 'lemon': 1},
'test2.txt': {'apple': 1, 'banana': 1},
'test3.txt': {'apple': 1, 'lemon': 2},
'test4.txt': {'apple': 1, 'lemon': 1, 'grape': 1}}

lemon = ['lemon']
apple = ['apple']
banana = ['banana']
grape = ['grape']
for key, value in data.items():
    print(key, value)
    if 'lemon' in value:
        lemon.append(value.get('lemon'))
    else:
        lemon.append(0)
    if 'apple' in value:
        apple.append(value.get('apple'))
    else:
        apple.append(0)
    if 'banana' in value:
        banana.append(value.get('banana'))
    else:
        banana.append(0)
    if 'grape' in value:
        grape.append(value.get('grape'))
    else:
        grape.append(0)

result = [list(data.keys()), lemon, apple, banana, grape]
</code></pre>

<p>Output:</p>

<pre><code>[['test1.txt', 'test2.txt', 'test3.txt', 'test4.txt'], ['lemon', 1, 0, 2, 1], ['apple', 1, 1, 1, 1], ['banana', 1, 1, 0, 0], ['grape', 0, 0, 0, 1]]
</code></pre>
","0","1","4584","259","83","602","60020243","60020529"
"60020446","<pre><code># Data.
d = {'test1.txt': {'apple': 1, 'banana': 1, 'lemon': 1},
     'test2.txt': {'apple': 1, 'banana': 1},
     'test3.txt': {'apple': 1, 'lemon': 2},
     'test4.txt': {'apple': 1, 'lemon': 1, 'grape': 1}}

vocab = {}
for i, words in enumerate(d.values()):
    seen = set()
    for word, word_count in words.items():
        seen.add(word)
        if word not in vocab:
            vocab[word] = [0] * i  # If first time word is seen, add zero count for previously read files.
        vocab[word].append(word_count)
    # Add zero for previously encountered words not seen in file.
    for word in vocab:
        if word not in seen:
            vocab[word].append(0)

&gt;&gt;&gt; [[''] + list(d.keys())] 
     + [[word] + word_counts for word, word_counts in vocab.items()]
[['', 'test1.txt', 'test2.txt', 'test3.txt', 'test4.txt'],
 ['apple', 1, 1, 1, 1],
 ['banana', 1, 1, 0, 0],
 ['lemon', 1, 0, 2, 1],
 ['grape', 0, 0, 0, 1]]
</code></pre>
","0","2","86106","1691","794","4699","60020243","60020529"
"60020450","<p>This uses no external libraries and generalizes to any input dictionary of the nature indicated.</p>

<pre><code>dictionary={'test1.txt': {'apple': 1, 'banana': 1, 'lemon': 1},
'test2.txt': {'apple': 1, 'banana': 1},
'test3.txt': {'apple': 1, 'lemon': 2},
'test4.txt': {'apple': 1, 'lemon': 1, 'grape': 1}}

row_keys=[]
for x,v in dictionary.items():
  row_keys+=v.keys()
row_keys=list(set(row_keys))
dkeys=list(dictionary.keys())
header=['']+dkeys
rows=[]
for rk in row_keys:
  rows.append([rk])
  for k in dkeys:
    if rk in list(dictionary[k].keys()): rows[-1].append(dictionary[k][rk])
    else: rows[-1].append(0)
out=[header]+rows
print(out)
</code></pre>
","0","1","1401","28","42","95","60020243","60020529"
"60020529","<p>Without external libraries</p>

<pre><code>dictionary = {'test1.txt': {'apple': 1, 'banana': 1, 'lemon': 1},
'test2.txt': {'apple': 1, 'banana': 1},
'test3.txt': {'apple': 1, 'lemon': 2},
'test4.txt': {'apple': 1, 'lemon': 1, 'grape': 1}}

# all the keys used by all dictionaries
#all_keys = set().union(*(d.keys() for d in dictionary.values()))
# update using @JonClements suggestion
all_keys = set().union(*dictionary.values())

# Start with list of keys
lst = [list(dictionary.keys())]

# Add item count from each dictionary
lst += [[k] + [d.get(k, 0) for d in dictionary.values()] for k in all_keys]
print(lst)
</code></pre>

<p><strong>Output</strong></p>

<pre><code>[['test1.txt', 'test2.txt', 'test3.txt', 'test4.txt'], 
 ['banana', 1, 1, 0, 0], 
 ['apple', 1, 1, 1, 1], 
 ['lemon', 1, 0, 2, 1], 
 ['grape', 0, 0, 0, 1]]
</code></pre>
","1","3","10876","714","1","925","60020243","60020529"
"60020562","<p>You can try this.</p>

<pre><code>dictionary = {'test1.txt': {'apple': 1, 'banana': 1, 'lemon': 1},
'test2.txt': {'apple': 1, 'banana': 1},
'test3.txt': {'apple': 1, 'lemon': 2},
'test4.txt': {'apple': 1, 'lemon': 1, 'grape': 1}}
val=list(dictionary.values())
uni=set()
for d in val:
    for i in d:
        uni.add(i) 
#uni will contain all the unique fruits

for key in uni:
    for d in val:
        new_dict.setdefault(key,[]).append(d.get(key,0))

res=['']+list(dictionary.keys())
out=[[k]+val for k,val in new_dict.items()]
fin=[res]+out
'''fin is 
['', 'test1.txt', 'test2.txt', 'test3.txt', 'test4.txt']
['grape', 0, 0, 0, 1]
['banana', 1, 1, 0, 0]
['apple', 1, 1, 1, 1]
['lemon', 1, 0, 2, 1]'''
</code></pre>
","0","1","14733","1831","61","1931","60020243","60020529"
"60020649","<p>Given your initial data as:</p>

<pre><code>d = {'test1.txt': {'apple': 1, 'banana': 1, 'lemon': 1},
'test2.txt': {'apple': 1, 'banana': 1},
'test3.txt': {'apple': 1, 'lemon': 2},
'test4.txt': {'apple': 1, 'lemon': 1, 'grape': 1}}
</code></pre>

<p>You can get the unique values and do a little bit of transposing of values, eg:</p>

<pre><code># Get all unique row_labels
keys = set().union(*d.values())
# Build up the rows to include zero values for items not present
rows = [[values.get(key, 0) for key in keys] for values in d.values()]
# Build the table with the header row and then each row_label with
# the transposed version of the values
table = [
    ['', *d], 
    *([key, *vals] for key, vals in zip(keys, zip(*rows)))
]
</code></pre>

<p>This'll give you <code>table</code> as:</p>

<pre><code>[['', 'test1.txt', 'test2.txt', 'test3.txt', 'test4.txt'],
 ['lemon', 1, 0, 2, 1],
 ['banana', 1, 1, 0, 0],
 ['apple', 1, 1, 1, 1],
 ['grape', 0, 0, 0, 1]]
</code></pre>
","0","2","123002","2821","1151","28415","60020243","60020529"
"60020989","<p>No Usage of Library </p>

<pre><code>dictionary = {'test1.txt': {'apple': 1, 'banana': 1, 'lemon': 1},
'test2.txt': {'apple': 1, 'banana': 1},
'test3.txt': {'apple': 1, 'lemon': 2},
'test4.txt': {'apple': 1, 'lemon': 1, 'grape': 1}}

keycount = [['']]
keycount[0].extend(list(dictionary.keys()))
keys = dict()
for d_key in dictionary.keys():
    for i_key in dictionary[d_key].keys():
        if not i_key in keys:
            keys.update({i_key: True})

for key in keys:
    lists = [key]
    for d_key in dictionary.keys():
        lists.append(dictionary[d_key].get(key, 0))
    keycount.append(lists)
print(keycount)
</code></pre>
","0","1","11","0","0","1","60020243","60020529"
"60041027","<h2>I know its late but since I solved it I want to share it.</h2>

<pre><code>fruits = ['lemon', 'apple', 'banana', 'grape']
fi = []
fi.append(fruits)
for k, v in d.items():
    li = []
    for i in ['lemon', 'apple', 'banana', 'grape']:
        li.append(v.get(i,0))
    fi.append(li)

print ([[i for i, v in d.items()]] + list(map(list, zip(*fi))))

# Result: [['test1.txt', 'test2.txt', 'test3.txt', 'test4.txt'], ['lemon', 1, 0, 2, 1], ['apple', 1, 1, 1, 1], ['banana', 1, 1, 0, 0], ['grape', 0, 0, 0, 1]]
</code></pre>

<p>I hope this helps and counts! :)</p>
","0","1","514","46","1","136","60020243","60020529"
"60020544","<p>You can use Python's builtin sum method, and a generator expression:</p>

<pre><code>def series_sum(N):
    return sum(1.0 / 2**k for k in range(1, N + 1))
</code></pre>

<p>This works as follows:</p>

<ul>
<li><code>range(1, N + 1)</code> produces an <em>iterable</em> whose elements are the values 1, 2, ..., N sequentially.<br>
Reference:  <a href=""https://docs.python.org/3/library/functions.html#func-range"" rel=""nofollow noreferrer"">builtin range()</a>.</li>
<li><code>1.0 / 2**k for k in range(1, N + 1)</code> produces a new iterable that transforms this into 1/2, 1/4, ..., 1/(2^N).<br>
Reference:  <a href=""https://docs.python.org/3/reference/expressions.html#generator-expressions"" rel=""nofollow noreferrer"">generator
expressions</a>.</li>
<li><code>sum(...)</code> computes the sum of all the elements of the iterable that it is passed.<br>
Reference:  <a href=""https://docs.python.org/3/library/functions.html#sum"" rel=""nofollow noreferrer"">builtin <code>sum()</code></a>.</li>
</ul>

<p>The nice thing about Python is that if you read the code out loud, you would say something very similar to the words you would say while reading the mathematical expression.</p>
","1","0","3743","4114","321","256","60020266","60020544"
"60026030","<p>Try this.</p>

<pre><code>from simplified_scrapy.request import req
from simplified_scrapy.simplified_doc import SimplifiedDoc
url = 'https://avito.ru/saransk?q=asus'
html = req.get(url) 
doc = SimplifiedDoc(html)
print(doc.listA(url=url))
</code></pre>

<p>Here is an example of using frame simplified_scrapy.</p>

<pre><code>from simplified_scrapy.spider import Spider, SimplifiedDoc
class MySpider(Spider):
  name = 'avito.ru'
  allowed_domains = ['avito.ru']
  # concurrencyPer1s=1
  refresh_urls = True # For debug. If efresh_urls = True, start_urls will be crawled again.
  def __init__(self):
    host = 'https://avito.ru/saransk'
    search_words = ['asus', 'lenovo', 'xiaomi', 'apple', 'ipad']
    self.start_urls = [host+'?q='+w for w in search_words] # Initialize variable start_urls
    Spider.__init__(self,self.name) #necessary

  def extract(self, url, html, models, modelNames):
    doc = SimplifiedDoc(html)
    print (doc.listA(url=url['url']))
    # return {""Urls"": doc.listA(url=url['url']), ""Data"": None} # Return data to framework
    return True

from simplified_scrapy.simplified_main import SimplifiedMain
SimplifiedMain.startThread(MySpider()) # Start crawling
</code></pre>

<p>Here are more examples:<a href=""https://github.com/yiyedata/simplified-scrapy-demo"" rel=""nofollow noreferrer"">https://github.com/yiyedata/simplified-scrapy-demo</a></p>
","0","1","2231","56","0","189","60020288","60026030"
"60021890","<pre><code>cd /path/to/my/file

for file in *.csv
do
cut -d, -f3,4,5,6,7 ""$file"" &gt; ""new_$file""
done
</code></pre>

<p>this actually did the job. </p>
","1","-1","591","75","2","111","60020294","60021973"
"60021973","<p>If not creating a temporary file is not a strinct requirement (<a href=""https://stackoverflow.com/a/60021890/5825294"">your self answer</a> creates new files indeed), this is oneliner.</p>

<pre><code>find /path/to/your/dir -name '*.csv' -exec sh -c 'cut -d, -f3-6 $0 &gt; $0.new &amp;&amp; mv $0.new $0' {} \;
</code></pre>
","0","2","11070","4964","1209","1187","60020294","60021973"
"60020452","<p>Following <a href=""https://matplotlib.org/3.1.0/gallery/subplots_axes_and_figures/axis_equal_demo.html"" rel=""nofollow noreferrer"">this documentation</a>, you need to add some settings to axes. Your script works for me in a right ways if I insert these rows after creation of <code>fig</code>:</p>

<pre><code>ax = plt.gca()
ax.set_aspect('equal', 'box')
</code></pre>
","0","1","3747","281","19","426","60020325","60020452"
"60020644","<p>Actually what is happening is that both Series <code>df['Date_start']</code> and <code>df['Date_end']</code> are of type <em>datetime64[ns]</em>, but when you show the dataframe, if all the time values of the columns are zero, it doesn't show them. What you can try, if you need a formatted output, is to convert them to object types again, and give them format with <a href=""https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.dt.strftime.html"" rel=""nofollow noreferrer"">dt.strftime</a>:</p>

<pre><code>df['Date_start'] = pd.to_datetime(df['Date_start']).dt.strftime('%Y/%m/%d %H:%M:%S')
df['Date_end'] = pd.to_datetime(df['Date_end']).dt.strftime('%Y/%m/%d %H:%M:%S')
print (df)
</code></pre>

<p>Outputs:</p>

<pre><code>   Id_sensor           Date_start             Date_end
0          1  2018/01/04 00:00:00  2018/01/05 00:00:00
1          2  2018/01/04 00:00:10  2018/01/06 00:00:00
2          3  2018/01/04 00:14:00  2017/01/06 00:00:00
3          4  2018/01/04 00:00:00  2018/01/05 00:00:00
</code></pre>
","0","1","340","154","1","49","60020418","60020644"
"60020824","<p>You can first convert your columns to <code>datetime</code> datatype using <a href=""https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.to_datetime.html"" rel=""nofollow noreferrer""><code>to_datetime</code></a>, and subsequently use <a href=""https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.dt.strftime.html"" rel=""nofollow noreferrer""><code>dt.strftime</code></a> to convert the columns to string datatype with your desired format:</p>

<pre><code>import pandas as pd
from datetime import datetime

df = pd.DataFrame({
    'Id_sensor': [1, 2, 3, 4], 
    'Date_start': ['2018-01-04 00:00:00.0', '2018-01-04 00:00:10.0',
                   '2018-01-04 00:14:00.0', '2018-01-04'],
    'Date_end': ['2018-01-05', '2018-01-06', '2017-01-06', '2018-01-05']})

df['Date_start'] = pd.to_datetime(df['Date_start']).dt.strftime('%Y-%m-%d %H:%M:%S')
df['Date_end'] = pd.to_datetime(df['Date_end']).dt.strftime('%Y-%m-%d %H:%M:%S')

print(df)
# Output:
#
#    Id_sensor           Date_start             Date_end
# 0          1  2018-01-04 00:00:00  2018-01-05 00:00:00
# 1          2  2018-01-04 00:00:10  2018-01-06 00:00:00
# 2          3  2018-01-04 00:14:00  2017-01-06 00:00:00
# 3          4  2018-01-04 00:00:00  2018-01-05 00:00:00
</code></pre>
","0","1","5765","1277","231","409","60020418","60020644"
"60020565","<p>Assuming you are using python 3.6 or above you should use format strings (also known as f strings) to construct strings from variables. Start the string with the letter ""f"" and then put whatever variables you want in curly brackets {}. Also if you use single quotes as the outer quote then you don't have to escape double quotes and vice versa.</p>

<p>Code:</p>

<pre class=""lang-py prettyprint-override""><code>db_name = ""'home/user/output/prueba.gpkg'""
table_name = '""prueba""'
outputlayer = f'ogr:dbname={db_name} table={table_name} (geom) sql='
outputlayer
</code></pre>

<p>Output: </p>

<pre><code>'ogr:dbname=\'home/user/output/prueba.gpkg\' table=""prueba"" (geom) sql='
</code></pre>
","1","2","341","24","1","24","60020453","60115622"
"60024883","<p>Another option is to use a triple quoted string:</p>

<pre><code>dbname = """"""/home/user/output/prueba.gpkg""""""
outputlayer = """"""ogr:dbname='""""""+dbname+""""""' table=""prueba"" (geom) sql=""""""
</code></pre>

<p>which gives:</p>

<pre><code>'ogr:dbname=\'/home/user/output/prueba.gpkg\' table=""prueba"" (geom) sql='
</code></pre>
","3","1","7952","1225","24","1037","60020453","60115622"
"60115622","<p>I think one of the issues that this isn't working is your path here <code>pn = os.path.realpath(outdir + '/' + n + '.gpkg')</code>. This is trying to combine UNIX path <code>/</code> with windows path <code>\\</code>. A more robust solution in terms of portability between linux and windows would be to use the <code>path.join</code> function in os module.</p>

<p>Additionally, python f strings will only add escapes to whichever quote character you used to open the string (<code>'</code> or <code>""</code>). If the escaped quotes around both strings are necessary, you're probably better off hard coding it into an f-string instead of setting 2 new variables with different quote types.</p>

<pre><code>import glob, time, sys, threading, os
from datetime import date, timedelta, datetime
import time, threading

#Parameters
layer = 'C:\\layer.gpkg' 
n ='2020'
outdir = 'C:\\output'

#Process
l = os.path.realpath(layer)
pn = os.path.realpath(os.path.join(outdir, f""{n}.gpkg""))
o = f'ogr:dbname=\'{pn}\' table=\""{n}\"" (geom) sql='

#Test
out = 'ogr:dbname=\'C:\\output\\2020.gpkg\' table=\""2020\"" (geom) sql='
o == out
</code></pre>

<p>A version of this (different path) has been tested to work on my linux machine.</p>
","2","1","76","2","0","1","60020453","60115622"
"60020513","<p>Consider this line in <code>GetAsciiListLC()</code>:</p>

<pre><code>num_list = [(num_list.append((str(num), chr(num)+"" ""))) for num in range(32, 42, 1)]
</code></pre>

<p><code>num_list.append((str(num), chr(num)+"" "")))</code> mutates the list and <em>returns <code>None</code></em>.</p>

<p>I think what you want is this:</p>

<pre><code>def GetAsciiListLC():
    """""" Return list of 2-tuples containing numbers and ASCII equivalents, both as strings. """"""
    return [(str(num), chr(num) + "" "") for num in range(32, 42)]
</code></pre>

<p>See this question for the rationale of returning None from the list.append() method:
<a href=""https://stackoverflow.com/questions/16641119/why-does-append-always-return-none-in-python"">Why does append() always return None in Python?</a></p>
","0","2","3743","4114","321","256","60020484","60020513"
"60106976","<p>web3py is not still fully compatible with solidity version 0.6.x. 
check out the link.
<a href=""https://github.com/ethereum/web3.py/issues/1566"" rel=""nofollow noreferrer"">https://github.com/ethereum/web3.py/issues/1566</a>
you can use solidity 0.5.x till then and track the progress through the link.</p>
","0","1","26","1","0","2","60020499","60106976"
"60020700","<p>1, It depends on how you want to define a ""region"", but looks like you just have feeling instead of strict definition. If you have a very clear definition of what kind of piece you want to cut out, you can try some method like ""matched filter""</p>

<p>2, You might want to detect the peak of absolute magnitude. If not working, try peak of absolute magnitude of first-order difference, even 2nd-order.</p>

<p>3, it is hard to work on the noisy data like this. My suggestion is to do filtering before you pick up sections (on unfiltered data). Filtering will give you smooth peaks so that the position of peaks can be detected by the change of derivative sign. For filtering, try just ""low-pass filter"" first. If it doesn't work, I also suggest ""Hilbert–Huang transform"".</p>

<p>*, Looks like you are using matlab. The methods mentioned are all included in matlab.</p>
","1","0","245","10","0","25","60020521","60029969"
"60029969","<p>To do this you need to find signal out of noise.</p>

<ol>
<li>get mean value of you signal and add some multiplayer that place borders on top and on bottom of noise - green dashed line</li>
<li>find peak values below bottom of noise -> array 2 groups of data</li>
<li>find peak values on top of noise -> array 2 groups of data</li>
<li>get min index of bottom first peak and max index of top of first peak to find first peak range</li>
<li>get min index of top second peak and max index of bottom of second peak to find second peak range</li>
</ol>

<p>Some description in code. With this method you can find other peaks.
One thing that you need to input by hand is to tell program the<code>x</code> value between peaks for splitting data into parts.</p>

<p>See graphic for summary.</p>



<pre><code>import numpy as np
from matplotlib import pyplot as plt


# create noise data
def function(x, noise):
    y = np.sin(7*x+2) + noise
    return y

def function2(x, noise):
    y = np.sin(6*x+2) + noise
    return y


noise = np.random.uniform(low=-0.3, high=0.3, size=(100,))
x_line0 = np.linspace(1.95,2.85,100)
y_line0 = function(x_line0, noise)
x_line = np.linspace(0, 1.95, 100)
x_line2 = np.linspace(2.85, 3.95, 100)
x_pik = np.linspace(3.95, 5, 100)
y_pik = function2(x_pik, noise)
x_line3 = np.linspace(5, 6, 100)

# concatenate noise data
x = np.linspace(0, 6, 500)
y = np.concatenate((noise, y_line0, noise, y_pik, noise), axis=0)

# plot data
noise_band = 1.1
top_noise = y.mean()+noise_band*np.amax(noise)
bottom_noise = y.mean()-noise_band*np.amax(noise)
fig, ax = plt.subplots()
ax.axhline(y=y.mean(), color='red', linestyle='--')
ax.axhline(y=top_noise, linestyle='--', color='green')
ax.axhline(y=bottom_noise, linestyle='--', color='green')
ax.plot(x, y)

# split data into 2 signals
def split(arr, cond):
  return [arr[cond], arr[~cond]]

# find bottom noise data indexes
botom_data_indexes = np.argwhere(y &lt; bottom_noise)
# split by visual x value
splitted_bottom_data = split(botom_data_indexes, botom_data_indexes &lt; np.argmax(x &gt; 3))

# find top noise data indexes
top_data_indexes = np.argwhere(y &gt; top_noise)
# split by visual x value
splitted_top_data = split(top_data_indexes, top_data_indexes &lt; np.argmax(x &gt; 3))

# get first signal range
first_signal_start = np.amin(splitted_bottom_data[0])
first_signal_end = np.amax(splitted_top_data[0])

# get x index of first signal
x_first_signal = np.take(x, [first_signal_start, first_signal_end])
ax.axvline(x=x_first_signal[0], color='orange')
ax.axvline(x=x_first_signal[1], color='orange')

# get second signal range
second_signal_start = np.amin(splitted_top_data[1])
second_signal_end = np.amax(splitted_bottom_data[1])

# get x index of first signal
x_second_signal = np.take(x, [second_signal_start, second_signal_end])
ax.axvline(x=x_second_signal[0], color='orange')
ax.axvline(x=x_second_signal[1], color='orange')

plt.show()
</code></pre>

<p><b>Output:</b></p>

<p>red line = mean value of all data</p>

<p>green line - top and bottom noise borders</p>

<p>orange line - selected peak data</p>

<p><a href=""https://i.stack.imgur.com/tpPW2.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/tpPW2.png"" alt=""enter image description here""></a></p>
","1","1","4584","259","83","602","60020521","60029969"
"60020612","<p>You can use the <code>key</code> argument to Python's <a href=""https://docs.python.org/3/library/functions.html#sorted"" rel=""nofollow noreferrer"">builtin <code>sorted</code> function</a>.</p>

<p>Assuming your records are tuples:</p>

<pre><code>records = [ 
  (""CHARLES"", 2, 4, ""DALLAS TX""),
  (""RICK"", 6, 9, ""AUSTIN TX""),
  (""BOB"", 9, 0, ""KELLER TX"")
] 

sorted(records, key=lambda rec: rec[0])

# Produces:                                                                                                                                    
[('BOB', 9, 0, 'KELLER TX'),
 ('CHARLES', 2, 4, 'DALLAS TX'),
 ('RICK', 6, 9, 'AUSTIN TX')]
</code></pre>

<p>My recommendation would be to use <a href=""https://docs.python.org/3/library/collections.html#collections.namedtuple"" rel=""nofollow noreferrer""><code>collections.namedtuple</code></a> to create a record class, and convert any text to the correct types (e.g. integers) as early as possible.  (The sample code below omits conversion to integers for simplicity.)</p>

<p>If you records are strings, you can call <code>line.split("" "")</code> on each element to produce lists.</p>

<pre><code>my_file = [ 
    ""CHARLES 2 4 DALLAS TX"", 
    ""RICK 6 9 AUSTIN TX"", 
    ""BOB 9 0 KELLER TX"", 
] 

Record = collections.namedtuple(""Record"", ""name, i, j, city, state"") 
records = [Record(*line.split("" "")) for line in my_file] 

sorted(records, key=lambda rec: rec.name)                                                                                                                                  
# Result: 
# [Record(name='BOB', i='9', j='0', city='KELLER', state='TX'),
#  Record(name='CHARLES', i='2', j='4', city='DALLAS', state='TX'),
#  Record(name='RICK', i='6', j='9', city='AUSTIN', state='TX')]
</code></pre>
","0","3","3743","4114","321","256","60020582","60020612"
"60020633","<p>Something like this?</p>

<pre><code>import os

# iterate over each file:
for file in os.walk('C:\\'):
    print(file)
</code></pre>
","0","0","1842","112","6","198","60020596","60020633"
"60020635","<pre><code>import os

for result in os.walk('path_to_directory'):
  print(result)
</code></pre>
","1","0","1489","27","6","129","60020596","60020633"
"60020704","<p>try this below code:</p>

<pre><code>df.groupby('ID_Customer')['ID_product'].count()
</code></pre>

<p>let me know if this works for you or not.</p>

<p>Thanks</p>
","0","0","366","68","7","34","60020648","60020704"
"60020707","<p>You can simply use <a href=""https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.core.groupby.DataFrameGroupBy.nunique.html"" rel=""nofollow noreferrer""><code>nunique</code></a>:</p>

<pre><code>df.groupby(['ID_Customer'])['ID_product'].nunique()
</code></pre>
","2","0","15706","461","31","1209","60020648","60020704"
"60029246","<p>The problem is caused, as stated by the error message, from <code>NaN</code> values in the <code>OH_X_test</code>. Those values are introduced in the <code>concat</code> statement since the indices of the dataframes are mixed up.</p>

<p>I've therefore added 3 fixes in the code below: look at the <code>###FIX</code> tag.</p>

<pre><code>#### DATASETS LOAD ####
import pandas as pd
from sklearn.model_selection import train_test_split

# Read the data
X = pd.read_csv('../input/train.csv', index_col='Id') 
X_test = pd.read_csv('../input/test.csv', index_col='Id')

# Remove rows with missing target, separate target from predictors
X.dropna(axis=0, subset=['SalePrice'], inplace=True)
y = X.SalePrice
X.drop(['SalePrice'], axis=1, inplace=True)

# To keep things simple, we'll drop columns with missing values
cols_with_missing = [col for col in X.columns if X[col].isnull().any()] 
X.drop(cols_with_missing, axis=1, inplace=True)
X_test.drop(cols_with_missing, axis=1, inplace=True)

# Break off validation set from training data
X_train, X_valid, y_train, y_valid = train_test_split(X, y,
                                                      train_size=0.8, test_size=0.2,
                                                      random_state=0)

#### IMPUTATION OF MISSING VALUES FOR X_TEST ####
from sklearn.impute import SimpleImputer

# All categorical columns
object_cols = [col for col in X_train.columns if X_train[col].dtype == ""object""]

# Columns that will be one-hot encoded
low_cardinality_cols = [col for col in object_cols if X_train[col].nunique() &lt; 10]

# Fill in the lines below: imputation
my_imputer = SimpleImputer(strategy='most_frequent')
imputed_X_test = pd.DataFrame(my_imputer.fit_transform(X_test))

# Fill in the lines below: imputation removed column names; put them back
imputed_X_test.columns = X_test.columns 
imputed_X_test.index = X_test.index ###FIX

#### ONEHOT ENCODING FOR DATA #####
from sklearn.preprocessing import OneHotEncoder

# Apply one-hot encoder to each column with categorical data
OH_encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)
OH_cols_train = pd.DataFrame(OH_encoder.fit_transform(X_train[low_cardinality_cols]))
OH_cols_valid = pd.DataFrame(OH_encoder.transform(X_valid[low_cardinality_cols]))
OH_cols_test = pd.DataFrame(OH_encoder.transform(imputed_X_test[low_cardinality_cols]))

# One-hot encoding removed index; put it back
OH_cols_train.index = X_train.index
OH_cols_valid.index = X_valid.index
OH_cols_test.index = imputed_X_test.index ####FIX

# Remove categorical columns (will replace with one-hot encoding)
num_X_train = X_train.drop(object_cols, axis=1)
num_X_valid = X_valid.drop(object_cols, axis=1)
num_X_test = imputed_X_test.drop(object_cols, axis=1) ####FIX

# Add one-hot encoded columns to numerical features
OH_X_train = pd.concat([num_X_train, OH_cols_train], axis=1)
OH_X_valid = pd.concat([num_X_valid, OH_cols_valid], axis=1)
OH_X_test = pd.concat([num_X_test, OH_cols_test], axis=1)

##### BUILD MODEL AND CREATE SUBMISSION ####
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_absolute_error

# normalize datatypes columns
#for colName in  ['BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', 'BsmtFullBath', 'BsmtHalfBath', 'GarageCars', 'GarageArea']:
#    OH_X_train[colName] = OH_X_train[colName].astype('float64')
#    OH_X_valid[colName] = OH_X_train[colName].astype('float64')

# Build model
model = RandomForestRegressor(n_estimators=100, random_state=0)
model.fit(OH_X_train, y_train)
preds_test = model.predict(OH_X_test)

# Save test predictions to file
output = pd.DataFrame({'Id': OH_X_test.index,
                       'SalePrice': preds_test})
output.to_csv('submission.csv', index=False)
</code></pre>
","0","0","814","12","3","81","60020698","60029246"
"60020873","<p>I wouldn't worry about the memory locations, they are simply an implementation detail here. It's really about function design, so if you want to set <code>object.three</code>, then do exactly that, otherwise, you can create a mapping to an index if you wanted to:</p>

<pre class=""lang-py prettyprint-override""><code>class MyClass:
    def __init__(self, *args):
        self.one, self.two, self.three, *_ = args

    # get an object by it's index
    def get_by_index(self, index):
        # here's how you could create such a mapping
        opts = dict(zip((1, 2, 3), ('one', 'two', 'three')))

        try:
            return getattr(self, opts[index])
        except KeyError as e:
            raise ValueError(f""Improper alias for attribute, select one of {', '.join(opts)}"") from e

    # if you want to set by an index, then do that this way
    def set_by_index(self, index, val):
        opts = dict(zip((1, 2, 3), ('one', 'two', 'three')))

        try:
            setattr(self, opts[index], val)
        except KeyError as e:
            raise ValueError(f""Improper alias for attribute, select one of {', '.join(opts)}"") from e



# otherwise, just set the attribute by the name
a = MyClass(0, 0, 0)
a.three = 55


</code></pre>

<p>The thing is, you're right, <code>is</code> will look at the three <code>0</code>'s the same way, because it never copied that data in the first place. <code>one, two, three</code> point to the same data because they were assigned the same data. Once you assign the attribute again, you've effectively re-binded that attribute to a <em>new</em> value, rather than updating an existing one.</p>

<p>Point being, don't worry about <em>where</em> the memory is for this implementation, just set explicitly against the attribute</p>
","1","1","9059","762","165","821","60020749","60020873"
"60021262","<p>You can either use the <code>TextAreaField</code> field (<code>from wtforms import TextAreaField</code>), or change the widget for the <code>StringField</code> to a textarea:</p>

<pre><code>from wtforms.widgets import TextArea

my_field = StringField('My Field', widget=TextArea())
</code></pre>

<p>In any case, you can also pass <code>rows</code> and <code>cols</code> parameters in your template:</p>

<pre><code>{{ form.my_field(cols=50, rows=10) }}
</code></pre>
","1","1","1692","43","14","107","60020791","60021262"
"60020980","<p>You can check if autocommit is set to 1, this forces to commit every row and disabling it makes it somewhat faster</p>

<p>Instead of committing every insert try to bulk insert.</p>

<p>For that you should check
<a href=""https://dev.mysql.com/doc/refman/8.0/en/optimizing-innodb-bulk-data-loading.html"" rel=""nofollow noreferrer"">https://dev.mysql.com/doc/refman/8.0/en/optimizing-innodb-bulk-data-loading.html</a></p>

<p>and do something like</p>

<pre><code>data = [
('city 1', 'MAC', 'district 1', 16822),
('city 2', 'PSE', 'district 2', 15642),
('city 3', 'ZWE', 'district 3', 11642),
('city 4', 'USA', 'district 4', 14612),
('city 5', 'USA', 'district 5', 17672),
]

sql = ""insert into city(name, countrycode, district, population) 
VALUES(%s, %s, %s, %s)""

number_of_rows = cursor.executemany(sql, data)
db.commit()
</code></pre>
","6","1","19057","673","1706","1943","60020847","60053608"
"60053608","<p>I want to put in here some of the ways I worked on finding a solution to this problem. I'm not an expert in MySQL but I think these steps can help anyone looking to find out why he has lock wait timeouts.</p>

<p>So the troubleshooting steps I took are as follows - </p>

<p>1- Check if I can find in the MySQL slow log the relevant query that is locking my table. Usually it's possible to find queries that run a long time and also locks with the info below and the query right after it</p>

<pre><code># Time: 2020-01-28T17:31:48.634308Z
# User@Host: @ localhost [::1]  Id: 980397
# Query_time: 250.474040  Lock_time: 0.000000 Rows_sent: 10  Rows_examined: 195738
</code></pre>

<p>2- The above should give some clue on what's going on in the server and what might be waiting for a long time. Next I ran the following 3 queries to identify what is in use:</p>

<ul>
<li>check process list on which process are running - </li>
</ul>

<p><code>show full processlist;</code></p>

<ul>
<li>check tables in use currently -</li>
</ul>

<p><code>show open tables where in_use&gt;0;</code></p>

<ul>
<li>check running transactions -</li>
</ul>

<p><code>SELECT * FROM `information_schema`.`innodb_trx` ORDER BY `trx_started`;</code></p>

<p>3- The above 2 steps should give enough information on which query is locking the tables. in my case here I had a SP that ran an <code>insert into &lt;different table&gt; select from &lt;my locked table&gt;</code>, while it was inserting to a totally different table, this query was locking my table due to the select operation that took a long time.
To work around it, I changed the SP to work with temporary tables and now although the query is still not completely optimized, there are no locks on my table.</p>

<p>Adding here how I run the SP on temporary tables for async aggregated updates.</p>

<pre><code>CREATE DEFINER=`username`@`%` PROCEDURE `procedureName`()
BEGIN
    drop temporary table if exists scheme.temp1;
    drop temporary table if exists scheme.temp2;
    drop temporary table if exists scheme.temp3;
    create temporary table scheme.temp1 AS select * from scheme.live1;
    create temporary table scheme.temp2 AS select * from scheme.live2;
    create temporary table scheme.temp3 AS select * from scheme.live3;
    create temporary table scheme.emptytemp (
      `cName1` int(11) NOT NULL,
      `cName2` varchar(45) NOT NULL,
      `cName3` int(11) NOT NULL,
      `cName4` datetime NOT NULL,
      `cName5` datetime NOT NULL,
      KEY `cName1` (`cName1`)
    ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_0900_ai_ci;

    INSERT into scheme.emptytemp
    select t1.x,t2.y,t3.z
    from scheme.temp1 t1
    JOIN scheme.temp2 t2
    ON t1.x = t2.x
    JOIN scheme.temp3 t3
    ON t2.y = t3.y

    truncate table scheme.liveTable;
    INSERT into scheme.liveTable
    select * from scheme.emptytemp;
END
</code></pre>

<p>Hope this helps anyone that encounters this issue</p>
","1","0","47","3","0","27","60020847","60053608"
"60020905","<p>I think you are installing your modules on a vitualenv and the Jupyter notebook is running outside the virtualenv.</p>

<p>This happened to me once.</p>
","0","1","69","4","0","8","60020874","60020905"
"60020995","<p>Maybe you forgot to append the path to your modules to sys.path.</p>

<p>Example from within your notebook, if u want to import some selfwritten module from some relative location:</p>

<pre><code>import sys
sys.path.append(""../../../"")
sys.path.append(""../../"")

# Rest of your code goes here, for example import $MODULE_NAME
</code></pre>

<p>Then you can <code>import $MODULE_NAME</code> (so, use the proper modulename of your desired module) iff. that module is in <code>../../</code> or in <code>../../../</code>.</p>

<p>HTH. :-)</p>
","0","1","89","4","0","24","60020874","60020905"
"60021220","<p>Following produces file4 from file1, file2, file3;</p>

<pre><code>def load_file(filepath):
  "" Loads the files as dictionary ""
  with open(filepath, 'r') as f:
    return dict(line.rstrip().split() for line in f)

# Get keys
with open('file1.txt') as file1:
  keys = [line.rstrip() for line in file1]

# Produce output (file4)
with open('file4.txt', 'w') as file_out:
  dic1 = load_file('file2.txt')
  dic2 = load_file('file3.txt')

  for k in keys:
    v1 = int(dic1.get(k, 0))  # convert dic counts to int)
    v2 = int(dic2.get(k, 0))  # (use default to 0 if not present)
    v = max(v1, v2)
    if v &gt; 0:                 # only write if count &gt; 0
        file_out.write(f""{k} {v}\n"")
</code></pre>
","0","1","10876","714","1","925","60021028","60021337"
"60021337","<p>This works for as many files as you want for input.</p>

<pre><code>values = {}
def func(file):
    number_of_lines = file.readlines()
    for line in number_of_lines:
        elements = line.split()
        if (elements[0] in values):
            if (int(elements[1]) &gt; int(values[elements[0]])):
                values[elements[0]] = elements[1]
        else:
            values[elements[0]] = 0
    file.close()


f = open(""1.txt"", ""r"")
func(f)
f = open(""2.txt"", ""r"")
func(f)
f = open(""3.txt"", ""r"")
func(f)
f = open(""4.txt"", ""w+"")
for key, val in values.items():
    print (key, "" "", val)
    to_write = key + "" "" + val + ""\n""
    f.write(to_write)

f.close()
</code></pre>
","1","0","22","0","0","4","60021028","60021337"
"60021157","<p>If you are reading your data from a csv file you can define <code>sep</code> to <code>;</code> and read it as:</p>

<pre><code>df=pd.read_csv('filename.csv', sep=';', index_col=False)
</code></pre>

<p>Output:</p>

<pre><code>    id  signin_count    status
0   353     20  done
1   374     94  pending
2   377     4   done
</code></pre>
","1","2","2271","358","52","360","60021054","60021157"
"60024750","<p>Here's a way to do this with a simple SPSS macro:</p>

<p>This will be the macro definition:</p>

<pre><code>define !doAnalysis (!pos=!cmdend)
!do !vr !in (!1)
!let !BL=!concat(!vr,""_BL"")
!let !PO=!concat(!vr,""_PO"")
EXAMINE VARIABLES=!BL !PO BY Treatment_Group
  /PLOT NONE
  /STATISTICS DESCRIPTIVES
  /CINTERVAL 95
  /MISSING LISTWISE
  /NOTOTAL.
UNIANOVA !PO BY Treatment_Group WITH !BL
  /METHOD=SSTYPE(3)
  /INTERCEPT=INCLUDE
  /PRINT ETASQ DESCRIPTIVE HOMOGENEITY
  /CRITERIA=ALPHA(.05)
  /DESIGN=!BL Treatment_Group.
!doend
!enddefine.
</code></pre>

<p>The macro is now built to take a list of items, loop through them one by one, creating two names from each item in the list - by adding ""BL"" or ""PO"", and using these names to run your analyses.<br>
This will be the macro call:</p>

<pre><code>!doAnalysis Brief2_Inhibit_T_SELF  Brief2_Completion_T_SELF  Brief2_Shift_T_SELF .
</code></pre>
","1","0","8253","1930","18","733","60021100","60024750"
"60021420","<p>Remove <code>right_ax</code> from everywhere and at the end plot it onto <code>top_ax</code></p>

<pre><code>import numpy as np
import matplotlib.pyplot as plt
from mpl_toolkits.axes_grid1 import make_axes_locatable
from scipy.stats import multivariate_normal
import scipy

fig, main_ax = plt.subplots(figsize=(5, 5))
divider = make_axes_locatable(main_ax)
top_ax = divider.append_axes(""top"", 1.05, pad=0.1,sharex=main_ax)

top_ax.xaxis.set_tick_params(labelbottom=False)

main_ax.set_xlabel('dim 1')
main_ax.set_ylabel('dim 2')
top_ax.set_ylabel('Z profile')

x, y = np.mgrid[-1:1:.01, -1:1:.01]
pos = np.empty(x.shape + (2,))
pos[:, :, 0] = x; pos[:, :, 1] = y
rv = multivariate_normal([-0.2, 0.2], [[1, 1.5], [0.25, 0.25]])
z = rv.pdf(pos)
z_max = z.max()

cur_x = 110
cur_y = 40

main_ax.imshow(z, origin='lower')
main_ax.autoscale(enable=False)
top_ax.autoscale(enable=False)
top_ax.set_ylim(top=z_max)
v_line = main_ax.axvline(cur_x, color='r')
h_line = main_ax.axhline(cur_y, color='g')
h_prof, = top_ax.plot(np.arange(x.shape[0]), z[int(cur_y),:], 'g-')
v_prof, = top_ax.plot(np.arange(x.shape[1])[::-1], z[:,int(cur_x)], 'r-')

plt.show()
</code></pre>
","3","1","1038","53","6","89","60021324","60021420"
"60022208","<p>Your problem arises because you try to use the <em>Avro converter</em> to read data from a topic that is <em>not Avro</em>.</p>

<p>There are two possible solutions: </p>

<p><em>1. Switch Kafka Connect’s sink connector to use the correct converter</em></p>

<p>For example, if you’re consuming JSON data from a Kafka topic into a Kafka Connect sink:</p>

<pre><code>...
value.converter=org.apache.kafka.connect.json.JsonConverter. 
value.converter.schemas.enable=true/false
...
</code></pre>

<p><code>value.converter.schemas.enable</code> depends on whether the message contains a schema..</p>

<p><em>2. Switch the upstream format to Avro</em></p>

<p>For DatagenConnector to produce messages to Kafka where the message value format is <code>Avro</code>, set the <code>value.converter</code> and <code>value.converter.schema.registry.url</code> parameters:</p>

<pre><code>...
""value.converter"": ""io.confluent.connect.avro.AvroConverter"",
""value.converter.schema.registry.url"": ""http://localhost:8081"",
...
</code></pre>

<p>See kafka-connect-datagen <a href=""https://github.com/confluentinc/kafka-connect-datagen#confusion-about-schemas-and-avro"" rel=""nofollow noreferrer"">docs</a> for details.</p>

<hr>

<p>Great <a href=""https://www.confluent.io/blog/kafka-connect-deep-dive-converters-serialization-explained/"" rel=""nofollow noreferrer"">article</a> on Kafka Connect Converters and Serialization. </p>
","1","1","2725","1241","6","266","60021343","60022237"
"60022237","<p>The topic expects a message in Avro type. </p>

<p><a href=""https://github.com/confluentinc/confluent-kafka-python"" rel=""nofollow noreferrer""><code>AvroProducer</code></a> from <a href=""https://github.com/confluentinc/confluent-kafka-python"" rel=""nofollow noreferrer""><code>confluent-kafka-python</code></a> does the trick: </p>

<pre><code>from confluent_kafka import avro
from confluent_kafka.avro import AvroProducer


value_schema_str = """"""
{
   ""namespace"": ""ksql"",
   ""name"": ""value"",
   ""type"": ""record"",
   ""fields"" : [
     {
       ""name"" : ""viewtime"",
       ""type"" : ""long""
     }, 
     {
       ""name"" : ""userid"",
       ""type"" : ""string""
     }, 
     {
       ""name"" : ""pageid"",
       ""type"" : ""string""
     }
   ]
}
""""""

key_schema_str = """"""
{
   ""namespace"": ""ksql"",
   ""name"": ""key"",
   ""type"": ""record"",
   ""fields"" : [
     {
       ""name"" : ""pageid"",
       ""type"" : ""string""
     }
   ]
}
""""""

value_schema = avro.loads(value_schema_str)
key_schema = avro.loads(key_schema_str)
value = {""name"": ""Value""}
key = {""name"": ""Key""}


def delivery_report(err, msg):
    """""" Called once for each message produced to indicate delivery result.
        Triggered by poll() or flush(). """"""
    if err is not None:
        print('Message delivery failed: {}'.format(err))
    else:
        print('Message delivered to {} [{}]'.format(msg.topic(), msg.partition()))


avroProducer = AvroProducer({
    'bootstrap.servers': 'mybroker,mybroker2',
    'on_delivery': delivery_report,
    'schema.registry.url': 'http://schema_registry_host:port'
    }, default_key_schema=key_schema, default_value_schema=value_schema)

avroProducer.produce(topic='my_topic', value=value, key=key)
avroProducer.flush()
</code></pre>
","7","1","22983","1501","72","2832","60021343","60022237"
"60021501","<p>Maybe you can try this, function isnumeric return True if all characters in string are numeric.</p>

<pre><code> for i in first_numerical:
    if i == 'N':
        completed_frequency.append(i+ 'o Cap Per Day')
    if i == 'B':
        completed_frequency.append(i+'lank')
    if (i.isnumeric()):
        completed_frequency.append(i+' x Per Day') 
</code></pre>
","0","0","22","0","0","4","60021446","60021504"
"60021504","<p>IIUC, your list kind of gets overwritten as you missed <code>elif</code> do this</p>

<pre><code>  for i in first_numerical:
        if i == 'N':
            completed_frequency.append(i+ 'o Cap Per Day')
        elif i == 'B':
            completed_frequency.append(i+'lank')
        else:
            completed_frequency.append(i+' x Per Day')
</code></pre>

<p>Lets have an example to clear the air</p>

<pre><code>n=['1','1','1']
b=[]
for i in n:
    if i == '1':
        b.append(i)
    if i=='2':
        b.append(2)
    else:
        b.append('none')
</code></pre>

<p>Output</p>

<pre><code>['1', 'none', '1', 'none', '1', 'none']
</code></pre>

<p><strong>Correct way</strong></p>

<pre><code>n=['1','1','1']
b=[]
for i in n:
    if i == '1':
        b.append(i)
    elif i=='2':
        b.append(2)
    else:
        b.append('none')
</code></pre>

<p>Output</p>

<pre><code>['1', '1', '1']
</code></pre>

<p>Not overwritten but gets appended with extra values</p>
","0","3","2271","358","52","360","60021446","60021504"
"60021895","<p>Azure Blob Storage it's a good thing to store your image with metadata. </p>

<p>Microsoft provides an example how set and retrive image with metadata using Azure SDK (in c#): <a href=""https://docs.microsoft.com/en-us/azure/storage/blobs/storage-blob-container-properties-metadata"" rel=""nofollow noreferrer"">https://docs.microsoft.com/en-us/azure/storage/blobs/storage-blob-container-properties-metadata</a></p>

<p>The best storage for this, is Azure Data Lake gen 2: <a href=""https://docs.microsoft.com/en-us/azure/storage/blobs/data-lake-storage-introduction"" rel=""nofollow noreferrer"">https://docs.microsoft.com/en-us/azure/storage/blobs/data-lake-storage-introduction</a>
New storage generation wich use Blob Storage (low price)</p>

<p>In python you can configure environment follow the step in next link:</p>

<p><a href=""https://docs.microsoft.com/en-us/azure/storage/blobs/storage-quickstart-blobs-python#code-examples"" rel=""nofollow noreferrer"">https://docs.microsoft.com/en-us/azure/storage/blobs/storage-quickstart-blobs-python#code-examples</a></p>
","0","2","44","0","0","0","60021457","60021895"
"60021603","<p>You can call the <a href=""https://docs.python.org/3/library/datetime.html#datetime.datetime.time"" rel=""nofollow noreferrer""><strong><code>.time()</code></strong> method [python-doc]</a> to retrieve the time object:</p>

<pre><code>&gt;&gt;&gt; from datetime import datetime
&gt;&gt;&gt; datetime(1958, 3, 25, 12, 34).time()
datetime.time(12, 34)
</code></pre>
","0","1","312807","16628","2518","41861","60021568","60021603"
"60022979","<p>Yes, if the main code is in C++ and the bindings are well fleshed out, then option 1 is the easiest to work with, as in that case the bound C++ objects are as natural to use in Python as native Python classes. It makes life easier because you get full control over object identity and whether or not to copy.</p>

<p>For 3, I'm finding pybind11 to be too aggressive with copying when using callbacks (as seems to be your use case), e.g. with numpy arrays it's perfectly possible to work with the buffer on the C++ side if it is verified to be contiguous. Sure, copying will safeguard against memory problems, but there's too little control given over copying v.s. non-copying (numpy has the same problem tbs).</p>

<p>The reason why 3 exists is mostly because it improves usability and provides nice syntax. For example, if we have a function with this signature:</p>

<pre><code>void func(const std::vector&lt;int&gt;&amp;)
</code></pre>

<p>then it is nice to be able to call it from the Python side as <code>func((1, 2, 3))</code> or even <code>func(range(3))</code>. It's convenient, easy to use, looks clean, etc. But at that point, there is no way out but to copy, since the memory layout of a <code>tuple</code> is so different from a <code>std::vector</code> (and the range does not even represent an in-memory container).</p>

<p>Note carefully however, that with the <code>func</code> example above, the caller could still decide to provide a bound <code>std::vector&lt;int&gt;</code> object, and thus pre-empt any copying. May not look as nice, but there is full control. This is useful, for example if the vector is a return value from some other function, or is modified in between calls:</p>

<pre><code>v = some_calc()   # with v a bound C++ vector
func(v)
v.append(4)       # add an element
func(v)
</code></pre>

<p>Contrast this to the case where a list of floats is returned after calculating some numbers, analog to (but not quite) your description:</p>

<pre><code>std::list&lt;float&gt; calc()
</code></pre>

<p>If you choose ""option 1"", then the bound function <code>calc</code> will return a bound C++ object of <code>std::list&lt;float&gt;</code>. If you choose ""option 3"", then the bound function <code>calc</code> will return a Python <code>list</code> with the contents of the C++ <code>std::list&lt;float&gt;</code> copied into it.</p>

<p>The problem that arises with ""option 3"" is that if the caller actually wanted a bound C++ object, then the values need to be copied back into a new list, so a total of 2 copies. OTOH, if you choose ""option 1"" and the caller wanted instead a Python <code>list</code>, then they are free to do the copy on the return value of <code>calc</code> if desired:</p>

<pre><code>res = calc()
list_res = list(res)
</code></pre>

<p>or even, if they want this all the time:</p>

<pre><code>def pycalc():
    return list(calc())
</code></pre>

<p>Now finally to your specific case where it is a Python callback, called from C++, that returns a list of floats. If you use ""option 1"", then the Python function is forced to create a C++ list to return, so for example (with type <code>cpplist</code> the name given to a bound type <code>std::list&lt;float&gt;</code>):</p>

<pre><code>def pycalc():
    return cpplist(range(3))
</code></pre>

<p>which a Python programmer would not find pretty. Instead, by choosing ""option 3"", checking the return type and doing a conversion if needed, this would be valid as well:</p>

<pre><code>def pycalc():
    return [x for x in range(3)]
</code></pre>

<p>Depending on the overall requirements and typical use cases then, ""option 3"" may be more appreciated by your users.</p>
","2","1","2323","67","2","219","60021569","60022979"
"60021791","<p>There is a difference between a <code>float</code> and a <code>Decimal</code>. A <code>Decimal</code> encodes the data by storing the digits of a decimal number. You can however <em>not</em> perform <code>DecimalValidation</code> on a <code>float</code>, since due to rounding errors, it will add extra digits.</p>

<p>You thus can use a <a href=""https://docs.djangoproject.com/en/dev/ref/models/fields/#decimalfield"" rel=""nofollow noreferrer""><strong><code>DecimalField</code></strong> [Django-doc]</a> instead. Note that you thus need to pass <code>Decimal</code> objects in that case, <em>not</em> floats.</p>

<pre><code>class Course(models.Model):
    title = models.CharField(max_length = 200)
    author = models.ForeignKey(User,default=None, on_delete=models.SET_DEFAULT)
    description = models.TextField(max_length=1000, blank=True)
    tags = models.TextField(blank = True)
    duration = models.<b>DecimalField(max_digits=3,decimal_places=2,</b> validators=(MinValueValidator(0.1),MaxValueValidator(12), DecimalValidator(max_digits=3,decimal_places=2))<b>)</b>


    def __str__(self):
            return self.title</code></pre>

<p>You might want to take a look at the <a href=""https://docs.djangoproject.com/en/dev/ref/models/fields/#durationfield"" rel=""nofollow noreferrer""><strong><code>DurationField</code></strong> [Django-doc]</a> to store duration however, this will automatically use a <code>timedelta</code>, and store it as an integer for databases that do <em>not</em> support such types.</p>
","2","1","312807","16628","2518","41861","60021577","60021791"
"63889173","<p>If you really need to use a <code>FloatField</code>, then you need to write your own validator:</p>
<pre><code>def validate_decimals(value):
    s = str(value)
    d = decimal.Decimal(s)
    if abs(d.as_tuple().exponent) &gt; 2:
        raise ValidationError(
            _('%(value)s has more than 2 decimals. Please enter 2 decimals only.'),
            params={'value': value},
        )
</code></pre>
<p>Then, you add <code>validators='validate_decimals'</code> when you declare the <code>FloatField</code>.</p>
<p>Note that a float value cannot directly be converted to decimal. It should first be converted to string and then to decimal. See also:</p>
<p><a href=""https://stackoverflow.com/questions/316238/python-float-to-decimal-conversion"">Python float to Decimal conversion</a></p>
","0","2","21","0","0","3","60021577","60021791"
"60021696","<p>IIUC for your current example you can try this:</p>

<pre><code>DataFrame[['column2','column3']]=DataFrame[['column2','column3']].bfill()
</code></pre>

<p>Output:</p>

<pre><code> column1  column2   column3
0   0.0     0.0     0.0
1   NaN     0.0     0.0
2   NaN     2.0     0.0
3   1.0     2.0     5.0
4   NaN     2.0     5.0
5   NaN     4.0     5.0
6   2.0     4.0     10.0
7   NaN     4.0     10.0
8   NaN     6.0     10.0
9   3.0     6.0     15.0
10  NaN     6.0     15.0
11  NaN     8.0     15.0
12  4.0     8.0     20.0
13  NaN     8.0     20.0
14  NaN     NaN     20.0
</code></pre>

<p>then remove the <code>NaN</code> :</p>

<pre><code>DataFrame.dropna(inplace=True)
</code></pre>

<p>Outpt:</p>

<pre><code> column1  column2   column3
0   0.0     0.0     0.0
3   1.0     2.0     5.0
6   2.0     4.0     10.0
9   3.0     6.0     15.0
12  4.0     8.0     20.0
</code></pre>
","1","1","2271","358","52","360","60021634","60021696"
"60021811","<p>You need to only subtract <code>m[i]</code> from the values in <code>n[i]</code>, but your code is subtracting <code>m[i]</code> from all elements of <code>n</code>, but then only returning the result from subtracting <code>m[2]</code> since you overwrite <code>newlist</code> in each pass through the <code>for</code> loop. Here's a list comprehension that does what you want:</p>

<pre><code>n = [[1,2,3], [2,3,4], [43,2,5]]
m = [4,5,6]

o = [[abs(v-m[i]) for v in n[i]] for i in range(len(m))]
print(o)
</code></pre>

<p>Output:</p>

<pre><code>[[3, 2, 1], [3, 2, 1], [37, 4, 1]]
</code></pre>
","0","1","116404","1598","3075","10590","60021764","60021869"
"60021869","<p>Just a pythonic list comprehension (with <code>zip</code> instead of indexes)...</p>

<pre><code>[[abs(b-x) for x in a] for a, b in zip(n, m)]
</code></pre>
","3","2","5574","625","2339","1000","60021764","60021869"
"60022145","<p>In your views:</p>

<pre><code>if request.method == ""POST"":
    ...
else:
    mini_form = MinitaskForm(
        minitask=minitask,
        data={
            ""reason"": minitask.reason,
            ""selected_choice"": minitask.selected_choice,
        },
    )
</code></pre>

<p>According to the <a href=""https://docs.djangoproject.com/en/dev/ref/forms/api/#bound-and-unbound-forms"" rel=""nofollow noreferrer"">docs</a>:</p>

<blockquote>
  <p>A Form instance is either bound to a set of data, or unbound.</p>
</blockquote>

<p>Most of the times, a form gets its data from the user through a <a href=""https://docs.djangoproject.com/en/dev/ref/request-response/#django.http.HttpRequest.POST"" rel=""nofollow noreferrer"">POST</a> request. (bound form)</p>

<p>The <a href=""https://docs.djangoproject.com/en/dev/ref/request-response/#django.http.HttpRequest.GET"" rel=""nofollow noreferrer"">GET</a> request provides the user with the form in order to fill it with data. (unbound form)</p>

<p>Therefore, through a GET request, you need to provide the user with an unbound form.</p>

<p>In your code, you declare that if the request is not POST (a GET request is not POST), then return a bound form populated with data you programmatically provide. </p>

<p>This does not make sense.</p>

<p>Chances are that if you insert a <a href=""https://docs.python.org/3/library/functions.html#breakpoint"" rel=""nofollow noreferrer""><code>breakpoint()</code></a> after <code>else</code>, render the page with <code>./manage.py runserver</code> and type in the prompt provided in the console:</p>

<p><code>minitask.reason == None</code> the result will be <code>True</code>.</p>

<p>The above, mean that you bound your form with data that contain an empty reason which is not allowed.</p>

<p>If you want to provide initial data in your <a href=""https://docs.djangoproject.com/en/dev/ref/forms/api/#attributes-of-boundfield"" rel=""nofollow noreferrer"">unbound form</a>, you can do it using <a href=""https://docs.djangoproject.com/en/dev/ref/forms/api/#django.forms.Form.initial"" rel=""nofollow noreferrer""><code>initial</code></a>:</p>

<pre><code>mini_form = MinitaskForm(
    minitask=minitask,
    initial={
        ""reason"": minitask.reason,
        ""selected_choice"": minitask.selected_choice,
    },
)
</code></pre>
","2","1","6085","3180","0","557","60021784","60022145"
"60021917","<p>Windows, Mac OS and UNIXes code new lines with differents chars.</p>

<ul>
<li>Windows uses <code>\r\n</code></li>
<li>Mac OS uses <code>\r</code></li>
<li>UNIXes use <code>\n</code></li>
</ul>

<p>if you want your program to be cross-platform, you should use <a href=""https://docs.python.org/3.7/library/os.html?highlight=linesep#os.linesep"" rel=""nofollow noreferrer""><code>os.linesep</code></a> instead of an OS-specific linebreak</p>

<hr>

<p>answering the comment:</p>

<p>Indeed on Windows, <code>\r</code> just return at the start of the line while <code>\n</code> actually starts a new line (see <a href=""https://softwareengineering.stackexchange.com/questions/29075/difference-between-n-and-r-n"">this StackExchange anwser</a> for a nice explanation).</p>

<p>I assume that, on windows, it allows you to simply write on the same line until the program exits.</p>

<p>Sadly it could work at least with some terminals on UNIXes but not necessarily on every terminals...</p>

<p>As a work around, you could probably use the <code>\b</code> character which deletes the last caracter of the line, like the <code>[backspace]</code> key.</p>
","4","1","4899","456","27","210","60021860","60021917"
"60022300","<p><strong>If you <code>truncate</code> a file<sup>1</sup> while another process has it open in <code>w</code> mode, that process will continue to write to the same offsets, making the file sparse. Low offsets will thus be read as <code>0</code>s.</strong></p>

<p>As per <a href=""https://unix.stackexchange.com/questions/346062/concurrent-writing-to-a-log-file-from-many-processes"">x11 - Concurrent writing to a log file from many processes - Unix &amp; Linux Stack Exchange</a> and <a href=""https://stackoverflow.com/questions/19667739/can-two-unix-processes-simultaneous-write-to-different-positions-in-a-single-file"">Can two Unix processes simultaneous write to different positions in a single file?</a>, each process that has a file open has its own offset in it, and a <code>ftruncate()</code> doesn't change that.</p>

<p><strong>If you want the other process to react to truncation, it needs to have it open in <code>a</code> mode.</strong></p>

<hr>

<p>Your approach has principal bugs, too. E.g. it's not atomic: you may (=will, eventually) truncate the file after the producer has added data but before you have read it so it would get lost.</p>

<p>Consider using dedicated data buffering utilities instead like <code>buffer</code> or <code>pv</code> as per <a href=""https://stackoverflow.com/questions/8554568/add-a-big-buffer-to-a-pipe-between-two-commands"">Add a big buffer to a pipe between two commands</a>.</p>

<hr>

<p><sup>1</sup><sub>Which is superfluous because <code>open(mode='w')</code> already does that. Either <code>truncate</code> or reopen, no need to do both.</sub></p>
","1","2","28324","2387","1411","4522","60021864","60022300"
"60022076","<p>This is an answer to a similar quesion which might help you.</p>

<p>Use the datetime library.</p>

<p>Loop through subset of days in august of that year.</p>

<p>Check if if it is thursday.</p>

<p><a href=""https://stackoverflow.com/questions/18424467/python-third-friday-of-a-month"">Python: third Friday of a month</a></p>

<p>Here is a solution based on one of the answers in that thread.  It is a generalized solution so you should be able to pick a month, a day of the week and the number in the month you want and get that date.</p>

<p>Note: Week days are 0 indexed starting at Monday.  So Sunday's index is 6 and monday's index is 0.  So when you feed the day_of_week into this function make sure you choose numbers between 0 and 6.</p>

<p>I have defaulted it to choose the 3rd Sunday of the month given the year.</p>

<pre><code>import datetime as dt

def get_year_day(year,month=8,day_of_week=6,num_in_month=3):
    ## set up possible ranges
    range_1 = 7*(num_in_month-1)+1
    range_2 = 7*num_in_month+1
    ## loop through possible range in the year and the month
    for i in range(range_1,range_2):
        date = dt.datetime(year=year,month=month, day=i)
        ## if we have our weekday we can break
        if date.weekday()==day_of_week:
            break
    return date

for i in range(2015,2021):

    print(i,get_year_day(i))

2015 2015-08-16 00:00:00
2016 2016-08-21 00:00:00
2017 2017-08-20 00:00:00
2018 2018-08-19 00:00:00
2019 2019-08-18 00:00:00
2020 2020-08-16 00:00:00

</code></pre>
","4","0","566","12","2","32","60021927","60022076"
"60022164","<p>Although QPainter is used to paint a widget it will not work for this case since it paints the ""MainWindow"" that is below its children as the QLabels. There are at least 2 possible solutions:</p>

<ul>
<li><p>Create a custom QLabel and detect the click and paint the circle,</p></li>
<li><p>Create a QLabel that shows a QPixmap that has the circle and move it based on the mouse information.</p></li>
</ul>

<p>In this case I will implement the second method:</p>

<pre class=""lang-py prettyprint-override""><code>import sys, cv2
from PyQt5.QtWidgets import QMainWindow, QApplication, QLabel
from PyQt5.QtGui import QImage, QPixmap, QPainter, QPen, QFont
from PyQt5.QtCore import QTimer, Qt


class MainWindow(QMainWindow):
    def __init__(self):
        super().__init__()
        self.initUI()

    def initUI(self):
        self.statusBar().showMessage(""Ready"")
        self.setGeometry(50, 50, 800, 600)
        self.setWindowTitle(""Statusbar"")
        self.vidWindow = QLabel(self)
        self.vidWindow.setGeometry(20, 20, 640, 480)
        self.maskWindow = QLabel(self)
        self.maskWindow.setGeometry(20, 20, 640, 480)
        self.maskWindow.setStyleSheet(""background-color: rgba(0,0,0,0%)"")
        font = QFont()
        font.setPointSize(18)
        font.setBold(True)
        font.setWeight(75)
        self.maskWindow.setFont(font)
        self.maskWindow.setText(""Message is on the mask Qlabel object"")
        self.msgLabel = QLabel(self)
        self.msgLabel.setGeometry(675, 300, 100, 20)

        self.marker_label = QLabel(self)

        pixmap = QPixmap(100, 100)
        pixmap.fill(Qt.transparent)

        painter = QPainter(pixmap)
        painter.setPen(QPen(Qt.green, 4, Qt.SolidLine))
        painter.drawEllipse(pixmap.rect().adjusted(4, 4, -4, -4))
        painter.end()

        self.marker_label.setPixmap(pixmap)
        self.marker_label.adjustSize()
        self.marker_label.hide()
        self.marker_label.raise_()

        self.cap = cv2.VideoCapture(0)
        self.timer = QTimer()
        self.frame_rate = 5
        self.show()
        self.start()

    def nextFrameSlot(self):
        ret, frame = self.cap.read()
        if ret == True:
            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            img = QImage(frame, frame.shape[1], frame.shape[0], QImage.Format_RGB888)
            img = img.scaled(640, 480, Qt.KeepAspectRatio)
            pix = QPixmap.fromImage(img)
            self.vidWindow.setPixmap(pix)

    def mousePressEvent(self, event):
        self.msgLabel.setText(""Mouse Clicked!"")
        if self.vidWindow.rect().contains(event.pos()):
            self.marker_label.move(event.pos() - self.marker_label.rect().center())
            self.marker_label.show()
        super().mousePressEvent(event)

    def start(self):
        rate = int(1000.0 / self.frame_rate)
        self.timer.setTimerType(Qt.PreciseTimer)
        self.timer.timeout.connect(self.nextFrameSlot)
        self.timer.start(rate)

    def closeEvent(self, event):
        if self.cap.isOpened():
            self.cap.release()
        super().closeEvent(event)


if __name__ == ""__main__"":
    app = QApplication(sys.argv)
    ex = MainWindow()
    sys.exit(app.exec_())
</code></pre>
","1","3","184341","3940","32065","41961","60021937","60022164"
"60034821","<p>That's a known PyCharm issue, please vote for the relevant ticket in the IDE's bug tracker <a href=""https://youtrack.jetbrains.com/issue/PY-39526"" rel=""nofollow noreferrer"">https://youtrack.jetbrains.com/issue/PY-39526</a></p>
","1","3","4976","1118","77","415","60021944","60034821"
"60022005","<p>You can use a list comprehension :</p>

<pre><code>x = [item for item in x if item[1] != 6]
</code></pre>
","0","1","904","133","2","157","60021978","60022005"
"60022125","<p>Since the temperature can be between 25 and 40 and out of range we probably need to calculate the duration of different intervals, so I use <a href=""https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.groupby.html"" rel=""nofollow noreferrer""><code>DataFrame.groupby</code></a> here</p>

<pre><code>l=25
h = 40
measure_range = df['Temperature'].between(l,h)
df_range = df.loc[measure_range]
groups = (~measure_range).cumsum()
intervals_df = (pd.to_datetime(df_range['Time'].astype(str))
                  .groupby(groups)
                  .agg(['first','last'])
                  .reset_index(drop=True)
                  .assign(Total_time=lambda x: x.diff(axis =1).iloc[:,-1],
                          first = lambda x: x['first'].dt.time,
                          last = lambda x: x['last'].dt.time)
                  )
print(intervals_df)
      first      last Total_time
0  09:13:00  09:13:03   00:00:03
</code></pre>

<p>in this way a row is generated in the dataframe for each time interval in which the temperature is between <code>l</code> and <code>h</code> continuously.</p>
","0","2","26109","745","224","1510","60022040","60022125"
"60022452","<p>Make sure the time column is in the right format.</p>

<pre><code>df['time'] = pd.to_timedelta(df['time'],unit='s')
</code></pre>

<p>Get the time when temp reaches 40. (Tail gives you the most recent temp. You can use head() if required). Reset index to get the diff later.</p>

<pre><code>temp_40 = df[df['temp'] == 40]['time'].tail(1)
temp_40 = temp_40.reset_index(drop = True)
</code></pre>

<p>Similarly, get the time when the temp reached 25.</p>

<pre><code>temp_25 = df[df['temp'] == 25]['time'].tail(1)
temp_25 = temp_25.reset_index(drop = True)
</code></pre>

<p>Now get the diff</p>

<pre><code>temp_40 - temp_25
</code></pre>
","3","1","31","13","0","5","60022040","60022125"
"60022897","<p>Do it step by step , <code>numpy.ptp</code> is a way to calculate the max and min different from <code>numpy</code></p>

<pre><code>df.Time=pd.Timedelta(df.Time)

s = df.Temperature.between(25,40)
out = df[s].groupby((~s).cumsum()).Time.agg(['min', 'max', np.ptp])
                 min      max      ptp
Temperature                           
10          09:13:00 09:13:03 00:00:03
</code></pre>
","1","2","252249","5881","962","22297","60022040","60022125"
"60022202","<p>Try:</p>

<pre><code>df.groupby(['Gene name','Level'], as_index=False)['Cell type'].agg(', '.join)
</code></pre>

<p>Output:</p>

<pre><code>|    | Gene name   | Level        | Cell type                                                                                                       |
|---:|:------------|:-------------|:----------------------------------------------------------------------------------------------------------------|
|  0 | CD99        | High         | hematopoietic cells                                                                                             |
|  1 | CD99        | Low          | adipocytes                                                                                                      |
|  2 | CD99        | Medium       | glandular cells                                                                                                 |
|  3 | CD99        | Not detected | glandular cells     ,  lymphoid tissue     ,  adipocytes                                                        |
|  4 | ENPP4       | High         | glandular cells                                                                                                 |
|  5 | ENPP4       | Low          | adipocytes          ,  lymphoid tissue                                                                          |
|  6 | ENPP4       | Medium       | glandular cells     ,  hematopoietic cells                                                                      |
|  7 | M6PR        | High         | adipocytes          ,  glandular cells     ,  glandular cells     ,  lymphoid tissue     ,  hematopoietic cells |
</code></pre>

<p>Update added per comments below:</p>

<pre><code>(df.groupby(['Gene name','Level'], as_index=False)['Cell type']
   .agg(','.join).set_index(['Gene name','Level'])['Cell type']
   .unstack().reset_index())
</code></pre>

<p>Output:</p>

<pre><code>| Gene name   |  High                                                                                                           |  Low                                   |  Medium                                    |  Not detected                                            |
|:------------|:----------------------------------------------------------------------------------------------------------------|:---------------------------------------|:-------------------------------------------|:---------------------------------------------------------|
| CD99        | hematopoietic cells                                                                                             | adipocytes                             | glandular cells                            | glandular cells     ,  lymphoid tissue     ,  adipocytes |
| ENPP4       | glandular cells                                                                                                 | adipocytes          ,  lymphoid tissue | glandular cells     ,  hematopoietic cells | nan                                                      |
| M6PR        | adipocytes          ,  glandular cells     ,  glandular cells     ,  lymphoid tissue     ,  hematopoietic cells | nan                                    | nan                                        | nan                                                      |
</code></pre>
","8","3","111735","6882","268","5246","60022107","60022202"
"60022212","<p>In your function, you're returning prime_factors.</p>

<p>But in your test, you're not using that return value.</p>

<p>Your prime_factor value in your test is never assigned, so it remains an empty list.</p>
","4","2","640","117","5","68","60022139","60022212"
"60022169","<p>Filter out character '-'-containing lines from your read-in lines:</p>

<pre><code>filtered_lines = [x for x in content if '-' not in x]
</code></pre>
","0","4","6047","467","19","531","60022157","60022273"
"60022210","<p>I'd filter out while reading the file, not collect the unwanted lines in the first place.</p>

<pre><code>def read_from_file(filename):
    with open(filename) as file:
        content = [line for line in file if '-' not in line]
</code></pre>

<p>Also note that the <code>'filename'</code> in your <code>open('filename', 'r')</code> is wrong and that the <code>'r'</code> is unnecessary, so I fixed/removed that.</p>
","0","2","5574","625","2339","1000","60022157","60022273"
"60022273","<p>Gwang-Jin Kim and Heap Overflow answers are both 100% right, but, I always feel that using the tools that Python give you to be a plus one, so here is a solution using the built-in <a href=""https://docs.python.org/3/library/functions.html#filter"" rel=""nofollow noreferrer""><code>filter()</code></a> function:</p>

<pre class=""lang-py prettyprint-override""><code>list(filter(lambda line: ""-"" not in line, file.splitlines()))
</code></pre>

<hr>

<pre class=""lang-py prettyprint-override""><code>def read_from_file(filename):
    with open(filename, ""r"") as file:
        content = filter(lambda line: ""-"" not in line, file.readlines())

    return list(content)
</code></pre>

<hr>

<p>Here is a more verbose, yet more efficient solution:</p>

<pre><code>def read_from_file(filename):

    content = []
    with open(filename, ""r"") as file:
        for line in file:
            if ""-"" not in line:
                content.append(line)

    return content
</code></pre>
","4","1","4588","211","39","464","60022157","60022273"