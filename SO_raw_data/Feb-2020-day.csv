Id,Body,CommentCount,LastEditDate,Score,Reputation,UpVotes,DownVotes,Views,QId,QAcceptedAnswerId,QBody
"60026924","<p>You might simplify your piece to make it more efficient:</p>

<pre><code>leaves = set()
leaves.update(*graph.values())
leaves -= graph.keys()
</code></pre>
","2","","0","1678","131","50","109","60012940","60026924","<p>Given a structure like the following:</p>

<pre><code>graph = {

    # c1 is root node, graph is directed, c1 is source/root node
    'c1': ['c2', 'c3'],
    'c2': ['c4']

}

      c1
      /\
     /  \ 
    c2   c3
   /
  /
c4
</code></pre>

<p>What would be a general-purpose algorithm to find all the leafs on the graph? My first thought was:</p>

<pre><code># values in the 'from' section, that don't have a 'to' entry
set(itertools.chain(*graph.values())) - set(graph.keys())
# {'c3', 'c4'}
</code></pre>

<p>Is this the proper way to do it? What would be some other approaches to determine if something is a leaf or not?</p>
"
"60013028","<p>Use <a href=""https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html"" rel=""nofollow noreferrer"">Pandas</a>.</p>

<p>Like this,</p>

<pre><code>import pandas as pd
</code></pre>

<p>I made a file from your provided data and imported,</p>

<pre><code>df = pd.read_csv('rcsv.csv')

print(df.head())
</code></pre>

<p>It looks like this,</p>

<pre><code>Time  Data1  Data2  Data3
0     0     10     25    100
1     1     20     30    120
2     2     25     35    125
3     3     30     50    150
</code></pre>

<p>You get a specific element like this (second element in second column, zero indexed)</p>

<pre><code>print(df.iloc[1][1])

20
</code></pre>

<p>If you have a <a href=""https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.to_datetime.html"" rel=""nofollow noreferrer"">date and/or time</a> axis then we could approach it differently.  </p>
","0","","0","423","27","14","87","60012972","60013072","<p>I have a CSV file (<code>data.csv</code>) that looks like:</p>

<pre><code>Time,Data1,Data2,Data3
0,10,25,100
1,20,30,120
2,25,35,125
3,30,50,150
</code></pre>

<p>I want to be able to access the data for a given column at a specified time (for example: inputs of <code>Data1</code> and <code>Time: 1</code> should return <code>20</code>).</p>

<p>I tried:</p>

<pre><code>import csv

dataFile = 'data.csv'

with open(dataFile) as inputData:
    csv_input = csv.reader(inputData)
    headers = next(csv_input)
    data = list(zip(*[map(int, row) for row in csv_input]))

my_list = list(zip(data[0], data[1:]))
my_dictionary = dict(zip(headers, my_list))

print(my_dictionary['Data1'][1])
</code></pre>

<p>However, this returns:</p>

<pre><code>(25, 30, 35, 50)
</code></pre>

<p>I would instead like to return:</p>

<pre><code>20
</code></pre>

<p>How can I update my code to achieve this?</p>
"
"60013049","<p>Solution without <code>pandas</code>:</p>

<pre><code>import csv

dataFile = 'data.csv'

with open(dataFile) as inputData:
    csv_input = csv.reader(inputData)
    i = zip(next(csv_input), zip(*csv_input))
    data, (_, times) = {}, next(i)
    for k, line in i:
        for t, l in zip(times, line):
            data.setdefault(k, {}).setdefault(t, {})
            data[k][int(t)] = l

print(data['Data1'][1])
</code></pre>

<p>Prints:</p>

<pre><code>20
</code></pre>
","0","","0","67907","1966","35","5948","60012972","60013072","<p>I have a CSV file (<code>data.csv</code>) that looks like:</p>

<pre><code>Time,Data1,Data2,Data3
0,10,25,100
1,20,30,120
2,25,35,125
3,30,50,150
</code></pre>

<p>I want to be able to access the data for a given column at a specified time (for example: inputs of <code>Data1</code> and <code>Time: 1</code> should return <code>20</code>).</p>

<p>I tried:</p>

<pre><code>import csv

dataFile = 'data.csv'

with open(dataFile) as inputData:
    csv_input = csv.reader(inputData)
    headers = next(csv_input)
    data = list(zip(*[map(int, row) for row in csv_input]))

my_list = list(zip(data[0], data[1:]))
my_dictionary = dict(zip(headers, my_list))

print(my_dictionary['Data1'][1])
</code></pre>

<p>However, this returns:</p>

<pre><code>(25, 30, 35, 50)
</code></pre>

<p>I would instead like to return:</p>

<pre><code>20
</code></pre>

<p>How can I update my code to achieve this?</p>
"
"60013070","<p>You do not need to load the immense Panda library to read a CSV file.Python provides modules for this:</p>

<pre class=""lang-py prettyprint-override""><code>
import csv
import collections

filename = ""data_80.csv""


def read_csv(filename):
    columns = collections.defaultdict(list)
    with open(filename, 'rt') as file:
        rows = csv.DictReader(file)
        for row in rows:
            for key, val in row.items():
                columns[key].append(val)
    return dict(columns)  

data = read_csv(filename)

print(data) # data is a dictionary of list
{
'Time': ['0', '1', '2', '3'], 
'Data1': ['10', '20', '25', '30'], 
'Data2': ['25', '30', '35', '50'], 
'Data3': ['100', '120', '125', '150']
}

# You just can do 
print(data['Data1'][0])
</code></pre>
","0","2020-02-01 00:55:41","2","695","55","5","87","60012972","60013072","<p>I have a CSV file (<code>data.csv</code>) that looks like:</p>

<pre><code>Time,Data1,Data2,Data3
0,10,25,100
1,20,30,120
2,25,35,125
3,30,50,150
</code></pre>

<p>I want to be able to access the data for a given column at a specified time (for example: inputs of <code>Data1</code> and <code>Time: 1</code> should return <code>20</code>).</p>

<p>I tried:</p>

<pre><code>import csv

dataFile = 'data.csv'

with open(dataFile) as inputData:
    csv_input = csv.reader(inputData)
    headers = next(csv_input)
    data = list(zip(*[map(int, row) for row in csv_input]))

my_list = list(zip(data[0], data[1:]))
my_dictionary = dict(zip(headers, my_list))

print(my_dictionary['Data1'][1])
</code></pre>

<p>However, this returns:</p>

<pre><code>(25, 30, 35, 50)
</code></pre>

<p>I would instead like to return:</p>

<pre><code>20
</code></pre>

<p>How can I update my code to achieve this?</p>
"
"60013072","<p>Keeping part posters original software</p>

<pre><code>import csv

dataFile = 'data.csv'

with open(dataFile) as inputData:
    csv_input = csv.reader(inputData)
    headers = next(csv_input)
    data = list(zip(*[map(int, row) for row in csv_input]))
</code></pre>

<p>Modification, dicitonary is simply:</p>

<pre><code>my_dictionary = dict(zip(headers, data))

print(my_dictionary ['Data1'][1])
&gt;&gt;&gt; 20
</code></pre>
","0","","1","10876","714","1","925","60012972","60013072","<p>I have a CSV file (<code>data.csv</code>) that looks like:</p>

<pre><code>Time,Data1,Data2,Data3
0,10,25,100
1,20,30,120
2,25,35,125
3,30,50,150
</code></pre>

<p>I want to be able to access the data for a given column at a specified time (for example: inputs of <code>Data1</code> and <code>Time: 1</code> should return <code>20</code>).</p>

<p>I tried:</p>

<pre><code>import csv

dataFile = 'data.csv'

with open(dataFile) as inputData:
    csv_input = csv.reader(inputData)
    headers = next(csv_input)
    data = list(zip(*[map(int, row) for row in csv_input]))

my_list = list(zip(data[0], data[1:]))
my_dictionary = dict(zip(headers, my_list))

print(my_dictionary['Data1'][1])
</code></pre>

<p>However, this returns:</p>

<pre><code>(25, 30, 35, 50)
</code></pre>

<p>I would instead like to return:</p>

<pre><code>20
</code></pre>

<p>How can I update my code to achieve this?</p>
"
"60013091","<p>You may use</p>

<pre><code>\b(by|per)\s+(.*?)(?=\s*(?:\b(?:by|per)\b|$))
</code></pre>

<p>See the <a href=""https://regex101.com/r/RIF5X1/1"" rel=""nofollow noreferrer"">regex demo</a></p>

<p><strong>Details</strong></p>

<ul>
<li><code>\b</code> - a word boundary</li>
<li><code>(by|per)</code> - Group 1: <code>by</code> or <code>per</code> words</li>
<li><code>\s+</code> - 1+ whitespaces</li>
<li><code>(.*?)</code> - Group 2: any zero or more chars other than line break chars, as few as possible up to the first occurrence of...</li>
<li><code>(?=\s*(?:\b(?:by|per)\b|$))</code> - a sequence of

<ul>
<li><code>\s*</code> - 0+ whitespaces</li>
<li><code>(?:\b(?:by|per)\b|$)</code> - either of

<ul>
<li><code>\b(?:by|per)\b</code> - <code>by</code> or <code>per</code> whole words</li>
<li><code>|</code> - or</li>
<li><code>$</code> - end of string.</li>
</ul></li>
</ul></li>
</ul>
","0","","0","477916","18508","53879","62572","60013016","60013091","<p>I would like a regex to match all characters after a certain word appear, and stop matching after if this same word appears (or if the expression ends). For example if I want to match every character after ""by"" or ""per"" and stop when ""by"" or ""per"" appears again:</p>

<ul>
<li>Order my clothes by color and by size => ['color and', 'size']</li>
<li>You much do you spend per week and per category? => ['week and', 'category?']</li>
</ul>

<p>So far, I have done the following:</p>

<pre><code>(by|per)\s(\w+)
</code></pre>

<p>But only gives me one word</p>
"
"60013126","<p>I believe it is because some diacritic characters in Unicode have duplicates. That is, while some characters appear identical, they may be different characters with different codes. Try <code>'á'.encode()</code> once by writing <code>á</code> and once again by copy-pasting as you did. If the bytes look different, that's because they are different characters that look identical.</p>
","2","","1","1525","43","4","59","60013043","60016032","<p>Suppose I have the following files in <code>path</code> , which is in my Google drive that is connected to a Python 3 Colab notebook:</p>

<p>(Here, the # line represents the output)</p>

<pre><code>ls = os.listdir(path)
print (ls)
# ['á.csv', 'b.csv']
</code></pre>

<p>Every seems ok, but if I write </p>

<pre><code>'á.csv' in ls
# False
</code></pre>

<p>But should returns True. However, if I repeat the last code, but instead of writing 'á.csv' I copy-paste it manually from <code>print (ls)</code>, it returns True.</p>

<p>Thanks</p>

<p>ps: The problem is not exactly with that filename, is with several filename wich contains special characters (namely í, á, é, ó, ñ)</p>
"
"60016032","<p>You can normalize the file list before comparing them.</p>

<pre class=""lang-py prettyprint-override""><code>from unicodedata import normalize
ls = [normalize('NFC', f) for f in os.listdir(path)]
# compare
normalize('NFC', 'á.csv') in ls
# or just 'á.csv' in ls
</code></pre>
","1","","1","23288","1366","13","1990","60013043","60016032","<p>Suppose I have the following files in <code>path</code> , which is in my Google drive that is connected to a Python 3 Colab notebook:</p>

<p>(Here, the # line represents the output)</p>

<pre><code>ls = os.listdir(path)
print (ls)
# ['á.csv', 'b.csv']
</code></pre>

<p>Every seems ok, but if I write </p>

<pre><code>'á.csv' in ls
# False
</code></pre>

<p>But should returns True. However, if I repeat the last code, but instead of writing 'á.csv' I copy-paste it manually from <code>print (ls)</code>, it returns True.</p>

<p>Thanks</p>

<p>ps: The problem is not exactly with that filename, is with several filename wich contains special characters (namely í, á, é, ó, ñ)</p>
"
"60014046","<p>Can you provide the <code>model.fit</code> call? Here is a working set of code. Working, meaning it does not raise errors using tensorflow 2.0 or 2.1.</p>

<pre class=""lang-py prettyprint-override""><code>import numpy as np
import tensorflow as tf

model = tf.keras.models.Sequential([
  #tf.keras.layers.Flatten(input_shape=(10, 1)),
  tf.keras.layers.Dense(128, activation='relu'),
  tf.keras.layers.Dropout(0.2),
  tf.keras.layers.Dense(2, activation='softmax')
])

model.compile(
    optimizer='adam',
    loss='categorical_crossentropy',
    metrics=['accuracy'])

# Generate fake data.
x = np.ones([10, 1], dtype=np.float32)
y = np.ones([10, 2], dtype=np.float32)

# Train the model, providing features and labels.
model.fit(x, y)
</code></pre>

<p>The error you are getting could be because you are not providing <code>y</code> to <code>model.fit</code>.</p>
","0","","0","10363","2079","274","1014","60013061","60014046","<p>Im running a simple neural network interface.</p>

<pre><code>model = tf.keras.models.Sequential([
  #tf.keras.layers.Flatten(input_shape=(10, 1)),
  tf.keras.layers.Dense(128, activation='relu'),
  tf.keras.layers.Dropout(0.2),
  tf.keras.layers.Dense(2, activation='softmax')
])
</code></pre>

<p>With a given loss function:</p>

<pre><code>          model.compile(optimizer='adam',
          loss='categorical_crossentropy',
          metrics=['accuracy'])
</code></pre>

<p>Feeding in a tensor of shape [10,1], that means values and labels.
When I fit the model i get an error:</p>

<blockquote>
  <p>output_shape = [product, shape[-1]] IndexError: list index out of
  range</p>
</blockquote>

<p>I`m using tensorflow 2.0</p>

<p>Here is the output error:</p>

<pre><code>If using Keras pass *_constraint arguments to layers.
Train on 200000 steps
Epoch 1/5
2020-02-02 12:48:13.088278: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
Traceback (most recent call last):
  File ""MLP.py"", line 121, in &lt;module&gt;
    model.fit(train, epochs=5)
  File ""/home/jacek/anaconda3/envs/alice_tf/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py"", line 727, in fit
    use_multiprocessing=use_multiprocessing)
  File ""/home/jacek/anaconda3/envs/alice_tf/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_arrays.py"", line 675, in fit
    steps_name='steps_per_epoch')
  File ""/home/jacek/anaconda3/envs/alice_tf/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_arrays.py"", line 300, in model_iteration
    batch_outs = f(actual_inputs)
  File ""/home/jacek/anaconda3/envs/alice_tf/lib/python3.7/site-packages/tensorflow_core/python/keras/backend.py"", line 3476, in __call__
    run_metadata=self.run_metadata)
  File ""/home/jacek/anaconda3/envs/alice_tf/lib/python3.7/site-packages/tensorflow_core/python/client/session.py"", line 1472, in __call__
    run_metadata_ptr)
tensorflow.python.framework.errors_impl.InvalidArgumentError: 2 root error(s) found.
  (0) Invalid argument: Expected dimension in the range [0, 0), but got -1
     [[{{node metrics/acc/ArgMax}}]]
     [[loss/mul/_59]]
  (1) Invalid argument: Expected dimension in the range [0, 0), but got -1
     [[{{node metrics/acc/ArgMax}}]]
0 successful operations.
0 derived errors ignored.
</code></pre>
"
"60013154","<p>I'm not sure if I understood correctly, but if youwant to return multiple variables you can do:</p>

<pre><code>def foo():
    return a, b

c, d = foo()
</code></pre>

<p>Based on the sample code you gave, you're calling the function incorrectly. Try this:</p>

<pre><code>def main():
    M = Mandelbrot(-2.025,0.6,-1.125,1.125,255,200)  
    #setting parameters for the iteration
    generated_set, counts = M.parameters()  #storing  the list of mandelbrot set coordinates in complex plane
    M.display(generated_set)  #graphically 
displaying the generated mandelbrot set 

main()      
</code></pre>

<p>The reason is that <code>M</code> is an instance of the Mendelbrot class. You don't pass M to the function, you use it to call it instead.</p>
","3","2020-02-01 01:27:45","3","3322","293","58","422","60013125","60013154","<p>I am trying to calculate the values of 2 variables in one method and then return them. Then use the returned values as inputs for another method which graphically displays them - the variables contain lists. I could not find any relevant information to solve this problem. Further elaboration below code snippet follows. </p>

<p>Here is the relevant code:</p>

<pre><code>import numpy as np  #importing numpy for optimised arrays
import matplotlib.pyplot as plt  # importing module to graphically display arrays 

class Mandelbrot(object):  #creating class to generate a mandelbrot set
    def __init__(self,x1,x2,y1,y2,iterations,axis_points):  #initialising the relevant parameters
        self.iterations = iterations
        self.axis_points = axis_points
        self.x1 = x1
        self.x2 = x2
        self.y1 = y1
        self.y2 = y2

    def parameters(self):  #creating method to generate a list of evenly spaced numbers to create a 2D grid, 
        xrange = np.linspace(self.x1,self.x2,self.axis_points)  #then only storing numbers which are part of the mandelbrot set
        yrange = np.linspace(self.y1,self.y2,self.axis_points)
        count = 0
        counts = []
        full_grid = []
        for i in xrange:  #looping over every coordinate in the created grid to test if it is in the mandelbrot set
            for j in yrange:
                count = 0
                z = complex(0.0,0.0)  #initialising complex number to hold the iterations inside the while loop
                z_mag = 0
                full_grid.append((complex(i,j)))
                while z_mag &lt;= 2:  #iterating until ""point-of-no-return"" thershold
                    z_mag = np.linalg.norm(z)  #optimised function to return the magnitude of the complex number
                    z =z**2 + complex(i,j)  #updating values of complex number 
                    count+=1
                    if z_mag &gt; 2: 
                        counts.append(count)
                    elif count &gt; 255:  #only adding to mandelbrot set if the number can pass a set number of iterations
                        counts.append(256)
                        break  #ending while loop to go to new coordinate on grid
        np_full_grid = np.array(full_grid)                
        return np_full_grid,counts

    def display(self):  #creating method to graphically display mandelbrot set       
        f, ax = plt.subplots()
        points = ax.scatter(self.real, self.imag, c=counts, s=1, cmap=""prism"")  #displaying filtered grid
        f.colorbar(points)  #generating colour bar from 
</code></pre>

<p>Here is my test code:</p>

<pre><code>def main():
    M = Mandelbrot(-2.025,0.6,-1.125,1.125,255,200)  #setting parameters for the iteration
    generated_set = Mandelbrot.parameters(M)  #storing the list of mandelbrot set coordinates in complex plane
    Mandelbrot.display(generated_set)  #graphically displaying the generated mandelbrot set 
main()      
</code></pre>

<p>When returning np_full_grid only and using it for the display method its all working, but I also need access to the counts list in order to correctly plot. But when I return np_full_grid and counts it becomes a tuple and the self. does not work anymore, how can I have access to both of the returned values to be used in the display method? thanks</p>
"
"60013327","<p>Although I have accepted an answer, I think this code is in a more OOP style</p>

<p>The code for the display method should be:</p>

<pre><code>def display(np_full_grid,counts):  #creating method to graphically display mandelbrot set       
        f, ax = plt.subplots()
        points = ax.scatter(np_full_grid.real, np_full_grid.imag, c=counts, s=1, cmap=""viridis"")  #displaying filtered grid
        f.colorbar(points)  #generating colour bar from 
</code></pre>

<p>The test code should be:</p>

<pre><code>def main():
    M = Mandelbrot(-2.025,0.6,-1.125,1.125,255,100)  #setting parameters for the iteration
    generated_set,counts = Mandelbrot.parameters(M)  #storing the list of mandelbrot set coordinates in complex plane and their corresponding count
    Mandelbrot.display(generated_set,counts)  #graphically displaying the generated mandelbrot set 
main()      
</code></pre>
","2","2020-02-01 15:18:58","0","217","20","0","22","60013125","60013154","<p>I am trying to calculate the values of 2 variables in one method and then return them. Then use the returned values as inputs for another method which graphically displays them - the variables contain lists. I could not find any relevant information to solve this problem. Further elaboration below code snippet follows. </p>

<p>Here is the relevant code:</p>

<pre><code>import numpy as np  #importing numpy for optimised arrays
import matplotlib.pyplot as plt  # importing module to graphically display arrays 

class Mandelbrot(object):  #creating class to generate a mandelbrot set
    def __init__(self,x1,x2,y1,y2,iterations,axis_points):  #initialising the relevant parameters
        self.iterations = iterations
        self.axis_points = axis_points
        self.x1 = x1
        self.x2 = x2
        self.y1 = y1
        self.y2 = y2

    def parameters(self):  #creating method to generate a list of evenly spaced numbers to create a 2D grid, 
        xrange = np.linspace(self.x1,self.x2,self.axis_points)  #then only storing numbers which are part of the mandelbrot set
        yrange = np.linspace(self.y1,self.y2,self.axis_points)
        count = 0
        counts = []
        full_grid = []
        for i in xrange:  #looping over every coordinate in the created grid to test if it is in the mandelbrot set
            for j in yrange:
                count = 0
                z = complex(0.0,0.0)  #initialising complex number to hold the iterations inside the while loop
                z_mag = 0
                full_grid.append((complex(i,j)))
                while z_mag &lt;= 2:  #iterating until ""point-of-no-return"" thershold
                    z_mag = np.linalg.norm(z)  #optimised function to return the magnitude of the complex number
                    z =z**2 + complex(i,j)  #updating values of complex number 
                    count+=1
                    if z_mag &gt; 2: 
                        counts.append(count)
                    elif count &gt; 255:  #only adding to mandelbrot set if the number can pass a set number of iterations
                        counts.append(256)
                        break  #ending while loop to go to new coordinate on grid
        np_full_grid = np.array(full_grid)                
        return np_full_grid,counts

    def display(self):  #creating method to graphically display mandelbrot set       
        f, ax = plt.subplots()
        points = ax.scatter(self.real, self.imag, c=counts, s=1, cmap=""prism"")  #displaying filtered grid
        f.colorbar(points)  #generating colour bar from 
</code></pre>

<p>Here is my test code:</p>

<pre><code>def main():
    M = Mandelbrot(-2.025,0.6,-1.125,1.125,255,200)  #setting parameters for the iteration
    generated_set = Mandelbrot.parameters(M)  #storing the list of mandelbrot set coordinates in complex plane
    Mandelbrot.display(generated_set)  #graphically displaying the generated mandelbrot set 
main()      
</code></pre>

<p>When returning np_full_grid only and using it for the display method its all working, but I also need access to the counts list in order to correctly plot. But when I return np_full_grid and counts it becomes a tuple and the self. does not work anymore, how can I have access to both of the returned values to be used in the display method? thanks</p>
"
"60031662","<p>Look in the API docs for <a href=""https://discordpy.readthedocs.io/en/latest/ext/commands/api.html?highlight=has_permissions#discord.ext.commands.has_role"" rel=""nofollow noreferrer"">discord.ext.commands.has_role()</a> and <a href=""https://discordpy.readthedocs.io/en/latest/ext/commands/api.html?highlight=has_permissions#discord.ext.commands.cooldown"" rel=""nofollow noreferrer"">discord.ext.commands.cooldown()</a><br>
Both can be used as <a href=""https://wiki.python.org/moin/PythonDecorators"" rel=""nofollow noreferrer"">decorators</a></p>
","0","","0","593","66","0","48","60013135","60031662","<p>How would you make a command that only people with a certain role can use, has a 5 hour cooldown per user, and the command takes a line from a .txt file and dms that string to the user that ran the command, and deletes it from the .txt file?</p>

<p>Edit: Sorry im new to this, i only started learning yesterday and im still dumb
If you can and want to help me please add me on discord ParrotSecurity9#0175</p>
"
"60013793","<p>In your TodoList model you do not have due_Date field thats why you are getting this error: The value of 'list_display[2]' refers to 'due_date', which is not a callable.
list_display in admin takes your model's field name only.
I dont know why you are using due_date which is not present in your model.</p>
","1","","2","393","34","1","45","60013141","60013793","<p>I am trying to make a todo-app in Django. It was going well until I get the following error:</p>

<p>: (admin.E108) The value of 'list_display[2]' refers to 'due_date', which is not a callable, an attribute of 'TodoListAdmin', or an attribute or method on 'todolist.TodoList'.</p>

<p>The models file:</p>

<pre><code>from django.db import models
from django.utils import timezone
# Create your models here.

class Category(models.Model): #The Category table name that inherits models.Model
    name = models.CharField(max_length=100)#Like a varchar

    class Meta:
        verbose_name = (""Category"")
        verbose_name_plural = (""Categories"")

    def __str__(self):
        return self.name #name to be shown when called(Whatever tf that means)

class TodoList(models.Model): #Todolist able that inherits models.Model
    title = models.CharField(max_length=250) #This is apparently a varchar
    content = models.TextField(blank=True) #A text field
    created = models.DateField(default=timezone.now().strftime(""%Y-%m-%d"")) #Presents a date.
    category = models.ForeignKey(Category, on_delete=models.PROTECT, default=""general"") #A foreignkey.

    class Meta:
        ordering = [""-created""] #ordering by the created field.

    def __str__(self):
        return self.title #Name to be sown when called.

</code></pre>

<p>The admin file:</p>

<pre><code>from django.contrib import admin
from . import models
# Register your models here.
class TodoListAdmin(admin.ModelAdmin):
    list_display = (""title"", ""created"", ""due_Date"")

class CategoryAdmin(admin.ModelAdmin):
    list_display = (""name"",)

admin.site.register(models.TodoList, TodoListAdmin)
admin.site.register(models.Category, CategoryAdmin)

</code></pre>

<p>The views file:</p>

<pre><code>from django.shortcuts import render,redirect
from .models import TodoList, Category
# Create your views here.
def index(request): #the index-view.
    todos = TodoList.objects.all() # querying all todos with the object manager.
    categories = Category.objects.all()#Gets all categories, using the object-manager.
    if request.method == ""POST"": #Checks if the request-method is a POST
        if ""taskAdd"" in request.POST: #Checks if there is a request to add a todo
            title = request.POST[""description""] #Title
            date = str(request.POST[""date""]) #date
            category = request.POST[""category_select""] #category
            content = title + ""--"" + date + """" + category #Adds the previously defined variables together to form the content-variable.
            Todo = TodoList(title=title, content=content, due_date=date, category=Category.objects.get(nae=category))
            Todo.save() #saving the todo
            return redirect(""/"") #Reloads the page

        if ""taskDelete"" in request.POST: #Checks if there is a request to delete a todo.
            checklist = request.POST[""checkedbox""] #checked todos to be deleted.
            for todo_id in checkedlist:
                todo = TodoList.objects.get(id=int(todo_id)) #gets id of todo.
                todo.delete() #deletes the todo in question.
        return render(request, ""index.html"", {""todos"" : todos, ""categories"":categories})

</code></pre>

<p>I don't actually know if any of these are relevant, so please let me know if there is anything else you might need to know. As you can probably tell, I am pretty new to both Django and this website. Thanks in advance.</p>
"
"60014051","<p>You can use a <strong>waiter</strong>:</p>

<pre class=""lang-py prettyprint-override""><code>waiter = client.get_waiter('db_cluster_snapshot_available')
</code></pre>

<blockquote>
  <p>Polls <code>RDS.Client.describe_db_cluster_snapshots()</code> every 30 seconds until a successful state is reached. An error is returned after 60 failed checks.</p>
</blockquote>

<p>See: <a href=""https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/rds.html#RDS.Waiter.DBClusterSnapshotAvailable"" rel=""nofollow noreferrer"">class RDS.Waiter.DBClusterSnapshotAvailable</a></p>
","0","","2","161426","2680","33","15860","60013146","60014051","<p>so I'm scheduling an AWS python job (through AWS Glue Python shell) that is supposed to clone a MySQL RDS database (best way to take a snapshot and restore?) and perform sql queries on the database. I have the boto3 library on the Python Shell and an SQL Python Library I loaded. I have this code currently</p>

<pre><code>import boto3
client = boto3.client('rds')
# Create a snapshot of the database
snapshot_response = client.create_db_snapshot(
    DBSnapshotIdentifier='snapshot-identifier',
    DBInstanceIdentifier='instance-db',
)

# Restore db from snapshot
restore_response = client.restore_db_instance_from_db_snapshot(
    DBInstanceIdentifier = 'restored-db',
    DBSnapshotIdentifier = 'snapshot-identifier',
)

# Code that will perform sql queries on the restored-db database.
</code></pre>

<p>However, the <code>client.restore_db_instance_from_db_snapshot</code> fails because it says the snapshot is being created. So I understand that this means these calls are asynchronous. But I am not sure how to get this snapshot restore to work (either by making them synchronous - not a good idea?) or by some other way. Thanks for the help in advance :).</p>
"
"60013609","<p>You are creating an oval one pixel wide and one pixel tall. What you see is the color of the oval outline. With only one pixel there isn't enough space to draw both the outline and an interior. </p>

<p>You can either set the <code>outline</code> attribute to the same color as the fill color, or set the outline width (<code>width</code> attribute) to zero. </p>

<p>Here is an example that shows two different blocks of 1-pixel ovals. One has the default outline width of one, and the other explicitly sets the outline width to zero. Notice in the first you're seeing the outline color, and in the second you're seeing the fill color.</p>

<pre><code>import tkinter as tk
root = tk.Tk()
canvas = tk.Canvas(root, width=200, height=200, background=""black"")
canvas.pack(fill=""both"", expand=True)

for x in range(100):
    for y in range(100):
        canvas.create_oval(x, y, x, y, outline=""red"", fill=""green"")

for x in range(100, 200):
    for y in range(100, 200):
        canvas.create_oval(x, y, x, y, outline=""red"", fill=""green"", width=0)

root.mainloop()
</code></pre>

<p><a href=""https://i.stack.imgur.com/xD63h.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/xD63h.png"" alt=""enter image description here""></a></p>
","3","","1","304622","14209","14165","34310","60013156","60013609","<p>I just started learning <code>tkinter</code> by drawing a Mandelbrot set.</p>

<p>I specify a fill colour as the string <code>'#0074bf'</code>, but it is rendered as <code>black</code>.   Why is the kwarg ignored in the call <code>c.create_oval(x, y, x, y, fill = '#0074bf')</code>?</p>

<pre><code>from tkinter import *

# Some globals
SIZE = 4
WIDTH = 600
HEIGHT = 600
ratio = (WIDTH / SIZE, HEIGHT / SIZE)
zmin = -SIZE / 2 - (SIZE / 2) * 1j
zmax = SIZE / 2 + (SIZE / 2) * 1j
ESCAPE_RADIUS = 4
max_iterations = 256

# Create the window with Canvas
master = Tk()
c = Canvas(master, width = WIDTH, height = HEIGHT)
c.pack()

# Define a function to iterate; here, the classic Mandelbrot set function, z -&gt; z^2 + c
f =  lambda z, c : z * z + c

def iterate(pixel):
    """"""
    Given a pixel (as a complex number x + iy) return the
    number of iterations it takes to escape,
    or the final count if it doesn't.
    """"""
    z0 = px_to_cx(pixel)
    z = z0
    num_iterations = 0
    while abs(z) &lt; ESCAPE_RADIUS and num_iterations &lt; max_iterations:
        z = f(z, z0)
        num_iterations += 1
    return num_iterations - 1

def px_to_cx(pixel):
    return (pixel.real - WIDTH / 2) / ratio[0] + ((pixel.imag - HEIGHT / 2) / ratio[1]) * 1j

for y in range(HEIGHT):
    for x in range(WIDTH):
        num = iterate(x + y * 1j)
        if  num &lt; max_iterations / 2:
            # Here, the fill argument I supply seems to be ignored:
            c.create_oval(x, y, x, y, fill = '#0074bf')

mainloop()
</code></pre>
"
"60013333","<p>At first glance it looks like because your <code>location=i</code> is not indented inside your if statement so it is getting set to the latest <code>i</code> on each iteration of the for loop. Let me know if this helps.</p>

<pre><code>def search_query(person_infos):
  if answer == '3':
    search_query = input('Who would you like to find: ')
    they_are_found = False
    location = None
    for i, each_employee in enumerate(person_infos):
      if each_employee['name'] == search_query:
        they_are_found = True
        location = i
    if they_are_found:
      print('Found: ', person_infos[location]['name'], person_infos[location]['job position'], person_infos[location]['date hired'], person_infos[location]['pay per hour'])
  else:
      print('Sorry, your search query is non-existent.')
</code></pre>
","0","","0","510","6","3","40","60013290","60013333","<p>I'm kind of new to python, and I need some help. I'm making an employee list menu. My list of dictionaries is: </p>

<pre><code>person_infos = [ {'name': 'John Doe', 'age': '46', 'job position': 'Chair Builder', 'pay per hour': '14.96','date hired': '2/26/19'},

  {'name': 'Phillip Waltertower', 'age': '19', 'job position': 'Sign Holder', 'pay per hour': '10','date hired': '5/9/19'},

  {'name': 'Karen Johnson', 'age': '40', 'job position': 'Manager', 'pay per hour': '100','date hired': '9/10/01'},

  {'name': 'Linda Bledsoe', 'age': '60', 'job position': 'CEO', 'pay per hour': '700', 'date hired': '8/24/99'},

  {'name': 'Beto Aretz', 'age': '22', 'job position': 'Social Media Manager', 'pay per hour': '49','date hired': '2/18/12'}]
</code></pre>

<p>and my ""search the list of dicts input function"" is how the program is supposed to print the correct dictionary based on the name the user inputs: </p>

<pre><code>def search_query(person_infos):
  if answer == '3':
    search_query = input('Who would you like to find: ')
    they_are_found = False
    location = None
    for i, each_employee in enumerate(person_infos):
      if each_employee['name'] == search_query:
        they_are_found = True
      location = i
    if they_are_found:
      print('Found: ', person_infos[location]['name'], person_infos[location]['job position'], person_infos[location]['date hired'], person_infos[location]['pay per hour'])
  else:
      print('Sorry, your search query is non-existent.')
</code></pre>

<p>and I also have this- </p>

<pre><code>elif answer =='3':
  person_infos = search_query(person_infos)
</code></pre>

<p>This seems like a step in the right direction, but for </p>

<pre><code>search_query = input('Who would you like to find: ')
</code></pre>

<p>if I input of the names in <code>person_infos</code>, like ""John Doe,"" it just prints the last dictionary's information (no matter which specific dictionary it is, the last one in the order will always be outputted) instead of John Doe's. in this case, it would only print ""Beto Aretz's.""
Can someone please help? It's something I've been struggling on for a while and it would be awesome.
I've researched so much and I could not find something with things that I either knew how to do, or were the input search.</p>

<p>Thanks,
LR</p>
"
"60013364","<blockquote>
  <p>if 'word' is in 'minor_words' join the 'minor_words' </p>
</blockquote>

<p>No, that's not what it means.</p>

<p><code>word if word in minor_words</code> means that if <code>word</code> is in <code>minor_words</code>, we join <code>word</code> (which is a word from <code>title</code>).</p>

<p><code>else word.capitalize()</code> means that if <code>word</code> is <em>not</em> in <code>minor_words</code>, we join the capitalized word.</p>

<blockquote>
  <p>why is there <code>=''</code>?</p>
</blockquote>

<p>That provides a default value to the <code>minor_words</code> parameter. In the last example, where you call the function with only one argument:</p>

<pre><code>title_case('the quick brown fox')
</code></pre>

<p>it's equivalent to:</p>

<pre><code>title_case('the quick brown fox', '')
</code></pre>

<p>Without the default value you would get an error that not enough arguments were provided.</p>
","0","2020-02-01 02:04:11","1","586865","7069","3864","89361","60013332","60013364","<p>I want to return these results with a def in Python:</p>

<pre><code>title_case('a clash of KINGS', 'a an the of') # should return: 'A Clash of Kings'
title_case('THE WIND IN THE WILLOWS', 'The In') # should return: 'The Wind in the Willows'
title_case('the quick brown fox') # should return: 'The Quick Brown Fox'
</code></pre>

<p>the solution can be this:</p>

<pre><code>def title_case(title, minor_words=''):
    title = title.capitalize().split()
    minor_words = minor_words.lower().split()
    return ' '.join([word if word in minor_words else word.capitalize() for word in title])
</code></pre>

<p>I can not understand the last line. What I get from this is this:
if 'word' is in 'minor_words' join the 'minor_words' ==> which is not what we want. we want to join the 'title'</p>

<p>the second question is about the first line of this solution. why is there =''?
I tried to write the ""minor_words"" with and without this and the output was the same.</p>
"
"60013406","<p><strong>You might also like pandas.</strong></p>

<p>If you do a lot of stuff like this, you should check into <a href=""https://pandas.pydata.org/pandas-docs/stable/index.html"" rel=""nofollow noreferrer"">pandas</a> and its <a href=""https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.apply.html"" rel=""nofollow noreferrer"">apply functionality</a>. It can make these sorts of things as quick as: </p>

<pre class=""lang-py prettyprint-override""><code>df = df.apply(your_func)
</code></pre>

<p>It's a really powerful tool and you can sometimes make some slick and handy one-liners if that's your kind of thing. </p>
","0","2020-02-01 02:41:23","0","81","3","0","20","60013385","60013434","<p>I'm using Python 3.7.  I have an array of dicts, each array having the same keys.  For example</p>

<pre><code>arr_of_dicts = ({""st"" : ""il""}, {""st"" : ""IL""}, {""st"" : ""Il""})
</code></pre>

<p>How do I apply the same function to a certain key's value in each dict?  For example, I would like to apply the uppercase function to the value making the above</p>

<pre><code>arr_of_dicts = ({""st"" : ""IL""}, {""st"" : ""IL""}, {""st"" : ""IL""})
</code></pre>

<p>?</p>
"
"60013434","<p>Using <a href=""https://docs.python.org/3/library/functions.html#map"" rel=""nofollow noreferrer""><code>map()</code></a>, you can make your transformation function accept a key to transform and return a lambda, which acts as the mapping method. By using the previously passed key (<code>k</code>) and the passed in dictionary (<code>d</code>), you can return a new dictionary with the dictionary's value converted to uppercase:</p>

<pre><code>arr_of_dicts = ({""st"" : ""il""}, {""st"" : ""IL""}, {""st"" : ""Il""})

upper = lambda k: lambda d: {k: d[k].upper()} # your func
res = map(upper('st'), arr_of_dicts) # mapping method

print(list(res))
</code></pre>

<p><strong>Result:</strong></p>

<pre><code>[{'st': 'IL'}, {'st': 'IL'}, {'st': 'IL'}]
</code></pre>

<hr>

<p>If your dictionaries have additional keys, then you can first spread the original dictionary into your new dictionary, and then overwrite the key propery you want to transform with the uppercase version like so:</p>

<pre><code>arr_of_dicts = [{""a"": 5, ""st"" : ""il""}, {""a"": 7, ""st"" : ""IL""}, {""a"": 8, ""st"" : ""Il""}]

upper = lambda k: lambda d: {**d, k: d[k].upper()}
res = map(upper('st'), arr_of_dicts) # mapping method

print(list(res))
</code></pre>

<p><strong>Result:</strong></p>

<pre><code>[{'a': 5, 'st': 'IL'}, {'a': 7, 'st': 'IL'}, {'a': 8, 'st': 'IL'}]
</code></pre>
","3","2020-02-01 05:52:24","2","30684","4111","819","2869","60013385","60013434","<p>I'm using Python 3.7.  I have an array of dicts, each array having the same keys.  For example</p>

<pre><code>arr_of_dicts = ({""st"" : ""il""}, {""st"" : ""IL""}, {""st"" : ""Il""})
</code></pre>

<p>How do I apply the same function to a certain key's value in each dict?  For example, I would like to apply the uppercase function to the value making the above</p>

<pre><code>arr_of_dicts = ({""st"" : ""IL""}, {""st"" : ""IL""}, {""st"" : ""IL""})
</code></pre>

<p>?</p>
"
"60013596","<p>Using <code>pandas</code> library, we can use subsetting technique for a <code>DataFrame</code>.</p>

<p>Firstly, for testing purpose, I recreate the data frame with only 2 columns: <code>Borough</code> and <code>Neighbourhood</code>. I also add another row, since none of the provided data meet the condition.</p>

<pre><code>borough = [""Not assigned"", ""Not assigned"", ""Not assigned"", ""Not assigned"", ""Etobicoke"", ""Etobicoke"", ""Etobicoke"", ""Etobicoke"", ""Etobicoke"", ""Not assigned"", ""Etobicoke""]
neighbourhood = [""Not assigned"", ""Not assigned"", ""Not assigned"", ""Not assigned"", ""Kingsway Park South West"", ""Mimico NW"", ""The Queensway West"", ""Royal York South West"", ""South of Bloor"", ""Not assigned"", ""Not assigned""]

df = pd.DataFrame({""Borough"": borough,
                   ""Neighbourhood"": neighbourhood})
print(df)
</code></pre>

<p>Then we create the conditional statement of: <strong>If a cell has a valid Borough location (can be anything) and the Neighbourhood is ""Not assigned"" then the Neighborhood will be set to equal the same as the Borough.</strong></p>

<pre><code>condition = (df[""Borough""] != ""Not assigned"") &amp; (df[""Neighbourhood""] == ""Not assigned"")
print(condition)
</code></pre>

<p><code>condition</code> is a <code>boolean Series</code> which contains only <code>True</code> and <code>False</code>, useful for subsetting the dataframe.</p>

<p>Lastly, we replace the value in <code>Neighbourhood</code> column with the value in <code>Borough</code> column if the row met the <code>condition</code>.</p>

<pre><code>df.loc[condition, ""Neighbourhood""] = df.loc[condition, ""Borough""]
print(df)
</code></pre>

<p><strong>Alternatively</strong>, you can also do looping, but it's not a good practice since the computation could be slower for bigger data:</p>

<pre><code>for idx, row in df.iterrows():
    condition = (row[""Borough""] != ""Not assigned"") &amp; (row[""Neighbourhood""] == ""Not assigned"")
    if condition:
        row[""Neighbourhood""] = row[""Borough""]
</code></pre>
","0","2020-02-01 11:52:43","1","61","0","0","3","60013459","60013596","<p>I have a dataframe containing 3 columns : <code>Postcode</code>, <code>Borough</code> and <code>Neighbourhood</code> with 257 rows. You can forget about <code>Postcode</code> for the moment. </p>

<p><a href=""https://i.stack.imgur.com/z0qbY.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/z0qbY.png"" alt=""enter image description here""></a></p>

<ul>
<li>For <code>Borough</code> and <code>Neighbourhood</code>, either column could have a valid location already added or be <code>Not assigned</code> and I am trying to figure out how to do the following. <strong>If a cell has a valid Borough location (can be anything) and the Neighbourhood is ""Not assigned"" then the Neighborhood will be set to equal the same as the Borough.</strong></li>
</ul>

<p>So the logic would be something like this:</p>

<pre><code> If Neighbourhood=""Not Assigned"" AND Borough&lt;&gt;""Not Assigned"" then Neighbourhood=Borough
    Repeat for all rows
</code></pre>
"
"60013500","<p>It seems like you're setting <code>[toggleLogger = false]</code>, but not the bool to false. 
<code>[isToggled  = false]</code>. Your code is checking whether <code>isToggled == false</code>, not <code>toggleLogger</code>.</p>

<p>if you print <code>toggleLogger</code> and <code>isToggled</code> before and after you will see the difference.</p>

<p>Try something like:
<code>isToggled = !isToggled</code>     or
<code>isToggled = False</code></p>
","0","2020-02-01 02:51:03","0","16","2","0","1","60013461","60013500","<p>As the title suggests, why can't I stop a while loop by calling the function it is in with a parameter that makes the while statement false, like this?: </p>

<pre><code>def toggleLogger(isToggled):
    while isToggled: 
        if(keyboard.read_key() == ""esc""):
            toggleLogger(False)

toggleLogger(True)
</code></pre>

<p>I did some changes to the code and replaced <code>toggleLogger(False)</code> with <code>break</code> which basically solved my little problem, but it really bugs me that it doesn't work. Especially since I don't get any errors. What I don't understand is that <code>toggleLogger(True)</code> that starts the script <strong>works</strong>, but not the other one.</p>
"
"60013827","<p>You can use <code>PyAstronomy</code> in python:</p>

<pre><code>from PyAstronomy import pyas

jd = 2440000.0
print(""HJD (ra=100 deg, dec=37 deg): "", pyas.helio_jd(jd-2.4e6, 100.0, 37.0))
</code></pre>

<p>Output:</p>

<pre><code>HJD (ra=100 deg, dec=37 deg):  39999.99536863883
</code></pre>
","1","","0","484","430","29","54","60013462","60013827","<p>I'm currently working on period analysis of a variable star, where I have a long csv file consisting of many measurements of the magnitude of the star at a given time. For the program I'm using, I need the time to be in JD, however my file measures the time in HJD. Is there any relatively straightforward way to convert JD to HJD in python? I heard that there is an astropy module that will do the conversion for you, however I'm having trouble figuring out what to do. I came across astropy.time, and cant figure out how exactly it performs the conversion. </p>

<p>Does anyone know of an easy way to do this?  </p>

<p>Thanks! </p>
"
"60013741","<p>I think you want to use drop_duplicates(). Here's a simplified example:</p>

<pre><code>import pandas as pd

df = pd.DataFrame([[""foo"", ""bar""],[""foo2"", ""bar2""],[""foo3"", ""bar3""]], columns=[""first_column"", ""second_column""])
df2 = pd.DataFrame([[""foo3"", ""bar4""],[""foo4"", ""bar5""],[""foo5"", ""bar6""]], columns=[""first_column"", ""second_column""])

print(pd.concat([df, df2], ignore_index=True).drop_duplicates(subset=""first_column""))
</code></pre>

<p>Output:</p>

<pre><code>  first_column second_column
0          foo           bar
1         foo2          bar2
2         foo3          bar3
4         foo4          bar5
5         foo5          bar6
</code></pre>

<p>As you can see, the ""foo3"" row from the second dataframe gets filtered out because it is already contained in the first dataframe.</p>

<p>In your case you would use something like:</p>

<pre><code>pd.concat([stats, stats2], ignore_index=True).drop_duplicates(subset=""Player""))
</code></pre>
","0","","0","145","19","0","9","60013509","60078626","<p>I am scraping some NBA data with Python. I have the following script </p>

<pre><code>def scrape_data():
    #URL
    url = ""https://basketball-reference.com/leagues/NBA_2020_advanced.html""
    html = urlopen(url)
    soup = bs(html, 'html.parser')
    soup.findAll('tr', limit = 2)
    headers = [th.getText() for th in soup.findAll('tr', limit = 2)[0].findAll('th')]
    headers = headers[1:]
    rows = soup.findAll('tr')[1:]
    player_stats = [[td.getText() for td in rows[i].findAll('td')]for i in range(len(rows))]
    stats = pd.DataFrame(player_stats, columns=headers)
    stats.head(10)
    return stats
</code></pre>

<p>Which returns this</p>

<pre><code>                       Player Pos Age   Tm   G  ...     OBPM  DBPM   BPM  VORP
0                Steven Adams   C  26  OKC  43  ...      1.6   3.3   4.9   2.0
1                 Bam Adebayo  PF  22  MIA  47  ...      1.2   3.8   5.0   2.8
2           LaMarcus Aldridge   C  34  SAS  43  ...      1.7   0.6   2.4   1.6
3    Nickeil Alexander-Walker  SG  21  NOP  38  ...     -3.4  -2.3  -5.6  -0.4
4               Grayson Allen  SG  24  MEM  30  ...     -0.7  -2.8  -3.5  -0.2
..                        ...  ..  ..  ...  ..  ... ..   ...   ...   ...   ...
537            Thaddeus Young  PF  31  CHI  49  ...     -2.2   0.9  -1.3   0.2
538                Trae Young  PG  21  ATL  44  ...      7.8  -2.3   5.5   2.9
539               Cody Zeller   C  27  CHO  45  ...      0.0  -0.6  -0.6   0.4
540                Ante Žižić   C  23  CLE  16  ...     -2.3  -1.4  -3.6  -0.1
541               Ivica Zubac   C  22  LAC  48  ...      0.4   2.3   2.7   1.0
</code></pre>

<p>I want to scrape a second url, where the table is formatted the exact same, and append the player's stats from this table to the other one, if that makes sense. The problem is, on the second url, there will be a few stats that are on both tables. I don't want to add these in again when I'm ""merging"" the two tables> How do I go about this?</p>
"
"60078626","<p>Your doing a ton of work to put a <code>&lt;table&gt;</code> tag into a table. Let pandas do that for you (it uses BeautifulSoup under the hood). Then to merge, there's 2 ways you can do it:</p>

<p>1) Make one of the dataframes only have what is not contained in the other (However, keep columns that you will do the merge on).</p>

<p>2) Drop columns from the second dataframe that are in the dataframe (again, make sure to not drop the columns you will do the merge on.</p>

<pre><code>import pandas as pd

def scrape_data(url):
    stats = pd.read_html(url)[0]
    return stats


df1 = scrape_data(""https://basketball-reference.com/leagues/NBA_2020_advanced.html"")
df1 = df1[df1['Rk'] != 'Rk']

df2 = scrape_data(""https://basketball-reference.com/leagues/NBA_2020_per_poss.html"")
df2 = df2[df2['Rk'] != 'Rk']

uniqueCols = [ col for col in df2.columns if col not in df1.columns ]

# Below will do the same as above line
#uniqueCols = list(df2.columns.difference(df1.columns))

df2 = df2[uniqueCols + ['Player', 'Tm']]

df = df1.merge(df2, how='left', on=['Player', 'Tm'])
</code></pre>

<p>OR</p>

<pre><code>import pandas as pd

def scrape_data(url):
    stats = pd.read_html(url)[0]
    return stats


df1 = scrape_data(""https://basketball-reference.com/leagues/NBA_2020_advanced.html"")
df1 = df1[df1['Rk'] != 'Rk']

df2 = scrape_data(""https://basketball-reference.com/leagues/NBA_2020_per_poss.html"")
df2 = df2[df2['Rk'] != 'Rk']

dropCols = [ col for col in df1.columns if col in df2.columns and col not in ['Player','Tm']]
df2 = df2.drop(dropCols, axis=1)

df = df1.merge(df2, how='left', on=['Player', 'Tm'])
</code></pre>
","0","","0","16881","862","128","1314","60013509","60078626","<p>I am scraping some NBA data with Python. I have the following script </p>

<pre><code>def scrape_data():
    #URL
    url = ""https://basketball-reference.com/leagues/NBA_2020_advanced.html""
    html = urlopen(url)
    soup = bs(html, 'html.parser')
    soup.findAll('tr', limit = 2)
    headers = [th.getText() for th in soup.findAll('tr', limit = 2)[0].findAll('th')]
    headers = headers[1:]
    rows = soup.findAll('tr')[1:]
    player_stats = [[td.getText() for td in rows[i].findAll('td')]for i in range(len(rows))]
    stats = pd.DataFrame(player_stats, columns=headers)
    stats.head(10)
    return stats
</code></pre>

<p>Which returns this</p>

<pre><code>                       Player Pos Age   Tm   G  ...     OBPM  DBPM   BPM  VORP
0                Steven Adams   C  26  OKC  43  ...      1.6   3.3   4.9   2.0
1                 Bam Adebayo  PF  22  MIA  47  ...      1.2   3.8   5.0   2.8
2           LaMarcus Aldridge   C  34  SAS  43  ...      1.7   0.6   2.4   1.6
3    Nickeil Alexander-Walker  SG  21  NOP  38  ...     -3.4  -2.3  -5.6  -0.4
4               Grayson Allen  SG  24  MEM  30  ...     -0.7  -2.8  -3.5  -0.2
..                        ...  ..  ..  ...  ..  ... ..   ...   ...   ...   ...
537            Thaddeus Young  PF  31  CHI  49  ...     -2.2   0.9  -1.3   0.2
538                Trae Young  PG  21  ATL  44  ...      7.8  -2.3   5.5   2.9
539               Cody Zeller   C  27  CHO  45  ...      0.0  -0.6  -0.6   0.4
540                Ante Žižić   C  23  CLE  16  ...     -2.3  -1.4  -3.6  -0.1
541               Ivica Zubac   C  22  LAC  48  ...      0.4   2.3   2.7   1.0
</code></pre>

<p>I want to scrape a second url, where the table is formatted the exact same, and append the player's stats from this table to the other one, if that makes sense. The problem is, on the second url, there will be a few stats that are on both tables. I don't want to add these in again when I'm ""merging"" the two tables> How do I go about this?</p>
"
"60013923","<p>I tried to <em>stay true</em> to your attempt.  Not sure I got the <em>empty lines</em> logic correct.</p>

<p>Iterate over the file till you find a line that has <code>'TIP4P'</code> in it; get the next line, split it and grab the eighth and ninth item.</p>

<pre><code>empty = False
with open(iFileName,""r"") as ifile:
    while not empty:   # keep looping till too many empty lines
        empties = 0
        line = next(ifile).strip()
        while line[13:18] != 'TIP4P':
            line = next(ifile).strip()
            #print(line)
            if not line:
               empties += 1 
            if empties &gt;= 10:
                empty = True
                break
        if empty: break
        line = next(ifile).strip()
        line = line.split()
        #print(list(enumerate(line)))
        val = line[8][:-1]
        units = line[9][1:-2]
        val = float(val)
        print('val: {} - {}'.format(val,units))
</code></pre>

<hr>

<p>It probably isn't the way I would do it. I would probably rely on the structure and find what I wanted with a regular expression.</p>

<pre><code>import re
pattern = r'TIP4P.*$\s+.*?(\d+\.\d+)\)\s\[(mol/kg)'
tip4p = re.compile(pattern,flags=re.MULTILINE)

with open(iFileName,""r"") as ifile:
    s = ifile.read()

for match in tip4p.finditer(s):
    #print(match.groups())
    val,units = match.groups()
    val = float(val)
    print('val: {} - {}'.format(val,units))
</code></pre>
","12","2020-02-01 16:35:18","0","19459","1049","1547","4170","60013524","60013923","<p>As I mentioned I am attempting to create a python script for data analysis. It is not displaying the data in the next line for the loading of the specific species which I denoted as the 8th value of the next line of the line starting with TIP4P.</p>

<pre><code>ifile = open(iFileName,""r"")
x = 0
while True:
    vals=ifile.readline().split()
    if (vals==[]):
        empties += 1
        if (empties &gt; 10):
            break
    else:
        empties = 0
       # print vals
        try:
            if (vals[0]==""(TIP4P)""):
              next(vals[0]==""absolute"")
              x = float(vals[8].rstrip("")""))
              print x
        except:
            pass
print p, ""\t"", x
</code></pre>

<p>I have attached an image of the data as well. This an attempt at specify a working script which I placed below.</p>

<pre><code>ifile = open(iFileName,""r"")
    x = 0
    while True:
        vals=ifile.readline().split()
        if (vals==[]):
            empties += 1
            if (empties &gt; 10):
                break
        else:
            empties = 0
           # print vals
            try:
                if (vals[0]==""absolute""):
                    x = float(vals[8].rstrip("")""))
                    print x
            except:
                pass
    print p, ""\t"", x

</code></pre>

<pre><code>oadings per component:
----------------------------------------------------------------------------------------------------------------------------------------------------
Component 0 (TIP4P), current number of integer/fractional/reaction molecules: 28/0/0 (avg.  28.00000), density:  47.96742 (avg.  47.96742) [kg/m^3]
    absolute adsorption:   3.50000 (avg.   3.50000) [mol/uc],   2.0371090732 (avg.   2.0371090732) [mol/kg],  38.7523740627 (avg.  38.7523740627) [mg/g]
                          45.6597133610 (avg.  45.6597133610) [cm^3 STP/g],   56.5172296926 (avg.  56.5172296926) [cm^3 STP/cm^3]
    excess adsorption:     3.5000000000 (avg.   3.5000000000) [mol/uc],   2.0371090732 (avg.   2.0371090732) [mol/kg],  38.7523740627 (avg.  38.7523740627) [mg/g]
                          45.6597133610 (avg.  45.6597133610) [cm^3 STP/g],   56.5172296926 (avg.  56.5172296926) [cm^3 STP/cm^3]
Component 1 (CO2), current number of integer/fractional/reaction molecules: 3/0/0 (avg.   5.25834), density:  11.88973 (avg.  20.84008) [kg/m^3]
    absolute adsorption:   0.37500 (avg.   0.65729) [mol/uc],   0.2182616864 (avg.   0.3825646976) [mol/kg],   9.6055876881 (avg.  16.8364810584) [mg/g]
                           4.8921121458 (avg.   8.5747958536) [cm^3 STP/g],    6.0554174671 (avg.  10.6138140420) [cm^3 STP/cm^3]
    excess adsorption:     0.3741837232 (avg.   0.5327501133) [mol/uc],   0.2177865878 (avg.   0.3100771684) [mol/kg],   9.5846788380 (avg.  13.6463411439) [mg/g]
                           4.8814632982 (avg.   6.9500621330) [cm^3 STP/g],    6.0422364083 (avg.   8.6027315775) [cm^3 STP/cm^3]
----------------------------------------------------------------------------------------------------------------------------------------------------
</code></pre>
"
"60021612","<p>Your debug output helpfully contains the following trace:</p>

<pre><code>-&gt; 1-23-0-2-0-1-0-23-0-1-2-0-1-55-131
&lt;- 1-151-1-143-240
</code></pre>

<p>Consider the following:</p>

<ul>
<li>The second byte is 23, so the correct function code was sent.</li>
<li>You actually got an ""illegal function code"" on the wire, which must have been generated by the device on purpose. You don't get a CRC error or ""illegal address"" or ""illegal value"".</li>
<li>It's possible (but I guess somewhat unlikely) that the device supports code 23, but only for some addresses.</li>
</ul>

<p>The only thing left that could have been wrong on <em>your</em> side is that the library botched the encoding of the actual request. I haven't checked the other bytes, but as <a href=""https://stackoverflow.com/questions/60013544/modbus-tk-for-modbus-rtu-read-write-multiple-registers-fn-code-23-returns-ex/60021612#comment106139591_60013544"">commented by Brits</a>, there might be a bug in modbus-tk with the encoding. It's possible that the person implementing the slave decided to respond with ""illegal function code"" to a malformed request.</p>

<p>It seems also plausible to me that they just didn't bother to implement this function code. For example, <a href=""http://www.simplymodbus.ca/FAQ.htm#FC"" rel=""nofollow noreferrer"">simplymodbus</a> doesn't even list it.</p>
","0","2020-02-01 23:00:31","2","3903","717","12","232","60013544","60022248","<p>I am using <code>modbus-tk</code> to serially communicate with a device via Modbus RTU over a RS-485 network.</p>

<p>I am trying to figure out how to use function 23, <code>READ_WRITE_MULTIPLE_REGISTERS</code>.  This is my first time using function 23.  Here is my current implementation: </p>

<pre class=""lang-py prettyprint-override""><code>response = modbus_master.execute(
    slave=SLAVE_NUM,
    function_code=cst.READ_WRITE_MULTIPLE_REGISTERS,
    starting_address=2,
    quantity_of_x=1,
    output_value=[1],
)
</code></pre>

<p>While running this command, I get the following error: <code>Modbus Error: Exception code = 1</code></p>

<p>I looked up this exception code on <a href=""https://en.wikipedia.org/wiki/Modbus#Exception_responses"" rel=""nofollow noreferrer"">Wikipedia</a>, and see:</p>

<blockquote>
  <p>Function code received in the query is not recognized or allowed by slave</p>
</blockquote>

<p><strong>Do you think this means my device truly does not support this function code?  Or do I have a syntax problem/am mis-using this function?</strong></p>

<p>I have placed my full script below.</p>

<hr>

<p><strong>Full Code Example</strong></p>

<p>Input</p>

<pre class=""lang-py prettyprint-override""><code>#!/usr/bin/env python3


import time
from collections import namedtuple
from logging import Logger

from serial import Serial
from modbus_tk.modbus_rtu import RtuMaster
import modbus_tk.defines as cst  # cst = constants
from modbus_tk.utils import create_logger


PORT = ""COM3""
SLAVE_NUM = 1
MODBUS_MASTER_TIMEOUT_SEC = 5.0

ModbusHoldingReg = namedtuple(
    ""ModbusHoldingRegister"", [""name"", ""address"", ""last_read_value"", ""to_write_value""]
)
shutdown_delay = ModbusHoldingReg(""shutdown delay"", 2, 0, None)  # sec

logger = create_logger(name=""console"")  # type: Logger

serial_ = Serial(PORT)
modbus_master = RtuMaster(serial_)
modbus_master.set_timeout(MODBUS_MASTER_TIMEOUT_SEC)
modbus_master.set_verbose(True)
# Sleep some time per [1]
# [1]: https://github.com/ljean/modbus-tk/issues/73#issuecomment-284800980
time.sleep(2.0)

# Read/write from/to multiple registers
response = modbus_master.execute(
    slave=SLAVE_NUM,
    function_code=cst.READ_WRITE_MULTIPLE_REGISTERS,
    starting_address=shutdown_delay.address,
    quantity_of_x=1,
    output_value=[1],
)  # type: tuple
print(response)
</code></pre>

<p>Output</p>

<pre class=""lang-py prettyprint-override""><code>2020-01-31 10:43:24,885 INFO    modbus_rtu.__init__     MainThread      RtuMaster COM3 is opened
2020-01-31 10:43:26,890 DEBUG   modbus.execute  MainThread      -&gt; 1-23-0-2-0-1-0-23-0-1-2-0-1-55-131
2020-01-31 10:43:31,933 DEBUG   modbus.execute  MainThread      &lt;- 1-151-1-143-240
---------------------------------------------------------------------------
ModbusError                               Traceback (most recent call last)
&lt;ipython-input-1-f42d200d6c09&gt; in &lt;module&gt;
     37     starting_address=shutdown_delay.address,
     38     quantity_of_x=1,
---&gt; 39     output_value=[1],
     40 )  # type: tuple
     41 print(response)

c:\path\to\venv\lib\site-packages\modbus_tk\utils.py in new(*args, **kwargs)
     37             ret = fcn(*args, **kwargs)
     38         except Exception as excpt:
---&gt; 39             raise excpt
     40         finally:
     41             if threadsafe:

c:\path\to\venv\lib\site-packages\modbus_tk\utils.py in new(*args, **kwargs)
     35             lock.acquire()
     36         try:
---&gt; 37             ret = fcn(*args, **kwargs)
     38         except Exception as excpt:
     39             raise excpt

c:\path\to\venv\lib\site-packages\modbus_tk\modbus.py in execute(self, slave, function_code, starting_address, quantity_of_x, output_value, data_format, expected_length)
    312                 # the slave has returned an error
    313                 exception_code = byte_2
--&gt; 314                 raise ModbusError(exception_code)
    315             else:
    316                 if is_read_function:

ModbusError: Modbus Error: Exception code = 1
</code></pre>

<hr>

<p><strong>Device Specifics</strong></p>

<ul>
<li>Device: SST Sensing's <a href=""https://www.sstsensing.com/product/oxy-lc-oxygen-sensor-interface-electronics/"" rel=""nofollow noreferrer"">OXY-LC-485</a></li>
<li>Modbus RTU, <code>9600/8-N-1</code></li>
<li><a href=""https://www.sstsensing.com/wp-content/uploads/2015/10/UG-004_OXY-LC-User-Guide.pdf"" rel=""nofollow noreferrer"">User Guide</a> (section 7.1.2.1 contains set of input registers)</li>
<li>Device is plugged into Windows machine that I run this Python script</li>
</ul>

<p><strong>Packages</strong></p>

<p>I am using Python 3.6 on Windows 10.</p>

<pre class=""lang-py prettyprint-override""><code>pyserial==3.4
modbus-tk==1.1.0
</code></pre>
"
"60022248","<p>Further to the answer from @maxy; the <a href=""http://www.modbus.org/docs/Modbus_Application_Protocol_V1_1b3.pdf"" rel=""nofollow noreferrer"">modbus spec</a> states that exception code 1 (ILLEGAL FUNCTION) means:</p>

<blockquote>
  <p>The function code received in the query is not an allowable action for
  the server (or slave). This may be because the function code is only
  applicable to newer devices, and was not implemented in the unit
  selected. It could also indicate that the server (or slave) is in the
  wrong state to process a request of this type, for example because it
  is unconfigured and is being asked to return register values.</p>
</blockquote>

<p>So, in this case, I'd say that the device does not support this command.</p>

<p>However given that another user has reported an issue with this command I thought it was worth checking the encoding:</p>

<pre class=""lang-none prettyprint-override""><code>1- Slave ID
23- Function Code
0, 2- Read Starting Address
0, 1- Quantity to Read
0, 23- Write Starting Address
0, 1 - Quantity to write
2, Write Byte Count
0,1, - Write Registers value
55,131 - CRC (have not checked)
</code></pre>

<p>This looks correct to me with one exception; it's not clear where the ""Write Starting Address"" comes from (and suspicious that it's the same as the function code). Looking at the <a href=""https://github.com/ljean/modbus-tk/blob/master/modbus_tk/modbus.py#L262"" rel=""nofollow noreferrer"">source</a>:</p>

<pre class=""lang-py prettyprint-override""><code>pdu = struct.pack(
    ""&gt;BHHHHB"",
    function_code, starting_address, quantity_of_x, defines.READ_WRITE_MULTIPLE_REGISTERS,
    len(output_value), byte_count
)
</code></pre>

<p>This looks wrong to me (<code>defines.READ_WRITE_MULTIPLE_REGISTERS</code> will always be 23). The code was changed to this in commit <a href=""https://github.com/ljean/modbus-tk/commit/dcb0a2f115d7a9d63930c9b4466c4501039880a3"" rel=""nofollow noreferrer"">dcb0a2f115d7a9d63930c9b4466c4501039880a3</a>; previously it was:</p>

<pre class=""lang-py prettyprint-override""><code>pdu = struct.pack(
    ""&gt;BHHHHB"",
    function_code, starting_address, quantity_of_x, starting_addressW_FC23,
    len(output_value), byte_count
)
</code></pre>

<p>This makes more sense to me (you need a way to pass in the address to start writing and the current interface does not seem to provide this). I have added a note re this to the <a href=""https://github.com/ljean/modbus-tk/issues/121"" rel=""nofollow noreferrer"">github issue</a>.</p>

<p>So in conclusion your issue is probably due to the device but even if the device supported the command I don't think it would work due to a bug in modbus-tk.</p>
","0","2020-02-04 01:15:53","3","3512","49","44","215","60013544","60022248","<p>I am using <code>modbus-tk</code> to serially communicate with a device via Modbus RTU over a RS-485 network.</p>

<p>I am trying to figure out how to use function 23, <code>READ_WRITE_MULTIPLE_REGISTERS</code>.  This is my first time using function 23.  Here is my current implementation: </p>

<pre class=""lang-py prettyprint-override""><code>response = modbus_master.execute(
    slave=SLAVE_NUM,
    function_code=cst.READ_WRITE_MULTIPLE_REGISTERS,
    starting_address=2,
    quantity_of_x=1,
    output_value=[1],
)
</code></pre>

<p>While running this command, I get the following error: <code>Modbus Error: Exception code = 1</code></p>

<p>I looked up this exception code on <a href=""https://en.wikipedia.org/wiki/Modbus#Exception_responses"" rel=""nofollow noreferrer"">Wikipedia</a>, and see:</p>

<blockquote>
  <p>Function code received in the query is not recognized or allowed by slave</p>
</blockquote>

<p><strong>Do you think this means my device truly does not support this function code?  Or do I have a syntax problem/am mis-using this function?</strong></p>

<p>I have placed my full script below.</p>

<hr>

<p><strong>Full Code Example</strong></p>

<p>Input</p>

<pre class=""lang-py prettyprint-override""><code>#!/usr/bin/env python3


import time
from collections import namedtuple
from logging import Logger

from serial import Serial
from modbus_tk.modbus_rtu import RtuMaster
import modbus_tk.defines as cst  # cst = constants
from modbus_tk.utils import create_logger


PORT = ""COM3""
SLAVE_NUM = 1
MODBUS_MASTER_TIMEOUT_SEC = 5.0

ModbusHoldingReg = namedtuple(
    ""ModbusHoldingRegister"", [""name"", ""address"", ""last_read_value"", ""to_write_value""]
)
shutdown_delay = ModbusHoldingReg(""shutdown delay"", 2, 0, None)  # sec

logger = create_logger(name=""console"")  # type: Logger

serial_ = Serial(PORT)
modbus_master = RtuMaster(serial_)
modbus_master.set_timeout(MODBUS_MASTER_TIMEOUT_SEC)
modbus_master.set_verbose(True)
# Sleep some time per [1]
# [1]: https://github.com/ljean/modbus-tk/issues/73#issuecomment-284800980
time.sleep(2.0)

# Read/write from/to multiple registers
response = modbus_master.execute(
    slave=SLAVE_NUM,
    function_code=cst.READ_WRITE_MULTIPLE_REGISTERS,
    starting_address=shutdown_delay.address,
    quantity_of_x=1,
    output_value=[1],
)  # type: tuple
print(response)
</code></pre>

<p>Output</p>

<pre class=""lang-py prettyprint-override""><code>2020-01-31 10:43:24,885 INFO    modbus_rtu.__init__     MainThread      RtuMaster COM3 is opened
2020-01-31 10:43:26,890 DEBUG   modbus.execute  MainThread      -&gt; 1-23-0-2-0-1-0-23-0-1-2-0-1-55-131
2020-01-31 10:43:31,933 DEBUG   modbus.execute  MainThread      &lt;- 1-151-1-143-240
---------------------------------------------------------------------------
ModbusError                               Traceback (most recent call last)
&lt;ipython-input-1-f42d200d6c09&gt; in &lt;module&gt;
     37     starting_address=shutdown_delay.address,
     38     quantity_of_x=1,
---&gt; 39     output_value=[1],
     40 )  # type: tuple
     41 print(response)

c:\path\to\venv\lib\site-packages\modbus_tk\utils.py in new(*args, **kwargs)
     37             ret = fcn(*args, **kwargs)
     38         except Exception as excpt:
---&gt; 39             raise excpt
     40         finally:
     41             if threadsafe:

c:\path\to\venv\lib\site-packages\modbus_tk\utils.py in new(*args, **kwargs)
     35             lock.acquire()
     36         try:
---&gt; 37             ret = fcn(*args, **kwargs)
     38         except Exception as excpt:
     39             raise excpt

c:\path\to\venv\lib\site-packages\modbus_tk\modbus.py in execute(self, slave, function_code, starting_address, quantity_of_x, output_value, data_format, expected_length)
    312                 # the slave has returned an error
    313                 exception_code = byte_2
--&gt; 314                 raise ModbusError(exception_code)
    315             else:
    316                 if is_read_function:

ModbusError: Modbus Error: Exception code = 1
</code></pre>

<hr>

<p><strong>Device Specifics</strong></p>

<ul>
<li>Device: SST Sensing's <a href=""https://www.sstsensing.com/product/oxy-lc-oxygen-sensor-interface-electronics/"" rel=""nofollow noreferrer"">OXY-LC-485</a></li>
<li>Modbus RTU, <code>9600/8-N-1</code></li>
<li><a href=""https://www.sstsensing.com/wp-content/uploads/2015/10/UG-004_OXY-LC-User-Guide.pdf"" rel=""nofollow noreferrer"">User Guide</a> (section 7.1.2.1 contains set of input registers)</li>
<li>Device is plugged into Windows machine that I run this Python script</li>
</ul>

<p><strong>Packages</strong></p>

<p>I am using Python 3.6 on Windows 10.</p>

<pre class=""lang-py prettyprint-override""><code>pyserial==3.4
modbus-tk==1.1.0
</code></pre>
"
"60049315","<p>Based on the rigor of @maxy's answer, then on @Brits's answer, I decided to investigate further.  The goal was to identify if the root cause was a <code>modbus-tk</code> bug, or if my device doesn't support function code 23.</p>

<p>In <a href=""https://github.com/ljean/modbus-tk/issues/121"" rel=""nofollow noreferrer"">modbus-tk Issue #121</a>, the OP mentions that <code>pymodbus</code> worked with function code 23, read/write multiple registers.</p>

<hr>

<p>So I installed <code>pymodbus==2.3.0</code>, and then gave it a whirl.  Here is the code I used:</p>

<p>Input</p>

<pre class=""lang-py prettyprint-override""><code>#!/usr/bin/env python3


import sys
import logging
from collections import namedtuple

from pymodbus.pdu import ModbusResponse, ExceptionResponse
from pymodbus.client.sync import ModbusSerialClient
from pymodbus.register_read_message import ReadWriteMultipleRegistersResponse


log = logging.getLogger()
log.addHandler(logging.StreamHandler(sys.stdout))
log.setLevel(logging.DEBUG)


ModbusHoldingReg = namedtuple(
    ""ModbusHoldingRegister"", [""name"", ""address"", ""last_read_value"", ""to_write_value""]
)

sensor_mode = ModbusHoldingReg(""sensor on, off, and standby enum"", 0, None, None)


PORT = ""COM3""
SLAVE_NUM = 1
BAUD_RATE = 9600


with ModbusSerialClient(
    method=""rtu"", port=PORT, baudrate=BAUD_RATE, strict=False
) as modbus_client:
    regs_to_write = [0, 1, 3]
    response = modbus_client.readwrite_registers(
        read_address=sensor_mode.address,
        read_count=len(regs_to_write),
        write_address=sensor_mode.address,
        write_registers=regs_to_write,
        unit=SLAVE_NUM,
    )  # type: ModbusResponse

    if response.isError():
        response: ExceptionResponse
        print(
            f""Exception!  Original function code = {response.original_code}, ""
            f""exception_code = {response.exception_code}.""
        )
    else:
        response: ReadWriteMultipleRegistersResponse
        print(f""Success!  response.registers = {response.registers}."")
</code></pre>

<p>Output</p>

<pre class=""lang-none prettyprint-override""><code>Current transaction state - IDLE
Running transaction 1
SEND: 0x1 0x17 0x0 0x0 0x0 0x3 0x0 0x0 0x0 0x3 0x6 0x0 0x0 0x0 0x1 0x0 0x3 0x5d 0xce
New Transaction state 'SENDING'
Changing transaction state from 'SENDING' to 'WAITING FOR REPLY'
Changing transaction state from 'WAITING FOR REPLY' to 'PROCESSING REPLY'
RECV: 0x1 0x97 0x1 0x8f 0xf0
Getting Frame - 0x97 0x1
Factory Response[151]
Frame advanced, resetting header!!
Adding transaction 1
Getting transaction 1
Changing transaction state from 'PROCESSING REPLY' to 'TRANSACTION_COMPLETE'
Original function code = 23, exception code = 1.
</code></pre>

<hr>

<p><strong>Conclusion</strong></p>

<p>One can see that the device responded with exception code 1, <code>Illegal Function</code>.  So I believe this device does not support function code 23.</p>

<p>I will circle back if I ever find a device that supports fn code 23.</p>
","0","2020-02-04 01:27:30","2","692","525","5","335","60013544","60022248","<p>I am using <code>modbus-tk</code> to serially communicate with a device via Modbus RTU over a RS-485 network.</p>

<p>I am trying to figure out how to use function 23, <code>READ_WRITE_MULTIPLE_REGISTERS</code>.  This is my first time using function 23.  Here is my current implementation: </p>

<pre class=""lang-py prettyprint-override""><code>response = modbus_master.execute(
    slave=SLAVE_NUM,
    function_code=cst.READ_WRITE_MULTIPLE_REGISTERS,
    starting_address=2,
    quantity_of_x=1,
    output_value=[1],
)
</code></pre>

<p>While running this command, I get the following error: <code>Modbus Error: Exception code = 1</code></p>

<p>I looked up this exception code on <a href=""https://en.wikipedia.org/wiki/Modbus#Exception_responses"" rel=""nofollow noreferrer"">Wikipedia</a>, and see:</p>

<blockquote>
  <p>Function code received in the query is not recognized or allowed by slave</p>
</blockquote>

<p><strong>Do you think this means my device truly does not support this function code?  Or do I have a syntax problem/am mis-using this function?</strong></p>

<p>I have placed my full script below.</p>

<hr>

<p><strong>Full Code Example</strong></p>

<p>Input</p>

<pre class=""lang-py prettyprint-override""><code>#!/usr/bin/env python3


import time
from collections import namedtuple
from logging import Logger

from serial import Serial
from modbus_tk.modbus_rtu import RtuMaster
import modbus_tk.defines as cst  # cst = constants
from modbus_tk.utils import create_logger


PORT = ""COM3""
SLAVE_NUM = 1
MODBUS_MASTER_TIMEOUT_SEC = 5.0

ModbusHoldingReg = namedtuple(
    ""ModbusHoldingRegister"", [""name"", ""address"", ""last_read_value"", ""to_write_value""]
)
shutdown_delay = ModbusHoldingReg(""shutdown delay"", 2, 0, None)  # sec

logger = create_logger(name=""console"")  # type: Logger

serial_ = Serial(PORT)
modbus_master = RtuMaster(serial_)
modbus_master.set_timeout(MODBUS_MASTER_TIMEOUT_SEC)
modbus_master.set_verbose(True)
# Sleep some time per [1]
# [1]: https://github.com/ljean/modbus-tk/issues/73#issuecomment-284800980
time.sleep(2.0)

# Read/write from/to multiple registers
response = modbus_master.execute(
    slave=SLAVE_NUM,
    function_code=cst.READ_WRITE_MULTIPLE_REGISTERS,
    starting_address=shutdown_delay.address,
    quantity_of_x=1,
    output_value=[1],
)  # type: tuple
print(response)
</code></pre>

<p>Output</p>

<pre class=""lang-py prettyprint-override""><code>2020-01-31 10:43:24,885 INFO    modbus_rtu.__init__     MainThread      RtuMaster COM3 is opened
2020-01-31 10:43:26,890 DEBUG   modbus.execute  MainThread      -&gt; 1-23-0-2-0-1-0-23-0-1-2-0-1-55-131
2020-01-31 10:43:31,933 DEBUG   modbus.execute  MainThread      &lt;- 1-151-1-143-240
---------------------------------------------------------------------------
ModbusError                               Traceback (most recent call last)
&lt;ipython-input-1-f42d200d6c09&gt; in &lt;module&gt;
     37     starting_address=shutdown_delay.address,
     38     quantity_of_x=1,
---&gt; 39     output_value=[1],
     40 )  # type: tuple
     41 print(response)

c:\path\to\venv\lib\site-packages\modbus_tk\utils.py in new(*args, **kwargs)
     37             ret = fcn(*args, **kwargs)
     38         except Exception as excpt:
---&gt; 39             raise excpt
     40         finally:
     41             if threadsafe:

c:\path\to\venv\lib\site-packages\modbus_tk\utils.py in new(*args, **kwargs)
     35             lock.acquire()
     36         try:
---&gt; 37             ret = fcn(*args, **kwargs)
     38         except Exception as excpt:
     39             raise excpt

c:\path\to\venv\lib\site-packages\modbus_tk\modbus.py in execute(self, slave, function_code, starting_address, quantity_of_x, output_value, data_format, expected_length)
    312                 # the slave has returned an error
    313                 exception_code = byte_2
--&gt; 314                 raise ModbusError(exception_code)
    315             else:
    316                 if is_read_function:

ModbusError: Modbus Error: Exception code = 1
</code></pre>

<hr>

<p><strong>Device Specifics</strong></p>

<ul>
<li>Device: SST Sensing's <a href=""https://www.sstsensing.com/product/oxy-lc-oxygen-sensor-interface-electronics/"" rel=""nofollow noreferrer"">OXY-LC-485</a></li>
<li>Modbus RTU, <code>9600/8-N-1</code></li>
<li><a href=""https://www.sstsensing.com/wp-content/uploads/2015/10/UG-004_OXY-LC-User-Guide.pdf"" rel=""nofollow noreferrer"">User Guide</a> (section 7.1.2.1 contains set of input registers)</li>
<li>Device is plugged into Windows machine that I run this Python script</li>
</ul>

<p><strong>Packages</strong></p>

<p>I am using Python 3.6 on Windows 10.</p>

<pre class=""lang-py prettyprint-override""><code>pyserial==3.4
modbus-tk==1.1.0
</code></pre>
"
"60073266","<p>I have the same problem but I know that my slave is compliant with Function Code 23, it is a wago 750-362.
I can read the datas but it seems the function writes to the wrong address. I do not have function code error.</p>

<p>This is the command I send:</p>

<pre><code>inputExt = master.execute(1, cst.READ_WRITE_MULTIPLE_REGISTERS, 0, 5, output_value=[32767,32767,32767,32767,0x00ff])
</code></pre>

<p>This is what I see with a wireshark capture:</p>

<pre><code>Modbus/TCP
    Transaction Identifier: 35394
    Protocol Identifier: 0
    Length: 21
    Unit Identifier: 1
Modbus
    .001 0111 = Function Code: Read Write Register (23)
    Read Reference Number: 0
    Read Word Count: 5
    Write Reference Number: 23
    Write Word Count: 5
    Byte Count: 10
    Data: 7fff7fff7fff7fff00ff
</code></pre>

<p>Why the Write reference Number, supposed to be the address where we write and the same as we read, is 23 and not 0? The read reference is OK.</p>
","2","2020-02-05 10:15:06","1","11","0","0","3","60013544","60022248","<p>I am using <code>modbus-tk</code> to serially communicate with a device via Modbus RTU over a RS-485 network.</p>

<p>I am trying to figure out how to use function 23, <code>READ_WRITE_MULTIPLE_REGISTERS</code>.  This is my first time using function 23.  Here is my current implementation: </p>

<pre class=""lang-py prettyprint-override""><code>response = modbus_master.execute(
    slave=SLAVE_NUM,
    function_code=cst.READ_WRITE_MULTIPLE_REGISTERS,
    starting_address=2,
    quantity_of_x=1,
    output_value=[1],
)
</code></pre>

<p>While running this command, I get the following error: <code>Modbus Error: Exception code = 1</code></p>

<p>I looked up this exception code on <a href=""https://en.wikipedia.org/wiki/Modbus#Exception_responses"" rel=""nofollow noreferrer"">Wikipedia</a>, and see:</p>

<blockquote>
  <p>Function code received in the query is not recognized or allowed by slave</p>
</blockquote>

<p><strong>Do you think this means my device truly does not support this function code?  Or do I have a syntax problem/am mis-using this function?</strong></p>

<p>I have placed my full script below.</p>

<hr>

<p><strong>Full Code Example</strong></p>

<p>Input</p>

<pre class=""lang-py prettyprint-override""><code>#!/usr/bin/env python3


import time
from collections import namedtuple
from logging import Logger

from serial import Serial
from modbus_tk.modbus_rtu import RtuMaster
import modbus_tk.defines as cst  # cst = constants
from modbus_tk.utils import create_logger


PORT = ""COM3""
SLAVE_NUM = 1
MODBUS_MASTER_TIMEOUT_SEC = 5.0

ModbusHoldingReg = namedtuple(
    ""ModbusHoldingRegister"", [""name"", ""address"", ""last_read_value"", ""to_write_value""]
)
shutdown_delay = ModbusHoldingReg(""shutdown delay"", 2, 0, None)  # sec

logger = create_logger(name=""console"")  # type: Logger

serial_ = Serial(PORT)
modbus_master = RtuMaster(serial_)
modbus_master.set_timeout(MODBUS_MASTER_TIMEOUT_SEC)
modbus_master.set_verbose(True)
# Sleep some time per [1]
# [1]: https://github.com/ljean/modbus-tk/issues/73#issuecomment-284800980
time.sleep(2.0)

# Read/write from/to multiple registers
response = modbus_master.execute(
    slave=SLAVE_NUM,
    function_code=cst.READ_WRITE_MULTIPLE_REGISTERS,
    starting_address=shutdown_delay.address,
    quantity_of_x=1,
    output_value=[1],
)  # type: tuple
print(response)
</code></pre>

<p>Output</p>

<pre class=""lang-py prettyprint-override""><code>2020-01-31 10:43:24,885 INFO    modbus_rtu.__init__     MainThread      RtuMaster COM3 is opened
2020-01-31 10:43:26,890 DEBUG   modbus.execute  MainThread      -&gt; 1-23-0-2-0-1-0-23-0-1-2-0-1-55-131
2020-01-31 10:43:31,933 DEBUG   modbus.execute  MainThread      &lt;- 1-151-1-143-240
---------------------------------------------------------------------------
ModbusError                               Traceback (most recent call last)
&lt;ipython-input-1-f42d200d6c09&gt; in &lt;module&gt;
     37     starting_address=shutdown_delay.address,
     38     quantity_of_x=1,
---&gt; 39     output_value=[1],
     40 )  # type: tuple
     41 print(response)

c:\path\to\venv\lib\site-packages\modbus_tk\utils.py in new(*args, **kwargs)
     37             ret = fcn(*args, **kwargs)
     38         except Exception as excpt:
---&gt; 39             raise excpt
     40         finally:
     41             if threadsafe:

c:\path\to\venv\lib\site-packages\modbus_tk\utils.py in new(*args, **kwargs)
     35             lock.acquire()
     36         try:
---&gt; 37             ret = fcn(*args, **kwargs)
     38         except Exception as excpt:
     39             raise excpt

c:\path\to\venv\lib\site-packages\modbus_tk\modbus.py in execute(self, slave, function_code, starting_address, quantity_of_x, output_value, data_format, expected_length)
    312                 # the slave has returned an error
    313                 exception_code = byte_2
--&gt; 314                 raise ModbusError(exception_code)
    315             else:
    316                 if is_read_function:

ModbusError: Modbus Error: Exception code = 1
</code></pre>

<hr>

<p><strong>Device Specifics</strong></p>

<ul>
<li>Device: SST Sensing's <a href=""https://www.sstsensing.com/product/oxy-lc-oxygen-sensor-interface-electronics/"" rel=""nofollow noreferrer"">OXY-LC-485</a></li>
<li>Modbus RTU, <code>9600/8-N-1</code></li>
<li><a href=""https://www.sstsensing.com/wp-content/uploads/2015/10/UG-004_OXY-LC-User-Guide.pdf"" rel=""nofollow noreferrer"">User Guide</a> (section 7.1.2.1 contains set of input registers)</li>
<li>Device is plugged into Windows machine that I run this Python script</li>
</ul>

<p><strong>Packages</strong></p>

<p>I am using Python 3.6 on Windows 10.</p>

<pre class=""lang-py prettyprint-override""><code>pyserial==3.4
modbus-tk==1.1.0
</code></pre>
"
"60013737","<pre><code>cols = ['date_crawled', 'ad_created', 'last_seen']
[print (autos[v].value_counts(normalize=True, dropna=False).describe()) for v in cols]
</code></pre>

<p>Does this work for you?</p>
","0","","0","800","54","1","57","60013547","60013737","<pre><code>cols = ['date_crawled', 'ad_created', 'last_seen']
for v in cols:
    autos[cols].value_counts(normalize=True, dropna=False).describe()
</code></pre>

<p>dataset = autos.</p>

<p>want to do on each of the three columns:</p>

<pre><code>{.value_counts(normalize=True, dropna=False).describe()} 
</code></pre>

<p>edit; solution compiled from multiple people</p>

<pre><code>cols = ['date_crawled', 'ad_created', 'last_seen']
for v in cols:
    temp = autos[v].value_counts(normalize=True, dropna=False).describe()
    print(temp)
</code></pre>

<p>alternate solution</p>

<pre><code>cols = ['date_crawled', 'ad_created', 'last_seen']
[print (autos[v].value_counts(normalize=True, dropna=False).describe()) for v in cols]
</code></pre>

<p>needed to change to autos[v] to make use of the for loop, and set to a variable to easily print the out the result of each loop.</p>

<p>thanks all.</p>
"
"60013635","<p>Try this basically, what it does it add the rows to a list as they are processed. This allows you to go back to the previous row if you need to update it. It only writes the output after the full input file is processed. <strong>This would not be an ideal solution if this csv is very large as this approach would use a lot of memory</strong>. </p>

<p>This will update the previous rows based on what the <code>Measurement Period</code> is. It checks to make sure that the update falls within the range of the list. For example if the second row has a <code>Measurement Period</code> of 4 you should only update the first row right not 4 rows? </p>

<p>This has the possibility of updating two rows twice aswell, for example. What if row two has a <code>Measurement Period</code> of 2 and row 3 has a <code>Measurement Period</code> of 4. The third rows <code>Rainfall Value</code> will overwrite rows 1 and 2. Does that make sense? </p>

<p>Make sure and test this out to see if it covers your scenrios. </p>

<pre><code>import csv

path = ""Sample.csv""
fields = ['Product code','Year','Month','Measurement period','Rainfall amount']
output2 = ""Sample2.csv""


with open(path,'r') as x, open(output2, 'w', newline='') as output:
    reader = csv.DictReader(x, fieldnames=fields)
    writer= csv.DictWriter(output, fieldnames=fields)
    rows = []
    for row in reader:

    try:
        if int(row['Measurement period']) &gt; 1:
            for i in range(int(row['Measurement period'])):
                if len(rows)-(i+1) &lt;= len(rows)-1 and len(rows)-(i+1) &gt;= 0:
                    rows[len(rows)-(i+1)]['Rainfall amount'] = row['Rainfall amount']
        rows.append(row)
    except ValueError:
        pass
writer.writerows(rows)`enter code here`
</code></pre>
","2","2020-02-01 11:20:09","0","510","6","3","40","60013552","60013635","<p>This is my CSV doc. :</p>

<pre><code>
Product code,Year,Month,Measurement period,Rainfall amount
1a,1962,01,0,01
1s,1962,01,1,02
1d,1962,01,0,03
1f,1962,01,0,04
1z,1962,01,0,05
1x,1962,01,0,06
1c,1962,01,3,07
1q,1962,01,0,01
1w,1962,01,0,02
1e,1962,01,0,03
1r,1962,01,0,04
1t,1962,01,4,05
1y,1962,01,0,06
1k,1962,01,0,07

</code></pre>

<p>And this is the code : </p>

<pre><code>import csv



path = r""C:\FEWS\Sample.csv""
fields = ['Product code','Year','Month','Measurement period','Rainfall amount']
output2 = r""C:\FEWS\Sample2.csv""


with open(path,'r') as x, open(output2, 'w', newline='') as output:
    reader = csv.DictReader(x, fieldnames=fields)
    writer= csv.DictWriter(output, fieldnames=fields)
    for row in reader:
        try:
            if int(row['Rainfall amount']) &gt; 1:
                Measure_period = row['Measurement period']

                for x in range(int(Measure_period) -1):
                    pass
                    # Update the previous rows
        except ValueError:
            pass
        writer.writerow(row)
</code></pre>

<p>What I am trying to do is if the Measurement period is higher than 1 and let's say it is 3 modify only rainfall amount of previous 3 rows coming before the current row and make their rainfall amount equal to current row.</p>

<p>Output should be like this : </p>

<pre><code>Product code,Year,Month,Measurement period,Rainfall amount
1a,1962,01,0,01
1s,1962,01,1,02
1d,1962,01,0,03
1f,1962,01,0,07
1z,1962,01,0,07
1x,1962,01,0,07
1c,1962,01,3,07
1q,1962,01,0,05
1w,1962,01,0,05
1e,1962,01,0,05
1r,1962,01,0,05
1t,1962,01,4,05
1y,1962,01,0,06
1k,1962,01,0,07



</code></pre>
"
"60013726","<p>You should assign it back and switch</p>

<pre><code>df = df.sort_values(by=['name', 'values'], ascending=[True, False])
</code></pre>
","0","","0","252249","5881","962","22297","60013707","60013730","<p>I am looking to sort a numerical column (desc) and a text column (asc) but it is not working as expected in pandas. </p>

<p>Here is my code:</p>

<pre><code>df.sort_values(by=['values', 'name'], ascending=[False, True])
</code></pre>

<p>The values are showing desc but the names are not in ascending order. </p>

<p>This is the desired result I am looking for:</p>

<p><a href=""https://i.stack.imgur.com/4APuP.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/4APuP.png"" alt=""enter image description here""></a></p>
"
"60013730","<p>Just change the order on how we sort the values:</p>

<pre><code>df.sort_values(by=['name', 'values'], ascending=[True, False])
</code></pre>

<p>We have to sort it by <code>name</code> first, and then <code>values</code>. Not the other way.</p>
","0","","1","61","0","0","3","60013707","60013730","<p>I am looking to sort a numerical column (desc) and a text column (asc) but it is not working as expected in pandas. </p>

<p>Here is my code:</p>

<pre><code>df.sort_values(by=['values', 'name'], ascending=[False, True])
</code></pre>

<p>The values are showing desc but the names are not in ascending order. </p>

<p>This is the desired result I am looking for:</p>

<p><a href=""https://i.stack.imgur.com/4APuP.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/4APuP.png"" alt=""enter image description here""></a></p>
"
"60014118","<p>use <code>pd.set_option('max_colwidth', &lt;width&gt;)</code> for column width &amp; <code>pd.set_option('max_rows', &lt;rows&gt;)</code> for number of rows.<br>
see <a href=""https://pandas.pydata.org/pandas-docs/stable/user_guide/options.html"" rel=""noreferrer"">https://pandas.pydata.org/pandas-docs/stable/user_guide/options.html</a></p>

<pre><code>[] pd.set_option('max_rows', 99999)
[] pd.set_option('max_colwidth', 400)
[] pd.describe_option('max_colwidth')

display.max_colwidth : int
    The maximum width in characters of a column in the repr of
    a pandas data structure. When the column overflows, a ""...""
    placeholder is embedded in the output.
    [default: 50] [currently: 400]

[] df = pd.DataFrame(d)
[] df

  name                                                                                     degree   score
0   a1  We explained to customer how correct fees (100) were charged. Account balance was too low   90
1   b2  customer was late in paying fees and we have to charge fine                                 40
2   c2  customer's credit score was too low and we have to charge higher interest rate              80
3   d3  customer complained a lot and didnt listen to our explanation. I had to escalate the call   98
</code></pre>
","0","2020-02-01 05:13:39","9","1132","71","34","145","60013721","60014118","<p>I am using Google Colab python 3.x and I have a Dataframe as below. I would like to see all cells on each row and column. How can I do this? I tried <code>pd.set_option('display.max_columns', 3000)</code> but it didn't work.</p>
<pre><code># importing pandas as pd 
import pandas as pd 
   
# dictionary of lists 
dict = {'name':[&quot;a1&quot;, &quot;b2&quot;, &quot;c2&quot;, &quot;d3&quot;], 
        'degree': [&quot;We explained to customer how correct fees (100) were charged. Account balance was too low&quot;, &quot;customer was late in paying fees and we have to charge fine&quot;, &quot;customer's credit score was too low and we have to charge higher interest rate&quot;, &quot;customer complained a lot and didnt listen to our explanation. I had to escalate the call&quot;], 
        'score':[90, 40, 80, 98]} 
  
# creating a dataframe from a dictionary  
df = pd.DataFrame(dict) 
print (df)


  name                                             degree  score
0   a1  We explained to customer how correct fees (100...     90
1   b2  customer was late in paying fees and we have t...     40
2   c2  customer's credit score was too low and we hav...     80
3   d3  customer complained a lot and didnt listen to ...     98
</code></pre>
"
"60015918","<p>Another way to display more content is to use <code>DataTable</code> to display pandas dataframe.</p>

<pre class=""lang-py prettyprint-override""><code>%load_ext google.colab.data_table
df = pd.DataFrame(dict) 
df
</code></pre>

<p>This seems to pack the data more densely and display a lot in each cell.</p>
","0","","1","23288","1366","13","1990","60013721","60014118","<p>I am using Google Colab python 3.x and I have a Dataframe as below. I would like to see all cells on each row and column. How can I do this? I tried <code>pd.set_option('display.max_columns', 3000)</code> but it didn't work.</p>
<pre><code># importing pandas as pd 
import pandas as pd 
   
# dictionary of lists 
dict = {'name':[&quot;a1&quot;, &quot;b2&quot;, &quot;c2&quot;, &quot;d3&quot;], 
        'degree': [&quot;We explained to customer how correct fees (100) were charged. Account balance was too low&quot;, &quot;customer was late in paying fees and we have to charge fine&quot;, &quot;customer's credit score was too low and we have to charge higher interest rate&quot;, &quot;customer complained a lot and didnt listen to our explanation. I had to escalate the call&quot;], 
        'score':[90, 40, 80, 98]} 
  
# creating a dataframe from a dictionary  
df = pd.DataFrame(dict) 
print (df)


  name                                             degree  score
0   a1  We explained to customer how correct fees (100...     90
1   b2  customer was late in paying fees and we have t...     40
2   c2  customer's credit score was too low and we hav...     80
3   d3  customer complained a lot and didnt listen to ...     98
</code></pre>
"
"60013814","<p><code>def avg(*args)</code> means that your function takes several arguments, but calling <code>avg(pkt)</code> passes a <em>list</em> to the function. You need to unpack that list with <code>avg(*pkt)</code> so its contents are passed individually to the function - or of course define the function as <code>def avg(args)</code> so it accepts a list as its only argument.</p>
","1","","1","247","20","0","20","60013785","60013814","<p>I have a list of user integers:</p>

<pre><code>user1 = [4,5,2,3,4]
user2 = [4,2,1,3,4,4,2]
</code></pre>

<p>I want to use *args to count avg.</p>

<pre><code>def avg(*args):
  sum=0
  for num in avg:
     sum =+ num
  result = sum/len(avg)
  return result
</code></pre>

<p>And if I call it this way:</p>

<pre><code>avg(4,5,2,3,4)
avg(4,2,1,3,4,4,2)
</code></pre>

<p>everythig is fine. Code works.
But I still need to change a code to do that. I don't understand how to use that *args.</p>

<p>For example, user put 3 int in table my code do something like that:</p>

<pre><code>avg(userTable) // and just put a 3 args in fun
</code></pre>

<p>Can someone explain me how can I do it? I need to use variable arguments for benchmark.</p>

<p>One of my attempts:</p>

<pre><code>pkt = [44,23,0,22]
def avg(*pkt):
    suma = 0
    count = len(pkt)
    for i in range(len(pkt)):
        if pkt[i] != 0:
            print(i)
            sum = sum + pkt[i]
        else:
            count = count - 1
    result= pkt[0] + pkt[1] + sum
    result= result/(count+2)
    print(result)
    return result


avg(pkt)
</code></pre>

<p>but i got an error in count line.</p>
"
"60013842","<p>I think an example is the best way to showcase <code>args</code> and <code>kwargs</code>. Notice the following:</p>

<pre class=""lang-py prettyprint-override""><code>def foo(*args):
    print(args)

foo(1, 2, 3)
</code></pre>

<p>outputs:</p>

<pre><code>(1, 2, 3)
</code></pre>

<hr>

<pre class=""lang-py prettyprint-override""><code>def bar(**kwargs):
    print(kwargs)

bar(a=1, b=2, c=3)
</code></pre>

<p>outputs:</p>

<pre><code>{'a': 1, 'b': 2, 'c': 3}
</code></pre>

<hr>

<pre class=""lang-py prettyprint-override""><code>def foobar(*args, **kwargs):
    print('args', args)
    print('kwargs', kwargs)

foobar(1, 2, 3, d=4, e=5, f=6)
</code></pre>

<p>outputs:</p>

<pre><code>args (1, 2, 3)
kwargs {'d': 4, 'e': 5, 'f': 6}
</code></pre>

<hr>

<p>In short, <code>args</code> allows functions to take any unnamed variables and <code>kwargs</code> allows functions to take any named variables. However, it is not the name <code>args</code> and <code>kwargs</code> that give them this special property, but rather the explicit definition of each with <code>*</code> and <code>**</code>:</p>

<pre class=""lang-py prettyprint-override""><code>def foo(*lol):
    print(lol)

foo(1, 2, 3)
</code></pre>

<p>outputs:</p>

<pre><code>(1, 2, 3)
</code></pre>

<p>Checkout the Python documentation on them <a href=""https://docs.python.org/3/tutorial/controlflow.html#arbitrary-argument-lists"" rel=""nofollow noreferrer"">here</a>.</p>

<hr>

<p>The concept above also works for unpacking other objects, such as <code>list</code> and <code>set</code>. Notice:</p>

<pre class=""lang-py prettyprint-override""><code>print([1, 2, 3])  # &gt;&gt;&gt; [1, 2, 3]
</code></pre>

<p>where</p>

<pre class=""lang-py prettyprint-override""><code>print(*[1, 2, 3]) # &gt;&gt;&gt; 1 2 3
</code></pre>

<p>The above is the equivalent of passing three separate arguments to the <code>print</code> function, so it is the same as doing:</p>

<pre class=""lang-py prettyprint-override""><code>print(1, 2, 3)
</code></pre>
","0","2020-02-01 04:01:22","2","4588","211","39","464","60013785","60013814","<p>I have a list of user integers:</p>

<pre><code>user1 = [4,5,2,3,4]
user2 = [4,2,1,3,4,4,2]
</code></pre>

<p>I want to use *args to count avg.</p>

<pre><code>def avg(*args):
  sum=0
  for num in avg:
     sum =+ num
  result = sum/len(avg)
  return result
</code></pre>

<p>And if I call it this way:</p>

<pre><code>avg(4,5,2,3,4)
avg(4,2,1,3,4,4,2)
</code></pre>

<p>everythig is fine. Code works.
But I still need to change a code to do that. I don't understand how to use that *args.</p>

<p>For example, user put 3 int in table my code do something like that:</p>

<pre><code>avg(userTable) // and just put a 3 args in fun
</code></pre>

<p>Can someone explain me how can I do it? I need to use variable arguments for benchmark.</p>

<p>One of my attempts:</p>

<pre><code>pkt = [44,23,0,22]
def avg(*pkt):
    suma = 0
    count = len(pkt)
    for i in range(len(pkt)):
        if pkt[i] != 0:
            print(i)
            sum = sum + pkt[i]
        else:
            count = count - 1
    result= pkt[0] + pkt[1] + sum
    result= result/(count+2)
    print(result)
    return result


avg(pkt)
</code></pre>

<p>but i got an error in count line.</p>
"
"60013826","<p>You can do </p>

<pre><code>s = df.groupby(['Place','zoneid','Id']).head(1)
df = df.drop(s.index[s['Event']=='Out'])
</code></pre>
","1","","3","252249","5881","962","22297","60013789","60013826","<p>I have a large dataset that looks like this:</p>
<p><a href=""https://i.stack.imgur.com/RT4gu.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/RT4gu.png"" alt=""enter image description here"" /></a></p>
<p>In my data, each group [groupby place,zoneid,id] should start with [In] as the first event. So, I need to drop the first row in the group if it was [Out]</p>
<p>My attempt is as the following:</p>
<pre><code>S=Data
for idx, group in Data.groupby(level='bayid'):
    if group ['Event'][0]=='Out':
        S= S.drop(data.index[0], axis=0)
</code></pre>
<p>But my data is too large. Is there is a faster way?</p>
"
"60013997","<p>Router provides argument <a href=""https://www.django-rest-framework.org/api-guide/routers/#usage"" rel=""nofollow noreferrer""><code>basename</code></a> which is using to reverse url.</p>

<pre><code>router = routers.DefaultRouter()
router.register(r'genres', GenreViewSet, basename='genres')

urlpatterns = [
    url(r'^api/',include(router.urls)),
    path('', views.index, name='index'),
</code></pre>

<p>Note that DRF's viewset has multiple urls. So you need to specify which one you want to use by adding specific suffix <code>-list</code> or <code>-detail</code>. First one will give you url of viewset <code>list()</code> and <code>create()</code> actions. And second using for <code>retrieve()</code> and <code>update()</code>.</p>

<p>So in template it would be something like this:</p>

<pre><code>&lt;a href=""{% url 'genres-list' %}""&gt;api&lt;/a&gt;
</code></pre>
","1","","2","37572","2148","0","2444","60013944","60013997","<p>I have a few api with django-rest-framework, my routing is like this below.</p>

<p>set <code>/api/genres</code> under <code>/api</code></p>

<pre><code>from rest_framework import routers
from django.conf.urls import url
from django.conf.urls import include

router = routers.DefaultRouter()
router.register(r'genres', GenreViewSet)

urlpatterns = [
    url(r'^api/',include(router.urls), name='api'),
    path('', views.index, name='index'),
</code></pre>

<p>Now I want to use this url in template, so I tried two patterns, but both shows error.</p>

<p>How should I make the link for api??</p>

<pre><code>&lt;a href=""{% url 'api' %}""&gt;api&lt;/a&gt;
Reverse for 'api' not found. 'api' is not a valid view function or pattern name.

&lt;a href=""{% url 'genres' %}""&gt;genre&lt;/a&gt;
Reverse for 'genres' not found. 'genres' is not a valid view function or pattern name.
</code></pre>
"
"60014125","<p>This will do:</p>

<pre><code>    if str(submit_button[""state""]) == ""disabled"":
        submit_button[""state""] = ""normal""
        browse_button[""state""] = ""disabled""
        show_fig[""state""] = ""disabled""

    elif str(browse_button[""state""]) == ""disabled"":
        submit_button[""state""] = ""disabled""
        browse_button[""state""] = ""normal""
        save_button[""state""] = ""disabled""
        show_button[""state""] = ""disabled""
</code></pre>

<p>Just replace your <code>switch1()</code> function with this.</p>
","0","","1","953","1008","3023","498","60013965","60014125","<p>In this code, the ""Change Input Option"" button switches between ""Process"" and ""Browse"" button. If we press any one of them, the buttons below it get activated. When ""Change Input Option"" button is clicked again, I want it to disable the buttons below ""Process"" and ""Browse"" and start switching between ""Process"" and ""Browse"" button again as it did initially. How do I do that?</p>

<pre><code>import tkinter as tk
import tkinter.ttk as ttk
window = tk.Tk()

def browse_file1():

    if browse_button[""state""] == ""normal"":
        show_fig[""state""] = ""disabled""
    else:
        show_fig[""state""] = ""normal"" 

def open_window():   
    if submit_button[""state""] == ""disabled"":

        save_button[""state""] = ""disabled""
        show_button[""state""] = ""disabled""

    else:
        save_button[""state""] = ""normal""       
        show_button[""state""] = ""normal""   

def switch1():
    submit_button.state(('!disabled' if 'disabled' in submit_button.state() else 'disabled',))
    browse_button.state(('!disabled' if 'disabled' in browse_button.state() else 'disabled',))

window.configure(background='white')
ws = window.winfo_screenwidth()
hs = window.winfo_screenheight()
w = 700 # width for the Tk root
h = 410  # height for the Tk root
x = (ws / 2) - (w / 2)
y = (hs / 2) - (h / 2)
window.geometry('%dx%d+%d+%d' % (w, h, x, y))      
canvas = tk.Canvas(window,bg=""white"",width=700, height=410, highlightthickness=0)
canvas.pack()

submit_button = ttk.Button(canvas, text=""Process"", command=lambda: open_window())
canvas.create_window(560, 215, window=submit_button, anchor=tk.NW)

show_button = ttk.Button(canvas, text='Show Figure')
canvas.create_window(523, 248, window=show_button, anchor=tk.NW)

save_button = ttk.Button(canvas, text=""Save Entry"")
canvas.create_window(605, 248, window=save_button, anchor=tk.NW)

browse_button = ttk.Button(canvas, text='Browse', command= lambda: browse_file1())
canvas.create_window(150, 335, window=browse_button, anchor=tk.NW)

show_fig = ttk.Button(canvas, text=""Show Figure"")
canvas.create_window(150, 370, window=show_fig, anchor=tk.NW)

show_fig[""state""] = ""disabled""
browse_button[""state""] = ""disabled""

save_button[""state""] = ""disabled""
show_button[""state""] = ""disabled""

one_button = ttk.Button(canvas, text='Change Input Option', command=switch1)
canvas.create_window(17, 13, window=one_button, anchor=tk.NW)  

window.resizable(False, False)
window.mainloop()
</code></pre>
"
"60014116","<p>Install Virtual Environment so you can use many and different versions of Python.</p>
","1","","0","39","0","0","5","60014044","60014195","<p>I am on OS Mojave and just used homebrew to install <code>geos</code> and <code>proj</code> and python3 disappeared. I had two versions and now I only have the 2.7 version. I did <code>brew install python3</code> and it says its already installed but not linked, I then did <code>brew link python</code> as it suggested but it returned an <code>Error: Could not symlink Frameworks/Python.framework/Headers Target /usr/local/Frameworks/Python.framework/Headers is a symlink belonging to python@2.</code>. </p>

<p>How can I go back to having both versions?. I am not 100% installing <code>geos</code> and <code>proj</code> was what caused it but I used python3 3 days ago.  I have also installed <code>phantomjs</code> via homebrew since the last time I used python3.</p>

<p>I need to have both versions of python installed. What would be the appropriate way of handling this since I seem to have all the files still on my computer?</p>

<p>Thanks in advance!</p>
"
"60014185","<p>use anaconda python distribution which better for python.</p>
","1","","1","531","88","20","94","60014044","60014195","<p>I am on OS Mojave and just used homebrew to install <code>geos</code> and <code>proj</code> and python3 disappeared. I had two versions and now I only have the 2.7 version. I did <code>brew install python3</code> and it says its already installed but not linked, I then did <code>brew link python</code> as it suggested but it returned an <code>Error: Could not symlink Frameworks/Python.framework/Headers Target /usr/local/Frameworks/Python.framework/Headers is a symlink belonging to python@2.</code>. </p>

<p>How can I go back to having both versions?. I am not 100% installing <code>geos</code> and <code>proj</code> was what caused it but I used python3 3 days ago.  I have also installed <code>phantomjs</code> via homebrew since the last time I used python3.</p>

<p>I need to have both versions of python installed. What would be the appropriate way of handling this since I seem to have all the files still on my computer?</p>

<p>Thanks in advance!</p>
"
"60014195","<p>Use <code>$ type python</code> to see where it points to. Use <code>brew info</code> command to list the info on installed python. </p>

<pre><code>$ brew info python
python: stable 3.7.6 (bottled), HEAD
Interpreted, interactive, object-oriented programming language
https://www.python.org/
/usr/local/Cellar/python/3.7.5 (4,032 files, 61.8MB) *
  Poured from bottle on 2019-11-04 at 22:34:01
From: https://github.com/Homebrew/homebrew-core/blob/master/Formula/python.rb
==&gt; Dependencies
Build: pkg-config ✔
Required: gdbm ✔, openssl@1.1 ✔, readline ✔, sqlite ✔, xz ✔
==&gt; Options
--HEAD
    Install HEAD version
==&gt; Caveats
Python has been installed as
  /usr/local/bin/python3

Unversioned symlinks `python`, `python-config`, `pip` etc. pointing to
`python3`, `python3-config`, `pip3` etc., respectively, have been installed into
  /usr/local/opt/python/libexec/bin

If you need Homebrew's Python 2.7 run
  brew install python@2

You can install Python packages with
  pip3 install &lt;package&gt;
They will install into the site-package directory
  /usr/local/lib/python3.7/site-packages

See: https://docs.brew.sh/Homebrew-and-Python

</code></pre>

<p>See the lines under <code>Caveats</code></p>

<blockquote>
  <p><code>Python has been installed as</code><br>
  <code>/usr/local/bin/python3</code></p>
</blockquote>

<p>that's your python3 alias path. you can safely symlink <code>python</code> to point to it in <code>~/.bash_profile</code></p>

<pre><code>$ echo 'alias python=/usr/local/bin/python' &gt; ~/.bash_profile
$ cat ~/.bash_profile
###########################
# you'll probably see these kind of lines before your alias
###########################

export PATH=/usr/local/bin:/usr/local/Cellar:$PATH
export ARCHFLAGS=""-arch x86_64""
export LC_ALL=""en_US.UTF-8""
export LANG=""en_US.UTF-8""
alias python=/usr/local/bin/python

</code></pre>

<p>restart your terminal for it to take effect</p>

<pre><code>$ type python
python is aliased to `python3'
$ python
Python 3.7.5 (default, Nov  1 2019, 02:16:32) 
[Clang 11.0.0 (clang-1100.0.33.8)] on darwin
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
&gt;&gt;&gt; 
</code></pre>
","6","","1","1132","71","34","145","60014044","60014195","<p>I am on OS Mojave and just used homebrew to install <code>geos</code> and <code>proj</code> and python3 disappeared. I had two versions and now I only have the 2.7 version. I did <code>brew install python3</code> and it says its already installed but not linked, I then did <code>brew link python</code> as it suggested but it returned an <code>Error: Could not symlink Frameworks/Python.framework/Headers Target /usr/local/Frameworks/Python.framework/Headers is a symlink belonging to python@2.</code>. </p>

<p>How can I go back to having both versions?. I am not 100% installing <code>geos</code> and <code>proj</code> was what caused it but I used python3 3 days ago.  I have also installed <code>phantomjs</code> via homebrew since the last time I used python3.</p>

<p>I need to have both versions of python installed. What would be the appropriate way of handling this since I seem to have all the files still on my computer?</p>

<p>Thanks in advance!</p>
"
"60056648","<p><a href=""https://i.stack.imgur.com/0u7cB.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/0u7cB.png"" alt=""enter image description here""></a></p>

<blockquote>
  <p>It seems I have entered wrong inputs, hence the reason I had this
  error. Below is the snapshot of the code results. </p>
  
  <p>These are case sensitive inputs. That was the reason why I had this
  issue.</p>
</blockquote>

<p><a href=""https://i.stack.imgur.com/BofoJ.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/BofoJ.png"" alt=""enter image description here""></a></p>
","0","","0","913","25","5","91","60014108","60056648","<p>I am trying the knowledge based recommended system in python by referring to the book ""Hands on Recommendation Systems with Python"" by Rounak Banik. We have the movies data set of IMDB. </p>

<p>I am getting error at the final output. Please see below my entire code and on build chart function is where I am getting the error. Please help me to resolve this issue. Thank you. </p>

<p>I was unable to find answer from similar question on this platform. Hence I have posted new question. </p>

<pre><code>import pandas as pd
import numpy as np

df = pd.read_csv('..../RecoSys/data/movies_metadata.csv')
#print all the features(or columns) of the dataFrame
df.columns

#only keep those that we require
df = df[['title', 'genres', 'release_date', 'runtime', 'vote_average', 'vote_count']]
df.head()
#convert release_date into pandas datetime format
df['release_date'] = pd.to_datetime(df['release_date'], errors='coerce')
df['year'] = df['release_date'].apply(lambda x: str(x).split('-')[0] if x!=np.nan else np.nan)
#Helper function to convert NaT to 0 and all other years to integers.

def convert_int(x):
    try:
        return int(x)
    except:
        return 0
#Apply convert_int to the year feature
df['year'] = df['year'].apply(convert_int)

#Drop the release_date column
df = df.drop('release_date', axis=1)

#Display the dataframe
df.head()

#Print genres of the first movie
df.iloc[0]['genres']

#Import the literal_eval function from ast
from ast import literal_eval
import json

#Define a stringified list and output its type
a = ""[1,2,3]""
print(type(a))

#Apply literal_eval and output type
b = literal_eval(a)
print(type(b))

#Convert all NaN into stringified empty lists
df['genres'] = df['genres'].fillna('[]')

#Apply literal_eval to convert to the list object
df['genres'] = df['genres'].apply(literal_eval)
#df['genres'] = json.loads(df['genres'])

#Convert list of dictionaries to a list of strings
df['genres'] = df['genres'].apply(lambda x: [i['name'] for i in x] if isinstance(x, list) else [])
df.head()

#Create a new feature by exploding genres
s = df.apply(lambda x: pd.Series(x['genres']),axis=1).stack().reset_index(level=1, drop=True)

#Name the new feature as 'genre'
s.name = 'genre'

#Create a new dataframe gen_df which by dropping the old 'genres' feature and adding the new 'genre'.
gen_df = df.drop('genres', axis=1).join(s)

#Print the head of the new gen_df
gen_df.head(15)

def build_chart(gen_df, percentile=0.8):
    #Ask for preferred genres
    print(""Please Input preferred genre"")
    genre = input()

    #Ask for lower limit of duration
    print(""Please Input shortest duration"")
    low_time = int(input())

    #Ask for upper limit of duration
    print(""Please Input Longesr Duration"")
    high_time = int(input())

    #Ask for lower limit of timeline
    print(""Input earliest year"")
    low_year = int(input())

    #Ask for upper limit of timeline
    print(""Input latest year"")
    high_year = int(input())

    #Define a new movies variable to store the preferred movies. Copy the contents of gen_df to movies
    movies = gen_df.copy()

    #Filter based on the condition
    movies = movies[(movies['genre'] == genre) &amp; 
                    (movies['runtime'] &gt;= low_time) &amp; 
                    (movies['runtime'] &lt;= high_time) &amp; 
                    (movies['year'] &gt;= low_year) &amp; 
                    (movies['year'] &lt;= high_year)]

    #Compute the values of C and m for the filtered movies
    C = movies['vote_average'].mean()
    m = movies['vote_count'].quantile(percentile)

    #Only consider movies that have higher than m votes. Save this in a new dataframe q_movies
    q_movies = movies.copy().loc[movies['vote_count'] &gt;= m]

    #Calculate score using the IMDB formula
    q_movies['score'] = q_movies.apply(lambda x: (x['vote_count']/(x['vote_count']+m) * x['vote_average']) 
                                       + (m/(m+x['vote_count']) * C), axis=1)
    #Sort movies in descending order of their scores
    q_movies = q_movies.sort_values('score', ascending=False)

    return q_movies

build_chart(gen_df).head()
</code></pre>

<pre><code>Please Input preferred genre
animation
Please Input shortest duration
30
Please Input Longesr Duration
120
Input earliest year
1990
Input latest year
2005

---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
~\Anaconda3\lib\site-packages\pandas\core\frame.py in _ensure_valid_index(self, value)
   3423             try:
-&gt; 3424                 value = Series(value)
   3425             except (ValueError, NotImplementedError, TypeError):

~\Anaconda3\lib\site-packages\pandas\core\series.py in __init__(self, data, index, dtype, name, copy, fastpath)
    263 
--&gt; 264                 data = SingleBlockManager(data, index, fastpath=True)
    265 

~\Anaconda3\lib\site-packages\pandas\core\internals\managers.py in __init__(self, block, axis, do_integrity_check, fastpath)
   1480         if not isinstance(block, Block):
-&gt; 1481             block = make_block(block, placement=slice(0, len(axis)), ndim=1)
   1482 

~\Anaconda3\lib\site-packages\pandas\core\internals\blocks.py in make_block(values, placement, klass, ndim, dtype, fastpath)
   3094 
-&gt; 3095     return klass(values, ndim=ndim, placement=placement)
   3096 

~\Anaconda3\lib\site-packages\pandas\core\internals\blocks.py in __init__(self, values, placement, ndim)
   2630         super(ObjectBlock, self).__init__(values, ndim=ndim,
-&gt; 2631                                           placement=placement)
   2632 

~\Anaconda3\lib\site-packages\pandas\core\internals\blocks.py in __init__(self, values, placement, ndim)
     86                 'Wrong number of items passed {val}, placement implies '
---&gt; 87                 '{mgr}'.format(val=len(self.values), mgr=len(self.mgr_locs)))
     88 

ValueError: Wrong number of items passed 6, placement implies 0

During handling of the above exception, another exception occurred:

ValueError                                Traceback (most recent call last)
&lt;ipython-input-53-3c3d1bc1cf24&gt; in &lt;module&gt;
     45     return q_movies
     46 
---&gt; 47 build_chart(gen_df).head()

&lt;ipython-input-53-3c3d1bc1cf24&gt; in build_chart(gen_df, percentile)
     39     #Calculate score using the IMDB formula
     40     q_movies['score'] = q_movies.apply(lambda x: (x['vote_count']/(x['vote_count']+m) * x['vote_average']) 
---&gt; 41                                        + (m/(m+x['vote_count']) * C), axis=1)
     42     #Sort movies in descending order of their scores
     43     q_movies = q_movies.sort_values('score', ascending=False)

~\Anaconda3\lib\site-packages\pandas\core\frame.py in __setitem__(self, key, value)
   3368         else:
   3369             # set column
-&gt; 3370             self._set_item(key, value)
   3371 
   3372     def _setitem_slice(self, key, value):

~\Anaconda3\lib\site-packages\pandas\core\frame.py in _set_item(self, key, value)
   3442         """"""
   3443 
-&gt; 3444         self._ensure_valid_index(value)
   3445         value = self._sanitize_column(key, value)
   3446         NDFrame._set_item(self, key, value)

~\Anaconda3\lib\site-packages\pandas\core\frame.py in _ensure_valid_index(self, value)
   3424                 value = Series(value)
   3425             except (ValueError, NotImplementedError, TypeError):
-&gt; 3426                 raise ValueError('Cannot set a frame with no defined index '
   3427                                  'and a value that cannot be converted to a '
   3428                                  'Series')

ValueError: Cannot set a frame with no defined index and a value that cannot be converted to a Series
</code></pre>
"
"60014270","<p>If you really want to read the entire file into a single list, where each element of the list is a line from the file, then use <code>.readlines()</code> instead of <code>.read()</code>.</p>

<p>However, if your file is large, then you may not want to load it all into memory at once.  You can process a file one line at a time like this:</p>

<pre><code>stroke = open('2018cut.txt', 'r')
for line in stroke:
    # do stuff with line
</code></pre>
","0","","0","1318","121","13","64","60014218","60014270","<p>I have uploaded a txt file into python that I am going to attempt to sort. Although, when I upload it, it becomes a string in python and I would like to instead use an array. I have attempted to use np.array, as well as attempting to open it with pandas and create it from there. I am relatively new to python so Im sure its pretty simple, but I would appreciate any help. Here's what I've attempted:</p>

<pre><code>    stroke = open('2018cut.txt', 'r')
    stroke = stroke.read()
    print(stroke)
    type(stroke)
</code></pre>

<ul>
<li>2018-07-07 00:00:57.849  40.3512 -103.8954    +3.6  C</li>
<li>2018-07-07 00:00:58.152  40.7638 -102.6134    +4.4  C</li>
<li>2018-07-07 00:00:58.862  40.5501 -104.1176   +10.8  C</li>
<li>class 'str'</li>
</ul>

<p>This is my output. I would like to create an array like this, rather than it being a string. So I tried:</p>

<pre><code>    strokes=np.array([stroke]) 
</code></pre>

<p>After this, I end up getting np.array as my output for type(strokes), but it puts it all in a 1x0 array...</p>
"
"60015067","<p>Here you go, description in code.</p>

<pre><code>from tkinter import *
import Image, ImageTk

# create canvas
canvas = Canvas(width=300, height=200, bg='black')
canvas.pack()
# create image object
img = Image.new('RGB', (60, 30), color='red')
new_image = ImageTk.PhotoImage(img)
# load into canvas
canvas.create_image(50, 10, image=new_image, anchor=NW)
mainloop()
</code></pre>

<p>Output:</p>

<p><a href=""https://i.stack.imgur.com/NiPv5.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/NiPv5.png"" alt=""enter image description here""></a></p>

<p>To update canvas create function, and update root after changes to the object are made.</p>

<pre><code>from tkinter import *
import Image, ImageTk
import time


def update_position():
    while True:
        canvas.move(rectangle, 30, 10)
        time.sleep(1)
        root.update()


root = Tk()
# create canvas
canvas = Canvas(root, width=300, height=200, bg='black')
canvas.pack()
# create image object
img = Image.new('RGB', (60, 30), color='red')
new_image = ImageTk.PhotoImage(img)
# load into canvas
rectangle = canvas.create_image(50, 10, image=new_image, anchor=NW)
update_position()
root.mainloop()
</code></pre>
","3","2020-02-01 12:48:13","1","4584","259","83","602","60014234","60015067","<p>I was trying to create and display an empty image to edit and update later on. This code worked when not using tkinter, just the image display. When i run the following code:</p>

<pre><code>from random import randint
from time import *
from PIL import Image as Img
from PIL import ImageTk as ImgTk
from tkinter import *
main = Tk()
main.geometry('1001x1001')
width, height = map(int, input('width and height\n').split())
canvas = Canvas(main, width = width, height = height)
canvas.pack()
next_cells = []
img = Img.new('RGB', (width, height))
pix = img.load()
tkpix = ImgTk.PhotoImage(pix)
imgsprite = canvas.create_image(width,height,image=pix)
main.mainloop()
</code></pre>

<p>I get the following error:</p>

<pre><code>File ""/Applications/eeie"", line 14, in &lt;module&gt;
  tkpix = ImgTk.PhotoImage(pix)
File ""/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/PIL/ImageTk.py"", line 108, in __init__
  mode = Image.getmodebase(mode)
File ""/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/PIL/Image.py"", line 275, in getmodebase
  return ImageMode.getmode(mode).basemode
File ""/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/PIL/ImageMode.py"", line 64, in getmode
  return _modes[mode]

builtins.KeyError: &lt;PixelAccess object at 0x108aa4790&gt;
</code></pre>

<p>What is causing this error?</p>
"
"60014926","<p>Simply add theta variable to title string</p>

<pre><code>theta = 1
ax.set_title(""Θ = %.i"" % theta, fontsize=25)
</code></pre>

<p>By saving file do the same</p>

<pre><code>fig.savefig('Θ = ' + str(theta) +'.png')
</code></pre>
","6","","1","4584","259","83","602","60014260","60014926","<p>I goal is to plot a figure and give it a title and save it as png file.</p>

<p>For example, I plot a figure first</p>

<pre><code>from matplotlib import pyplot as plt
import numpy as np
from skimage import measure


# Set up mesh
n = 100

x = np.linspace(-3,3,n)
y = np.linspace(-3,3,n)
z = np.linspace(-3,3,n)
X, Y, Z =  np.meshgrid(x, y, z)

# Create cardioid function
def f_heart(x,y,z):
    F = 320 * ((-x**2 * z**3 -9*y**2 * z**3/80) +
               (x**2 + 9*y**2/4 + z**2-1)**3)
    return F

# Obtain value to at every point in mesh
vol = f_heart(X,Y,Z)

# Extract a 2D surface mesh from a 3D volume (F=0)
verts, faces ,_ ,_ = measure.marching_cubes_lewiner(vol, 0, spacing=(0.1, 0.1, 0.1))


# Create a 3D figure
fig = plt.figure(figsize=(12,8))
ax = fig.add_subplot(111, projection='3d')

# Plot the surface
ax.plot_trisurf(verts[:, 0], verts[:,1], faces, verts[:, 2],
                cmap='Spectral', lw=1)

# Change the angle of view and title
ax.view_init(15, -15)
</code></pre>

<p>Now, I want to use a variable as a title to the plot and save it as png file.</p>

<pre><code>#set the number of variable Θ
Θ = 1

#give the title
ax.set_title(""Θ = "", fontsize=25)


plt.show()
fig.savefig('D:/Θ = .png')
</code></pre>

<p>I hope this code can give me a plot with title Θ = 1 (or other value that I set for Θ), and save the plot at D:/ with a name Θ = 1.</p>

<p>How can I edit my code to achieve this?
Thank you!!!</p>
"
"60015456","<p>You are not using the <code>host</code> variable in <code>for host in keys:</code> loop at all.</p>

<p>And you can actually use the data as you read them straight away. It does not look like you need to collect the data to <code>keys</code> at all.</p>

<pre><code>for row in reader:
    host = row[1]
    ms_key = row[2]
    rm_key = row[3]

    i = 1

    while True:
        print (""\nTrying to connect to %s (%i/2)"" % (host, i))

        try:
           ssh = paramiko.SSHClient()
           ssh.set_missing_host_key_policy(paramiko.AutoAddPolicy())
           ssh.connect(
               host, username=username, password=password, look_for_keys=False, timeout= 5)
           print (""\nConnected to %s"" % host )
           connection_state = 1
           break

    if connection_state == 1:
        client_shell = ssh.invoke_shell()
        time.sleep(.4)
        client_shell.send(multi_site + ""\n"")
        time.sleep(.4)
        client_shell.send(remote_monitor + ""\n"")
</code></pre>

<p><em>(btw, the <code>i</code> is never changed from its initial value of <code>1</code>)</em></p>
","1","","0","144036","8283","6276","21385","60014311","60015456","<p>I am currently using the paramiko module to SSH into a list of IP addresses provided as a .csv file then push commands to those IPs.  To accomplish this, I am using the csv.reader() to open and read 100 rows of the file which is in the following format.</p>
<p><em>Serial number, IP Address, MS, RM</em> (MS &amp; RM are pieces of info correlated to IP address)</p>
<h3>The Context</h3>
<p>This is where Im using csv.reader() to open and read the file to then place information as a dictionary <code>keys</code>.</p>
<p>I then go to nest another dictionary within <code>keys</code> as <code>keys[row[0]]</code> to index IP address and other pieces of info as <code>ep_ip</code>,<code>ms_key</code> and <code>rm_key</code>.</p>
<pre><code>option_dict = open('OptionKeyDict.csv','r')
reader= csv.reader(option_dict)

keys= {}

for row in reader:
    keys[row[0]]= {'IP':row[1],'MS': row[2],'RM': row[3]}

ep_ip = keys[row[0]]['IP']
ms_key= keys[row[0]]['MS']
rm_key= keys[row[0]]['RM']

command= 'xCommand SystemUnit OptionKey Add Key: '

multi_site= command + ms_key
remote_monitor= command + rm_key
</code></pre>
<p>Then I go on to introduce the Paramiko logic of the script to take the statements above and SSH into IP address, then execute the <code>multi-site</code> &amp; <code>remote-monitor</code> commands.</p>
<pre><code>for host in keys:
    host= ep_ip
    i = 1

    while True:
        print (&quot;\nTrying to connect to %s (%i/2)&quot; % (host, i))

        try:
           ssh = paramiko.SSHClient()
           ssh.set_missing_host_key_policy(paramiko.AutoAddPolicy())
           ssh.connect(host, username=username, password=password, look_for_keys=False, timeout= 5)
           print (&quot;\nConnected to %s&quot; % host )
           connection_state = 1
           break

    if connection_state == 1:
        client_shell = ssh.invoke_shell()
        time.sleep(.4)
        client_shell.send(multi_site + &quot;\n&quot;)
        time.sleep(.4)
        client_shell.send(remote_monitor + &quot;\n&quot;)
</code></pre>
<p>So, running this works partially. The script successfully SSH then pushes the commands but it only uses the pieces of information from the last row (IP address, MS &amp; RM) and runs 100 times as there are 100 rows in .csv.</p>
<p>I cant seem to have the script to start at the first row then work its way down each line to the 100th row.</p>
<p>Now that I got the context out of the way... (Sorry, new to StackOverflow)</p>
<h3>The Question</h3>
<p>What am I missing here that will enable this to happen? I feel its a simple adjustment that Im not seeing.</p>
<p>Any and all feedback would be greatly appreciated.
Thank you!</p>
"
"60014721","<p>If tag is <code>Name</code> in loop then set to variable and last add to <code>dictionary</code> values:</p>

<pre><code>import xml.etree.cElementTree as ET
def read_xml(xml_file):

   etree = ET.parse(xml_file)
   root = etree.getroot()
   items = []
   for item in root.findall('LIST/'):
       values = {}
       if (item.tag == 'Name'):
           name = item.text
           continue
       for it in item:
           values[it.tag] = it.text
       values['Name'] = name
       items.append(values)

   columns = ['Name','Mode', 'LEVELS','Group','Type']
   df = pd.DataFrame(items, columns = columns)

   return df

xml_file = 'xml.xml'
print(read_xml(xml_file))
         Name    Mode LEVELS Group Type
0       ALICE    Hole      1    11    0
1       ALICE   BEWEL      2    22    0
2  WONDERLAND    Mole      1    11    0
3  WONDERLAND  Matrix      6    66    0
</code></pre>
","0","","1","615041","23439","1483","126104","60014315","60014721","<p>I am trying to extract the following values from an xml file: 
<code>NAME, Mode,LEVELS,Group,Type</code> and after I want to make <code>data.frame</code>. The problem I having so far is that I cannot get <code>&lt;Name&gt;ALICE&lt;/Name&gt;</code> variables and output data.frame format is different than I need.</p>

<p>Here is the some post that I used when I built my <code>read_xml</code> function</p>

<ol>
<li><a href=""https://www.geeksforgeeks.org/xml-parsing-python/"" rel=""nofollow noreferrer"">https://www.geeksforgeeks.org/xml-parsing-python/</a></li>
<li><a href=""https://stackoverflow.com/questions/7691514/extracting-text-from-xml-using-python"">Extracting text from XML using python</a></li>
<li><a href=""https://stackoverflow.com/questions/1912434/how-do-i-parse-xml-in-python"">How do I parse XML in Python?</a></li>
</ol>

<p>here is the example <code>xml</code> file format</p>

<pre><code>&lt;?xml version=""1.0""?&gt;
&lt;Body&gt;
    &lt;DocType&gt;List&lt;/DocType&gt;
    &lt;DocVersion&gt;1&lt;/DocVersion&gt;
    &lt;LIST&gt;
            &lt;Name&gt;ALICE&lt;/Name&gt;
            &lt;Variable&gt;
                &lt;Mode&gt;Hole&lt;/Mode&gt;
                &lt;LEVELS&gt;1&lt;/LEVELS&gt;
                &lt;Group&gt;11&lt;/Group&gt;
                &lt;Type&gt;0&lt;/Type&gt;
                &lt;Paint /&gt;
            &lt;/Variable&gt;
            &lt;Variable&gt;
                &lt;Mode&gt;BEWEL&lt;/Mode&gt;
                &lt;LEVELS&gt;2&lt;/LEVELS&gt;
                &lt;Group&gt;22&lt;/Group&gt;
                &lt;Type&gt;0&lt;/Type&gt;
                &lt;Paint /&gt;
            &lt;/Variable&gt;

            &lt;Name&gt;WONDERLAND&lt;/Name&gt;
            &lt;Variable&gt;
                &lt;Mode&gt;Mole&lt;/Mode&gt;
                &lt;LEVELS&gt;1&lt;/LEVELS&gt;
                &lt;Group&gt;11&lt;/Group&gt;
                &lt;Type&gt;0&lt;/Type&gt;
                &lt;Paint /&gt;
            &lt;/Variable&gt;
            &lt;Variable&gt;
                &lt;Mode&gt;Matrix&lt;/Mode&gt;
                &lt;LEVELS&gt;6&lt;/LEVELS&gt;
                &lt;Group&gt;66&lt;/Group&gt;
                &lt;Type&gt;0&lt;/Type&gt;
                &lt;Paint /&gt;
            &lt;/Variable&gt;
    &lt;/LIST&gt;
&lt;/Body&gt;
</code></pre>

<p>I built the following function;</p>

<pre><code>xml_file = r""C:\xml.xml""

def read_xml(xml_file):

   etree = ET.parse(xml_file)
   root = etree.getroot()
   items = []
   for item in root.findall('./LIST/'):
      values  = {}
      for it in item:
         #print(it)
        values[it.tag] = it.text
      items.append(values)

   columns = ['Name','Mode', 'LEVELS','Group','Type']
   df = pd.DataFrame(items, columns = columns)

   return df


    print(read_xml(xml_file))
</code></pre>

<p>giving me this output</p>

<pre><code> Name    Mode LEVELS Group Type
0   NaN     NaN    NaN   NaN  NaN
1   NaN    Hole      1    11    0
2   NaN   BEWEL      2    22    0
3   NaN     NaN    NaN   NaN  NaN
4   NaN    Mole      1    11    0
5   NaN  Matrix      6    66    0
</code></pre>

<p>the expected output</p>

<pre><code>            NAME      MODE   LEVELS  Group  Type
1            ALICE      Hole      1      11     0
2            ALICE      BEWEL     11     22     0      
3       WONDERLAND      MOLE      1      11     0      
4       WONDERLAND      MATRIX    6      66     0      
</code></pre>

<p>How can I get the expected output!!</p>

<p>Thx!</p>
"
"60018412","<p>The variable Name needs to be <code>""PRD""</code> (the string itself must contain double quotes). Python considers <code>Name = """"""PRD""""""</code> the same as <code>Name = ""PRD""</code> so it's incorrect because the variable Name will just contain <code>PRD</code> (missing double quotes).</p>

<p>Hence, need to use string backslash (<code>Name = ""\""PRD\""""</code> or other possibilities mentioned <a href=""https://stackoverflow.com/a/6717689/9150270"">here</a>) to maintain the double quote in the variable Name.</p>

<p>Complete code:</p>

<pre><code>from subprocess import call
import win32com.client
import time
import os

GUIPath = 'C:/Program Files (x86)/SAP/FrontEnd/SAPgui/'
WinTitle = 'SAP'
Name = ""\""PRD\""""
SID = 'PRD'
InstanceNo = '01'

shell = win32com.client.Dispatch(""WScript.Shell"")
call(os.path.join(GUIPath, 'SAPgui.exe') + "" "" + Name + "" "" + InstanceNo)
</code></pre>
","4","2020-02-02 10:02:47","3","33","3","0","3","60014378","60018412","<p>I used this script to login SAP session:</p>

<pre><code>from subprocess import call
import win32com.client
import time
import os

GUIPath = 'C:/Program Files (x86)/SAP/FrontEnd/SAPgui/'
WinTitle = 'SAP'
Name = """"""PRD""""""
SID = 'PRD'
InstanceNo = '01'

shell = win32com.client.Dispatch(""WScript.Shell"")
call(os.path.join(GUIPath, 'SAPgui.exe') + "" "" + Name + "" "" + InstanceNo)
</code></pre>

<p>however, it always return with the error:</p>

<pre><code>hostname 'PRD' unknown
check you application server name
</code></pre>

<p>anyone knows how to fix this?
thanks</p>
"
"60023371","<p>Use this simple one-liner for connecting:</p>

<pre><code>import subprocess
subprocess.check_call(['C:\Program Files (x86)\SAP\FrontEnd\SAPgui\\sapshcut.exe', '-system=DCG210', '-client=100', '-user=USERNAME', '-pw=PASSWORD'])
</code></pre>

<p>You should use <code>subprocess</code> module instead of <code>os.call</code>, it is <a href=""https://stackoverflow.com/a/17094488/911419"">preferred</a> now.</p>
","0","","1","8255","2572","121","1571","60014378","60018412","<p>I used this script to login SAP session:</p>

<pre><code>from subprocess import call
import win32com.client
import time
import os

GUIPath = 'C:/Program Files (x86)/SAP/FrontEnd/SAPgui/'
WinTitle = 'SAP'
Name = """"""PRD""""""
SID = 'PRD'
InstanceNo = '01'

shell = win32com.client.Dispatch(""WScript.Shell"")
call(os.path.join(GUIPath, 'SAPgui.exe') + "" "" + Name + "" "" + InstanceNo)
</code></pre>

<p>however, it always return with the error:</p>

<pre><code>hostname 'PRD' unknown
check you application server name
</code></pre>

<p>anyone knows how to fix this?
thanks</p>
"
"60014455","<p>Your file is called <code>email.py</code>. A standard Python library module with the same name is used by <code>smtplib</code>. As a result, <code>smtplib</code> imports <em>your</em> file instead of the standard module. Solution: rename your file.</p>
","0","","1","44660","2964","3976","8780","60014386","60014455","<p>I have included the screenshot of output. Please help me solve this issue. <a href=""https://i.stack.imgur.com/GuFmB.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/GuFmB.png"" alt=""Screenshot""></a></p>

<p><strong>input</strong></p>

<pre><code>import smtplib
conn = smtplib.SMTP('imap.gmail.com',587)
conn.ehlo()
conn.starttls()
conn.login('example@gmail.com', 'password')

conn.sendmail('example@gmail.com','emaple2@gmail.com','Subject: What you like? \n\n Reply Reply Reply')
conn.quit()
</code></pre>

<p><strong>output</strong></p>

<pre><code>Traceback (most recent call last):
  File ""E:\python\openCV\email.py"", line 3, in &lt;module&gt;
    import smtplib
  File ""C:\Users\loges\AppData\Local\Programs\Python\Python36\lib\smtplib.py"", line 47, in &lt;module&gt;
    import email.utils
  File ""E:\python\openCV\email.py"", line 4, in &lt;module&gt;
    conn = smtplib.SMTP('imap.gmail.com',587)
AttributeError: module 'smtplib' has no attribute 'SMTP'
</code></pre>
"
"60014443","<p>I think you need remove <code>[]</code> because <code>ALTJ_genes</code> is list and <code>[ALTJ_genes]</code> is nested list:</p>

<pre><code>df1.drop(df1.columns.difference(ALTJ_genes), axis=1, inplace=True)
</code></pre>

<p>But simplier is select columns by list:</p>

<pre><code>df1 = df1[ALTJ_genes]
</code></pre>

<p>EDIT:</p>

<p>I think problem is with defined columns with nested list, so get one level non standard MultiIndex:</p>

<pre><code>df1 = pd.DataFrame([[1,2,3,4]])
#nested list
df1.columns = [['APEX1', 'ASF1A', 'CDKN2D', 'AAA']]
print (df1) 
  APEX1 ASF1A CDKN2D AAA
0     1     2      3   4

print (df1.columns)
MultiIndex([( 'APEX1',),
            ( 'ASF1A',),
            ('CDKN2D',),
            (   'AAA',)],
           )
</code></pre>

<p>If pass non nested list:</p>

<pre><code>df1 = pd.DataFrame([[1,2,3,4]])
#not nested list
df1.columns = ['APEX1', 'ASF1A', 'CDKN2D', 'AAA']
print (df1) 
   APEX1  ASF1A  CDKN2D  AAA
0      1      2       3    4

print (df1.columns)
Index(['APEX1', 'ASF1A', 'CDKN2D', 'AAA'], dtype='object')
</code></pre>
","16","2020-02-01 16:15:50","2","615041","23439","1483","126104","60014438","60014443","<p>I tried searching for the answer to this question but was not able to find it... so here it goes. </p>

<p>I have a dataset with 23987 columns. I actually only want the information in 35 of those columns (quite spread out between them). I have put these 35 items in a list. I wanted to know if there is a quick way to <strong>drop all the columns except those by passing the list</strong></p>

<p>I tried this: </p>

<pre><code>df1.drop(df1.columns.difference([ALTJ_genes]), axis=1, inplace=True)
</code></pre>

<p>ALTJ_genes is the list with the 35 items. The error I get is:</p>

<pre><code>TypeError: unhashable type: 'list'
</code></pre>

<p>I was wondering if there is a way to do it, I know I can reach my goal by passing the individual columns but I want to know if with the list is possible. This would make the code much clearer.</p>

<p>In any case, thanks!</p>

<p>EDIT: I provide some screenshot, maybe it is useful.</p>

<p><a href=""https://i.stack.imgur.com/zD9CL.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/zD9CL.png"" alt=""The first screenshot shows the head of the dataframe""></a>
<a href=""https://i.stack.imgur.com/ttkTB.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/ttkTB.png"" alt=""The second screenshot shows how I can select one column""></a></p>

<p>Now, this is the complete error I get when passing the list with all the genes.</p>

<pre><code>---------------------------------------------------------------------------
</code></pre>

<p>KeyError                                  Traceback (most recent call last)
 in 
----> 1 df1[ALTJ_genes]</p>

<p>/opt/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in <strong>getitem</strong>(self, key)
   2984             if is_iterator(key):
   2985                 key = list(key)
-> 2986             indexer = self.loc._convert_to_indexer(key, axis=1, raise_missing=True)
   2987 
   2988         # take() does not accept boolean indexers</p>

<p>/opt/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py in _convert_to_indexer(self, obj, axis, is_setter, raise_missing)
   1283                 # When setting, missing keys are not allowed, even with .loc:
   1284                 kwargs = {""raise_missing"": True if is_setter else raise_missing}
-> 1285                 return self._get_listlike_indexer(obj, axis, **kwargs)<a href=""https://i.stack.imgur.com/zD9CL.png"" rel=""nofollow noreferrer"">1</a>
   1286         else:
   1287             try:</p>

<p>/opt/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py in _get_listlike_indexer(self, key, axis, raise_missing)
   1090 
   1091         self._validate_read_indexer(
-> 1092             keyarr, indexer, o._get_axis_number(axis), raise_missing=raise_missing
   1093         )
   1094         return keyarr, indexer</p>

<p>/opt/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py in _validate_read_indexer(self, key, indexer, axis, raise_missing)
   1175                 raise KeyError(
   1176                     ""None of [{key}] are in the [{axis}]"".format(
-> 1177                         key=key, axis=self.obj._get_axis_name(axis)
   1178                     )
   1179                 )</p>

<p>KeyError: ""None of [Index([ ('APEX1',),  ('ASF1A',), ('CDKN2D',),   ('CIB1',),   ('DNA2',),\n       ('FAAP24',),  ('FANCM',),   ('GEN1',),   ('HRAS',),   ('LIG1',),\n         ('LIG3',),   ('MEN1',),  ('MRE11',),   ('MSH3',),   ('MSH6',),\n        ('NUDT1',),   ('MTOR',),  ('NABP2',),  ('NTHL1',),  ('PALB2',),\n        ('PARP1',),  ('PARP3',),  ('POLA1',),   ('POLM',),   ('POLQ',),\n       ('PRPF19',), ('RAD51D',),  ('RBBP8',),   ('RRM2',), ('RUVBL2',),\n         ('SOD1',),   ('KAT5',),    ('UNG',),    ('WRN',),  ('XRCC1',)],\n      dtype='object', name='Gene_Name')] are in the [columns]""</p>
"
"60014796","<h2>Simplification of the code</h2>

<p>If we define a helper function which returns cyclically the data from the tuple:</p>

<pre class=""lang-py prettyprint-override""><code>def cyclic_iter(values):
    while True:
        for v in values:
            yield v
</code></pre>

<p>then the code could simply become:</p>

<pre class=""lang-py prettyprint-override""><code>def multiple_writer(self, val:tuple):
    with open(self.file_path, 'wb+') as file:
        generator = cyclic_iter(val)
        for _ in range(self.file_size):
            file.write(next(generator))
</code></pre>

<p>or one could exploit the <code>zip</code> function:</p>

<pre class=""lang-py prettyprint-override""><code>def multiple_writer(self, val:tuple):
    with open(self.file_path, 'wb+') as file:
        for _, value in zip(range(self.file_size), cyclic_iter(val)):
            file.write(value)
</code></pre>

<h2>Edit: Simplest way</h2>

<p>Since you mentioned that you just started with python I'll add the simplest way I know.</p>

<pre class=""lang-py prettyprint-override""><code>def multiple_writer(self, val:tuple):
    with open(self.file_path, 'wb+') as file:
        for i in range(self.file_size):
            file.write(val[i % len(val))
</code></pre>
","3","2020-02-02 20:47:15","-1","629","93","2","56","60014448","60014796","<p>I am developing a Customized File Shredder.</p>

<p>I want to write tuple values bytes inside the files.</p>

<p><strong>for example:</strong>
If i pass 3 variable (0,100,1) # 'b'00, 'b'd, 'b'01 
and the File Size is 200 Bytes.
for 200/3 = 66 times it will write all the tuple data. and in last round 200%3 = 2 so it will write the first 2 tuple data.
when I tried to implement it, it goes wrong.</p>

<p>When i used write byte mode:</p>

<pre class=""lang-py prettyprint-override""><code>def multiple_writer(self, val:tuple):
    with open(self.file_path, 'wb+') as file:
        file_current = 0
        main_mode = True
        while file_current &lt; self.file_size:
            if main_mode:
                for values in val:
                    if file_current &lt;= self.file_size:
                        file.write(values)
                        file_current += 1
                    else:
                        main_mode = False
                        break
            else:
                break
</code></pre>

<p>When i used append byte mode:</p>

<pre class=""lang-py prettyprint-override""><code>def multiple_writer(self, val:tuple):
    with open(self.file_path, 'ab+') as file:
        file_current = 0
        main_mode = True
        file.seek(0)
        while file_current &lt; self.file_size:
            if main_mode:
                for values in val:
                    if file_current &lt;= self.file_size:
                        file.write(values)
                        file_current += 1
                    else:
                        main_mode = False
                        break
            else:
                break
</code></pre>

<p>My Result is :</p>

<p><strong>When Running Write Byte mode</strong>
<a href=""https://i.stack.imgur.com/VSRMd.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/VSRMd.png"" alt=""When Running Write Byte mode""></a>
<strong>When Running Append Byte mode</strong>
<a href=""https://i.stack.imgur.com/63Fqp.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/63Fqp.png"" alt=""When Running Append Byte mode""></a>
<strong>Required Result</strong>
<a href=""https://i.stack.imgur.com/OfLNx.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/OfLNx.png"" alt=""Required Result""></a></p>

<p>I Search everywhere and still, I can't find the answer where the bug is happening.</p>
"
"60015849","<p>Try this:</p>

<pre><code>%run another.ipynb
</code></pre>

<p>You may need to mount drive to access your <code>drive/My Drive/Colab Notebooks/</code></p>
","2","","2","23288","1366","13","1990","60014501","60015849","<p>I'm trying to run a <code>.ipynb</code> file inside another.  The reason why I want to nest the two is because in one of them, I have all of the conda packages, github repos installed and I don't want to redo the entire thing for a demo file that I'll be using temporarily.  I'm using colab because my computer does not have an NVIDIA GPU and therefore I can't use CUDA.</p>
"
"60014521","<p>Get all object columns by <a href=""http://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.select_dtypes.html"" rel=""nofollow noreferrer""><code>DataFrame.select_dtypes</code></a>, convert to dict and pass to <a href=""http://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.astype.html"" rel=""nofollow noreferrer""><code>DataFrame.astype</code></a>:</p>

<pre><code>train = train.astype(dict.fromkeys(train.select_dtypes('object').columns, 'category'))
</code></pre>
","0","","1","615041","23439","1483","126104","60014502","60014521","<p>This is my code:</p>

<pre><code>l1 = list(train)
for i in (0,len(l1)):
    if train[l1[i]].dtypes == object:
        train[l1[i]] = pd.Categorical(train[l1[i]])

train.info(verbose=True)
</code></pre>

<p>But this just makes the first variable change and nothing else. The rest of the 62 object variables aren't converted to object. </p>

<p>How do you do it?</p>
"
"60014737","<p>You have used <code>predict = model.predict_classes(encode)</code> which overwrites any function definition of predict and replace with an array.</p>

<p>So Predict is an array which is not callable.
If you just to see the predicted class for <code>encode[0]</code> you can use: <code>print(predict[0])</code></p>
","0","2020-02-01 08:28:27","1","61","37","0","2","60014565","60014737","<p>I'm currently learning ML from tensorflow series. In this case is about text classification. As you can see in the code, I already trained the model and save it as a file to test it.</p>

<p><strong>Loading the saved file</strong></p>

<pre class=""lang-py prettyprint-override""><code>modelFile = keras.models.load_model('model_text_classification.h5')
</code></pre>

<p><strong>Function to encode:</strong></p>

<pre class=""lang-py prettyprint-override""><code>def review_encode(string):
  '''look up the mapping of all the words and return to us an encoded list'''

  encoded = [1] # start with 1 as a starting tag as the system with word_index['&lt;START&gt;'] = 1

  for word in string:
    if word in word_index:
      encoded.append(word_index[word.lower()])
    else:
      encoded.append(2) # as the END tag

  return encoded
</code></pre>

<p><strong>Pre-processing:</strong></p>

<ol>
<li>the file is a large string, but I need to convert this into an encoded list of numbers</li>
<li>the size of the text is only at max 256 words, because that's how I was using when I trained the data  </li>
</ol>

<pre class=""lang-py prettyprint-override""><code>with open('lion_king.txt', encoding = 'utf-8') as f:
  for line in f.readlines():
    nline = line.replace(',', '').replace('.', '').replace('(', '').replace(')', '').replace('\""', '').replace(':', '')
    nline = nline.split(' ')

    # encode and trim the data down to 256 words
    encode = review_encode(nline)
    encode = keras.preprocessing.sequence.pad_sequences([encode], value = word_index['&lt;PAD&gt;'], padding = 'post', maxlen = 256) # [encode], because is expecting a list of lists

    # using the model to make a prediction
    predict = model.predict_classes(encode)

    print(line)
    print(encode)
    print(predict(encode[0])) #HERE IS ERROR
</code></pre>

<p><strong>Expecting output:</strong>
print the prediction as 96% positive.<br />
<em>example:</em> [0.9655667]</p>

<p><strong>The full traceback:</strong></p>

<pre class=""lang-py prettyprint-override""><code>TypeError                                 Traceback (most recent call last)
&lt;ipython-input-58-790c338a89ce&gt; in &lt;module&gt;()
     13     print(line)
     14     print(encode)
---&gt; 15     print(predict(encode[0]))

TypeError: 'numpy.ndarray' object is not callable
</code></pre>
"
"60029126","<p>The issue is that Pillow loads the image in greyscale mode, because it can, but then Pygame can’t recognise this. To fix it, you need to <code>convert()</code> the image to a format Pygame understands, by changing your third line to this:</p>

<pre class=""lang-py prettyprint-override""><code>image = Image.open(""./QR/test.png"").convert(""RGB"")
</code></pre>

<p>If you need an alpha channel, change <code>""RGB""</code> to <code>""RGBA""</code>.</p>

<p>Note that if you don’t intend to use the image in Pillow, you can just use</p>

<pre class=""lang-py prettyprint-override""><code>py_image = pygame.image.load(""./QR/test.png"")
</code></pre>

<p>which is much faster and shorter.</p>
","0","","1","1272","52","4","65","60014571","60029126","<p>I want to load a Pillow <code>Image</code> with Pygame. I converted a PNG image to a Python <code>bytes</code> object though <code>.tobytes()</code> and loaded it into Pygame with <code>pygame.image.fromstring()</code>.</p>

<p>This is my code:</p>

<pre class=""lang-py prettyprint-override""><code>from PIL import Image
import pygame
image = Image.open(""./QR/test.png"")

image.show()
mode = image.mode
size = image.size
data = image.tobytes()

py_image = pygame.image.fromstring(data, size, mode)
</code></pre>

<p>My Python version is 3.7.5, Pillow version is 7.0.0, and Pygame version is 1.9.6.
I got an error in the last line:</p>

<p><code>ValueError: Unrecognized type of format</code></p>
"
"60014697","<pre><code>import os
import platform

path = os.path.basename(__file__)
run_on=platform.system()
if run_on=='Windows': path=f'.\\{path}'
elif run_on=='Linux': path=f'./{path}'

print(f'path is {path}')
</code></pre>
","1","","1","373","4","1","27","60014652","60014697","<p>How can I get my script's file name as a relative path to <code>cwd</code> and it being OS independent?</p>

<p>e.g if I'm in linux it should return ""./script.py"" and if I'm in windows it should return "".\\script.py""</p>

<p>I tried with <code>os.path.join</code> and <code>os.path.basename(__file__)</code> but it returns absolute path. </p>
"
"60014789","<p>Why not simply let <code>os</code> handle that for you?</p>

<pre><code>path = os.path.normcase(os.path.join('.', os.path.relpath(__file__)))
</code></pre>
","4","","0","972","24","5","77","60014652","60014697","<p>How can I get my script's file name as a relative path to <code>cwd</code> and it being OS independent?</p>

<p>e.g if I'm in linux it should return ""./script.py"" and if I'm in windows it should return "".\\script.py""</p>

<p>I tried with <code>os.path.join</code> and <code>os.path.basename(__file__)</code> but it returns absolute path. </p>
"
"60015032","<p>You can do this in Loop, while changing input arguments of function. This is one way of doing it inside you Windows. You can define your locations (x,y) on plan. it will keep on doing things inside your VM.</p>

<pre><code>import win32api, win32con
def click(x,y):
    win32api.SetCursorPos((x,y))
    win32api.mouse_event(win32con.MOUSEEVENTF_RIGHTDOWN,x,y,0,0)
    win32api.mouse_event(win32con.MOUSEEVENTF_RIGHTUP,x,y,0,0)
click(100,100)
</code></pre>
","0","2020-02-01 08:01:48","2","107","9","0","16","60014869","60015032","<p>I would like to know if there is a way to make automated clicking tasks without making me unable to use the mouse on my pc to do other stuff. I mean, I want to use the pc normally with the main monitor while on the second monitor python would be performing some clicks.</p>

<p>There is any lib that can do this? Or maybe if I use a virtual machine only to run the code and the program to be automated I could use my pc without been affect? </p>
"
"60017217","<p>This should work:</p>

<pre class=""lang-py prettyprint-override""><code>cur.execute(
  ""INSERT INTO engagement.geospatial_countries (name, code, polygon) VALUES (%s, %s, %s)"",
  geometry_to_insert
)
</code></pre>

<p>please read in the docs <a href=""https://www.psycopg.org/docs/usage.html#passing-parameters-to-sql-queries"" rel=""nofollow noreferrer"">how to pass parameters to the query</a> and, if you want to insert several objects at time, <a href=""https://www.psycopg.org/docs/extras.html#psycopg2.extras.execute_values"" rel=""nofollow noreferrer"">the <code>execute_values()</code> function</a>.</p>
","1","","1","11617","147","36","778","60014973","60030831","<p>After Redshift announced support for Geometry types and spatial functions, I'd like to create a table with polygons for all countries. I'm failing to do the INSERT and would appreciate help.</p>

<p>Here is what I've tried:</p>

<p>I've downloaded the geojson and unzipped (<a href=""https://datahub.io/core/geo-countries"" rel=""nofollow noreferrer"">https://datahub.io/core/geo-countries</a>)</p>

<p>Then the following python snippet was used to create the table successfully (I've used the type GEOMETRY, not sure if I can optimise and use the sub-type POLYGON):</p>

<pre><code>import psycopg2

conn = psycopg2.connect(...connection params)
cur = conn.cursor()
cur.execute(""CREATE TABLE engagement.geospatial_countries (id INTEGER PRIMARY KEY, name VARCHAR(25), code VARCHAR(10), polygon GEOMETRY);"")
</code></pre>

<p>The following script successfully reads the geojson, each entry in ""countries"" holding a Polygon GeoJson feature: </p>

<pre><code>f = open(""geospatial-data/countries.geojson"", ""r"")
countries_file_contents = f.read()
countries_geojson = json.loads(countries_file_contents)
countries = countries_geojson[""features""]
</code></pre>

<p>For those not familiar with GeoJson, it's simply a set of JSON data that describes geospatial shapes. Here is an excerpt of the data:</p>

<pre><code>{ ""type"": ""FeatureCollection"", ""features"": [{ ""type"": ""Feature"", ""properties"": { ""ADMIN"": ""Aruba"", ""ISO_A3"": ""ABW"" }, ""geometry"": { ""type"": ""Polygon"", ""coordinates"": [ [ [ -69.996937628999916, 12.577582098000036 ], [ -69.936390753999945, 12.531724351000051 ], [ -69.924672003999945, 12.519232489000046 ], [ -69.915760870999918, 12.497015692000076 ], [ -69.880197719999842, 12.453558661000045 ], [ -69.876820441999939, 12.427394924000097 ], [ -69.888091600999928, 12.417669989000046 ], [ -69.908802863999938, 12.417792059000107 ], [ -69.930531378999888, 12.425970770000035 ], [ -69.945139126999919, 12.44037506700009 ], [ -69.924672003999945, 12.44037506700009 ], [ -69.924672003999945, 12.447211005000014 ], [ -69.958566860999923, 12.463202216000099 ], [ -70.027658657999922, 12.522935289000088 ], [ -70.048085089999887, 12.531154690000079 ], [ -70.058094855999883, 12.537176825000088 ], [ -70.062408006999874, 12.546820380000057 ], [ -70.060373501999948, 12.556952216000113 ], [ -70.051096157999893, 12.574042059000064 ], [ -70.048736131999931, 12.583726304000024 ], [ -70.052642381999931, 12.600002346000053 ], [ -70.059641079999921, 12.614243882000054 ], [ -70.061105923999975, 12.625392971000068 ], [ -70.048736131999931, 12.632147528000104 ], [ -70.00715084499987, 12.5855166690001 ], [ -69.996937628999916, 12.577582098000036 ] ] ] } }, ... more countries }]}
</code></pre>

<p>Before I insert all countries, I first just want to try and create it for a single country:</p>

<pre><code>country = countries[0]
geometry_to_insert = (
    country[""properties""][""ADMIN""],
    country[""properties""][""ISO_A3""],
    Json.dumps(country[""geometry""]) # Have also tried psycopg2.extras.Json(country[""geometry""]), as well as just using the dict
)
</code></pre>

<p>The following fails:</p>

<pre><code>cur.execute(
  ""INSERT INTO engagement.geospatial_countries (name, code, polygon) VALUES %s"",
  geometry_to_insert
)
</code></pre>

<p>With the following error:
    TypeError: not all arguments converted during string formatting</p>

<p>I've also tried</p>

<pre><code>cur.execute(
  ""INSERT INTO engagement.geospatial_countries (name, code, polygon) VALUES (%s, %s, %s)"",
  geometry_to_insert
)
</code></pre>

<p>But that gives the following error: psycopg2.errors.InternalError_: Compass I/O exception: Invalid hexadecimal character(s) found</p>

<p>How do I insert a polygon into redshift, using the new Geometry types?</p>
"
"60028730","<p>A postgres/redshift geometry is not a GeoJSON, you need to use JSON column type:</p>

<pre><code>...
cur.execute(""CREATE TABLE engagement.geospatial_countries (id INTEGER PRIMARY KEY, name VARCHAR(25), code VARCHAR(10), polygon JSON)"")
country = countries[0]
geometry_to_insert = (
    country[""properties""][""ADMIN""],
    country[""properties""][""ISO_A3""],
    Json.dumps(country[""geometry""])
)
cur.execute(
      ""INSERT INTO engagement.geospatial_countries (name, code, polygon) VALUES (%s, %s, %s)"", geometry_to_insert
)
</code></pre>
","1","","1","11727","812","303","942","60014973","60030831","<p>After Redshift announced support for Geometry types and spatial functions, I'd like to create a table with polygons for all countries. I'm failing to do the INSERT and would appreciate help.</p>

<p>Here is what I've tried:</p>

<p>I've downloaded the geojson and unzipped (<a href=""https://datahub.io/core/geo-countries"" rel=""nofollow noreferrer"">https://datahub.io/core/geo-countries</a>)</p>

<p>Then the following python snippet was used to create the table successfully (I've used the type GEOMETRY, not sure if I can optimise and use the sub-type POLYGON):</p>

<pre><code>import psycopg2

conn = psycopg2.connect(...connection params)
cur = conn.cursor()
cur.execute(""CREATE TABLE engagement.geospatial_countries (id INTEGER PRIMARY KEY, name VARCHAR(25), code VARCHAR(10), polygon GEOMETRY);"")
</code></pre>

<p>The following script successfully reads the geojson, each entry in ""countries"" holding a Polygon GeoJson feature: </p>

<pre><code>f = open(""geospatial-data/countries.geojson"", ""r"")
countries_file_contents = f.read()
countries_geojson = json.loads(countries_file_contents)
countries = countries_geojson[""features""]
</code></pre>

<p>For those not familiar with GeoJson, it's simply a set of JSON data that describes geospatial shapes. Here is an excerpt of the data:</p>

<pre><code>{ ""type"": ""FeatureCollection"", ""features"": [{ ""type"": ""Feature"", ""properties"": { ""ADMIN"": ""Aruba"", ""ISO_A3"": ""ABW"" }, ""geometry"": { ""type"": ""Polygon"", ""coordinates"": [ [ [ -69.996937628999916, 12.577582098000036 ], [ -69.936390753999945, 12.531724351000051 ], [ -69.924672003999945, 12.519232489000046 ], [ -69.915760870999918, 12.497015692000076 ], [ -69.880197719999842, 12.453558661000045 ], [ -69.876820441999939, 12.427394924000097 ], [ -69.888091600999928, 12.417669989000046 ], [ -69.908802863999938, 12.417792059000107 ], [ -69.930531378999888, 12.425970770000035 ], [ -69.945139126999919, 12.44037506700009 ], [ -69.924672003999945, 12.44037506700009 ], [ -69.924672003999945, 12.447211005000014 ], [ -69.958566860999923, 12.463202216000099 ], [ -70.027658657999922, 12.522935289000088 ], [ -70.048085089999887, 12.531154690000079 ], [ -70.058094855999883, 12.537176825000088 ], [ -70.062408006999874, 12.546820380000057 ], [ -70.060373501999948, 12.556952216000113 ], [ -70.051096157999893, 12.574042059000064 ], [ -70.048736131999931, 12.583726304000024 ], [ -70.052642381999931, 12.600002346000053 ], [ -70.059641079999921, 12.614243882000054 ], [ -70.061105923999975, 12.625392971000068 ], [ -70.048736131999931, 12.632147528000104 ], [ -70.00715084499987, 12.5855166690001 ], [ -69.996937628999916, 12.577582098000036 ] ] ] } }, ... more countries }]}
</code></pre>

<p>Before I insert all countries, I first just want to try and create it for a single country:</p>

<pre><code>country = countries[0]
geometry_to_insert = (
    country[""properties""][""ADMIN""],
    country[""properties""][""ISO_A3""],
    Json.dumps(country[""geometry""]) # Have also tried psycopg2.extras.Json(country[""geometry""]), as well as just using the dict
)
</code></pre>

<p>The following fails:</p>

<pre><code>cur.execute(
  ""INSERT INTO engagement.geospatial_countries (name, code, polygon) VALUES %s"",
  geometry_to_insert
)
</code></pre>

<p>With the following error:
    TypeError: not all arguments converted during string formatting</p>

<p>I've also tried</p>

<pre><code>cur.execute(
  ""INSERT INTO engagement.geospatial_countries (name, code, polygon) VALUES (%s, %s, %s)"",
  geometry_to_insert
)
</code></pre>

<p>But that gives the following error: psycopg2.errors.InternalError_: Compass I/O exception: Invalid hexadecimal character(s) found</p>

<p>How do I insert a polygon into redshift, using the new Geometry types?</p>
"
"60030831","<p>Here I give the steps that worked to insert it into the DB.</p>

<p>First, a minor correction in creating a table for the geometries, using IDENTITY to have an auto-incrementing ID:</p>

<pre><code>conn = psycopg2.connect(...connection params)
cur = conn.cursor()
cur.execute(""CREATE TABLE engagement.geospatial_countries (id INTEGER IDENTITY(0,1) PRIMARY KEY, name VARCHAR(25), code VARCHAR(10), polygon GEOMETRY);"")
</code></pre>

<p>Onto the Geometries. To insert the value, use a WKT value:</p>

<pre><code>import geojson
from shapely.geometry import shape
...
# exact same steps as in question to read file, then
country = countries[0]
geom = shape(country[""geometry""])
geometry_to_insert = (
    country[""properties""][""ADMIN""],
    country[""properties""][""ISO_A3""],
    geom.wkt
)
</code></pre>

<p>Then the following command to insert the value:</p>

<pre><code>cur.execute(
  ""INSERT INTO engagement.geospatial_countries (name, code, polygon) VALUES (%s, %s, ST_GeomFromText(%s))"",
  geometry_to_insert
)
</code></pre>

<p>Answers from both @Maurice Meyer and @piro guided me to this answer.</p>
","0","2020-02-02 21:50:56","2","753","255","1","68","60014973","60030831","<p>After Redshift announced support for Geometry types and spatial functions, I'd like to create a table with polygons for all countries. I'm failing to do the INSERT and would appreciate help.</p>

<p>Here is what I've tried:</p>

<p>I've downloaded the geojson and unzipped (<a href=""https://datahub.io/core/geo-countries"" rel=""nofollow noreferrer"">https://datahub.io/core/geo-countries</a>)</p>

<p>Then the following python snippet was used to create the table successfully (I've used the type GEOMETRY, not sure if I can optimise and use the sub-type POLYGON):</p>

<pre><code>import psycopg2

conn = psycopg2.connect(...connection params)
cur = conn.cursor()
cur.execute(""CREATE TABLE engagement.geospatial_countries (id INTEGER PRIMARY KEY, name VARCHAR(25), code VARCHAR(10), polygon GEOMETRY);"")
</code></pre>

<p>The following script successfully reads the geojson, each entry in ""countries"" holding a Polygon GeoJson feature: </p>

<pre><code>f = open(""geospatial-data/countries.geojson"", ""r"")
countries_file_contents = f.read()
countries_geojson = json.loads(countries_file_contents)
countries = countries_geojson[""features""]
</code></pre>

<p>For those not familiar with GeoJson, it's simply a set of JSON data that describes geospatial shapes. Here is an excerpt of the data:</p>

<pre><code>{ ""type"": ""FeatureCollection"", ""features"": [{ ""type"": ""Feature"", ""properties"": { ""ADMIN"": ""Aruba"", ""ISO_A3"": ""ABW"" }, ""geometry"": { ""type"": ""Polygon"", ""coordinates"": [ [ [ -69.996937628999916, 12.577582098000036 ], [ -69.936390753999945, 12.531724351000051 ], [ -69.924672003999945, 12.519232489000046 ], [ -69.915760870999918, 12.497015692000076 ], [ -69.880197719999842, 12.453558661000045 ], [ -69.876820441999939, 12.427394924000097 ], [ -69.888091600999928, 12.417669989000046 ], [ -69.908802863999938, 12.417792059000107 ], [ -69.930531378999888, 12.425970770000035 ], [ -69.945139126999919, 12.44037506700009 ], [ -69.924672003999945, 12.44037506700009 ], [ -69.924672003999945, 12.447211005000014 ], [ -69.958566860999923, 12.463202216000099 ], [ -70.027658657999922, 12.522935289000088 ], [ -70.048085089999887, 12.531154690000079 ], [ -70.058094855999883, 12.537176825000088 ], [ -70.062408006999874, 12.546820380000057 ], [ -70.060373501999948, 12.556952216000113 ], [ -70.051096157999893, 12.574042059000064 ], [ -70.048736131999931, 12.583726304000024 ], [ -70.052642381999931, 12.600002346000053 ], [ -70.059641079999921, 12.614243882000054 ], [ -70.061105923999975, 12.625392971000068 ], [ -70.048736131999931, 12.632147528000104 ], [ -70.00715084499987, 12.5855166690001 ], [ -69.996937628999916, 12.577582098000036 ] ] ] } }, ... more countries }]}
</code></pre>

<p>Before I insert all countries, I first just want to try and create it for a single country:</p>

<pre><code>country = countries[0]
geometry_to_insert = (
    country[""properties""][""ADMIN""],
    country[""properties""][""ISO_A3""],
    Json.dumps(country[""geometry""]) # Have also tried psycopg2.extras.Json(country[""geometry""]), as well as just using the dict
)
</code></pre>

<p>The following fails:</p>

<pre><code>cur.execute(
  ""INSERT INTO engagement.geospatial_countries (name, code, polygon) VALUES %s"",
  geometry_to_insert
)
</code></pre>

<p>With the following error:
    TypeError: not all arguments converted during string formatting</p>

<p>I've also tried</p>

<pre><code>cur.execute(
  ""INSERT INTO engagement.geospatial_countries (name, code, polygon) VALUES (%s, %s, %s)"",
  geometry_to_insert
)
</code></pre>

<p>But that gives the following error: psycopg2.errors.InternalError_: Compass I/O exception: Invalid hexadecimal character(s) found</p>

<p>How do I insert a polygon into redshift, using the new Geometry types?</p>
"
"60015697","<p>Just create two plots, in which case axes will be a list of 2 elements and use those plot.</p>

<p>Refer the <a href=""https://matplotlib.org/api/_as_gen/matplotlib.pyplot.subplots.html#matplotlib.pyplot.subplots"" rel=""nofollow noreferrer"">documentation</a>.</p>

<pre><code>f, axes = plt.subplots(2, figsize = (14,10))
sns.boxplot(x='Heating QC',y='SalePrice',hue='Central Air',  data=df, ax=axes[0])
sns.boxplot(x='Heating',y='SalePrice',hue='Central Air',  data=df, ax=axes[1])
</code></pre>
","0","","1","1151","33","3","71","60015020","60015697","<p>I want to draw two parallel box plot in together. For that I used sub plots function in python, below code I used for the that process, but I couldn't get good out put from the code, because its already draw addition two empty graphs, how I remove these empty graphs from the output? Please give ideas for that?</p>

<pre><code>f, axes = plt.subplots(2,2,figsize = (14,10))
sns.boxplot(x='Heating QC',y='SalePrice',hue='Central Air',  data=df ,ax=axes[0,0])
sns.boxplot(x='Heating',y='SalePrice',hue='Central Air',  data=df ,ax=axes[0,1])
</code></pre>

<p><strong>out put</strong></p>

<p><a href=""https://i.stack.imgur.com/8aV42.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/8aV42.png"" alt=""p""></a></p>

<p><strong>After changes got below outputs</strong></p>

<pre><code>IndexError                                Traceback (most recent call last)
&lt;ipython-input-543-7dfa6ebf0390&gt; in &lt;module&gt;
      1 f, axes = plt.subplots(1,2,figsize = (14,10))
----&gt; 2 sns.boxplot(x='Heating QC',y='SalePrice',hue='Central Air',  data=df ,ax=axes[0,0])
      3 sns.boxplot(x='Heating',y='SalePrice',hue='Central Air',  data=df ,ax=axes[0,1])

IndexError: too many indices for array
</code></pre>

<p><a href=""https://i.stack.imgur.com/zNych.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/zNych.png"" alt=""enter image description here""></a></p>
"
"60015336","<p>You need to create new twix axis on host and shrink subplot to create space for additional axis on right side. Then move new axis at right position. Some descriptions in code.   </p>

<pre><code>import matplotlib.pyplot as plt
import numpy as np

fig, host = plt.subplots()
# shrink subplot
fig.subplots_adjust(right=0.75)

# create new axis on host
par1 = host.twinx()
par2 = host.twinx()
# place second axis at far right position
par2.spines[""right""].set_position((""axes"", 1.2))


# define plot functions
def function_sin(x):
    return np.sin(x)


def function_parabola(x):
    return x**2


def function_line(x):
    return x+1

# plot data
x = np.linspace(0, 10, 100)
y_sin = function_sin(x)
y_parabola = function_parabola(x)
y_line = function_line(x)
host.plot(x, y_sin, ""b-"")
par1.plot(x, y_parabola, ""r-"")
par2.plot(x, y_line, ""g-"")

# set labels for each axis
host.set_xlabel(""VAV 16"")
host.set_ylabel(""Temperature"")
par1.set_ylabel(""Temperature"")
par2.set_ylabel(""Air Flow"")

plt.show()
</code></pre>

<p>Output:</p>

<p><a href=""https://i.stack.imgur.com/yctiy.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/yctiy.png"" alt=""enter image description here""></a></p>
","3","","3","4584","259","83","602","60015071","60015336","<p>I am trying to plot three variables, in a graph using primary and secondary axis with one variable on primary axis and two on secondary axis. My code</p>

<pre><code>vav = floor_data[floor_data['vavId'] == i]
        vav = vav.reset_index()
        x = vav.index 
        y1 = vav['nvo_temperature_sensor_pps']
        y2 = vav['nvo_airflow']
        y3 = vav['nvo_air_damper_position']   

        fig, ax1 = plt.subplots()
        ax2 = ax1.twinx()
        ax1.plot(x, y1, 'g-')
        ax2.plot(x, y2, 'b-')
        ax2.plot(x, y3, 'r-')
        ax2 = ax1.twinx()

        ax1.set_xlabel('VAV '+str(i))
        ax1.set_ylabel('temperature ', color='g')
        ax2.set_ylabel('air flow, temperature', color='b')

        plt.show()
</code></pre>

<p>I have added all the three variables but I am facing problem in y-ticks of secondary axis. My plot looks like
<a href=""https://i.stack.imgur.com/ZXaVt.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/ZXaVt.png"" alt=""enter image description here""></a></p>

<p>Is it possible to have a single y tick values on secondary axis for better readability?</p>
"
"60015615","<p>if you use Ubuntu add ""sh"" and ""-c"":</p>

<pre><code> String[] cmd = {
                            ""sh"",
                            ""-c"",
                            ""python"",
                            ""/Users/rasheenruwisha/final-year-proj/build.py"",
                            ""ARG 1"",
                            ""ARG 2"",
                        };
                        try {
                                Runtime.getRuntime().exec(cmd);
                             } catch (IOException e) {
                                e.printStackTrace();
                             }
</code></pre>
","0","","2","326","37","2","20","60015120","60015615","<p>I have a spring MVC application that need to run a python script that uploads a zip to the api. I need to render the page to the user and run the python script in the background so that the zip gets updates while the user can keep on working in the Spring Application.</p>

<pre><code>    Thread t1 = new Thread(new Runnable() {
                @Override
                public void run() {
                    String[] cmd = {
                            ""python"",
                            ""/Users/rasheenruwisha/final-year-proj/build.py"",
                            ""ARG 1"",
                            ""ARG 2"",
                    };
                    try {
                        Runtime.getRuntime().exec(cmd);
                    } catch (IOException e) {
                        e.printStackTrace();
                    }
                }
            });
            t1.start();
            return modelAndView;
</code></pre>

<p>This is the current approach I am using, I am not getting any errors but the script does not get executed,  is there anything I'm doing wrong?</p>
"
"60020115","<p>1.You can also use org.python.util.PythonInterpreter</p>

<pre><code>    PythonInterpreter interpreter = new PythonInterpreter();
    try {
     interpreter.execfile(""/Users/rasheenruwisha/final-year-proj/build.py"",""ARG 1,""ARG 
     2"");
    } catch (Exception e) {
        e.printStackTrace();
    }
</code></pre>
","0","","1","476","63","7","46","60015120","60015615","<p>I have a spring MVC application that need to run a python script that uploads a zip to the api. I need to render the page to the user and run the python script in the background so that the zip gets updates while the user can keep on working in the Spring Application.</p>

<pre><code>    Thread t1 = new Thread(new Runnable() {
                @Override
                public void run() {
                    String[] cmd = {
                            ""python"",
                            ""/Users/rasheenruwisha/final-year-proj/build.py"",
                            ""ARG 1"",
                            ""ARG 2"",
                    };
                    try {
                        Runtime.getRuntime().exec(cmd);
                    } catch (IOException e) {
                        e.printStackTrace();
                    }
                }
            });
            t1.start();
            return modelAndView;
</code></pre>

<p>This is the current approach I am using, I am not getting any errors but the script does not get executed,  is there anything I'm doing wrong?</p>
"
"60015184","<p>Idea is use <a href=""http://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.pivot_table.html"" rel=""nofollow noreferrer""><code>pivot_table</code></a> for reshape and then found index values if only one value is non missing per rows:</p>

<pre><code>df1 = df.pivot_table(index='Site', columns='Segment', aggfunc='size')
print (df1)
Segment   groupa  groupb  groupc
Site                            
cnn.com      NaN     1.0     NaN
dc.com       NaN     NaN     1.0
espn.com     1.0     1.0     NaN
news.com     1.0     NaN     NaN

print (df1.notna().sum(axis=1))
Site
cnn.com     1
dc.com      1
espn.com    2
news.com    1
dtype: int64

a = df1.index[df1.notna().sum(axis=1).eq(1)].tolist()
print (a)
['cnn.com', 'dc.com', 'news.com']
</code></pre>
","0","","2","615041","23439","1483","126104","60015157","60015184","<p>I have a columns in df such as below:</p>

<pre><code>Site      | Segment
espn.com    groupa
news.com    groupa
cnn.com     groupb
dc.com      groupc
espn.com    groupb
continued...
</code></pre>

<p>If I want to find unique sites that only exist in a segment how can I get that?</p>

<p>Meaning I only want to find unique websites that exist in one segment but not in any other.</p>

<p>So if cnn.com only exists in group b than I want that and not espn.com</p>

<p>thanks</p>
"
"60086640","<p>If you need just the normal <code>ppf</code>, it is indeed puzzling that it is so slow, but you can use <code>scipy.special.erfinv</code> instead:</p>

<pre><code>x = np.random.uniform(0,1,100)
np.allclose(special.erfinv(2*x-1)*np.sqrt(2),stats.norm().ppf(x))
# True
timeit(lambda:stats.norm().ppf(x),number=1000)
# 0.7717257660115138
timeit(lambda:special.erfinv(2*x-1)*np.sqrt(2),number=1000)
# 0.015020604943856597
</code></pre>

<p>EDIT:</p>

<p><code>lognormal</code> and <code>triangle</code> are also straight forward:</p>

<pre><code>c = np.random.uniform()

np.allclose(np.exp(c*special.erfinv(2*x-1)*np.sqrt(2)),stats.lognorm(c).ppf(x))
# True

np.allclose(((1-np.sqrt(1-(x-c)/((x&gt;c)-c)))*((x&gt;c)-c))+c,stats.triang(c).ppf(x))
# True
</code></pre>

<p>skew normal I'm not familiar enough, unfortunately.</p>
","2","2020-02-07 02:29:25","3","46998","848","1","8605","60015261","60497749","<p>I have fit a series of SciPy continuous distributions for a Monte-Carlo simulation and am looking to take a large number of samples from these distributions. However, I would like to be able to take correlated samples, such that the <code>i</code>th sample takes the e.g., 90th percentile from each of the distributions. </p>

<p>In doing this, I've found a quirk in SciPy performance:</p>

<pre class=""lang-py prettyprint-override""><code># very fast way to many uncorrelated samples of length n
for shape, loc, scale, in distro_props:
    sp.stats.norm.rvs(*shape, loc=loc, scale=scale, size=n)

# verrrrryyyyy slow way to take correlated samples of length n
correlate = np.random.uniform(size=n)
for shape, loc, scale, in distro_props:
    sp.stats.norm.ppf(correlate, *shape, loc=loc, scale=scale)
</code></pre>

<p>Most of the results about this claim that the slowness on these SciPy distros if from the type-checking etc. wrappers. However when I profiled the code, the vast bulk of the time is spent in the underlying math function <code>[_continuous_distns.py:179(_norm_pdf)]</code><a href=""https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.rv_continuous.html"" rel=""noreferrer"">1</a>. Furthermore, it scales with <code>n</code>, implying that it's looping through every elemnt internally.</p>

<p>The SciPy <a href=""https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.rv_continuous.html"" rel=""noreferrer"">docs on rv_continuous</a> almost seem to suggest that the subclass should override this for performance, but it seems bizarre that I would monkeypatch into SciPy to speed up their ppf. I would just compute this for the normal from the ppf formula, but I also use lognormal and skewed normal, which are more of a pain to implement.</p>

<p>So, what is the best way in Python to compute a fast ppf for normal, lognormal, and skewed normal distributions? Or more broadly, to take correlated samples from several such distributions?</p>
"
"60497749","<p>Ultimately, this issue was caused by my use of the <a href=""https://en.wikipedia.org/wiki/Skew_normal_distribution"" rel=""nofollow noreferrer"">skew-normal</a> distribution. The ppf of the skew-normal actually does not have a closed-form analytic definition, so in order to compute the ppf, it fell back to <code>scipy.continuous_rv</code>'s numeric approximation, which involved iteratively computing the cdf and using that to zero in on the ppf value. The skew-normal pdf is the product of the normal pdf and normal cdf, so this numeric approximation called the normal's pdf and cdf many many times. This is why when I profiled the code, it <em>looked</em> like the normal distribution was the problem, not the SKU normal. The other answer to this question was able to achieve time savings by skipping type-checking, but didn't actually make a difference on the run-time growth, just a difference on small-n runtimes.  </p>

<p>To solve this problem, I have replaced the skew-normal distribution with the <a href=""https://en.wikipedia.org/wiki/Johnson%27s_SU-distribution"" rel=""nofollow noreferrer"">Johnson SU</a> distribution. It has 2 more free parameters than a normal distribution so it can fit different types of skew and kurtosis effectively. It's supported for all real numbers, and it has a closed-form ppf definition with a fast implementation in SciPy. Below you can see example Johnson SU distributions I've been fitting from the 10th, 50th, and 90th percentiles.</p>

<p><a href=""https://i.stack.imgur.com/Lrk9q.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/Lrk9q.png"" alt=""Example distributions""></a></p>
","0","","0","792","159","5","95","60015261","60497749","<p>I have fit a series of SciPy continuous distributions for a Monte-Carlo simulation and am looking to take a large number of samples from these distributions. However, I would like to be able to take correlated samples, such that the <code>i</code>th sample takes the e.g., 90th percentile from each of the distributions. </p>

<p>In doing this, I've found a quirk in SciPy performance:</p>

<pre class=""lang-py prettyprint-override""><code># very fast way to many uncorrelated samples of length n
for shape, loc, scale, in distro_props:
    sp.stats.norm.rvs(*shape, loc=loc, scale=scale, size=n)

# verrrrryyyyy slow way to take correlated samples of length n
correlate = np.random.uniform(size=n)
for shape, loc, scale, in distro_props:
    sp.stats.norm.ppf(correlate, *shape, loc=loc, scale=scale)
</code></pre>

<p>Most of the results about this claim that the slowness on these SciPy distros if from the type-checking etc. wrappers. However when I profiled the code, the vast bulk of the time is spent in the underlying math function <code>[_continuous_distns.py:179(_norm_pdf)]</code><a href=""https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.rv_continuous.html"" rel=""noreferrer"">1</a>. Furthermore, it scales with <code>n</code>, implying that it's looping through every elemnt internally.</p>

<p>The SciPy <a href=""https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.rv_continuous.html"" rel=""noreferrer"">docs on rv_continuous</a> almost seem to suggest that the subclass should override this for performance, but it seems bizarre that I would monkeypatch into SciPy to speed up their ppf. I would just compute this for the normal from the ppf formula, but I also use lognormal and skewed normal, which are more of a pain to implement.</p>

<p>So, what is the best way in Python to compute a fast ppf for normal, lognormal, and skewed normal distributions? Or more broadly, to take correlated samples from several such distributions?</p>
"
"60015515","<p>If you override the <code>__init__</code> method of the superclass, then the <code>__init__</code> method of the subclass needs to explicitly call it if that is the intended behavior, yes.</p>

<p>Your mental model of <code>__init__</code> is incorrect; it is not the constructor method, it is a hook which the constructor method calls to let you customize object initialization easily. (The actual constructor is called <code>__new__</code> but you don't need to know this, and will probably never need to interact with it directly, let alone change it.)</p>
","0","2020-02-01 09:22:25","5","136497","9042","39241","29487","60015319","60015515","<p>I came from Java where we can avoid calling super class zero-argument constructor. The call to it is generated implicitly by the compiler. </p>

<p>I read <a href=""https://stackoverflow.com/q/2399307/8990329"">this post about super()</a> and now in question about is it really necessary to do something like this explicitly:</p>

<pre><code>class A(object):
 def __init__(self):
   print(""world"")

class B(A):
 def __init__(self):
   print(""hello"")
   super().__init__() #Do we get some Undefined Behavior if we do not call it explicitly?
</code></pre>
"
"60015466","<p>change your url pattern to</p>

<pre><code>urlpatterns = [
    # ex: /polls/
    path('', views.index, name='index'),
    # ex: /polls/5/
    path('&lt;int:question_id&gt;/detail/', views.detail, name='detail'),
    # ex: /polls/5/results/
    path('&lt;int:question_id&gt;/results/', views.results, name='results'),
    # ex: /polls/5/vote/
    path('&lt;int:question_id&gt;/vote/', views.vote, name='vote'),
]
</code></pre>

<p>Instead of curly brackets you have to use square brackets and make pattern in such a way that it should not <strong>overlap</strong> </p>
","1","","0","3084","21","48","293","60015326","60015466","<p>I just learned Django, I'm following the 'Writing your first Django app' from the website. But when I come to the Django Admin part, I got an error. </p>

<pre><code>TypeError at /admin/
'set' object is not reversible
Request Method: GET
Request URL:    http://localhost:8000/admin/
Django Version: 3.0.2
Exception Type: TypeError
Exception Value:    
'set' object is not reversible
Exception Location: D:\python\lib\site-packages\django\urls\resolvers.py in _populate, line 455
Python Executable:  D:\python\python.exe
Python Version: 3.8.1
Python Path:    
['D:\\python\\projek\\mysite',
 'D:\\python\\python38.zip',
 'D:\\python\\DLLs',
 'D:\\python\\lib',
 'D:\\python',
 'D:\\python\\lib\\site-packages']
Server time:    Sat, 1 Feb 2020 08:37:20 +0000
</code></pre>

<p>I realize that the error comes when I add new path to the urls.py file as the tutorial told.</p>

<p>Here is my urls.py code</p>

<pre><code>from django.contrib import admin
from django.urls import include, path

urlpatterns = [
    path('polls/', include('polls.urls')), &lt;&lt;---- This is the problem
    path('admin/', admin.site.urls),
]
</code></pre>

<p>here is my polls/urls.py</p>

<pre><code>from django.urls import path

from . import views

urlpatterns = {
    # ex: /polls/
    path('', views.index, name='index'),
    # ex: /polls/5/
    path('&lt;int:question_id&gt;/', views.detail, name='detail'),
    # ex: /polls/5/results/
    path('&lt;int:question_id&gt;/results/', views.results, name='results'),
    # ex: /polls/5/vote/
    path('&lt;int:question_id&gt;/vote/', views.vote, name='vote'),
}
</code></pre>

<p>When I add the polls path the error comes, but when I comment that line the app work.</p>

<p>What's wrong with my code?</p>
"
"60015358","<p>Use <a href=""https://docs.scipy.org/doc/numpy/reference/generated/numpy.where.html"" rel=""nofollow noreferrer"">where</a> with <a href=""https://docs.scipy.org/doc/numpy/reference/generated/numpy.amax.html"" rel=""nofollow noreferrer"">amax</a>, <a href=""https://docs.scipy.org/doc/numpy/reference/generated/numpy.amin.html"" rel=""nofollow noreferrer"">amin</a>.</p>

<pre><code>import numpy as np

arr = np.array([[2, 3, 9], [1,6,7], [4, 5, 8]])

max_value_index = np.where(arr == np.amax(arr))
min_value_index = np.where(arr == np.amin(arr))
</code></pre>

<p>Output:</p>

<pre><code>(array([0]), array([2]))
(array([1]), array([0]))
</code></pre>
","2","2020-02-01 08:54:56","2","4584","259","83","602","60015349","60015358","<p>Say I have a Numpy nd array like below.</p>

<pre><code>arr = np.array([[2, 3, 9], [1,6,7], [4, 5, 8]])
</code></pre>

<p>The numpy array is a 3 x 3 matrix.</p>

<p>What I want to do is the find row index which contains the overall maximum value.</p>

<p>For instance in the above example, the maximum value for the whole ndarray is 9. Since it is located in the first row, I want to return index 0.</p>

<p>What would be the most optimal way to do this?</p>

<p>I know that </p>

<pre><code>np.argmax(arr)
</code></pre>

<p>Can return the index of the maximum for the whole array, per row, or per column. However is there method that can return the index of the row which contains the overall maximum value?</p>

<p>It would also be nice if this could also be changed to column wise easily or find the minimum, etc.</p>

<p>I am unsure on how to go about this without using a loop and finding the overall max while keeping a variable for the index, however I feel that this is inefficient for numpy and that there must be a better method.</p>

<p>Any help or thoughts are appreciated.</p>

<p>Thank you for reading.</p>
"
"60017260","<p>According to the comment, I use repr() to check where the difference is. </p>

<pre><code>repr(d.find('div', 'date').string.lstrip()) == repr(date)
# ' 2/01' '2/01'
</code></pre>

<p>So I need to remove the blank</p>

<pre><code>d.find('div', 'date').string.lstrip() == date
# '2/01' '2/01'
</code></pre>

<p>Then the condition is true.</p>
","0","","1","9","0","0","2","60015354","60017260","<p>I'm crawling past some articles posted in a certain date.
The following is part of my code:</p>

<pre class=""lang-py prettyprint-override""><code>def get_articles(dom, date):
    soup = BeautifulSoup(dom, 'html.parser')

    articles = []
    divs = soup.find_all('div', ""r-ent"")
    for d in divs:
        print(""A"")
        print(d.find('div', 'date').string, date)
        if d.find('div', 'date').string == date: #Where the problem is.
            print(""YYYYYYYYYY"")
            ...
    return articles


    import time
    page = get_web_page('https://www.ptt.cc/bbs/joke/index.html')

    if page:
        date = time.strftime(""%m/%d"").lstrip('0') # date is string
        current_articles = get_articles(page, date)
        for post in current_articles:
            print(post)
</code></pre>

<pre><code>    #A 
    #2/01 2/01
    #A 
    #2/01 2/01
    #A 
    #2/01 2/01
    #A 
    #2/01 2/01
    #A 
    #2/01 2/01
    #A 
    #2/01 2/01
    #A 
    #2/01 2/01
    #A 
    #11/04 2/01
</code></pre>

<p>Ideally, the <code>YYYYYYYYYY</code> should be printed when<br>
<code>d.find('div', 'date').string == date</code></p>

<p>Why does the code execute not ideally and how do I edit it? </p>
"
"60015444","<p><code>x1_change</code>, <code>y1_change</code> are local variables in scope of <code>nextMove</code>. Variables with the same name exists in scope of <code>gameLoop</code>. This are different variables, they have just the same name. 
When you change <code>x1_change</code>, <code>y1_change</code> in <code>nextMove</code>, then do not change then identically named variables in <code>gameLoop</code>.</p>

<p>Add arguments to <code>nextMove</code> and return the changed values of <code>x1_change</code> and <code>y1_change</code>:</p>

<pre class=""lang-py prettyprint-override""><code>def nextMove(snake_head, x_ch, y_ch):
    x1_change, y1_change = x_ch, y_ch

    # chang x1_change, y1_change
    # [...]

    return x1_change, y1_change
</code></pre>

<p>Pass <code>x1_change</code> and <code>y1_change</code> to and get the new values from <code>nextMove</code> in <code>gameLoop</code>:</p>

<pre class=""lang-py prettyprint-override""><code>def gameLoop():

    # [...]

    while not game_over:

        # [...]

        our_snake(snake_block, snake_List)

        x1_change, y1_change = nextMove(snake_Head, x1_change, y1_change)

        Your_score(Length_of_snake - 1)
        pygame.display.update()
</code></pre>

<hr>

<p>If the length of the snake grows, it will hit itself, when it changes the direction to the opposite.<br>
I recommend to change the direction to the left or right instead:</p>

<pre class=""lang-py prettyprint-override""><code>def nextMove(snake_head, x_ch, y_ch):

    x1_change, y1_change = x_ch, y_ch
    x1, y1 = snake_head
    next_x, next_y = x1 + x1_change, y1 + y1_change

    if next_x &lt; 0 or next_x &gt;= dis_width:
        x1_change = 0
        y1_change = 10 if y1 &lt; dis_height // 2 else -10
    if next_y &lt; 0 or next_y &gt;= dis_height:
        x1_change = 10 if x1 &lt; dis_width // 2 else -10
        y1_change = 0

    return x1_change, y1_change
</code></pre>
","7","2020-02-01 10:09:45","0","136140","16645","626","8521","60015363","60015444","<p>I am creating Pygame script of traditional snake game which can run autonomously I.e. The snake should be aware of the surroundings (crash If hit the wall) and occupy the food</p>

<p>In order to do I just checking the next pixel position of the snake From every Direction NSWE<br>
to determine snake trajectory by this Python <code>nextMove</code> function </p>

<p>I set the screen resolution to 600*400 i.e when the snake is approaching towards wall the value of coordinates becomes 0 to 600 (min to max height) and 0 to 400(min to max width)</p>

<pre class=""lang-py prettyprint-override""><code>def nextMove(snake_head):

    x1=snake_head[0]
    y1=snake_head[1]
    next_left=x1-10
    next_right=x1+10
    next_top=y1-10
    next_down=y1+10
    print(next_left,next_right,next_top,next_down)

    if next_left&lt;0:
        x1_change=10
        y1_change=0
        x1+=x1_change
        y1+=y1_change
    if next_right&gt;= dis_width:
        x1_change=-10
        y1_change=0
        x1+=x1_change
        y1+=y1_change
    if next_top&lt;0:
        x1_change=0
        y1_change=10
        x1+=x1_change
        y1+=y1_change
    if next_down&gt;=dis_height:
        x1_change=0
        y1_change=-10
        x1+=x1_change
        y1+=y1_change
</code></pre>

<p>Snake head is a list which gives the value of x1,y1 coordinates
Although code has no error the snake still refuses and hit the wall</p>

<p>The full code</p>

<pre class=""lang-py prettyprint-override""><code>import pygame
import time
import random
import math

pygame.init()

white = (255, 255, 255)
yellow = (255, 255, 102)
black = (0, 0, 0)
red = (213, 50, 80)
green = (0, 255, 0)
blue = (50, 153, 213)

dis_width = 600
dis_height = 400

dis = pygame.display.set_mode((dis_width, dis_height))
pygame.display.set_caption('Snake Game')

clock = pygame.time.Clock()

snake_block = 10
snake_speed = 15

font_style = pygame.font.SysFont(""bahnschrift"", 25)
score_font = pygame.font.SysFont(""comicsansms"", 35)


def Your_score(score):
    value = score_font.render(""Your Score: "" + str(score), True, yellow)
    dis.blit(value, [0, 0])



def our_snake(snake_block, snake_list):
    for x in snake_list:
        pygame.draw.rect(dis, black, [x[0], x[1], snake_block, snake_block])

def nextMove(snake_head):

    x1=snake_head[0]
    y1=snake_head[1]
    next_left=x1-10
    next_right=x1+10
    next_top=y1-10
    next_down=y1+10
    print(next_left,next_right,next_top,next_down)

    if next_left&lt;0:
        x1_change=10
        y1_change=0
        x1+=x1_change
        y1+=y1_change
    if next_right&gt;= dis_width:
        x1_change=-10
        y1_change=0
        x1+=x1_change
        y1+=y1_change
    if next_top&lt;0:
        x1_change=0
        y1_change=10
        x1+=x1_change
        y1+=y1_change
    if next_down&gt;=dis_height:
        x1_change=0
        y1_change=-10
        x1+=x1_change
        y1+=y1_change



def message(msg, color):
    mesg = font_style.render(msg, True, color)
    dis.blit(mesg, [dis_width / 6, dis_height / 3])


def gameLoop():
    game_over = False
    game_close = False

    x1 = dis_width / 2
    y1 = dis_height / 2

    x1_change = 0
    y1_change = 0

    snake_List = []
    Length_of_snake = 1

    foodx = round(random.randrange(0, dis_width - snake_block) / 10.0) * 10.0
    foody = round(random.randrange(0, dis_height - snake_block) / 10.0) * 10.0

    while not game_over:

        while game_close == True:
            dis.fill(blue)
            message(""You Lost! Press C-Play Again or Q-Quit"", red)
            Your_score(Length_of_snake - 1)
            pygame.display.update()

            for event in pygame.event.get():
                if event.type == pygame.KEYDOWN:
                    if event.key == pygame.K_q:
                        game_over = True
                        game_close = False
                    if event.key == pygame.K_c:
                        gameLoop()

        for event in pygame.event.get():
            if event.type == pygame.QUIT:
                game_over = True
            if event.type == pygame.KEYDOWN:
                if event.key == pygame.K_LEFT:
                    x1_change = -snake_block
                    y1_change = 0
                elif event.key == pygame.K_RIGHT:
                    x1_change = snake_block
                    y1_change = 0
                elif event.key == pygame.K_UP:
                    y1_change = -snake_block
                    x1_change = 0
                elif event.key == pygame.K_DOWN:
                    y1_change = snake_block
                    x1_change = 0




        if x1 &gt;= dis_width or x1 &lt; 0 or y1 &gt;= dis_height or y1 &lt; 0:
            game_close = True
        x1 += x1_change
        y1 += y1_change

        dis.fill(blue)
        pygame.draw.rect(dis, green, [foodx, foody, snake_block, snake_block])
        snake_Head = []
        snake_Head.append(x1)
        snake_Head.append(y1)
        snake_List.append(snake_Head)
        print(snake_Head)
        #print(snake_List)
        if len(snake_List) &gt; Length_of_snake:
            del snake_List[0]

        for x in snake_List[:-1]:
            if x == snake_Head:
                game_close = True


        our_snake(snake_block, snake_List)
        nextMove(snake_Head)
        Your_score(Length_of_snake - 1)
        pygame.display.update()
        #determibe next move



        """"""    
        #calculating distance
        def Distance():
            x=snake_Head[0]
            y=snake_Head[1]
            dis_wleft=dis_width-x
            dis_wright=x-dis_wleft
            dis_wtop=dis_height-y
            dis_wdown=y-dis_wtop
            dis_food=math.sqrt(((foodx-x)**2)+((foody-y)**2))
            print(dis_wleft,dis_wright,dis_wtop,dis_wdown,dis_food)
        Distance()
        """"""


        if x1 == foodx and y1 == foody:
            foodx = round(random.randrange(0, dis_width - snake_block) / 10.0) * 10.0
            foody = round(random.randrange(0, dis_height - snake_block) / 10.0) * 10.0
            Length_of_snake += 1

        clock.tick(snake_speed)

    pygame.quit()
    quit()


gameLoop()

</code></pre>
"
"60015388","<p>You don't need to use <code>global</code></p>

<p>And you're <a href=""https://stackoverflow.com/questions/59996634/how-do-i-print-multiple-variables-in-a-line-of-code"">missing a formatted string</a> </p>

<pre><code>#!/usr/bin/env python3

import os

print ('Ping Of Death')
os.system(""clear"")
print() 
ipdeath = input(""ip:"")
packetsize = input(""size:"")
os.system(f""ping {ipdeath} -s {packetsize} "")
</code></pre>

<p>You're not capturing the output of the ping command, so that's why nothing would be printed for it (hint: use subprocess module instead of <code>os</code></p>
","9","","1","124322","2234","5803","53684","60015364","60015388","<p>I have a problem where running this code which seems to be right to me, but it says that my variable cannot be known </p>

<pre><code>#!/usr/bin/env python3

import random
import socket
import time
import sys
import os

print ('Ping Of Death')
os.system(""clear"")
print() 
ipdeath = input(""ip:"")
packetsize = input(""size:"")
print (ipdeath)
global ipdeath , packetsize
os.system(""ping {ipdeath} -s {packetsize} "")
</code></pre>

<p>The Variable works because it prints out of the print (ipdeath) but not out of the os.system(""ping {ipdeath} -s {packetsize} "")</p>

<p>just returns with an error that says </p>

<pre><code>ping: {ipdeath}: Name or service not known
</code></pre>

<p>thank you.</p>
"
"60028764","<h2>Make use of pairwise distances from sklearn</h2>

<ul>
<li>Pairwise distances of sparse matrices are supported (no dense temporary array needed)</li>
<li>This algorithm uses a algebraic reformulation like <a href=""https://stackoverflow.com/a/42994680/4045774"">in this answer</a></li>
<li>It can be a lot faster on high dimensional problems like yours (20k) since most of the calculation is done within a highly optimized matrix-matrix product.</li>
<li>Check if this method is precise enough, it is less numerically stable
than a ""naive"" approach pdist uses</li>
</ul>

<p><strong>Example</strong></p>

<pre><code>import numpy as np
from scipy import sparse
from sklearn import metrics
from scipy.spatial import distance

matrix=sparse.random(1_000, 20_000, density=0.05, format='csr', dtype=np.float64)

%%timeit
dist_2=distance.squareform(distance.pdist(matrix.todense()))
dist_2.sort(axis=1)
dist_2=dist_2[:,1:3]
#10.1 s ± 23.1 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)

%%timeit
dist=metrics.pairwise.euclidean_distances(matrix,squared=True)
dist.sort(axis=1)
dist=np.sqrt(dist[:,1:3])
#401 ms ± 13.1 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)
</code></pre>
","0","2020-02-02 17:39:21","0","5188","591","6","1183","60015409","60028764","<p>I've been recently trying to compute distances to top 2 nearest neighbors in Python Numba as follows</p>

<pre><code>@jit(nopython=True)
def _latent_dim_kernel(data, pointers, indices, nrange, sampling_percentage = 1):

    pdists_t2 = np.zeros((nrange, 2))
    for a in range(nrange):

        rct = 0
        for b in range(nrange):
            if np.random.random() &gt; 1- sampling_percentage:
                if a == b:
                    continue

                r1 = _get_sparse_row(a, data, pointers, indices)
                r2 = _get_sparse_row(b, data, pointers, indices)

                dist = np.linalg.norm(r2 - r1)

                if rct &gt; 1:
                    if pdists_t2[a,0] &gt; dist:
                        pdists_t2[a,0] = dist

                    elif pdists_t2[a,1] &gt; dist:
                        pdists_t2[a,1] = dist
                else:
                    pdists_t2[a,rct] = dist

                rct += 1

    return pdists_t2
</code></pre>

<p>The data, pointers and indices are x.data, x.indptr, x.indices of a CSR matrix (scipy).
This works fine, however, is substantially slower than doing </p>

<pre><code>squareform(pdist(matrix)).sort(axis=1)[:,1:3]
</code></pre>

<p>How can I speed this further without additional memory overhead?</p>

<p>Thanks!</p>
"
"60015603","<p>You can use <a href=""https://www.regular-expressions.info/lookaround.html"" rel=""nofollow noreferrer"">positive lookahead</a> expression and transform your pattern into <a href=""https://regex101.com/r/MjGtDC/3"" rel=""nofollow noreferrer""><code>(?=(aaa))</code></a>:</p>

<pre><code>for m in re.finditer('(?=(aaa))', 'aaaaaa'):
    print(m.start())
</code></pre>

<p>To get match text you need to use <code>m.group(1)</code>.</p>
","1","","1","4972","166","141","1029","60015417","60015603","<p>Here is the string I get: <code>aaaaaa</code>, And I want to report all the positions of pattern: <code>aaa</code>.</p>

<pre class=""lang-py prettyprint-override""><code>&gt;&gt;&gt; for m in re.finditer('aaa', 'aaaaaa'):
...     print(m.start())
...
0
3
</code></pre>

<p>But I want to report the starts of all the hits: </p>

<pre><code>0
1
2
3
</code></pre>
"
"60015499","<p>Manipulate the generator manually </p>

<pre><code>gen = iter(range(15)) 
while True:
    try:
        i = next(gen) 
        if i ==2:
            next(gen) 
            continue 
        else:
            pass
    except: StopIteration
        break 
</code></pre>
","2","2020-02-01 09:20:38","1","124322","2234","5803","53684","60015478","60015499","<p>I am using Python 3.8 and I was wandering if is there any way to make two steps in a one step for loop like this:</p>

<pre><code>for i in range(15):
 if i == 2:
  # make two steps
 else:
  #continue normaly
</code></pre>
"
"60015543","<p>You are missing brackets in your <code>student</code>'s class constructor:</p>

<pre class=""lang-py prettyprint-override""><code>self.Lap=self.Laptop()
</code></pre>
","2","","0","9474","543","121","728","60015491","60015543","<pre class=""lang-py prettyprint-override""><code>class student :
    def __init__(self,name,rno) :
        self.name=name
        self.rno=rno
        self.Lap=self.Laptop

    def show(self) :
        print(self.name,self.rno)
        self.Lap.show()

    class Laptop:
        def __init__(self) :
            self.brand=""hp""
            self.cpu=""i5""
            self.ram=8

        def show(self):
            print(self.brand,self.cpu,self.ram) 

s1=student(""ravi"",2)
s2=student(""kumar"",3)
s1.show()
</code></pre>

<p>I am getting the following error:</p>

<blockquote>
  <p>TypeError: show() missing 1 required positional argument: 'self'</p>
</blockquote>
"
"60015808","<p>You need to get dipper in dictionary tree to get some data like latitude. Results are collected into collection of lists then loaded into data frame and saved as csv file.</p>

<pre><code>import requests
import pandas as pd

r=requests.get('https://data.police.uk/api/crimes-street/all-crime?poly=51.169,-0.633:51.186,-0.5436:51.226,-0.6224&amp;date=2019-12')
r_json=r.json()

# collect data into list of lists
collected_data = []
for data in r_json:
    category = data.get('category')
    month = data.get('month')
    latitude = ''
    longitude = ''
    street = ''
    for key, value in data.items():
        if key == 'location':
            latitude = value.get('latitude')
            longitude = value.get('longitude')
            street = value.get('street').get('name')
    collected_data.append([category, latitude, longitude, street, month])

# load data into data frame
df = pd.DataFrame(collected_data, columns = ['Category' , 'Latitude', 'Longitude', 'Street', 'Month'])
# save data frame into csv
df.to_csv('data.csv')
</code></pre>
","3","","0","4584","259","83","602","60015529","60015808","<p>I'm trying to sort out  UK Police free API response to a readable format-csv or excel. 
Im using Requests library. My initial code is getting the response in a json format:</p>

<pre><code>import requests

r=requests.get('https://data.police.uk/api/crimes-street/all-crime?poly=51.169,-0.633:51.186,-0.5436:51.226,-0.6224&amp;date=2019-12')
r_json=r.json()
for i in j:
    for key,value in i.items():
        print (key, "":"", value)
</code></pre>

<p><strong>The code above produces as follows:</strong></p>

<pre><code>category : anti-social-behaviour location_type : Force location : {'latitude': '51.196818', 'street': {'id': 1147343, 'name': 'On or near Parking Area'}, 'longitude': '-0.605146'} context :  outcome_status : None persistent_id :  id : 79955592 location_subtype :  month : 2019-12
</code></pre>

<p>How can I create a table with correct headers for the response I get? Headers would be  'category',  'latitude', 'street', 'name', 'longitude', ' month'. </p>
"
"60016707","<p>Hi let me know if this works for you or not,</p>

<p>Just For example I have created the data frame</p>

<pre><code>import pandas as pd

data1={'A':[1,2,3,43],
    'B':[11,22,3,53],
    'C':[21,23,3,433],
    'D':[131,223,3,54]}

df=pd.DataFrame(data1)
df.index.names=['index']
print(df)
</code></pre>

<p><strong>DataFrame</strong></p>

<pre><code>       A    B   C   D
index               
0      1    11  21  131
1      2    22  23  223
2      3    3   3   3
3      43   53  433 54

ind=df[df['A']+df['B'] == df['C']+df['D']].index # get the index where values are similar. Here i have done the addition of the values from first two columns and same with next two columns, if both sums are equal then get the index.

df.drop(ind,inplace=True)  #drop row (ind=2) and save the dataframe 
print(df)
</code></pre>

<p><strong>Final output</strong></p>

<pre><code>       A    B   C   D
index               
0      1    11  21  131
1      2    22  23  223
3      43   53  433 54
</code></pre>

<p>Note: index 2 row is removed.</p>
","2","","0","366","68","7","34","60015596","60016707","<p>I have a data set like below and I want to drop the row of data with same value:</p>

<p><a href=""https://i.stack.imgur.com/TDkPJ.png"" rel=""nofollow noreferrer"">enter image description here</a></p>

<p>I think I can check the value of all rows, if all are duplicate then drop it, or I can specify a row with specific time (12:30 in this case), but I don't know how to code it...</p>

<p>I tried the following and try to drop just one line but fail..</p>

<p>df.drop['2020-01-29 12:30']</p>

<p>Anyone could give me a push? Thanks in advance!</p>
"
"60015803","<p>By typing:</p>

<pre class=""lang-py prettyprint-override""><code>example_tuple[0[:-1]]
</code></pre>

<p>Python tries to compute what's inside the bracket first, that is <code>0[:-1]</code>. That explains the error:</p>

<pre class=""lang-py prettyprint-override""><code>TypeError: 'int' object is not subscriptable
</code></pre>

<p>You are trying to access <code>0</code> as an array.</p>

<p>As @ShubhamShaswat said, to access an array within an array, you need to get the first one, and access the value you want in it:</p>

<pre class=""lang-py prettyprint-override""><code>example_tuple = [[5.7, 2.9, 7.9], [0.1, 4.2], [1.2]]

### Using 2 steps ###
# temp_var equals [5.7, 2.9, 7.9]
temp_var = example_tuple[0]
# output: [5.7, 2.9]
print(temp_var[:-1])

### Which can be shortened in Python by assembling array access ###
# output: [5.7, 2.9]
print(example_tuple[0][:-1])
</code></pre>
","0","","2","61","0","0","2","60015606","60015803","<p>In a python tuple I want to acces the first entry. I can do that by writing:</p>

<pre><code>example_tuple[0]
</code></pre>

<p>Now this first entry is an array of float. From this array I want to get all entries except the last one. Like descibed <a href=""https://stackoverflow.com/questions/18169965/how-to-delete-last-item-in-list"">here</a>, I did this by writing:</p>

<pre><code>example_array[:-1]
</code></pre>

<p>Now I want to stack these two features and I tried it with the following command:</p>

<pre><code>example_tuple[0[:-1]]
</code></pre>

<p>This is producing the following error:</p>

<pre><code>TypeError: 'int' object is not subscriptable
</code></pre>

<p>I'm not sure what's wrong as there is no integer involved in this.</p>
"
"60028526","<p>Downgrading JRE version to 8 and installing the <code>language-check</code> package as <code>root</code> user did the trick for me.</p>
","0","","0","4486","291","5","855","60015613","60028526","<p>I'm using <a href=""https://github.com/myint/language-check"" rel=""nofollow noreferrer"">language-check</a> python package in one of my Django projects.</p>

<p>I've installed it using <code>pip install --upgrade language-check</code> command. It was working fine in my device. Then I've hosted the project to an AWS ec2 instance. When I try to use the package it gives me to the following error : </p>

<blockquote>
  <p>language_check.Error: <a href=""http://127.0.0.1:8081"" rel=""nofollow noreferrer"">http://127.0.0.1:8081</a>: Remote end closed
  connection without response</p>
</blockquote>

<p>And this is my inbound rules : </p>

<p><a href=""https://i.stack.imgur.com/PG5jP.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/PG5jP.png"" alt=""enter image description here""></a></p>

<p>How can I solve the issue? Thanks in advance!</p>
"
"60015729","<p>You need to unpack the params list:</p>

<pre><code>out += '({:.4f},{:.4f})'.format(x,f(x, *params ))  # * == splat operator, unpacks list
</code></pre>

<p>to get</p>

<pre><code>\draw[thick] (0.0000,0.0000) -- (1.0000,1.0000) -- (2.0000,2.0000);
\draw[thick] (0.0000,0.1000) -- (1.0000,1.1000) -- (2.0000,2.1000);
\draw[thick] (0.0000,2.0000) -- (1.0000,2.3000) -- (2.0000,2.6000);
</code></pre>
","0","","2","42762","4753","7949","7626","60015678","60015729","<p>I would like to define a function that uses another function with a variable number of parameters passed as parameter.
The problem is to get the parameters in (1) and pass them to the call in (2):</p>

<pre><code>def f1(x):
  return x
def f2(x,a):
  return x+a  
def f3(x,a,b):
  return b*x+a

def genStr(x0,x1, n, f, *params):  # &lt;----------------- (1)
  out = ''
  dx = (x1-x0)/(n-1)
  x = x0
  out += r'\draw[thick] '
  for k in range(0,n):
    if k!=0:
      out += r' -- '
    out += '({:.4f},{:.4f})'.format(x,f(x,params))  # &lt;------- (2)
    x += dx
  out += r';'
  return out

print(genStr(0, 2, 3, f1))
print(genStr(0, 2, 3, f2, 0.1))
print(genStr(0, 2, 3, f3, 2, 0.3))
</code></pre>
"
"60015917","<p>One of the alternate ways is to extract the groups first, then replace like in below, your looping method is still better. </p>

<p>We need to alter the regex_dict a bit, </p>

<pre><code>regex_dict = {
 r'mcdonalds|mcdonald_s':""McDonalds"",
 r'lidl|lidi':""Lidl"",
 r'wallmart': ""Wallmart"",
 r'kfc':""KFC"" ,
 r'aldi|aldi':""Aldi""
}

df.str.extract(r'('+ '|'.join(regex_dict.keys())+')',expand=False).replace(regex_dict,regex=True)
0    McDonalds
1         Lidl
2         Lidl
3          KFC
4         Lidl
</code></pre>
","1","2020-02-01 10:33:02","2","26658","1663","208","2991","60015726","60238126","<p>I have a dataframe of shop names that I'm trying to standardize. Small sample to test here:</p>

<pre><code>import pandas as pd

df = pd.DataFrame({'store': pd.Series(['McDonalds', 'Lidls', 'Lidl New York 123', 'KFC', 'Lidi Berlin', 'Wallmart LA 90210', 'Aldi', 'London Lidl', 'Aldi627', 'mcdonaldsabc123', 'Mcdonald_s', 'McDonalds12345', 'McDonalds5555', 'McDonalds888', 'Aldi123', 'KFC-786', 'KFC-908', 'McDonalds511', 'GerALDInes Shop'],dtype='object',index=pd.RangeIndex(start=0, stop=19, step=1)), 'standard': pd.Series([pd.np.nan, pd.np.nan, pd.np.nan, pd.np.nan, pd.np.nan, pd.np.nan, pd.np.nan, pd.np.nan, pd.np.nan, pd.np.nan, pd.np.nan, pd.np.nan, pd.np.nan, pd.np.nan, pd.np.nan, pd.np.nan, pd.np.nan, pd.np.nan, pd.np.nan],dtype='float64',index=pd.RangeIndex(start=0, stop=19, step=1))}, index=pd.RangeIndex(start=0, stop=19, step=1))

                store  standard
0           McDonalds       NaN
1               Lidls       NaN
2   Lidl New York 123       NaN
3                 KFC       NaN
4         Lidi Berlin       NaN
5   Wallmart LA 90210       NaN
6                Aldi       NaN
7         London Lidl       NaN
8             Aldi627       NaN
9     mcdonaldsabc123       NaN
10         Mcdonald_s       NaN
11     McDonalds12345       NaN
12      McDonalds5555       NaN
13       McDonalds888       NaN
14            Aldi123       NaN
15            KFC-786       NaN
16            KFC-908       NaN
17       McDonalds511       NaN
18    GerALDInes Shop       NaN
</code></pre>

<p>I set up a regex dictionary to search for a string, and insert a standardized version of the shop name into the column <code>standard</code>. This works fine for this small dataframe:</p>

<pre><code># set up the dictionary
regex_dict = {
 ""McDonalds"": r'(mcdonalds|mcdonald_s)',
 ""Lidl"" : r'(lidl|lidi)',
 ""Wallmart"":r'wallmart',
 ""KFC"": r'KFC',
 ""Aldi"":r'(\baldi\b|\baldi\d+)'
}

# loop through dictionary, using str.replace 
for regname, regex_formula in regex_dict.items(): 

    df.loc[df['store'].str.contains(regex_formula,na=False,flags=re.I), 'standard'] = regname

print(df)

                store   standard
0           McDonalds  McDonalds
1               Lidls       Lidl
2   Lidl New York 123       Lidl
3                 KFC        KFC
4         Lidi Berlin       Lidl
5   Wallmart LA 90210   Wallmart
6                Aldi       Aldi
7         London Lidl       Lidl
8             Aldi627       Aldi
9     mcdonaldsabc123  McDonalds
10         Mcdonald_s  McDonalds
11     McDonalds12345  McDonalds
12      McDonalds5555  McDonalds
13       McDonalds888  McDonalds
14            Aldi123       Aldi
15            KFC-786        KFC
16            KFC-908        KFC
17       McDonalds511  McDonalds
18    GerALDInes Shop        NaN
</code></pre>

<p>The problem is I have about SIX million rows to standardize, with a regex dictionary much larger than the one shown here. (many different shop names with some mispellings etc.)</p>

<p>What I would like to do is at each loop, only use <code>str.contains</code> for rows that have <strong>not</strong> been standardized, and ignore the rows that have been standardized. The idea is to reduce the search space with each loop, therefore reducing the overall processing time. </p>

<p>I have tested indexing by the <code>standard</code> column, only performing <code>str.contains</code> on rows where <code>standard</code> is <code>Nan</code>, but it does not result in any real speedup. It still takes time to figure out which rows are <code>Nan</code> before applying <code>str.contains</code>. </p>

<p>Here is what I tried to reduce the processing time each loop:</p>

<pre><code>for regname, regex_formula in regex_dict.items(): 

    # only apply str.contains to rows where standard == NAN
    df.loc[df['standard'].isnull() &amp; df['store'].str.contains(regex_formula,na=False,flags=re.I), 'standard'] = regname
</code></pre>

<p>This works .. but using this on my full 6 million rows makes no real difference in speed. </p>

<p>Is it even possible to speed this up on a dataframe of 6 million rows? </p>
"
"60238126","<p>I managed to reduced the time needed by 40% using this. Best I could do</p>

<p>I create an empty dataframe called <code>fixed_df</code> to append new standardized rows, then delete the same rows in the original dataframe at the end of each loop. The search space is reduced for each loop as each shop is standardized, and the <code>fixed_df</code> increases in size with each loop. In the end, <code>fixed_df</code> should have all the original rows, now standardized, and the original df should be empty. </p>

<pre><code># create empty df to store new results
fixed_df = pd.DataFrame()

# loop through dictionary
for regname, regex_formula in regex_dict.items(): 

    # search for regex formula, add standardized name into standard column
    df.loc[df['term_location'].str.contains(regex_formula,na=False,flags=re.I), 'standard'] = regname

    # get index of where names were fixed
    ind = df[df['standard']==regname].index

    # append fixed data to new df
    fixed_df.append(df[df.index.isin(ind)].copy())

    # remove processed stuff from original df
    df = df[~df.index.isin(ind)].copy()
</code></pre>
","0","","1","2167","119","1","235","60015726","60238126","<p>I have a dataframe of shop names that I'm trying to standardize. Small sample to test here:</p>

<pre><code>import pandas as pd

df = pd.DataFrame({'store': pd.Series(['McDonalds', 'Lidls', 'Lidl New York 123', 'KFC', 'Lidi Berlin', 'Wallmart LA 90210', 'Aldi', 'London Lidl', 'Aldi627', 'mcdonaldsabc123', 'Mcdonald_s', 'McDonalds12345', 'McDonalds5555', 'McDonalds888', 'Aldi123', 'KFC-786', 'KFC-908', 'McDonalds511', 'GerALDInes Shop'],dtype='object',index=pd.RangeIndex(start=0, stop=19, step=1)), 'standard': pd.Series([pd.np.nan, pd.np.nan, pd.np.nan, pd.np.nan, pd.np.nan, pd.np.nan, pd.np.nan, pd.np.nan, pd.np.nan, pd.np.nan, pd.np.nan, pd.np.nan, pd.np.nan, pd.np.nan, pd.np.nan, pd.np.nan, pd.np.nan, pd.np.nan, pd.np.nan],dtype='float64',index=pd.RangeIndex(start=0, stop=19, step=1))}, index=pd.RangeIndex(start=0, stop=19, step=1))

                store  standard
0           McDonalds       NaN
1               Lidls       NaN
2   Lidl New York 123       NaN
3                 KFC       NaN
4         Lidi Berlin       NaN
5   Wallmart LA 90210       NaN
6                Aldi       NaN
7         London Lidl       NaN
8             Aldi627       NaN
9     mcdonaldsabc123       NaN
10         Mcdonald_s       NaN
11     McDonalds12345       NaN
12      McDonalds5555       NaN
13       McDonalds888       NaN
14            Aldi123       NaN
15            KFC-786       NaN
16            KFC-908       NaN
17       McDonalds511       NaN
18    GerALDInes Shop       NaN
</code></pre>

<p>I set up a regex dictionary to search for a string, and insert a standardized version of the shop name into the column <code>standard</code>. This works fine for this small dataframe:</p>

<pre><code># set up the dictionary
regex_dict = {
 ""McDonalds"": r'(mcdonalds|mcdonald_s)',
 ""Lidl"" : r'(lidl|lidi)',
 ""Wallmart"":r'wallmart',
 ""KFC"": r'KFC',
 ""Aldi"":r'(\baldi\b|\baldi\d+)'
}

# loop through dictionary, using str.replace 
for regname, regex_formula in regex_dict.items(): 

    df.loc[df['store'].str.contains(regex_formula,na=False,flags=re.I), 'standard'] = regname

print(df)

                store   standard
0           McDonalds  McDonalds
1               Lidls       Lidl
2   Lidl New York 123       Lidl
3                 KFC        KFC
4         Lidi Berlin       Lidl
5   Wallmart LA 90210   Wallmart
6                Aldi       Aldi
7         London Lidl       Lidl
8             Aldi627       Aldi
9     mcdonaldsabc123  McDonalds
10         Mcdonald_s  McDonalds
11     McDonalds12345  McDonalds
12      McDonalds5555  McDonalds
13       McDonalds888  McDonalds
14            Aldi123       Aldi
15            KFC-786        KFC
16            KFC-908        KFC
17       McDonalds511  McDonalds
18    GerALDInes Shop        NaN
</code></pre>

<p>The problem is I have about SIX million rows to standardize, with a regex dictionary much larger than the one shown here. (many different shop names with some mispellings etc.)</p>

<p>What I would like to do is at each loop, only use <code>str.contains</code> for rows that have <strong>not</strong> been standardized, and ignore the rows that have been standardized. The idea is to reduce the search space with each loop, therefore reducing the overall processing time. </p>

<p>I have tested indexing by the <code>standard</code> column, only performing <code>str.contains</code> on rows where <code>standard</code> is <code>Nan</code>, but it does not result in any real speedup. It still takes time to figure out which rows are <code>Nan</code> before applying <code>str.contains</code>. </p>

<p>Here is what I tried to reduce the processing time each loop:</p>

<pre><code>for regname, regex_formula in regex_dict.items(): 

    # only apply str.contains to rows where standard == NAN
    df.loc[df['standard'].isnull() &amp; df['store'].str.contains(regex_formula,na=False,flags=re.I), 'standard'] = regname
</code></pre>

<p>This works .. but using this on my full 6 million rows makes no real difference in speed. </p>

<p>Is it even possible to speed this up on a dataframe of 6 million rows? </p>
"
"60015871","<p>First create groups by test non missing values with cumulative sum and pass to <a href=""http://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.core.groupby.GroupBy.apply.html"" rel=""nofollow noreferrer""><code>GroupBy.apply</code></a> with lambda function with <a href=""https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.ffill.html"" rel=""nofollow noreferrer""><code>Series.ffill</code></a> with limit by first value of <code>times</code> per groups:</p>

<pre><code>#if necessary convert strings t onumeric and NaNs
#df['amount'] = pd.to_numeric(df['amount'], errors='coerce')

print (df['amount'].dtype)
float64

g = df['amount'].notna().cumsum()

f = lambda x: x['amount'].ffill(limit=x['times'].iat[0])
df['amount'] = df.groupby(g, group_keys=False).apply(f)
print (df)
       amount  times
0   2800000.0      6
1   2800000.0      0
2   2800000.0      0
3   2800000.0      0
4   2800000.0      0
5   2800000.0      0
6   2800000.0      0
7   4750000.0      4
8   4750000.0      0
9   4750000.0      0
10  4750000.0      0
11  4750000.0      0
12        NaN      0
13        NaN      0
</code></pre>
","1","2020-02-01 10:14:28","2","615041","23439","1483","126104","60015834","60015871","<p>I want to forward fill the amount column based on times column. for example first value is 2800000.0 , i want this value to be filled 6 times.</p>

<pre><code>amount      times       
2800000.0    6
nan     0    0   
nan     0    0   
nan     0    0   
nan     0    0   
nan     0    0   
nan     0    0   
4750000.0    4         
nan     0    0   
nan     0    0   
nan     0    0   
nan     0    0   
nan     0    0   
nan     0    0    
</code></pre>

<p>Desired output:</p>

<pre><code>amount      times       
2800000.0    6
2800000.0    0   
2800000.0    0   
2800000.0    0   
2800000.0    0   
2800000.0    0   
2800000.0    0   
4750000.0    4         
4750000.0    0   
4750000.0    0   
4750000.0    0   
4750000.0    0   
nan     0    0   
nan     0    0   
</code></pre>
"
"60016037","<p>Assuming that you don't want to use the straight forward solution by iterating the indices list instead:</p>

<p>The problem is that one of the variables you're depending on (the index) is not included in your call to <code>map</code>. You'll have to insert that into the map call in some way, for example by using <code>enumerate</code> - which will emit a <code>(idx, value)</code> tuple for each element in your list.</p>

<pre><code>nums = [123, 456, 1, 0, -2, 13, 15, 29, 47, 48]
indices = [0, 1, 2, 3]

result = list(
    map(
        lambda x: x[1] + 10 if x[0] in indices else x[1],
        enumerate(nums)
    )
)

print(result)
</code></pre>

<p>Be aware that the <code>if x[0] in indices</code> part will search the indices list linearly, and will make the whole operation <code>O(n * m)</code>. This can be optimised by using a set (which has O(1) lookup as the common case) or a dictionary instead.  </p>

<pre><code>&gt; [133, 466, 11, 10, -2, 13, 15, 29, 47, 48]
</code></pre>
","0","2020-02-01 10:34:24","1","37257","1432","259","3476","60015884","60016037","<p>I want to map a function only to specific elements in a list; those would be the elements of the indices existent in the indices list. I have tried lots of things similar to what I've written here, below. I am trying to achieve this without using the classic for-loop. *edit: by ""classic for-loop"" I mean using range ( something like: for i in range(len(list)) )</p>

<pre><code>lista = [123, 456, 1, 0, -2, 13, 15, 29, 47, 48]
index_list = [0, 1, 2, 3]
lista = list( map( lambda x: x + 10 if #some condition here I could not figure out#
\ else x for x in list ) ) 
print(lista) 
#expected output: [133, 466, 11, 10, -2, 13, 15, 29, 47, 48]
</code></pre>

<p>I have also tried defining my own function and then mapping it, but to no avail. How can I do this?</p>
"
"60021414","<p>With cx_Oracle 7.3, you can access <a href=""https://cx-oracle.readthedocs.io/en/latest/api_manual/cursor.html#Cursor.lastrowid"" rel=""nofollow noreferrer""><code>Cursor.lastRowid</code></a> after executing the INSERT.  See the cx_Oracle example <a href=""https://github.com/oracle/python-cx_Oracle/blob/master/samples/LastRowid.py"" rel=""nofollow noreferrer""><code>LastRowid.py</code></a>:</p>

<pre><code>cursor = connection.cursor()
cursor.execute(""insert into mytab (id, data) values (:1, :2)"", [1, ""First""])
print(""Rowid 1:"", cursor.lastrowid)
</code></pre>

<p>Otherwise use the RETURNING INTO clause you were looking at.  There is a RETURNING INTO example at <a href=""https://cx-oracle.readthedocs.io/en/latest/user_guide/bind.html#dml-returning-bind-variables"" rel=""nofollow noreferrer"">https://cx-oracle.readthedocs.io/en/latest/user_guide/bind.html#dml-returning-bind-variables</a>.</p>
","0","","1","5893","301","67","1035","60015903","60021414","<p>I am trying to create a definition using cx_oracle to insert data in to the database and in return get the record id. I searched the forum and found the solution as below. </p>

<pre><code>def insert_data(self,SqlQry):
     try:
         idvar=self.__cursor.var(cx_Oracle.NUMBER)
         SqlQry=SqlQry + "" returning ID into :vrecord_id""

         self.__cursor.execute(SqlQry,v1='test1',v2='test2',v3='test3',v4='test4', vrecord_id=idvar)
         vid= idvar.getvalue()
         self.__con.commit()
         retuen vid    

     except cx_Oracle.DatabaseError as e:
         return e
         print(""Error in data insert"")  


print(sql_insertData(""INSERT INTO MYTABLE(Field1,Field2,Field3,Field4) VALUES(:v1, :v2, :v3,:v4)"")
</code></pre>

<p>This works fine and i am able to get the ID. But i want to pass the values with the sql statement inplace of defining each individually as i have done now in .execute line.</p>

<pre><code>cursor.execute(SqlQry,v1='test1',v2='test2',v3='test3',v4='test4', vrecord_id=idvar)
</code></pre>

<p>I want to change the current print statement to like this :</p>

<pre><code>print(sql_insertData(
        """"""INSERT INTO RAP_RISK_TYPE(RISK_HEADER,RISK_TYPE_DISP,RISK_TYPE_DESC,RISK_TYPE_CAT) 
           VALUES
           (:v1, :v2, :v3,:v4)"""""", ['newvalue1','newvalue2','newvalue3','newvalue4']
</code></pre>

<p>But if i do this how do i write the execute statement to get the ID, i get error if i do the below</p>

<pre><code>def insert_data(self,SqlQry,parm):
        try:
            idvar=self.__cursor.var(cx_Oracle.NUMBER)
            SqlQry=SqlQry + "" returning ID into :vrecord_id""

            self.__cursor.execute(SqlQry,parm, vrecord_id=idvar)
            vid= idvar.getvalue()
            self.__con.commit()
            retuen vid    

        except cx_Oracle.DatabaseError as e:
            return e
            print(""Error in data insert"")  


print(sql_insertData(
        """"""INSERT INTO RAP_RISK_TYPE(RISK_HEADER,RISK_TYPE_DISP,RISK_TYPE_DESC,RISK_TYPE_CAT) 
           VALUES
           (:v1, :v2, :v3,:v4)"""""", ['newvalue1','newvalue2','newvalue3','newvalue4']

</code></pre>

<p>I am not able to pass the list from the print statement and add the ""idvar"" both at same time.</p>
"
"60047300","<p>Chris has given an excellent generic answer. If you are looking for the specific answer to your question, you need to do the following:</p>

<pre><code>self.__cursor.execute(SqlQry, parm + [idvar])
</code></pre>

<p>In other words, you need to ensure that only one set of parameters is passed, not multiple!</p>
","0","","1","4845","20","3","677","60015903","60021414","<p>I am trying to create a definition using cx_oracle to insert data in to the database and in return get the record id. I searched the forum and found the solution as below. </p>

<pre><code>def insert_data(self,SqlQry):
     try:
         idvar=self.__cursor.var(cx_Oracle.NUMBER)
         SqlQry=SqlQry + "" returning ID into :vrecord_id""

         self.__cursor.execute(SqlQry,v1='test1',v2='test2',v3='test3',v4='test4', vrecord_id=idvar)
         vid= idvar.getvalue()
         self.__con.commit()
         retuen vid    

     except cx_Oracle.DatabaseError as e:
         return e
         print(""Error in data insert"")  


print(sql_insertData(""INSERT INTO MYTABLE(Field1,Field2,Field3,Field4) VALUES(:v1, :v2, :v3,:v4)"")
</code></pre>

<p>This works fine and i am able to get the ID. But i want to pass the values with the sql statement inplace of defining each individually as i have done now in .execute line.</p>

<pre><code>cursor.execute(SqlQry,v1='test1',v2='test2',v3='test3',v4='test4', vrecord_id=idvar)
</code></pre>

<p>I want to change the current print statement to like this :</p>

<pre><code>print(sql_insertData(
        """"""INSERT INTO RAP_RISK_TYPE(RISK_HEADER,RISK_TYPE_DISP,RISK_TYPE_DESC,RISK_TYPE_CAT) 
           VALUES
           (:v1, :v2, :v3,:v4)"""""", ['newvalue1','newvalue2','newvalue3','newvalue4']
</code></pre>

<p>But if i do this how do i write the execute statement to get the ID, i get error if i do the below</p>

<pre><code>def insert_data(self,SqlQry,parm):
        try:
            idvar=self.__cursor.var(cx_Oracle.NUMBER)
            SqlQry=SqlQry + "" returning ID into :vrecord_id""

            self.__cursor.execute(SqlQry,parm, vrecord_id=idvar)
            vid= idvar.getvalue()
            self.__con.commit()
            retuen vid    

        except cx_Oracle.DatabaseError as e:
            return e
            print(""Error in data insert"")  


print(sql_insertData(
        """"""INSERT INTO RAP_RISK_TYPE(RISK_HEADER,RISK_TYPE_DISP,RISK_TYPE_DESC,RISK_TYPE_CAT) 
           VALUES
           (:v1, :v2, :v3,:v4)"""""", ['newvalue1','newvalue2','newvalue3','newvalue4']

</code></pre>

<p>I am not able to pass the list from the print statement and add the ""idvar"" both at same time.</p>
"
"60016212","<p>you should write like this</p>

<pre><code>idx= -1
for i in range(len(transmisiones)):
        if transmisiones[i] == 1:
            idx = i
        transmisiones[i] = 0

transmisiones[idx] = 1

</code></pre>

<p>the <code>idx</code> always keep the last index where the value is equal to 1</p>

<p>if you want all the indices to be saved append them in the a list</p>
","1","","2","1054","33","16","194","60015929","60016212","<p>I want to replace elements in a list if they coincide in the same list untill there is only an 1 in the list. If I have [1,0,1,0,1], the list becomes [0,0,1,0,0] or something like that, only with an 1... but it doesnt replace elements and it prints the same list...</p>

<pre><code> import random 

p = float(input(""Introduzca probabilidad de transmisión: ""))
q = 1 - p
usuarios = ['Usuario1','Usuario2', 'Usuario3', 'Usuario 4', 'Usuario5']
transmisiones = []

for i in usuarios:
    if random.random() &lt; p:
        transmisiones.append(1)
    else:
        transmisiones.append(0)

    print(transmisiones)

    for elemento in transmisiones:
        if elemento == 1 and transmisiones[0:5] == 1:
            transmisiones[elemento] = 0


    print(transmisiones)




    output:

    Introduzca probabilidad de transmisión: 0.6
    [1, 1, 0, 0, 0]
    [1, 1, 0, 0, 0]
</code></pre>
"
"60016125","<p>I've run into bugs like this before. I don't know if Kivy is working as intended with this or how to fix it. Anyone with more knowledge than me, I'd be glad to hear the reasoning to this.</p>

<pre><code>class CustomDropDown(DropDown):

    def __init__(self, **kwargs):
        super(CustomDropDown, self).__init__(**kwargs)
        self.add_buttons()

    def add_buttons(self):
        for index in range(10):

            #btn = Button(text='Value %d' % index, size_hint_y=None, height=44)
            btn = Button(text='Value %d' % index)
            btn.size_hint_y = None
            btn.height = 44


            btn.bind(on_release=lambda btn: self.select(btn.text))

            self.add_widget(btn)
</code></pre>

<p>These kind of things cause me nothing but frustration.</p>
","5","","1","66","2","0","9","60015941","60016125","<p>I am trying to create a dropdown list that is called when a button is submitted. After the drop down list is called i want the value of the button to be set to the button in the dropdown list that has been selected. I then want to retrieve this value back in my code to carry out some logic. I found this question that has been previously asked and it outlines exactly what i would like to achieve <a href=""https://stackoverflow.com/questions/50759993/python-kivy-get-text-from-dynamically-created-buttons-with-a-dropdown"">Python, Kivy. Get text from dynamically created buttons with a dropdown</a>. However, i tried incorporating the answer in my code but for some reason the drop down list does not appear. I would really appreciate if someone could help me out and tell me what is it i am doing in correctly.</p>

<p><strong>Scrap.py</strong></p>

<pre><code>from kivy.app import App
from kivy.uix.checkbox import CheckBox
from kivy.uix.button import Button
from kivy.uix.screenmanager import Screen, ScreenManager
from kivy.properties import ObjectProperty
from kivy.core.window import Window
from kivy.uix.dropdown import DropDown
import datetime as dt

Window.size = (800,600)

class CustomDropDown(DropDown):

    def __init__(self, **kwargs):
        super(CustomDropDown, self).__init__(**kwargs)
        self.add_buttons()

    def add_buttons(self):
        for index in range(10):

            btn = Button(text='Value %d' % index, size_hint_y=None, height=44)

            btn.bind(on_release=lambda btn: self.select(btn.text))

            self.add_widget(btn)

class MainWindow(Screen):

    check_solid = ObjectProperty(False)
    check_water = ObjectProperty(False)
    check_boiling = ObjectProperty(False)
    s_id = str(dt.datetime.now().strftime(""%y%m%d%H%M""))

    def btn(self):

        print(self.check_solid.state)
        print(self.check_water.state)
        print(self.check_boiling.state)

class MyScreenManager(ScreenManager):
    def Run_Draws_Test(self, value):
        print(value)

class Checkbox(CheckBox):
    pass


class ScrapApp(App):
    title = ""Chemistry Sample Requests""

    def build(self):
        return MyScreenManager()


if __name__ == '__main__':
    ScrapApp().run()
</code></pre>

<p><strong>scrap.kv</strong></p>

<pre><code>#:import Factory kivy.factory.Factory

&lt;Button&gt;:
    size_hint: 0.1,0.1

&lt;Label&gt;:
    size_hint: 0.1,0.1

&lt;Checkbox&gt;:
    size_hint: 0.1,0.1

&lt;TextInput&gt;:
    size_hint: 0.2,0.1
    multiline: False

&lt;CustomDropDown&gt;:
    on_select:
        app.root.ids.MainWindow.ids.mainbutton.text = '{}'.format(args[1])
        app.root.Run_Draws_Test(args[1])

&lt;MainWindow&gt;:
    orientation: ""vertical""

    check_solid: solid_check
    check_boiling: boiling_check
    check_water: water_check

    FloatLayout:

        Label:
            text: ""Sample ID: ""
            pos_hint: {""x"":0.05, ""top"":0.95}

        Label:
            text: root.s_id
            pos_hint: {""x"":0.2, ""top"": 0.95}

        Label:
            text: ""Plant ID: ""
            pos_hint: {""x"":0.05, ""top"": 0.8}

        Button:
            id: mainbutton
            text: ""Choose""
            pos: 400,400
            size_hint: None,None
            size: 150, 50
            on_release: Factory.CustomDropDown().open(self)

        Label:
            text: ""Formulation: ""
            pos_hint: {""x"":0.05, ""top"": 0.65}

        TextInput:
            id: id_formulation
            pos_hint: {""x"":0.2, ""top"": 0.65}

        Label:
            text: ""Solids Test: ""
            pos_hint: {""x"":0.05, ""top"": 0.5}

        Checkbox:
            id: solid_check
            pos_hint: {""x"":0.25, ""top"": 0.5}

        Label:
            text: ""Water Content Test: ""
            pos_hint: {""x"":0.05, ""top"": 0.35}

        Checkbox:
            id: water_check
            pos_hint: {""x"":0.25, ""top"": 0.35}

        Label:
            text: ""Boiling Point: ""
            pos_hint: {""x"":0.05, ""top"": 0.2}

        Checkbox:
            id: boiling_check
            pos_hint: {""x"":0.25, ""top"": 0.2}

        Button:
            text: ""Submit""
            pos_hint: {""x"": 0.7, ""top"": 0.5}
            on_release: root.btn()

&lt;MyScreenManager&gt;:
    canvas.before:
        Color:
            rgba: 0.5, 0.5, 0.5, 0.5
        Rectangle:
            pos: 0,0
            size: 800, 600
    MainWindow:
        id: MainWindow
        name: 'MainWindow'
</code></pre>
"
"60018431","<p>Pygame is built on SDL2 which has some rules regarding in which threads certain functions can be called. For example, for functions in the event module, (<em><a href=""https://wiki.libsdl.org/SDL_PollEvent"" rel=""nofollow noreferrer"">""you can only call this function in the thread that set the video mode.""</a></em>).</p>

<p>You should almost always avoid using threads unless they are absolutely necessary! They make your program non-deterministic, harder to debug, harder to test, harder to maintain and often slower (unless you use them effectively). In your program, there are no reasons to use threads. In your case, they are unnecessary. You should do this instead:</p>

<pre><code>import pygame
import ctypes

class Game:
    def __init__(self):
        self.init = pygame.init()
        self.screen = pygame.display.set_mode((800, 500))
        self.runGame()

    def runGame(self):
        self.running = True
        while self.running:
            for event in pygame.event.get():
                if event.type == pygame.QUIT:
                    ctypes.windll.user32.MessageBoxW(0, 'Thank you for Playing!', 'Thank You', 0)
                    self.running = False

            self.screen.fill((255, 255, 255))
            pygame.draw.circle(self.screen, (0, 0, 255), (250, 250), 75)

            pygame.display.flip()  # Don't forget to call this to update the screen!



if __name__ == '__main__':
    ins = Game()
</code></pre>

<p>Less code, deterministic, and most likely faster and using less memory.</p>
","0","","2","7215","573","1024","1156","60016180","60018431","<p>I'm making a nice game with the <code>pygame</code> module, and basically I want to do two things:  </p>

<ol>
<li><p>Run the game in an endless loop and see if the user wants to close the game, and if he wants to close the game, pop him a MessageBox.  </p></li>
<li><p>In the second function, I want to add all the features of the game and draw on the screen.</p></li>
</ol>

<p>My problem is that when I try to run them both with Thread, the game gets stuck and unresponsive.</p>

<p>Is this a problem with my computer, meaning it's too weak to run the game?<br>
Or is it a problem with my code that keeps the game from running properly?</p>

<p><strong>Code:</strong></p>

<pre><code>import pygame
import ctypes
from threading import Thread

class Game:
    def __init__(self):
        self.init = pygame.init()
        self.screen = pygame.display.set_mode((800, 500))
        self.allProcess()

    def runGame(self):
        self.running = True
        while self.running:
            for event in pygame.event.get():
                if event.type == pygame.QUIT:
                    ctypes.windll.user32.MessageBoxW(0, 'Thank you for Playing!', 'Thank You', 0)
                    self.running = False

    def items(self):
        self.screen.fill((255, 255, 255))
        pygame.draw.circle(self.screen, (0, 0, 255), (250, 250), 75)

    def allProcess(self):
        Thread(target=self.runGame).start()
        Thread(target=self.items).start()


if __name__ == '__main__':
    ins = Game()
</code></pre>
"
"60016567","<p>What do you want to achieve - get/print the text of each element? Because <code>Get Webelements</code> does just what its name says - returns you a list of matching elements - selenium element objects. 
Having that, if you want to print the text of each one, just iterate over the list and call <code>Get Text</code> on each member:</p>

<pre><code>FOR    ${el}    IN    @{get_t3}
    ${txt}=    Get Text    ${el}
    Log    ${txt}
END
</code></pre>
","4","","5","14399","689","156","1239","60016277","60016567","<pre><code>${get_t}=    Get Text    //h6[@class='MuiTypography-root MuiTypography-subtitle2']
Log    ${get_t}
${get_t1}=    Get Element Count    xpath://h6[@class='MuiTypography-root MuiTypography-subtitle2']
Log    ${get_t1}
${get_t3}=    Get WebElements    xpath://h6[@class='MuiTypography-root MuiTypography-subtitle2']
Log    ${get_t3}
</code></pre>

<p>when I get Count it shows the count but when i print it using <strong>Get WebElements</strong> it doens't print the text. If I give <strong>Get Text</strong> it print the first text alone.</p>

<p><a href=""https://i.stack.imgur.com/MkDfG.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/MkDfG.png"" alt=""enter image description here""></a></p>

<p><strong>Xpath</strong>
<a href=""https://i.stack.imgur.com/EWc4q.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/EWc4q.png"" alt=""enter image description here""></a></p>
"
"60022398","<p>You cannot modify the airflow image that runs in Cloud Composer; however, you can use the <a href=""https://cloud.google.com/composer/docs/how-to/using/using-kubernetes-pod-operator"" rel=""nofollow noreferrer"">KubernetesPodOperator</a> to launch a new pod with pg_dump, execute it and upload the file to Cloud Storage. </p>
","0","","1","2117","150","7","242","60016322","60022398","<p>i have a airflow running on GCP as a composer. I an working on a python peoject where i need to dump a remote postgreSQL database to my airflow bucket but the airflow doesn’t allow me to do so. I am wonder, i can run mysqldump on the same instance to so but my requirement is changed and now i want to do the same on postgresql using pg_dump.</p>
"
"60016385","<p>In the second for-loop you are appending the <em>same</em> list to <code>List</code> n-times over. </p>

<pre><code>for i in range(n):
    List.append(listx)
</code></pre>

<p>You need to make copies of <code>listx</code> &amp; use those inside <code>List</code>. Like this:</p>

<pre><code>for i in range(n):
    List.append(listx[::])
</code></pre>

<p><code>listx[::]</code> makes a copy of <code>listx</code> to use. </p>
","0","","1","15185","371","2705","1878","60016360","60016389","<p>I have a script that makes a list of list that represent a playground:</p>

<pre><code>#Script:
import math
listx=[]
List=[]
N_M=input(""Enter N M: "").split()
n=int(N_M[0])
m=int(N_M[1])
for i in range(m):
    listx+=[0]
for i in range(n):
    List.append(listx)
print(List)

#Example of playground for M=3 and N=3:
[0,0,0] 
[0,0,0] 
[0,0,0]
</code></pre>

<p>Then I want to change a certain place to 1</p>

<pre><code>List[0][1]=1
</code></pre>

<p>That should (if I understand it correctly) change it to:</p>

<pre><code>[0,1,0]
[0,0,0] 
[0,0,0]
</code></pre>

<p>But instead it changes every list to:</p>

<pre><code>[0,1,0]
[0,1,0] 
[0,1,0]
</code></pre>

<p>Please help!
Thank you very much in advise!</p>
"
"60016389","<p>This bit:</p>

<pre><code>for i in range(n):
    List.append(listx)
</code></pre>

<p>Adds the same list (<code>listx</code>) to <code>List</code> three times. So when you change it one place, all references change, because they are all pointing to the same list.</p>

<p>Also, as a side note: don't name variables <code>List</code> with a capital, because that makes others (and software) think it's a class. And the name <code>list</code> is of course even worse, because that would be shadowing the type <code>list</code>. Come up with names that are meaningful and not overly generic - like <code>playground</code>.</p>

<p>A more efficient way of creating an <code>n</code> x <code>m</code> list:</p>

<pre><code>playground = [[0] * m for _ in range(n)]
</code></pre>

<p>The bit <code>[0] * m</code> creates a list with <code>m</code> zeroes; this works because a number isn't referenced like a list and the zeroes won't be copies of the same variable.</p>

<p>The <code>for _ in range(n)</code> causes the resulting list to be filled with <code>n</code> of those lists. The <code>_</code> just means you're not doing anything with the number from the <code>range()</code>, it's only there for a number of repetitions and the <code>for</code> loop needs something in that place, either a variable or the <code>_</code> ""don't care"".</p>
","0","","3","12065","76","218","1202","60016360","60016389","<p>I have a script that makes a list of list that represent a playground:</p>

<pre><code>#Script:
import math
listx=[]
List=[]
N_M=input(""Enter N M: "").split()
n=int(N_M[0])
m=int(N_M[1])
for i in range(m):
    listx+=[0]
for i in range(n):
    List.append(listx)
print(List)

#Example of playground for M=3 and N=3:
[0,0,0] 
[0,0,0] 
[0,0,0]
</code></pre>

<p>Then I want to change a certain place to 1</p>

<pre><code>List[0][1]=1
</code></pre>

<p>That should (if I understand it correctly) change it to:</p>

<pre><code>[0,1,0]
[0,0,0] 
[0,0,0]
</code></pre>

<p>But instead it changes every list to:</p>

<pre><code>[0,1,0]
[0,1,0] 
[0,1,0]
</code></pre>

<p>Please help!
Thank you very much in advise!</p>
"
"60016459","<p>In your second for loop you are appending the same list many times, you are appending a ""view/reference"" not the actual list, so in your second four you have to append a copy of the <code>listx</code>, for this you can use : </p>

<ul>
<li><code>list(listx)</code></li>
<li><code>listx[::]</code></li>
<li><code>listx.copy()</code></li>
</ul>

<p>Is like you want to buy apples, but you have only one and other 3 pictures of the first apple, you can' say you have 4 apples </p>
","0","","0","15189","2120","120","950","60016360","60016389","<p>I have a script that makes a list of list that represent a playground:</p>

<pre><code>#Script:
import math
listx=[]
List=[]
N_M=input(""Enter N M: "").split()
n=int(N_M[0])
m=int(N_M[1])
for i in range(m):
    listx+=[0]
for i in range(n):
    List.append(listx)
print(List)

#Example of playground for M=3 and N=3:
[0,0,0] 
[0,0,0] 
[0,0,0]
</code></pre>

<p>Then I want to change a certain place to 1</p>

<pre><code>List[0][1]=1
</code></pre>

<p>That should (if I understand it correctly) change it to:</p>

<pre><code>[0,1,0]
[0,0,0] 
[0,0,0]
</code></pre>

<p>But instead it changes every list to:</p>

<pre><code>[0,1,0]
[0,1,0] 
[0,1,0]
</code></pre>

<p>Please help!
Thank you very much in advise!</p>
"
"60035820","<p><a href=""https://pytorch.org/docs/stable/nn.html#conv1d"" rel=""nofollow noreferrer"">Conv1D</a> takes as input a tensor with 3 dimensions <code>(N, C, L)</code> where <code>N</code> is the batchsize, <code>C</code> is the number of channels and <code>L</code> size of the 1D data. In your case it seems like one sample has 20 entries and you have one channel. You have a <code>batch_size</code> variable but it is not used in the code posted.</p>

<pre><code> nn.Conv1d(20,40,kernel_size=5,stride=1,padding=2)
</code></pre>

<p>This lines creates a convolution which takes a input with 20 channels (you have 1) and outputs 40 channels. So you have to change the 20 to a 1 and you might wanna change the 40 to something smaller. Since convolutions are applied to the whole input (controlled by stride, patting and kernel size), there is no need to specify the size of a sample.</p>

<p>Also you might wanna add some logic to build minibatches. Right now it seems like you just want to input every sample by itself. Maybe read a bit about dataset classes and data loaders in pytorch.</p>
","0","","1","1178","13","20","45","60016597","60035820","<p>I load data from a CSV FILE OF 20+6 Columns(Features and Labels). Im trying to run my data through Convolutional Neural Network in pytorch. I get error saying it expects a 3D input and Im giving it 1D input. I am using Conv1d . </p>

<pre><code>import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
import pandas as pd
from torch.utils.data import Dataset,DataLoader
from sklearn.model_selection import train_test_split

#Read Data
data=pd.read_csv('Data.csv')
Features=data[data.columns[0:20]]
Labels=data[data.columns[20:]]
#Split Data
X_train, X_test, y_train, y_test = train_test_split( Features, Labels, test_size=0.33, shuffle=True)
#Create Tensors
train_in=torch.tensor(X_train.values)
train_out=torch.tensor(y_train.values)
test_in=torch.tensor(X_test.values)
test_out=torch.tensor(y_test.values)
#Model CNN
class CNN(nn.Module):
        def __init__(self):
                super(CNN,self).__init__()
                self.layer1 = nn.Sequential(
                                nn.Conv1d(20,40,kernel_size=5,stride=1,padding=2),
                                nn.ReLU(),
                                nn.MaxPool1d(kernel_size=2,stride=2)
                                )
                self.layer2 = nn.Sequential(
                                nn.Conv1d(40,60,kernel_size=5,stride=1,padding=2),
                                nn.ReLU(),
                                nn.MaxPool1d(kernel_size=2,stride=2)
                                )
                self.drop_out = nn.Dropout()
                self.fc1 = nn.Linear(60,30)
                self.fc2 = nn.Linear(30,15)
                self.fc3 = nn.Linear(15,6)

        def forward(self,x):
                out=self.layer1(x)
                out=self.layer2(out)
                out=self.drop_out(out)
                out=self.fc1(out)
                out=self.fc2(out)
                out=self.fc3(out)
                return out


Epochs=10
N_labels=len(Labels.columns)
N_features=len(Features.columns)
batch_size=100
learning_rate=0.001
#TRAIN MODEL        
model = CNN()
#LOSS AND OPTIMIZER
criterion = torch.nn.SmoothL1Loss()
optimizer = torch.optim.Adam(model.parameters(),lr=learning_rate)
#TRAIN MODEL
model.train()
idx=0
for i in train_in:
        y=model(i)
        loss=criterion(y,train_out[idx])
        idx+=1
        loss.backward()
        optimizer.step()
</code></pre>

<p>How do I write the Training and Eval loop? All the examples I see on the internet all use images and they also use DataLoader.</p>
"
"60022133","<p>In TensorFlow 2.x, the recommended method of creating reusable neural network layers is to create a new <code>tf.keras.layers.Layer</code> subclass. TensorFlow provides a <a href=""https://www.tensorflow.org/guide/keras/custom_layers_and_models"" rel=""nofollow noreferrer"">great tutorial on this</a>. You can reuse the vast majority of the code in your posted example in a <code>tf.keras</code> layer class. You might also be able to inherit from <code>tensorflow.python.keras.layers.convolutional.Conv</code> to reduce the amount of boilerplate code.</p>

<p>As for the some modules not being found, you should use the aliases that TensorFlow exposes. Here is an incomplete list:</p>

<ul>
<li><code>array_ops.reshape</code> -> <code>tf.reshape</code></li>
<li><code>init_ops.constant_initializer</code> -> <code>tf.initializers.constant</code></li>
<li><code>tensor_shape</code> -> <code>tf.TensorShape</code></li>
<li><code>nn_ops.Convolution</code> -> <code>tf.nn.convolution</code> or <code>tf.keras.layers.Conv?D</code></li>
</ul>
","1","2020-02-02 00:02:39","1","10363","2079","274","1014","60016635","60022133","<p>I have this code here from <a href=""https://github.com/skokec/DAU-ConvNet"" rel=""nofollow noreferrer"">https://github.com/skokec/DAU-ConvNet</a>, which is based on this paper <a href=""https://arxiv.org/abs/1902.07474"" rel=""nofollow noreferrer"">https://arxiv.org/abs/1902.07474</a> and replaces the standard grid-based filters in a convolutional block with an adaptive filter version. When I try to import the package I get this error: </p>

<blockquote>
  <p>ModuleNotFoundError: No module named 'tensorflow.contrib.framework'.</p>
</blockquote>

<p>I know that ""tensorflow.contrib"" is apparently being removed in version 2.0 and I need to revert back to version &lt;= 1.14 to make it work. BUT I wanted to see if someone can make this code work in the newer TF.2 version as this is a very interesting paper and the results are very good and by migrating this code to TF2 it will encourage other people to try it out and experiment with this layer in different architectures/setups. Below is the source code:</p>

<pre><code>import os
import numpy as np
import tensorflow as tf

from tensorflow.python.layers import base
from tensorflow.python.layers import utils

from tensorflow.python.framework import ops
from tensorflow.python.framework import tensor_shape

from tensorflow.python.ops import nn_ops
from tensorflow.python.ops import array_ops
from tensorflow.python.ops import nn
from tensorflow.python.ops import init_ops

class DAUConv2dTF(base.Layer):
def __init__(self, filters,
             dau_units,
             max_kernel_size,
             strides=1,
             data_format='channels_first',
             activation=None,
             use_bias=True,
             weight_initializer=init_ops.random_normal_initializer(stddev=0.1),
             mu1_initializer=None,
             mu2_initializer=None,
             sigma_initializer=None,
             bias_initializer=init_ops.zeros_initializer(),
             weight_regularizer=None,
             mu1_regularizer=None,
             mu2_regularizer=None,
             sigma_regularizer=None,
             bias_regularizer=None,
             activity_regularizer=None,
             weight_constraint=None,
             mu1_constraint=None,
             mu2_constraint=None,
             sigma_constraint=None,
             bias_constraint=None,
             trainable=True,
             mu_learning_rate_factor=500,
             dau_unit_border_bound=0.01,
             dau_sigma_trainable=False,
             name=None,
             **kwargs):
    super(DAUConv2dTF, self).__init__(trainable=trainable, name=name,
                                activity_regularizer=activity_regularizer,
                                **kwargs)
    self.rank = 2
    self.filters = filters
    self.dau_units = utils.normalize_tuple(dau_units, self.rank, 'dau_components')
    self.max_kernel_size = max_kernel_size
    self.padding = np.floor(self.max_kernel_size/2.0)
    self.strides = strides
    self.data_format = utils.normalize_data_format(data_format)
    self.activation = activation
    self.use_bias = use_bias
    self.bias_initializer = bias_initializer
    self.bias_regularizer = bias_regularizer
    self.bias_constraint = bias_constraint

    self.weight_initializer = weight_initializer
    self.weight_regularizer = weight_regularizer
    self.weight_constraint = weight_constraint

    self.mu1_initializer = mu1_initializer
    self.mu1_regularizer = mu1_regularizer
    self.mu1_constraint = mu1_constraint

    self.mu2_initializer = mu2_initializer
    self.mu2_regularizer = mu2_regularizer
    self.mu2_constraint = mu2_constraint

    self.sigma_initializer = sigma_initializer
    self.sigma_regularizer = sigma_regularizer
    self.sigma_constraint = sigma_constraint

    if self.mu1_initializer is None:
        raise Exception(""Must initialize MU1"")
    if self.mu2_initializer is None:
        raise Exception(""Must initialize MU2"")

    if self.sigma_initializer is None:
        self.sigma_initializer=init_ops.constant_initializer(0.5)

    self.mu_learning_rate_factor = mu_learning_rate_factor

    self.input_spec = base.InputSpec(ndim=self.rank + 2)

    self.dau_unit_border_bound = dau_unit_border_bound
    self.num_dau_units_all = np.int32(np.prod(self.dau_units))

    self.dau_weights = None
    self.dau_mu1 = None
    self.dau_mu2 = None
    self.dau_sigma = None

    self.dau_sigma_trainable = dau_sigma_trainable

def set_dau_variables_manually(self, w = None, mu1 = None, mu2 = None, sigma = None):
    """""" Manually set w,mu1,mu2 and/or sigma variables with custom tensor. Call before build() or __call__().
    The shape must match the expecated shape as returned by the get_dau_variable_shape(input_shape)
    otherwise the build() function will fail.""""""

    if w is not None:
        self.dau_weights = w

    if mu1 is not None:
        self.dau_mu1 = mu1

    if mu2 is not None:
        self.dau_mu2 = mu2

    if sigma is not None:
        self.dau_sigma = sigma

def _get_input_channel_axis(self):
    if self.data_format == 'channels_first':
        channel_axis = 1
    else:
        channel_axis = -1

    return channel_axis

def _get_input_channels(self, input_shape):
    channel_axis = self._get_input_channel_axis()

    if input_shape[channel_axis].value is None:
        raise ValueError('The channel dimension of the inputs '
                         'should be defined. Found `None`.')

    return input_shape[channel_axis].value

def get_dau_variable_shape(self, input_shape):
    # get input
    num_input_channels = self._get_input_channels(input_shape)

    dau_params_shape_ = (num_input_channels, self.dau_units[0], self.dau_units[1], self.filters)
    dau_params_shape = (1, num_input_channels, self.num_dau_units_all, self.filters)

    return dau_params_shape

def add_dau_weights_var(self, input_shape):
    dau_params_shape = self.get_dau_variable_shape(input_shape)
    return self.add_variable(name='weights',
                             shape=dau_params_shape,
                             initializer=self.weight_initializer,
                             regularizer=self.weight_regularizer,
                             constraint=self.weight_constraint,
                             trainable=True,
                             dtype=self.dtype)

def add_dau_mu1_var(self, input_shape):
    dau_params_shape = self.get_dau_variable_shape(input_shape)
    mu1_var = self.add_variable(name='mu1',
                             shape=dau_params_shape,
                             initializer=self.mu1_initializer,
                             regularizer=self.mu1_regularizer,
                             constraint=self.mu1_constraint,
                             trainable=True,
                             dtype=self.dtype)

    # limit max offset based on self.dau_unit_border_bound and kernel size
    mu1_var = tf.minimum(tf.maximum(mu1_var,
                                    -(self.max_kernel_size - self.dau_unit_border_bound)),
                         self.max_kernel_size - self.dau_unit_border_bound)

    return mu1_var



def add_dau_mu2_var(self, input_shape):
    dau_params_shape = self.get_dau_variable_shape(input_shape)
    mu2_var = self.add_variable(name='mu2',
                               shape=dau_params_shape,
                               initializer=self.mu2_initializer,
                               regularizer=self.mu2_regularizer,
                               constraint=self.mu2_constraint,
                               trainable=True,
                               dtype=self.dtype)


    # limit max offset based on self.dau_unit_border_bound and kernel size
    mu2_var = tf.minimum(tf.maximum(mu2_var,
                                    -(self.max_kernel_size - self.dau_unit_border_bound)),
                         self.max_kernel_size - self.dau_unit_border_bound)

    return mu2_var
def add_dau_sigma_var(self, input_shape, trainable=False):
    dau_params_shape = self.get_dau_variable_shape(input_shape)

    # create single sigma variable
    sigma_var = self.add_variable(name='sigma',
                                  shape=dau_params_shape,
                                  initializer=self.sigma_initializer,
                                  regularizer=self.sigma_regularizer,
                                  constraint=self.sigma_constraint,
                                  trainable=self.dau_sigma_trainable,
                                  dtype=self.dtype)

    # but make variable shared across all channels as required for the efficient DAU implementation
    return sigma_var


def add_bias_var(self):
    return self.add_variable(name='bias',
                             shape=(self.filters,),
                             initializer=self.bias_initializer,
                             regularizer=self.bias_regularizer,
                             constraint=self.bias_constraint,
                             trainable=True,
                             dtype=self.dtype)

def build(self, input_shape):
    input_shape = tensor_shape.TensorShape(input_shape)

    dau_params_shape = self.get_dau_variable_shape(input_shape)
    if self.dau_weights is None:
        self.dau_weights = self.add_dau_weights_var(input_shape)
    elif np.any(self.dau_weights.shape != dau_params_shape):
        raise ValueError('Shape mismatch for variable `dau_weights`')
    if self.dau_mu1 is None:
        self.dau_mu1 = self.add_dau_mu1_var(input_shape)
    elif np.any(self.dau_mu1.shape != dau_params_shape):
        raise ValueError('Shape mismatch for variable `dau_mu1`')

    if self.dau_mu2 is None:
        self.dau_mu2 = self.add_dau_mu2_var(input_shape)
    elif np.any(self.dau_mu2.shape != dau_params_shape):
        raise ValueError('Shape mismatch for variable `dau_mu2`')
    if self.dau_sigma is None:
        self.dau_sigma = self.add_dau_sigma_var(input_shape, trainable=self.dau_sigma_trainable)
    elif np.any(self.dau_sigma.shape != dau_params_shape):
        raise ValueError('Shape mismatch for variable `dau_sigma`')

    if self.use_bias:
        self.bias = self.add_bias_var()
    else:
        self.bias = None

    input_channel_axis = self._get_input_channel_axis()
    num_input_channels = self._get_input_channels(input_shape)

    self.input_spec = base.InputSpec(ndim=self.rank + 2,
                                     axes={input_channel_axis: num_input_channels})

    kernel_shape = tf.TensorShape((self.max_kernel_size, self.max_kernel_size, num_input_channels, self.filters))

    self._convolution_op = nn_ops.Convolution(
        input_shape,
        filter_shape=kernel_shape,
        dilation_rate=(1,1),
        strides=(self.strides,self.strides),
        padding=""SAME"",
        data_format=utils.convert_data_format(self.data_format,
                                              self.rank + 2))
    self.built = True

def call(self, inputs):

    def get_kernel_fn(dau_w, dau_mu1, dau_mu2, dau_sigma, max_kernel_size, mu_learning_rate_factor=1):

        # add mu1/mu2 gradient multiplyer
        if mu_learning_rate_factor != 1:
            dau_mu1 = mu_learning_rate_factor * dau_mu1 + (1 - mu_learning_rate_factor) * tf.stop_gradient(dau_mu1)
            dau_mu2 = mu_learning_rate_factor * dau_mu2 + (1 - mu_learning_rate_factor) * tf.stop_gradient(dau_mu2)

        [X,Y] = np.meshgrid(np.arange(max_kernel_size),np.arange(max_kernel_size))

        X = np.reshape(X,(max_kernel_size*max_kernel_size,1,1,1)) - int(max_kernel_size/2)
        Y = np.reshape(Y,(max_kernel_size*max_kernel_size,1,1,1)) - int(max_kernel_size/2)

        X = X.astype(np.float32)
        Y = Y.astype(np.float32)

        # Gaussian kernel
        X = tf.convert_to_tensor(X,name='X',dtype=tf.float32)
        Y = tf.convert_to_tensor(Y,name='Y',dtype=tf.float32)

        gauss_kernel = tf.exp(-1* (tf.pow(X - dau_mu1,2.0) + tf.pow(Y - dau_mu2,2.0)) / (2.0*tf.pow(dau_sigma,2.0)),name='gauss_kernel')

        gauss_kernel_sum = tf.reduce_sum(gauss_kernel,axis=0, keep_dims=True,name='guass_kernel_sum')

        gauss_kernel_norm = tf.divide(gauss_kernel, gauss_kernel_sum ,name='gauss_kernel_norm')

        # normalize to sum of 1 and add weight
        gauss_kernel_norm = tf.multiply(dau_w, gauss_kernel_norm,name='gauss_kernel_weight')

        # sum over Gaussian units
        gauss_kernel_norm = tf.reduce_sum(gauss_kernel_norm, axis=2, keep_dims=True,name='gauss_kernel_sum_units')

        # convert to [Kw,Kh,S,F] shape
        gauss_kernel_norm = tf.reshape(gauss_kernel_norm, (max_kernel_size, max_kernel_size, gauss_kernel_norm.shape[1], gauss_kernel_norm.shape[3]),name='gauss_kernel_reshape')

        return gauss_kernel_norm

    try:
        # try with XLA if exists
        from tensorflow.contrib.compiler import xla

        gauss_kernel_norm = xla.compile(computation=get_kernel_fn, inputs=(self.dau_weights, self.dau_mu1, self.dau_mu2, self.dau_sigma, self.max_kernel_size, self.mu_learning_rate_factor))[0]

    except:
        # otherwise revert to direct method call
        gauss_kernel_norm = get_kernel_fn(self.dau_weights, self.dau_mu1, self.dau_mu2, self.dau_sigma, self.max_kernel_size, self.mu_learning_rate_factor)

    outputs = self._convolution_op(inputs, gauss_kernel_norm)

    if self.use_bias:
        if self.data_format == 'channels_first':
            if self.rank == 1:
                # nn.bias_add does not accept a 1D input tensor.
                bias = array_ops.reshape(self.bias, (1, self.filters, 1))
                outputs += bias
            if self.rank == 2:
                outputs = nn.bias_add(outputs, self.bias, data_format='NCHW')
            if self.rank == 3:
                # As of Mar 2017, direct addition is significantly slower than
                # bias_add when computing gradients. To use bias_add, we collapse Z
                # and Y into a single dimension to obtain a 4D input tensor.
                outputs_shape = outputs.shape.as_list()
                if outputs_shape[0] is None:
                    outputs_shape[0] = -1
                outputs_4d = array_ops.reshape(outputs,
                                               [outputs_shape[0], outputs_shape[1],
                                                outputs_shape[2] * outputs_shape[3],
                                                outputs_shape[4]])
                outputs_4d = nn.bias_add(outputs_4d, self.bias, data_format='NCHW')
                outputs = array_ops.reshape(outputs_4d, outputs_shape)
        else:
            outputs = nn.bias_add(outputs, self.bias, data_format='NHWC')

    if self.activation is not None:
        return self.activation(outputs)
    return outputs

def compute_output_shape(self, input_shape):
    input_shape = tensor_shape.TensorShape(input_shape).as_list()
    if self.data_format == 'channels_last':
        space = input_shape[1:-1]
        new_space = []
        for i in range(len(space)):
            new_dim = utils.conv_output_length(
                space[i],
                self.max_kernel_size[i],
                padding=self.padding,
                stride=self.strides[i],
                dilation=1)
            new_space.append(new_dim)
        return tensor_shape.TensorShape([input_shape[0]] + new_space +
                                        [self.filters])
    else:
        space = input_shape[2:]
        new_space = []
        for i in range(len(space)):
            new_dim = utils.conv_output_length(
                space[i],
                self.kernel_size[i],
                padding=self.padding,
                stride=self.strides,
                dilation=1)
            new_space.append(new_dim)
        return tensor_shape.TensorShape([input_shape[0], self.filters] +
                                        new_space)


from tensorflow.contrib.framework.python.ops import add_arg_scope
from tensorflow.python.ops import variable_scope
from tensorflow.contrib.layers.python.layers import layers as layers_contrib
from tensorflow.contrib.layers.python.layers import utils as utils_contrib

@add_arg_scope
def dau_conv2d_tf(inputs,
             filters,
             dau_units,
             max_kernel_size,
             stride=1,
             mu_learning_rate_factor=500,
             data_format=None,
             activation_fn=nn.relu,
             normalizer_fn=None,
             normalizer_params=None,
             weights_initializer=init_ops.random_normal_initializer(stddev=0.1), #init_ops.glorot_uniform_initializer(),
             weights_regularizer=None,
             weights_constraint=None,
             mu1_initializer=None,
             mu1_regularizer=None,
             mu1_constraint=None,
             mu2_initializer=None,
             mu2_regularizer=None,
             mu2_constraint=None,
             sigma_initializer=None,
             sigma_regularizer=None,
             sigma_constraint=None,
             biases_initializer=init_ops.zeros_initializer(),
             biases_regularizer=None,
             biases_constraint=None,
             dau_unit_border_bound=0.01,
             dau_sigma_trainable=False,
             reuse=None,
             variables_collections=None,
             outputs_collections=None,
             trainable=True,
             scope=None):

if data_format not in [None, 'NWC', 'NCW', 'NHWC', 'NCHW', 'NDHWC', 'NCDHW']:
    raise ValueError('Invalid data_format: %r' % (data_format,))

layer_variable_getter = layers_contrib._build_variable_getter({
    'bias': 'biases',
    'weight': 'weights',
    'mu1': 'mu1',
    'mu2': 'mu2',
    'sigma': 'sigma'
})

with variable_scope.variable_scope(
        scope, 'DAUConv', [inputs], reuse=reuse,
        custom_getter=layer_variable_getter) as sc:
    inputs = ops.convert_to_tensor(inputs)
    input_rank = inputs.get_shape().ndims

    if input_rank != 4:
        raise ValueError('DAU convolution not supported for input with rank',
                         input_rank)

    df = ('channels_first'
          if data_format and data_format.startswith('NC') else 'channels_last')

    layer = DAUConv2dTF(filters,
                      dau_units,
                      max_kernel_size,
                      strides=stride,
                      data_format=df,
                      activation=None,
                      use_bias=not normalizer_fn and biases_initializer,
                      mu_learning_rate_factor=mu_learning_rate_factor,
                      weight_initializer=weights_initializer,
                      mu1_initializer=mu1_initializer,
                      mu2_initializer=mu2_initializer,
                      sigma_initializer=sigma_initializer,
                      bias_initializer=biases_initializer,
                      weight_regularizer=weights_regularizer,
                      mu1_regularizer=mu1_regularizer,
                      mu2_regularizer=mu2_regularizer,
                      sigma_regularizer=sigma_regularizer,
                      bias_regularizer=biases_regularizer,
                      activity_regularizer=None,
                      weight_constraint=weights_constraint,
                      mu1_constraint=mu1_constraint,
                      mu2_constraint=mu2_constraint,
                      sigma_constraint=sigma_constraint,
                      bias_constraint=biases_constraint,
                      dau_unit_border_bound=dau_unit_border_bound,
                      dau_sigma_trainable=dau_sigma_trainable,
                      trainable=trainable,
                      name=sc.name,
                      _scope=sc,
                      _reuse=reuse)

    outputs = layer.apply(inputs)

    # Add variables to collections.
    layers_contrib._add_variable_to_collections(layer.dau_weights, variables_collections, 'weights')
    layers_contrib._add_variable_to_collections(layer.dau_mu1, variables_collections, 'mu1')
    layers_contrib._add_variable_to_collections(layer.dau_mu2, variables_collections, 'mu2')
    layers_contrib._add_variable_to_collections(layer.dau_sigma, variables_collections, 'sigma')

    if layer.use_bias:
        layers_contrib._add_variable_to_collections(layer.bias, variables_collections, 'biases')

    if normalizer_fn is not None:
        normalizer_params = normalizer_params or {}
        outputs = normalizer_fn(outputs, **normalizer_params)

    if activation_fn is not None:
        outputs = activation_fn(outputs)
    return utils_contrib.collect_named_outputs(outputs_collections, sc.name, outputs)
</code></pre>

<p>Any help would be highly appreciated. 
Cheers, 
H </p>
"
"60016905","<p>Here is a solution involving <code>lxml.html</code>:</p>

<p>We extract all <code>div</code>s between the <em>first</em> and <em>last</em> <code>div</code>s which contain an <code>h2</code> tag:</p>

<pre class=""lang-py prettyprint-override""><code>import lxml.html


# HTML file saved as ""file.html""
file_name = ""file.html""
with open(file_name, 'r') as f:
    tree = lxml.html.fromstring(f.read())

# all_div = tree.findall('div')
all_div = tree.find_class('foo-bar-details')[0].findall('div')
start, stop = None, None
for k, div in enumerate(all_div):
    if div.findall('h2') and start is None:
        print(""Range starts at %d"" % k)
        start = k
        continue
    if div.findall('h2') and start is not None:
        print(""Range stops at %d"" % k)
        stop = k + 1  # add one as range stops at k - 1
        continue

# div_list = all_div[start:stop]
img_list = [_.xpath('.//img') for _ in all_div[start:stop]]
print(img_list)
# [[], [&lt;Element img at 0x20b58d73f40&gt;], [&lt;Element img at 0x20b58d73f90&gt;], []]

# Or
img_list = [_.xpath('.//img/@src') for _ in all_div[start:stop]]
print(img_list)
# [[], ['../../images/123456_thumb.jpg'], ['../../images/67890_thumb.JPG'], []]
</code></pre>
","5","2020-02-02 12:31:34","2","4391","311","4","409","60016647","60016905","<p>I just found out about how to process webpages in python using BeautifulSoup.
There's a list of <code>div</code> from which I want to get those in a specific range. The range is defined by two <code>div</code> that have a <code>h2</code> child.
How would I do that? Thank you for your support!</p>

<p>EDIT: I added an actual representation of my html code below instead of a previous ""simplified"" version that was missing tags.
The new code shows a root <code>div</code> with class <code>foo-bar-details</code>.
Nested are 9 <code>div</code> tags. Two of which have a nested <code>h2</code> tag. All of those 9 <code>div</code> tags contain <code>img</code> elements deeply nested within. What I need is each <code>img</code> element of those <code>div</code>s that are <strong>between</strong> the ones containing the <code>h2</code> element.
An expected outcome if applied to the html code below would be:</p>

<pre><code>&lt;img src=""../../images/123456_thumb.jpg"" alt=""Image 123456"" title=""Image 123456""&gt;
&lt;img src=""../../images/67890_thumb.JPG"" alt=""Image 67890 "" title=""Image 67890""&gt;
</code></pre>

<p>This is the html code:</p>

<pre><code>&lt;div class=""foo-bar-details""&gt;
    &lt;div class=""padding-y-10 padding-x-40 gray-sand-bg"" id=""sec-feat-3-1""&gt;
        &lt;div class=""row""&gt;
            &lt;div class=""col-sm-6 info-panel""&gt;
                &lt;div class=""row""&gt;
                    &lt;div class=""col-sm-6 margin-bottom-10""&gt;
                        &lt;p class=""margin-0""&gt;
                            &lt;strong&gt;fsuhfsdf &lt;/strong&gt; 
                        &lt;/p&gt;
                    &lt;/div&gt;
                    &lt;div class=""col-sm-6 margin-bottom-10""&gt;
                        &lt;p class=""margin-0""&gt;
                            &lt;strong&gt;Feat&lt;/strong&gt;&lt;a href=""../linkglossary0.pdf"" class=""link"" title=""test""&gt;&lt;span class=""icon-help""&gt;&lt;/span&gt;&lt;/a&gt; 
                        &lt;/p&gt;
                    &lt;/div&gt;
                &lt;/div&gt;
            &lt;/div&gt;
            &lt;div class=""col-sm-6 foo-images""&gt;
                &lt;div class=""row""&gt;
                    &lt;a href=""image-39826.html""&gt;&lt;img src=""../../images/39826_thumb.JPG"" alt=""Image 39826"" title=""Image 39826 ""&gt;&lt;/a&gt; 
                    &lt;div class=""img-description""&gt;
                    &lt;/div&gt;
                &lt;/div&gt;
            &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
    &lt;div class=""padding-y-10 padding-x-40 gray-sand-bg"" id=""sec-feat-3-1""&gt;
        &lt;div class=""row""&gt;
            &lt;div class=""col-sm-6 info-panel""&gt;
                &lt;div class=""row""&gt;
                    &lt;div class=""col-sm-6 margin-bottom-10""&gt;
                        &lt;p class=""margin-0""&gt;
                            &lt;strong&gt;JHFDFD &lt;/strong&gt; 
                        &lt;/p&gt;
                    &lt;/div&gt;
                    &lt;div class=""col-sm-6 margin-bottom-10""&gt;
                        &lt;p class=""margin-0""&gt;
                            &lt;strong&gt;Feat&lt;/strong&gt;&lt;a href=""../linkglossary2.pdf"" class=""link"" title=""test""&gt;&lt;span class=""icon-help""&gt;&lt;/span&gt;&lt;/a&gt; 
                        &lt;/p&gt;
                    &lt;/div&gt;
                &lt;/div&gt;
            &lt;/div&gt;
            &lt;div class=""col-sm-6 foo-images""&gt;
                &lt;div class=""row""&gt;
                    &lt;a href=""image-223234.html""&gt;&lt;img src=""../../images/223234_thumb.JPG"" alt=""Image 223234"" title=""Image 223234 ""&gt;&lt;/a&gt; 
                    &lt;div class=""img-description""&gt;
                    &lt;/div&gt;
                &lt;/div&gt;
            &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
    &lt;div class=""padding-y-10 padding-x-40 gray-sand-bg"" id=""sec-feat-3-1""&gt;
        &lt;div class=""row""&gt;
            &lt;div class=""col-sm-6 info-panel""&gt;
                &lt;div class=""row""&gt;
                    &lt;div class=""col-sm-6 margin-bottom-10""&gt;
                        &lt;p class=""margin-0""&gt;
                            &lt;strong&gt;sdfsdf &lt;/strong&gt; 
                        &lt;/p&gt;
                    &lt;/div&gt;
                    &lt;div class=""col-sm-6 margin-bottom-10""&gt;
                        &lt;p class=""margin-0""&gt;
                            &lt;strong&gt;Feat&lt;/strong&gt;&lt;a href=""../linkglossary1.pdf"" class=""link"" title=""test""&gt;&lt;span class=""icon-help""&gt;&lt;/span&gt;&lt;/a&gt; 
                        &lt;/p&gt;
                    &lt;/div&gt;
                &lt;/div&gt;
            &lt;/div&gt;
            &lt;div class=""col-sm-6 foo-images""&gt;
                &lt;div class=""row""&gt;
                    &lt;a href=""image-223823.html""&gt;&lt;img src=""../../images/223823_thumb.JPG"" alt=""Image 223823"" title=""Image 223823 ""&gt;&lt;/a&gt; 
                    &lt;div class=""img-description""&gt;
                    &lt;/div&gt;
                &lt;/div&gt;
            &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
    &lt;div class=""element-header mystic-bg padding-y-10 padding-x-20"" id=""elem-4""&gt;
        &lt;h2 class=""h3 margin-bottom-5""&gt;
            Foo 
        &lt;/h2&gt;
        &lt;ul class=""list-inline margin-0""&gt;
            &lt;li&gt; &lt;a href=""#foo-feat-4-1""&gt;Foo feature&lt;/a&gt; &lt;/li&gt;
            ... 
        &lt;/ul&gt;
    &lt;/div&gt;
    &lt;div id=""info-panel-header"" class=""padding-y-10 padding-x-40""&gt;
        &lt;div class=""row""&gt;
            &lt;div class=""col-se-6 element-info""&gt;
                &lt;div class=""col-se-12""&gt;
                    &lt;div class=""row""&gt;
                    &lt;/div&gt;
                &lt;/div&gt;
            &lt;/div&gt;
            &lt;div class=""col-sm-6 foo-images""&gt;
                &lt;div class=""row""&gt;
                    &lt;a href=""image-123456.html""&gt;&lt;img src=""../../images/123456_thumb.jpg"" alt=""Image 123456"" title=""Image 123456""&gt;&lt;/a&gt; 
                    &lt;div class=""img-description""&gt;
                    &lt;/div&gt;
                &lt;/div&gt;
            &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
    &lt;div class=""padding-y-10 padding-x-40 gray-wild-sand-bg"" id=""sec-feat-4-1""&gt;
        &lt;div class=""row""&gt;
            &lt;div class=""col-sm-6 info-panel""&gt;
                &lt;div class=""row""&gt;
                    &lt;div class=""col-sm-6 margin-bottom-10""&gt;
                        &lt;p class=""margin-0""&gt;
                            &lt;strong&gt;Foo strin: &lt;/strong&gt; 
                        &lt;/p&gt;
                    &lt;/div&gt;
                    &lt;div class=""col-sm-6 margin-bottom-10""&gt;
                        &lt;p class=""margin-0""&gt;
                            &lt;strong&gt;Barbar&lt;/strong&gt;&lt;a href=""../test.pdf"" class=""link"" title=""test""&gt;&lt;span class=""icon-help""&gt;&lt;/span&gt;&lt;/a&gt; 
                        &lt;/p&gt;
                    &lt;/div&gt;
                &lt;/div&gt;
                &lt;div class=""row""&gt;
                    &lt;div class=""col-sm-6 margin-bottom-10""&gt;
                        &lt;p class=""margin-0""&gt;
                            &lt;strong&gt;Mine: &lt;/strong&gt; 
                        &lt;/p&gt;
                    &lt;/div&gt;
                    &lt;div class=""col-sm-6 margin-bottom-10""&gt;
                        &lt;p class=""margin-0""&gt;
                            TEST&lt;a href=""../link.pdf"" class=""my-link"" title=""title""&gt;&lt;span class=""icon-help""&gt;&lt;/span&gt;&lt;/a&gt; 
                        &lt;/p&gt;
                    &lt;/div&gt;
                &lt;/div&gt;
            &lt;/div&gt;
            &lt;div class=""col-sm-6 foo-images""&gt;
                &lt;div class=""row""&gt;
                    &lt;a href=""image-67890.html""&gt;&lt;img src=""../../images/67890_thumb.JPG"" alt=""Image 67890 "" title=""Image 67890""&gt;&lt;/a&gt; 
                    &lt;div class=""img-description""&gt;
                    &lt;/div&gt;
                &lt;/div&gt;
            &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
    &lt;div class=""element-header mystic-bg padding-y-10 padding-x-20"" id=""elem-5""&gt;
        &lt;h2 class=""h3 margin-bottom-5""&gt;
            Bar 
        &lt;/h2&gt;
        &lt;ul class=""list-inline margin-0""&gt;
            &lt;li&gt; &lt;a href=""#foo-feat-5-1""&gt;Bar feature&lt;/a&gt; &lt;/li&gt;
            ... 
        &lt;/ul&gt;
    &lt;/div&gt;
    &lt;div class=""padding-y-10 padding-x-40 gray-sand-bg"" id=""sec-feat-3-1""&gt;
        &lt;div class=""row""&gt;
            &lt;div class=""col-sm-6 info-panel""&gt;
                &lt;div class=""row""&gt;
                    &lt;div class=""col-sm-6 margin-bottom-10""&gt;
                        &lt;p class=""margin-0""&gt;
                            &lt;strong&gt;fsuhfsdf &lt;/strong&gt; 
                        &lt;/p&gt;
                    &lt;/div&gt;
                    &lt;div class=""col-sm-6 margin-bottom-10""&gt;
                        &lt;p class=""margin-0""&gt;
                            &lt;strong&gt;Feat&lt;/strong&gt;&lt;a href=""../linkglossary0.pdf"" class=""link"" title=""test""&gt;&lt;span class=""icon-help""&gt;&lt;/span&gt;&lt;/a&gt; 
                        &lt;/p&gt;
                    &lt;/div&gt;
                &lt;/div&gt;
            &lt;/div&gt;
            &lt;div class=""col-sm-6 foo-images""&gt;
                &lt;div class=""row""&gt;
                    &lt;a href=""image-39826.html""&gt;&lt;img src=""../../images/39826_thumb.JPG"" alt=""Image 39826"" title=""Image 39826 ""&gt;&lt;/a&gt; 
                    &lt;div class=""img-description""&gt;
                    &lt;/div&gt;
                &lt;/div&gt;
            &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
    &lt;div class=""padding-y-10 padding-x-40 gray-sand-bg"" id=""sec-feat-3-1""&gt;
        &lt;div class=""row""&gt;
            &lt;div class=""col-sm-6 info-panel""&gt;
                &lt;div class=""row""&gt;
                    &lt;div class=""col-sm-6 margin-bottom-10""&gt;
                        &lt;p class=""margin-0""&gt;
                            &lt;strong&gt;fsuhfsdf &lt;/strong&gt; 
                        &lt;/p&gt;
                    &lt;/div&gt;
                    &lt;div class=""col-sm-6 margin-bottom-10""&gt;
                        &lt;p class=""margin-0""&gt;
                            &lt;strong&gt;Feat&lt;/strong&gt;&lt;a href=""../linkglossary0.pdf"" class=""link"" title=""test""&gt;&lt;span class=""icon-help""&gt;&lt;/span&gt;&lt;/a&gt; 
                        &lt;/p&gt;
                    &lt;/div&gt;
                &lt;/div&gt;
            &lt;/div&gt;
            &lt;div class=""col-sm-6 foo-images""&gt;
                &lt;div class=""row""&gt;
                    &lt;a href=""image-209876.html""&gt;&lt;img src=""../../images/209876_thumb.JPG"" alt=""Image 209876"" title=""Image 209876 ""&gt;&lt;/a&gt; 
                    &lt;div class=""img-description""&gt;
                    &lt;/div&gt;
                &lt;/div&gt;
            &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;
</code></pre>
"
"60022477","<p>Another solution involving SimplifiedDoc:</p>

<pre><code>from simplified_scrapy.simplified_doc import SimplifiedDoc
html ='''
&lt;div class=""foo-bar-details""&gt;
    &lt;div class=""element-header mystic-bg padding-y-10 padding-x-20"" id=""elem-4""&gt;
        &lt;h2 class=""h3 margin-bottom-5""&gt;
            Foo 
        &lt;/h2&gt;
        &lt;ul class=""list-inline margin-0""&gt;
            &lt;li&gt; &lt;a href=""#foo-feat-4-1""&gt;Foo feature&lt;/a&gt; &lt;/li&gt;
            ... 
        &lt;/ul&gt;
    &lt;/div&gt;
    &lt;div id=""info-panel-header"" class=""padding-y-10 padding-x-40""&gt;Test 1&lt;/div&gt;
    &lt;div class=""padding-y-10 padding-x-40 gray-wild-sand-bg"" id=""foo-feat-4-1""&gt;Test 2&lt;/div&gt;
    &lt;div class=""padding-y-10 padding-x-40 "" id=""foo-feat-4-2""&gt;Test 3&lt;/div&gt;
    &lt;div class=""padding-y-10 padding-x-40 gray-wild-sand-bg"" id=""foo-feat-4-3""&gt;Test 4&lt;/div&gt;
    &lt;div class=""element-header mystic-bg padding-y-10 padding-x-20"" id=""elem-5""&gt;
        &lt;h2 class=""h3 margin-bottom-5""&gt;
            Bar 
        &lt;/h2&gt;
        &lt;ul class=""list-inline margin-0""&gt;
            &lt;li&gt; &lt;a href=""#foo-feat-5-1""&gt;Bar feature&lt;/a&gt; &lt;/li&gt;
            ... 
        &lt;/ul&gt;
    &lt;/div&gt;
&lt;/div&gt;
'''
doc = SimplifiedDoc(html)
divs = doc.select('div.foo-bar-details').divs.contains('&lt;h2')
print ([div.id for div in divs])
divs = doc.select('div.foo-bar-details').divs.notContains('&lt;h2')
print ([div.id for div in divs])
</code></pre>

<p>Result:</p>

<pre><code>['elem-4', 'elem-5']
['info-panel-header', 'foo-feat-4-1', 'foo-feat-4-2', 'foo-feat-4-3']
</code></pre>

<p>Simplifieddoc library does not rely on the third-party library, which is lighter and faster, perfect for beginners.
Here are more examples <a href=""https://github.com/yiyedata/simplified-scrapy-demo/tree/master/doc_examples"" rel=""nofollow noreferrer"">here</a></p>
","0","","0","2231","56","0","189","60016647","60016905","<p>I just found out about how to process webpages in python using BeautifulSoup.
There's a list of <code>div</code> from which I want to get those in a specific range. The range is defined by two <code>div</code> that have a <code>h2</code> child.
How would I do that? Thank you for your support!</p>

<p>EDIT: I added an actual representation of my html code below instead of a previous ""simplified"" version that was missing tags.
The new code shows a root <code>div</code> with class <code>foo-bar-details</code>.
Nested are 9 <code>div</code> tags. Two of which have a nested <code>h2</code> tag. All of those 9 <code>div</code> tags contain <code>img</code> elements deeply nested within. What I need is each <code>img</code> element of those <code>div</code>s that are <strong>between</strong> the ones containing the <code>h2</code> element.
An expected outcome if applied to the html code below would be:</p>

<pre><code>&lt;img src=""../../images/123456_thumb.jpg"" alt=""Image 123456"" title=""Image 123456""&gt;
&lt;img src=""../../images/67890_thumb.JPG"" alt=""Image 67890 "" title=""Image 67890""&gt;
</code></pre>

<p>This is the html code:</p>

<pre><code>&lt;div class=""foo-bar-details""&gt;
    &lt;div class=""padding-y-10 padding-x-40 gray-sand-bg"" id=""sec-feat-3-1""&gt;
        &lt;div class=""row""&gt;
            &lt;div class=""col-sm-6 info-panel""&gt;
                &lt;div class=""row""&gt;
                    &lt;div class=""col-sm-6 margin-bottom-10""&gt;
                        &lt;p class=""margin-0""&gt;
                            &lt;strong&gt;fsuhfsdf &lt;/strong&gt; 
                        &lt;/p&gt;
                    &lt;/div&gt;
                    &lt;div class=""col-sm-6 margin-bottom-10""&gt;
                        &lt;p class=""margin-0""&gt;
                            &lt;strong&gt;Feat&lt;/strong&gt;&lt;a href=""../linkglossary0.pdf"" class=""link"" title=""test""&gt;&lt;span class=""icon-help""&gt;&lt;/span&gt;&lt;/a&gt; 
                        &lt;/p&gt;
                    &lt;/div&gt;
                &lt;/div&gt;
            &lt;/div&gt;
            &lt;div class=""col-sm-6 foo-images""&gt;
                &lt;div class=""row""&gt;
                    &lt;a href=""image-39826.html""&gt;&lt;img src=""../../images/39826_thumb.JPG"" alt=""Image 39826"" title=""Image 39826 ""&gt;&lt;/a&gt; 
                    &lt;div class=""img-description""&gt;
                    &lt;/div&gt;
                &lt;/div&gt;
            &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
    &lt;div class=""padding-y-10 padding-x-40 gray-sand-bg"" id=""sec-feat-3-1""&gt;
        &lt;div class=""row""&gt;
            &lt;div class=""col-sm-6 info-panel""&gt;
                &lt;div class=""row""&gt;
                    &lt;div class=""col-sm-6 margin-bottom-10""&gt;
                        &lt;p class=""margin-0""&gt;
                            &lt;strong&gt;JHFDFD &lt;/strong&gt; 
                        &lt;/p&gt;
                    &lt;/div&gt;
                    &lt;div class=""col-sm-6 margin-bottom-10""&gt;
                        &lt;p class=""margin-0""&gt;
                            &lt;strong&gt;Feat&lt;/strong&gt;&lt;a href=""../linkglossary2.pdf"" class=""link"" title=""test""&gt;&lt;span class=""icon-help""&gt;&lt;/span&gt;&lt;/a&gt; 
                        &lt;/p&gt;
                    &lt;/div&gt;
                &lt;/div&gt;
            &lt;/div&gt;
            &lt;div class=""col-sm-6 foo-images""&gt;
                &lt;div class=""row""&gt;
                    &lt;a href=""image-223234.html""&gt;&lt;img src=""../../images/223234_thumb.JPG"" alt=""Image 223234"" title=""Image 223234 ""&gt;&lt;/a&gt; 
                    &lt;div class=""img-description""&gt;
                    &lt;/div&gt;
                &lt;/div&gt;
            &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
    &lt;div class=""padding-y-10 padding-x-40 gray-sand-bg"" id=""sec-feat-3-1""&gt;
        &lt;div class=""row""&gt;
            &lt;div class=""col-sm-6 info-panel""&gt;
                &lt;div class=""row""&gt;
                    &lt;div class=""col-sm-6 margin-bottom-10""&gt;
                        &lt;p class=""margin-0""&gt;
                            &lt;strong&gt;sdfsdf &lt;/strong&gt; 
                        &lt;/p&gt;
                    &lt;/div&gt;
                    &lt;div class=""col-sm-6 margin-bottom-10""&gt;
                        &lt;p class=""margin-0""&gt;
                            &lt;strong&gt;Feat&lt;/strong&gt;&lt;a href=""../linkglossary1.pdf"" class=""link"" title=""test""&gt;&lt;span class=""icon-help""&gt;&lt;/span&gt;&lt;/a&gt; 
                        &lt;/p&gt;
                    &lt;/div&gt;
                &lt;/div&gt;
            &lt;/div&gt;
            &lt;div class=""col-sm-6 foo-images""&gt;
                &lt;div class=""row""&gt;
                    &lt;a href=""image-223823.html""&gt;&lt;img src=""../../images/223823_thumb.JPG"" alt=""Image 223823"" title=""Image 223823 ""&gt;&lt;/a&gt; 
                    &lt;div class=""img-description""&gt;
                    &lt;/div&gt;
                &lt;/div&gt;
            &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
    &lt;div class=""element-header mystic-bg padding-y-10 padding-x-20"" id=""elem-4""&gt;
        &lt;h2 class=""h3 margin-bottom-5""&gt;
            Foo 
        &lt;/h2&gt;
        &lt;ul class=""list-inline margin-0""&gt;
            &lt;li&gt; &lt;a href=""#foo-feat-4-1""&gt;Foo feature&lt;/a&gt; &lt;/li&gt;
            ... 
        &lt;/ul&gt;
    &lt;/div&gt;
    &lt;div id=""info-panel-header"" class=""padding-y-10 padding-x-40""&gt;
        &lt;div class=""row""&gt;
            &lt;div class=""col-se-6 element-info""&gt;
                &lt;div class=""col-se-12""&gt;
                    &lt;div class=""row""&gt;
                    &lt;/div&gt;
                &lt;/div&gt;
            &lt;/div&gt;
            &lt;div class=""col-sm-6 foo-images""&gt;
                &lt;div class=""row""&gt;
                    &lt;a href=""image-123456.html""&gt;&lt;img src=""../../images/123456_thumb.jpg"" alt=""Image 123456"" title=""Image 123456""&gt;&lt;/a&gt; 
                    &lt;div class=""img-description""&gt;
                    &lt;/div&gt;
                &lt;/div&gt;
            &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
    &lt;div class=""padding-y-10 padding-x-40 gray-wild-sand-bg"" id=""sec-feat-4-1""&gt;
        &lt;div class=""row""&gt;
            &lt;div class=""col-sm-6 info-panel""&gt;
                &lt;div class=""row""&gt;
                    &lt;div class=""col-sm-6 margin-bottom-10""&gt;
                        &lt;p class=""margin-0""&gt;
                            &lt;strong&gt;Foo strin: &lt;/strong&gt; 
                        &lt;/p&gt;
                    &lt;/div&gt;
                    &lt;div class=""col-sm-6 margin-bottom-10""&gt;
                        &lt;p class=""margin-0""&gt;
                            &lt;strong&gt;Barbar&lt;/strong&gt;&lt;a href=""../test.pdf"" class=""link"" title=""test""&gt;&lt;span class=""icon-help""&gt;&lt;/span&gt;&lt;/a&gt; 
                        &lt;/p&gt;
                    &lt;/div&gt;
                &lt;/div&gt;
                &lt;div class=""row""&gt;
                    &lt;div class=""col-sm-6 margin-bottom-10""&gt;
                        &lt;p class=""margin-0""&gt;
                            &lt;strong&gt;Mine: &lt;/strong&gt; 
                        &lt;/p&gt;
                    &lt;/div&gt;
                    &lt;div class=""col-sm-6 margin-bottom-10""&gt;
                        &lt;p class=""margin-0""&gt;
                            TEST&lt;a href=""../link.pdf"" class=""my-link"" title=""title""&gt;&lt;span class=""icon-help""&gt;&lt;/span&gt;&lt;/a&gt; 
                        &lt;/p&gt;
                    &lt;/div&gt;
                &lt;/div&gt;
            &lt;/div&gt;
            &lt;div class=""col-sm-6 foo-images""&gt;
                &lt;div class=""row""&gt;
                    &lt;a href=""image-67890.html""&gt;&lt;img src=""../../images/67890_thumb.JPG"" alt=""Image 67890 "" title=""Image 67890""&gt;&lt;/a&gt; 
                    &lt;div class=""img-description""&gt;
                    &lt;/div&gt;
                &lt;/div&gt;
            &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
    &lt;div class=""element-header mystic-bg padding-y-10 padding-x-20"" id=""elem-5""&gt;
        &lt;h2 class=""h3 margin-bottom-5""&gt;
            Bar 
        &lt;/h2&gt;
        &lt;ul class=""list-inline margin-0""&gt;
            &lt;li&gt; &lt;a href=""#foo-feat-5-1""&gt;Bar feature&lt;/a&gt; &lt;/li&gt;
            ... 
        &lt;/ul&gt;
    &lt;/div&gt;
    &lt;div class=""padding-y-10 padding-x-40 gray-sand-bg"" id=""sec-feat-3-1""&gt;
        &lt;div class=""row""&gt;
            &lt;div class=""col-sm-6 info-panel""&gt;
                &lt;div class=""row""&gt;
                    &lt;div class=""col-sm-6 margin-bottom-10""&gt;
                        &lt;p class=""margin-0""&gt;
                            &lt;strong&gt;fsuhfsdf &lt;/strong&gt; 
                        &lt;/p&gt;
                    &lt;/div&gt;
                    &lt;div class=""col-sm-6 margin-bottom-10""&gt;
                        &lt;p class=""margin-0""&gt;
                            &lt;strong&gt;Feat&lt;/strong&gt;&lt;a href=""../linkglossary0.pdf"" class=""link"" title=""test""&gt;&lt;span class=""icon-help""&gt;&lt;/span&gt;&lt;/a&gt; 
                        &lt;/p&gt;
                    &lt;/div&gt;
                &lt;/div&gt;
            &lt;/div&gt;
            &lt;div class=""col-sm-6 foo-images""&gt;
                &lt;div class=""row""&gt;
                    &lt;a href=""image-39826.html""&gt;&lt;img src=""../../images/39826_thumb.JPG"" alt=""Image 39826"" title=""Image 39826 ""&gt;&lt;/a&gt; 
                    &lt;div class=""img-description""&gt;
                    &lt;/div&gt;
                &lt;/div&gt;
            &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
    &lt;div class=""padding-y-10 padding-x-40 gray-sand-bg"" id=""sec-feat-3-1""&gt;
        &lt;div class=""row""&gt;
            &lt;div class=""col-sm-6 info-panel""&gt;
                &lt;div class=""row""&gt;
                    &lt;div class=""col-sm-6 margin-bottom-10""&gt;
                        &lt;p class=""margin-0""&gt;
                            &lt;strong&gt;fsuhfsdf &lt;/strong&gt; 
                        &lt;/p&gt;
                    &lt;/div&gt;
                    &lt;div class=""col-sm-6 margin-bottom-10""&gt;
                        &lt;p class=""margin-0""&gt;
                            &lt;strong&gt;Feat&lt;/strong&gt;&lt;a href=""../linkglossary0.pdf"" class=""link"" title=""test""&gt;&lt;span class=""icon-help""&gt;&lt;/span&gt;&lt;/a&gt; 
                        &lt;/p&gt;
                    &lt;/div&gt;
                &lt;/div&gt;
            &lt;/div&gt;
            &lt;div class=""col-sm-6 foo-images""&gt;
                &lt;div class=""row""&gt;
                    &lt;a href=""image-209876.html""&gt;&lt;img src=""../../images/209876_thumb.JPG"" alt=""Image 209876"" title=""Image 209876 ""&gt;&lt;/a&gt; 
                    &lt;div class=""img-description""&gt;
                    &lt;/div&gt;
                &lt;/div&gt;
            &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;
</code></pre>
"
"60027428","<p>If I understand you correctly, you want to find <code>&lt;img&gt;</code> tags and corresponding <code>&lt;h2&gt;</code> to which the images belong to.</p>

<p>This example (<code>txt</code> variable contains the HTML snippet from your question):</p>

<pre><code>from bs4 import BeautifulSoup

soup = BeautifulSoup(txt, 'html.parser')

out = {}
for img in soup.select('div:has(h2) ~ div img'):
    out.setdefault(img.find_previous('h2').get_text(strip=True), []).append(img['src'])

from pprint import pprint
pprint(out)
</code></pre>

<p>Prints:</p>

<pre><code>{'Bar': ['../../images/39826_thumb.JPG', '../../images/209876_thumb.JPG'],
 'Foo': ['../../images/123456_thumb.jpg', '../../images/67890_thumb.JPG']}
</code></pre>
","0","","0","67907","1966","35","5948","60016647","60016905","<p>I just found out about how to process webpages in python using BeautifulSoup.
There's a list of <code>div</code> from which I want to get those in a specific range. The range is defined by two <code>div</code> that have a <code>h2</code> child.
How would I do that? Thank you for your support!</p>

<p>EDIT: I added an actual representation of my html code below instead of a previous ""simplified"" version that was missing tags.
The new code shows a root <code>div</code> with class <code>foo-bar-details</code>.
Nested are 9 <code>div</code> tags. Two of which have a nested <code>h2</code> tag. All of those 9 <code>div</code> tags contain <code>img</code> elements deeply nested within. What I need is each <code>img</code> element of those <code>div</code>s that are <strong>between</strong> the ones containing the <code>h2</code> element.
An expected outcome if applied to the html code below would be:</p>

<pre><code>&lt;img src=""../../images/123456_thumb.jpg"" alt=""Image 123456"" title=""Image 123456""&gt;
&lt;img src=""../../images/67890_thumb.JPG"" alt=""Image 67890 "" title=""Image 67890""&gt;
</code></pre>

<p>This is the html code:</p>

<pre><code>&lt;div class=""foo-bar-details""&gt;
    &lt;div class=""padding-y-10 padding-x-40 gray-sand-bg"" id=""sec-feat-3-1""&gt;
        &lt;div class=""row""&gt;
            &lt;div class=""col-sm-6 info-panel""&gt;
                &lt;div class=""row""&gt;
                    &lt;div class=""col-sm-6 margin-bottom-10""&gt;
                        &lt;p class=""margin-0""&gt;
                            &lt;strong&gt;fsuhfsdf &lt;/strong&gt; 
                        &lt;/p&gt;
                    &lt;/div&gt;
                    &lt;div class=""col-sm-6 margin-bottom-10""&gt;
                        &lt;p class=""margin-0""&gt;
                            &lt;strong&gt;Feat&lt;/strong&gt;&lt;a href=""../linkglossary0.pdf"" class=""link"" title=""test""&gt;&lt;span class=""icon-help""&gt;&lt;/span&gt;&lt;/a&gt; 
                        &lt;/p&gt;
                    &lt;/div&gt;
                &lt;/div&gt;
            &lt;/div&gt;
            &lt;div class=""col-sm-6 foo-images""&gt;
                &lt;div class=""row""&gt;
                    &lt;a href=""image-39826.html""&gt;&lt;img src=""../../images/39826_thumb.JPG"" alt=""Image 39826"" title=""Image 39826 ""&gt;&lt;/a&gt; 
                    &lt;div class=""img-description""&gt;
                    &lt;/div&gt;
                &lt;/div&gt;
            &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
    &lt;div class=""padding-y-10 padding-x-40 gray-sand-bg"" id=""sec-feat-3-1""&gt;
        &lt;div class=""row""&gt;
            &lt;div class=""col-sm-6 info-panel""&gt;
                &lt;div class=""row""&gt;
                    &lt;div class=""col-sm-6 margin-bottom-10""&gt;
                        &lt;p class=""margin-0""&gt;
                            &lt;strong&gt;JHFDFD &lt;/strong&gt; 
                        &lt;/p&gt;
                    &lt;/div&gt;
                    &lt;div class=""col-sm-6 margin-bottom-10""&gt;
                        &lt;p class=""margin-0""&gt;
                            &lt;strong&gt;Feat&lt;/strong&gt;&lt;a href=""../linkglossary2.pdf"" class=""link"" title=""test""&gt;&lt;span class=""icon-help""&gt;&lt;/span&gt;&lt;/a&gt; 
                        &lt;/p&gt;
                    &lt;/div&gt;
                &lt;/div&gt;
            &lt;/div&gt;
            &lt;div class=""col-sm-6 foo-images""&gt;
                &lt;div class=""row""&gt;
                    &lt;a href=""image-223234.html""&gt;&lt;img src=""../../images/223234_thumb.JPG"" alt=""Image 223234"" title=""Image 223234 ""&gt;&lt;/a&gt; 
                    &lt;div class=""img-description""&gt;
                    &lt;/div&gt;
                &lt;/div&gt;
            &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
    &lt;div class=""padding-y-10 padding-x-40 gray-sand-bg"" id=""sec-feat-3-1""&gt;
        &lt;div class=""row""&gt;
            &lt;div class=""col-sm-6 info-panel""&gt;
                &lt;div class=""row""&gt;
                    &lt;div class=""col-sm-6 margin-bottom-10""&gt;
                        &lt;p class=""margin-0""&gt;
                            &lt;strong&gt;sdfsdf &lt;/strong&gt; 
                        &lt;/p&gt;
                    &lt;/div&gt;
                    &lt;div class=""col-sm-6 margin-bottom-10""&gt;
                        &lt;p class=""margin-0""&gt;
                            &lt;strong&gt;Feat&lt;/strong&gt;&lt;a href=""../linkglossary1.pdf"" class=""link"" title=""test""&gt;&lt;span class=""icon-help""&gt;&lt;/span&gt;&lt;/a&gt; 
                        &lt;/p&gt;
                    &lt;/div&gt;
                &lt;/div&gt;
            &lt;/div&gt;
            &lt;div class=""col-sm-6 foo-images""&gt;
                &lt;div class=""row""&gt;
                    &lt;a href=""image-223823.html""&gt;&lt;img src=""../../images/223823_thumb.JPG"" alt=""Image 223823"" title=""Image 223823 ""&gt;&lt;/a&gt; 
                    &lt;div class=""img-description""&gt;
                    &lt;/div&gt;
                &lt;/div&gt;
            &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
    &lt;div class=""element-header mystic-bg padding-y-10 padding-x-20"" id=""elem-4""&gt;
        &lt;h2 class=""h3 margin-bottom-5""&gt;
            Foo 
        &lt;/h2&gt;
        &lt;ul class=""list-inline margin-0""&gt;
            &lt;li&gt; &lt;a href=""#foo-feat-4-1""&gt;Foo feature&lt;/a&gt; &lt;/li&gt;
            ... 
        &lt;/ul&gt;
    &lt;/div&gt;
    &lt;div id=""info-panel-header"" class=""padding-y-10 padding-x-40""&gt;
        &lt;div class=""row""&gt;
            &lt;div class=""col-se-6 element-info""&gt;
                &lt;div class=""col-se-12""&gt;
                    &lt;div class=""row""&gt;
                    &lt;/div&gt;
                &lt;/div&gt;
            &lt;/div&gt;
            &lt;div class=""col-sm-6 foo-images""&gt;
                &lt;div class=""row""&gt;
                    &lt;a href=""image-123456.html""&gt;&lt;img src=""../../images/123456_thumb.jpg"" alt=""Image 123456"" title=""Image 123456""&gt;&lt;/a&gt; 
                    &lt;div class=""img-description""&gt;
                    &lt;/div&gt;
                &lt;/div&gt;
            &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
    &lt;div class=""padding-y-10 padding-x-40 gray-wild-sand-bg"" id=""sec-feat-4-1""&gt;
        &lt;div class=""row""&gt;
            &lt;div class=""col-sm-6 info-panel""&gt;
                &lt;div class=""row""&gt;
                    &lt;div class=""col-sm-6 margin-bottom-10""&gt;
                        &lt;p class=""margin-0""&gt;
                            &lt;strong&gt;Foo strin: &lt;/strong&gt; 
                        &lt;/p&gt;
                    &lt;/div&gt;
                    &lt;div class=""col-sm-6 margin-bottom-10""&gt;
                        &lt;p class=""margin-0""&gt;
                            &lt;strong&gt;Barbar&lt;/strong&gt;&lt;a href=""../test.pdf"" class=""link"" title=""test""&gt;&lt;span class=""icon-help""&gt;&lt;/span&gt;&lt;/a&gt; 
                        &lt;/p&gt;
                    &lt;/div&gt;
                &lt;/div&gt;
                &lt;div class=""row""&gt;
                    &lt;div class=""col-sm-6 margin-bottom-10""&gt;
                        &lt;p class=""margin-0""&gt;
                            &lt;strong&gt;Mine: &lt;/strong&gt; 
                        &lt;/p&gt;
                    &lt;/div&gt;
                    &lt;div class=""col-sm-6 margin-bottom-10""&gt;
                        &lt;p class=""margin-0""&gt;
                            TEST&lt;a href=""../link.pdf"" class=""my-link"" title=""title""&gt;&lt;span class=""icon-help""&gt;&lt;/span&gt;&lt;/a&gt; 
                        &lt;/p&gt;
                    &lt;/div&gt;
                &lt;/div&gt;
            &lt;/div&gt;
            &lt;div class=""col-sm-6 foo-images""&gt;
                &lt;div class=""row""&gt;
                    &lt;a href=""image-67890.html""&gt;&lt;img src=""../../images/67890_thumb.JPG"" alt=""Image 67890 "" title=""Image 67890""&gt;&lt;/a&gt; 
                    &lt;div class=""img-description""&gt;
                    &lt;/div&gt;
                &lt;/div&gt;
            &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
    &lt;div class=""element-header mystic-bg padding-y-10 padding-x-20"" id=""elem-5""&gt;
        &lt;h2 class=""h3 margin-bottom-5""&gt;
            Bar 
        &lt;/h2&gt;
        &lt;ul class=""list-inline margin-0""&gt;
            &lt;li&gt; &lt;a href=""#foo-feat-5-1""&gt;Bar feature&lt;/a&gt; &lt;/li&gt;
            ... 
        &lt;/ul&gt;
    &lt;/div&gt;
    &lt;div class=""padding-y-10 padding-x-40 gray-sand-bg"" id=""sec-feat-3-1""&gt;
        &lt;div class=""row""&gt;
            &lt;div class=""col-sm-6 info-panel""&gt;
                &lt;div class=""row""&gt;
                    &lt;div class=""col-sm-6 margin-bottom-10""&gt;
                        &lt;p class=""margin-0""&gt;
                            &lt;strong&gt;fsuhfsdf &lt;/strong&gt; 
                        &lt;/p&gt;
                    &lt;/div&gt;
                    &lt;div class=""col-sm-6 margin-bottom-10""&gt;
                        &lt;p class=""margin-0""&gt;
                            &lt;strong&gt;Feat&lt;/strong&gt;&lt;a href=""../linkglossary0.pdf"" class=""link"" title=""test""&gt;&lt;span class=""icon-help""&gt;&lt;/span&gt;&lt;/a&gt; 
                        &lt;/p&gt;
                    &lt;/div&gt;
                &lt;/div&gt;
            &lt;/div&gt;
            &lt;div class=""col-sm-6 foo-images""&gt;
                &lt;div class=""row""&gt;
                    &lt;a href=""image-39826.html""&gt;&lt;img src=""../../images/39826_thumb.JPG"" alt=""Image 39826"" title=""Image 39826 ""&gt;&lt;/a&gt; 
                    &lt;div class=""img-description""&gt;
                    &lt;/div&gt;
                &lt;/div&gt;
            &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
    &lt;div class=""padding-y-10 padding-x-40 gray-sand-bg"" id=""sec-feat-3-1""&gt;
        &lt;div class=""row""&gt;
            &lt;div class=""col-sm-6 info-panel""&gt;
                &lt;div class=""row""&gt;
                    &lt;div class=""col-sm-6 margin-bottom-10""&gt;
                        &lt;p class=""margin-0""&gt;
                            &lt;strong&gt;fsuhfsdf &lt;/strong&gt; 
                        &lt;/p&gt;
                    &lt;/div&gt;
                    &lt;div class=""col-sm-6 margin-bottom-10""&gt;
                        &lt;p class=""margin-0""&gt;
                            &lt;strong&gt;Feat&lt;/strong&gt;&lt;a href=""../linkglossary0.pdf"" class=""link"" title=""test""&gt;&lt;span class=""icon-help""&gt;&lt;/span&gt;&lt;/a&gt; 
                        &lt;/p&gt;
                    &lt;/div&gt;
                &lt;/div&gt;
            &lt;/div&gt;
            &lt;div class=""col-sm-6 foo-images""&gt;
                &lt;div class=""row""&gt;
                    &lt;a href=""image-209876.html""&gt;&lt;img src=""../../images/209876_thumb.JPG"" alt=""Image 209876"" title=""Image 209876 ""&gt;&lt;/a&gt; 
                    &lt;div class=""img-description""&gt;
                    &lt;/div&gt;
                &lt;/div&gt;
            &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;
</code></pre>
"
"60017714","<p>I don't have an exact solution but you could create a pivot table: ids on the index and datetimes on the columns. Then you just have to select the columns you want. </p>

<pre><code>import pandas as pd
import numpy as np

df = pd.DataFrame(
{
    ""date_time"": [
        ""2018-10-16 23:00:00"",
        ""2018-10-16 23:10:00"",
        ""2018-10-16 23:20:00"",
        ""2018-10-16 23:30:00"",
        ""2018-10-16 23:40:00"",
        ""2018-10-16 23:50:00"",
        ""2018-10-17 00:00:00"",
        ""2018-10-17 00:10:00"",
        ""2018-10-17 00:20:00"",
    ],
    ""uids"": [
        ""1000,1321,7654,1321"",
        ""7654"",
        np.nan,
        ""7654,1000,7654,1321,1000"",
        ""691,3974,3974,323"",
        np.nan,
        np.nan,
        np.nan,
        ""27,33,3974,3974,7665,27"",
    ],
}
)

df[""date_time""] = pd.to_datetime(df[""date_time""])

df = (
    df.set_index(""date_time"") #do not use set_index if date_time is current index
    .loc[:, ""uids""]
    .str.extractall(r""(?P&lt;uids&gt;\d+)"")
    .droplevel(level=1)
) # separate all the ids

df[""number""] = df.index.minute.astype(float) / 10 + 1 # get the number 1 to 6 depending on the minutes

df_pivot = df.pivot_table(
    values=""number"", 
    index=""uids"", 
    columns=[""date_time""], 
) #dataframe with all the uids on the index and all the datetimes in columns. 
</code></pre>

<p>You can apply this to the whole dataframe or just a subset containing 6 rows. Then you rename your columns.</p>
","1","2020-02-01 14:39:43","2","377","38","0","12","60016683","60017714","<p>I have a Dataframe of the form</p>

<pre><code>date_time                                                            uids
2018-10-16 23:00:00                                                 1000,1321,7654,1321
2018-10-16 23:10:00                                                 7654
2018-10-16 23:20:00                                                  NaN
2018-10-16 23:30:00                                                 7654,1000,7654,1321,1000
2018-10-16 23:40:00                                                 691,3974,3974,323
2018-10-16 23:50:00                                                  NaN
2018-10-17 00:00:00                                                  NaN
2018-10-17 00:10:00                                                  NaN
2018-10-17 00:20:00                                                 27,33,3974,3974,7665,27 
</code></pre>

<p>This is a very big data frame containing the 5 mins time interval and the number of appearances of ids during those time intervals.</p>

<p>I want to iterate over these DataFrame 6 rows at a time (corresponding to 1 hour) and create DataFrame containing the ID and the number of times each id appear during this time.</p>

<p>Expected output is one dataframe per hour information. For example, in the above case dataframe for the hour 23 - 00 will have this form</p>

<pre><code>uid   1   2   3   4   5   6

1000  1   0   0   2   0  0
1321  2   0   0   1   0  0
</code></pre>

<p>and so on    </p>

<p>How can I do this efficiently?</p>
"
"60018108","<p>You can use the function <code>crosstab</code>:</p>

<pre><code>df['uids'] = df['uids'].str.split(',')
df = df.explode('uids')
df['date_time'] = df['date_time'].dt.minute.floordiv(10).add(1)
pd.crosstab(df['uids'], df['date_time'], dropna=False)
</code></pre>

<p>Output:</p>

<pre><code>date_time  1  2  3  4  5  6
uids                       
1000       1  0  0  2  0  0
1321       2  0  0  1  0  0
27         0  0  2  0  0  0
323        0  0  0  0  1  0
33         0  0  1  0  0  0
3974       0  0  2  0  2  0
691        0  0  0  0  1  0
7654       1  1  0  2  0  0
7665       0  0  1  0  0  0
</code></pre>
","0","2020-02-01 22:48:02","1","8392","1681","353","792","60016683","60017714","<p>I have a Dataframe of the form</p>

<pre><code>date_time                                                            uids
2018-10-16 23:00:00                                                 1000,1321,7654,1321
2018-10-16 23:10:00                                                 7654
2018-10-16 23:20:00                                                  NaN
2018-10-16 23:30:00                                                 7654,1000,7654,1321,1000
2018-10-16 23:40:00                                                 691,3974,3974,323
2018-10-16 23:50:00                                                  NaN
2018-10-17 00:00:00                                                  NaN
2018-10-17 00:10:00                                                  NaN
2018-10-17 00:20:00                                                 27,33,3974,3974,7665,27 
</code></pre>

<p>This is a very big data frame containing the 5 mins time interval and the number of appearances of ids during those time intervals.</p>

<p>I want to iterate over these DataFrame 6 rows at a time (corresponding to 1 hour) and create DataFrame containing the ID and the number of times each id appear during this time.</p>

<p>Expected output is one dataframe per hour information. For example, in the above case dataframe for the hour 23 - 00 will have this form</p>

<pre><code>uid   1   2   3   4   5   6

1000  1   0   0   2   0  0
1321  2   0   0   1   0  0
</code></pre>

<p>and so on    </p>

<p>How can I do this efficiently?</p>
"
"60020367","<p>We can achieve this with extracting the minutes from your datetime column. Then using <code>pivot_table</code> to get your wide format:</p>

<pre><code>df['date_time'] = pd.to_datetime(df['date_time'])

df['minute'] = df['date_time'].dt.minute // 10

piv = (df.assign(uids=df['uids'].str.split(','))
         .explode('uids')
         .pivot_table(index='uids', columns='minute', values='minute', aggfunc='size')
      )
</code></pre>

<pre><code>minute    0    1    2    3    4
uids                           
1000    1.0  NaN  NaN  2.0  NaN
1321    2.0  NaN  NaN  1.0  NaN
27      NaN  NaN  2.0  NaN  NaN
323     NaN  NaN  NaN  NaN  1.0
33      NaN  NaN  1.0  NaN  NaN
3974    NaN  NaN  2.0  NaN  2.0
691     NaN  NaN  NaN  NaN  1.0
7654    1.0  1.0  NaN  2.0  NaN
7665    NaN  NaN  1.0  NaN  NaN
</code></pre>
","0","","1","31021","2441","310","2308","60016683","60017714","<p>I have a Dataframe of the form</p>

<pre><code>date_time                                                            uids
2018-10-16 23:00:00                                                 1000,1321,7654,1321
2018-10-16 23:10:00                                                 7654
2018-10-16 23:20:00                                                  NaN
2018-10-16 23:30:00                                                 7654,1000,7654,1321,1000
2018-10-16 23:40:00                                                 691,3974,3974,323
2018-10-16 23:50:00                                                  NaN
2018-10-17 00:00:00                                                  NaN
2018-10-17 00:10:00                                                  NaN
2018-10-17 00:20:00                                                 27,33,3974,3974,7665,27 
</code></pre>

<p>This is a very big data frame containing the 5 mins time interval and the number of appearances of ids during those time intervals.</p>

<p>I want to iterate over these DataFrame 6 rows at a time (corresponding to 1 hour) and create DataFrame containing the ID and the number of times each id appear during this time.</p>

<p>Expected output is one dataframe per hour information. For example, in the above case dataframe for the hour 23 - 00 will have this form</p>

<pre><code>uid   1   2   3   4   5   6

1000  1   0   0   2   0  0
1321  2   0   0   1   0  0
</code></pre>

<p>and so on    </p>

<p>How can I do this efficiently?</p>
"
"60017010","<p>In your program, you have this line  <code>del store_1[y]</code>. This is an O(n) operation according to <a href=""https://wiki.python.org/moin/TimeComplexity"" rel=""nofollow noreferrer"">here</a>. So, your code works in O(n<sup>2</sup>). That is why you are getting <strong>CPU Time Exceeded</strong>.</p>

<p>Maintain 2 counters , <code>b=0</code> and <code>m=0</code>. Iterate through the given string and find if the given index is part of the set, If yes, don't do anything. Else check if it is <code>B</code> or <code>M</code>. Accordingly, increment the counters and do the necessary check in the end. </p>

<p>Also, instead of generating Fibonacci series multiple times, you can actually generate it once and use the results again and again for the test cases.</p>
","3","2020-02-02 11:35:29","0","1997","716","58","334","60016724","60017010","<p>I am trying to solve the <a href=""https://toph.co/p/aaj-kemon-bodh-korcho"" rel=""nofollow noreferrer"">""Aaj Kemon Bodh Korcho"" problem on Toph</a>: </p>

<blockquote>
  <p>There is a match between Barcelona and Real Madrid. [...]  There is a
  GOAL in each and every second of the match. All the goals may not be
  valid i.e. some of the goals can be done from OFF SIDE  which is out
  of the rules.</p>
  
  <p>[Output] “Aaj Kemon Bodh Korcho” (without quotes) if Barcelona won the
  match,  “Hala Madrid” (without quotes) if Real Madrid won the match or
  “Meh :\” (without quotes) if there is no winner.</p>
  
  <p>[...] The goals that are done from OFF SIDE are belongs (sic) to a
  famous series [...]:</p>
  
  <p>0, 1, 1, 2, 3, 5, 8 …, …, …, …, …, n<sup>th</sup> term</p>
  
  <h3>Input</h3>
  
  <p>You’re given an integer number <strong>T</strong> which denotes the number of test
  cases <strong>(T &lt;=100)</strong>. In (sic) each of the <strong>T</strong> line contains a string
  (<strong>S</strong>) of following characters <strong>(B, M)</strong>. The maximum length of the
  string will not be greater than <strong>10<sup>5</sup></strong>. Note that, the
  starting index will be <strong>0</strong>.</p>
  
  <p>Here,<br>
  If the <strong>i</strong><sup>th</sup> character is <strong>B</strong> then it denotes a
  goal is done by Barcelona at <strong>i</strong><sup>th</sup> second.<br>
  If the
  <strong>i</strong><sup>th</sup> character is <strong>M</strong> then it denotes a goal is done by Real Madrid at <strong>i</strong><sup>th</sup> second.  </p>
  
  <h3>Output</h3>
  
  <p>For each of the <strong>T</strong> lines you have to print the case number first
  according to the format <strong>Case #X</strong> where X is the case number.  Then
  you have to print <strong>Aaj Kemon Bodh Korcho</strong> if Barcelona won the match
  or <strong>Hala Madrid</strong> if Real Madrid won the match.  Otherwise print
  <strong>Meh :\</strong> . For more clarification see the samples below.</p>
  
  <h3>Sample</h3>
  
  <pre class=""lang-none prettyprint-override""><code>Input   Output

2
BBMMMM  Case #1: Hala Madrid
MMBBBB  Case #2: Aaj Kemon Bodh Korcho
</code></pre>
</blockquote>

<p>Here's my code:</p>

<pre><code>f=[0,1]
num_of_testcase = int(input())
store_2 = []
for i in range(num_of_testcase):
    numbers = input()
    store_1 = list(numbers)
    for x in range(len(store_1)):
        f.append(f[x]+f[x+1])
    f = sorted(set(f), key=f.index)
    for y in f:
        try:
            del store_1[y]
        except:
            store_2.append(store_1)
    if store_1.count(""B"") &gt; store_1.count(""M""):
        print(""Case #"" + str(int(i+1)) + "":"" + "" Aaj Kemon Bodh Korcho"")
    elif store_1.count(""B"") &lt; store_1.count(""M""):
        print(""Case #"" + str(int(i+1)) + "":"" + "" Hala Madrid"")
    else:
        print(""Case #"" + str(int(i+1)) + "":"" + "" Meh :\\"")
</code></pre>

<p>When I submit my code it shows CPU Time Exceeded on the second testcase. How can I make my code run faster?</p>
"
"60017413","<p>There are several things that slow down your code:</p>

<ul>
<li>You start with <em>x</em> from 0 to reproduce the same Fibonacci numbers which you already generated for the previous test case. You should only generate those you did not have yet.</li>
<li>Because of the previous point, you have duplicates which you need to get rid of by applying <code>set</code>, and then you have to sort that set. If you would only generate unique Fibonacci numbers, you would not have to perform those actions.</li>
<li><code>del</code> is not a constant time operation. You should not need to delete list elements at all. All you <em>really</em> need to do, is counting</li>
<li>You potentially call the <code>count</code> method four times in a test case, while it should be enough to only perform a count once.  </li>
</ul>

<p>You can save more:</p>

<ul>
<li>Don't actually store the Fibonacci numbers in a list, but just keep the last two values in memory, and produce the next one once your index reaches the current Fibonacci number</li>
<li>Keep track of <em>one</em> count, a balance, which will go positive when Madrid scores more, or negative when Barcelona scores more.</li>
</ul>

<p>Here is how that could look:</p>

<pre><code>num_of_testcase = int(input())
for i in range(num_of_testcase):
    goals = input()
    balance = 0
    # Fibonacci pair
    a = 3
    b = 5
    # Don't bother looking at index 0-3: they are to be ignored
    for j in range(4, len(goals)):
        if j &lt; b:
            balance += 1 if goals[j] == ""M"" else -1
        else:
            a, b = b, a+b # Up to next Fibonacci number
    if balance &lt; 0:
        print(""Case #{}: Aaj Kemon Bodh Korcho"".format(i+1))
    elif balance &gt; 0:
        print(""Case #{}: Hala Madrid"".format(i+1))
    else:
        print(""Case #{}: Meh :\\"".format(i+1))
</code></pre>
","8","2020-02-01 15:00:08","-1","204854","1897","2832","18633","60016724","60017010","<p>I am trying to solve the <a href=""https://toph.co/p/aaj-kemon-bodh-korcho"" rel=""nofollow noreferrer"">""Aaj Kemon Bodh Korcho"" problem on Toph</a>: </p>

<blockquote>
  <p>There is a match between Barcelona and Real Madrid. [...]  There is a
  GOAL in each and every second of the match. All the goals may not be
  valid i.e. some of the goals can be done from OFF SIDE  which is out
  of the rules.</p>
  
  <p>[Output] “Aaj Kemon Bodh Korcho” (without quotes) if Barcelona won the
  match,  “Hala Madrid” (without quotes) if Real Madrid won the match or
  “Meh :\” (without quotes) if there is no winner.</p>
  
  <p>[...] The goals that are done from OFF SIDE are belongs (sic) to a
  famous series [...]:</p>
  
  <p>0, 1, 1, 2, 3, 5, 8 …, …, …, …, …, n<sup>th</sup> term</p>
  
  <h3>Input</h3>
  
  <p>You’re given an integer number <strong>T</strong> which denotes the number of test
  cases <strong>(T &lt;=100)</strong>. In (sic) each of the <strong>T</strong> line contains a string
  (<strong>S</strong>) of following characters <strong>(B, M)</strong>. The maximum length of the
  string will not be greater than <strong>10<sup>5</sup></strong>. Note that, the
  starting index will be <strong>0</strong>.</p>
  
  <p>Here,<br>
  If the <strong>i</strong><sup>th</sup> character is <strong>B</strong> then it denotes a
  goal is done by Barcelona at <strong>i</strong><sup>th</sup> second.<br>
  If the
  <strong>i</strong><sup>th</sup> character is <strong>M</strong> then it denotes a goal is done by Real Madrid at <strong>i</strong><sup>th</sup> second.  </p>
  
  <h3>Output</h3>
  
  <p>For each of the <strong>T</strong> lines you have to print the case number first
  according to the format <strong>Case #X</strong> where X is the case number.  Then
  you have to print <strong>Aaj Kemon Bodh Korcho</strong> if Barcelona won the match
  or <strong>Hala Madrid</strong> if Real Madrid won the match.  Otherwise print
  <strong>Meh :\</strong> . For more clarification see the samples below.</p>
  
  <h3>Sample</h3>
  
  <pre class=""lang-none prettyprint-override""><code>Input   Output

2
BBMMMM  Case #1: Hala Madrid
MMBBBB  Case #2: Aaj Kemon Bodh Korcho
</code></pre>
</blockquote>

<p>Here's my code:</p>

<pre><code>f=[0,1]
num_of_testcase = int(input())
store_2 = []
for i in range(num_of_testcase):
    numbers = input()
    store_1 = list(numbers)
    for x in range(len(store_1)):
        f.append(f[x]+f[x+1])
    f = sorted(set(f), key=f.index)
    for y in f:
        try:
            del store_1[y]
        except:
            store_2.append(store_1)
    if store_1.count(""B"") &gt; store_1.count(""M""):
        print(""Case #"" + str(int(i+1)) + "":"" + "" Aaj Kemon Bodh Korcho"")
    elif store_1.count(""B"") &lt; store_1.count(""M""):
        print(""Case #"" + str(int(i+1)) + "":"" + "" Hala Madrid"")
    else:
        print(""Case #"" + str(int(i+1)) + "":"" + "" Meh :\\"")
</code></pre>

<p>When I submit my code it shows CPU Time Exceeded on the second testcase. How can I make my code run faster?</p>
"
"60016863","<p>You can do this:</p>

<pre><code>def on_release(key):
    print('{0} released'.format(key))
    #Add your code to stop motor
    if key == keyboard.Key.esc:
        # Stop listener
        # Stop the Robot Code
        return False
    if 'char' in dir(key):     #check if char method exists,
        if key.char == 'q':    #check if it is 'q' key
            print(""fviokbhvxfb"")
</code></pre>
","1","","1","3276","1384","197","432","60016734","60016863","<p>I am using <code>pynput</code> to detect <code>keypress</code> release but I want to execute some different code on release of a specific key.</p>

<p>Here is my code:</p>

<pre><code>1   from pynput import keyboard
2
3   def on_press(key):
4        try:
5           print('Key {0} pressed'.format(key.char))
6           #Add your code to drive motor
7       except AttributeError:
8           print('Key {0} pressed'.format(key))
9           #Add Code
10  def on_release(key):
11      print('{0} released'.format(key))
12      #Add your code to stop motor
13      if key == keyboard.Key.esc:
14          # Stop listener
15          # Stop the Robot Code
16          return False
17      if key == keyboard.Key.Qkey:
18          print (""fviokbhvxfb"")
19
20  # Collect events until released
21  with keyboard.Listener(
22          on_press=on_press,
23          on_release=on_release) as listener:
24      listener.join()
</code></pre>

<p>they point which does't work is this : </p>

<pre><code>if key == keyboard.Key.Qkey:
    print (""fviokbhvxfb"")`
</code></pre>

<p>probably my problem is the <code>Qkey</code>.</p>

<p>i have written at line 17
what should i replace it with?
I am trying to detect if <code>q</code> is released and pressed and execute some code only if it is pressed down and not something else.</p>
"
"60023072","<p>If you are using virtual environments, depending how you run your script, <code>'python'</code> might refer to the system Python. Using <code>sys.executable</code> instead of <code>'python'</code> might help.</p>

<p>Note that if you are using WSGI, <code>sys.executable</code> is probably not set correctly, so you might want to set it explicitly in your WSGI entry point script.</p>
","0","","0","3579","482","206","406","60016929","60023072","<ol>
<li>python dbtest1.py  ==> work O.K.</li>
</ol>

<pre><code>       dbtest1.py :&lt;br&gt;
       import pymysql.connector&lt;br&gt;
       dbCon = pymysql.connector.connect(host='...', database='...', user='...', password='...')&lt;br&gt;
       cursor = dbCon.cursor()&lt;br&gt;
       cursor.execute(""INSERT INTO cm_person (name) VALUES ('고길송')"")&lt;br&gt;
       dbCon.commit()
</code></pre>

<ol start=""2"">
<li>access from Django using subprocess, Not found error...</li>
</ol>

<pre><code>
   views.py include...

    def datatest(request):&lt;br&gt;
       subprocess.call(['python', 'dbtest3.py'])&lt;br&gt;
       return HttpResponse('Call python...')
</code></pre>

<p><strong>Error message;</strong></p>

<pre><code>     ModuleNotFoundError: No module named 'pymysql'

</code></pre>

<p>Did I miss something? or is there any other methods?
Thank you.</p>
"
"60041049","<p>views.py</p>

<p>def datatest(request):<br>
   subprocess.call([sys.executable, ""-c"", ""import dbtest2""])<br>
   return HttpResponse('Call python...')</p>
","0","","0","33","0","0","3","60016929","60023072","<ol>
<li>python dbtest1.py  ==> work O.K.</li>
</ol>

<pre><code>       dbtest1.py :&lt;br&gt;
       import pymysql.connector&lt;br&gt;
       dbCon = pymysql.connector.connect(host='...', database='...', user='...', password='...')&lt;br&gt;
       cursor = dbCon.cursor()&lt;br&gt;
       cursor.execute(""INSERT INTO cm_person (name) VALUES ('고길송')"")&lt;br&gt;
       dbCon.commit()
</code></pre>

<ol start=""2"">
<li>access from Django using subprocess, Not found error...</li>
</ol>

<pre><code>
   views.py include...

    def datatest(request):&lt;br&gt;
       subprocess.call(['python', 'dbtest3.py'])&lt;br&gt;
       return HttpResponse('Call python...')
</code></pre>

<p><strong>Error message;</strong></p>

<pre><code>     ModuleNotFoundError: No module named 'pymysql'

</code></pre>

<p>Did I miss something? or is there any other methods?
Thank you.</p>
"
"60017112","<p>since your column datatype is timestamp you can not use str <code>'2020-02-01'</code> to compare with your column so you need also a timestamp value: <code>pd.Timestamp(2020, 2,1)</code></p>

<p>you can use <a href=""https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.map.html"" rel=""nofollow noreferrer"">pandas.Series.map</a>:</p>

<pre><code>df_main['month_1'] = df_main['month_1'].map(lambda x: 0 if x &gt;= pd.Timestamp(2020, 2,1) else x)
</code></pre>

<p>or you can filter and assign: </p>

<pre><code>df_main['month_1'][ df_main['month_1'] &gt;= pd.Timestamp(2020, 2,1)] = 0 
</code></pre>
","2","2020-02-01 17:24:45","1","15189","2120","120","950","60017006","60017112","<pre><code>df_main['month_1']= np.where(df_main['month_1'] &gt;='2020-02-01',0,df_main['month_1'])
</code></pre>

<p>I need all the items in the month_1 column to be zero if the date is February 1st, 2020. 
I tried '02/01/2020' format as well, which doesn't work.</p>
"
"60047191","<p>QPainter supports floating point coordinates, but has to be done using an implicit QPointF statement:</p>

<p><code>qp.drawPoint(QPointF(10.5, 10))</code> </p>

<p><a href=""https://i.stack.imgur.com/w4fFo.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/w4fFo.png"" alt=""parameters""></a></p>
","0","2020-02-08 10:44:42","0","270","287","9","98","60017009","60047191","<p>Are there any widget or option for painting anything at non integer (e.g 3.5) position? I currently use a QWidget, a QGraphicsView and a QGraphicsScene. However, the widget only supports painting at integer pixel locations. </p>
"
"60104107","<p>What is it you are really trying to do? There are many float/real methods to choose from so it doesn't sound like you are asking the correct question.</p>

<p><a href=""https://doc.qt.io/qt-5/qgraphicsview.html#mapFromScene-5"" rel=""nofollow noreferrer"">mapFromScene()</a>
<a href=""https://doc.qt.io/qt-5/qgraphicsview.html#centerOn"" rel=""nofollow noreferrer"">centerOn()</a></p>

<p>In C++ when you <a href=""https://doc.qt.io/qt-5/qgraphicsscene.html#addWidget"" rel=""nofollow noreferrer"">addWidget()</a> you get back QGraphicsProxyWidget *. and it just so happens that QGraphicsProxyWidget has <a href=""https://doc.qt.io/qt-5/qgraphicsitem.html#setPos-1"" rel=""nofollow noreferrer"">setPos(qreal x, qreal y)</a></p>

<p>I'm certain you can find something similar in the Python interface. If you cannot, convert your QWidget to a QGraphicsItem which also has a setPos(qreal x, qreal y)</p>
","2","","1","159","7","2","35","60017009","60047191","<p>Are there any widget or option for painting anything at non integer (e.g 3.5) position? I currently use a QWidget, a QGraphicsView and a QGraphicsScene. However, the widget only supports painting at integer pixel locations. </p>
"
"60017551","<p>Before you go down this route, you should evaluate if that is even neccessary. One important limit is the <a href=""https://www.rabbitmq.com/blog/2012/04/25/rabbitmq-performance-measurements-part-2/"" rel=""nofollow noreferrer"">rabbitmq bandwidth</a>.</p>

<p>Build a single-threaded app, and start feeding it synthetic rabbitmq messages. Increase the msg/s rate until it cannot keep up anymore.</p>

<p>If that rate is much higher than is likely to occur in practice, you are done. :-)</p>

<p>If not, then you start <em>profiling</em> your application to find which parts of it take the most time. Those are your bottlenecks.
Only when you know what the bottlenecks are, you can look at the relevant code and think about how to improve them.</p>

<p>Note that <code>multiprocessing</code> and <code>threading</code> do different things and have different applications. If your application is limited by the amount of calculations that it can do then <code>multiprocessing</code> can help by spreading out the calculations over multiple CPU cores. Note that this only works well if the calculations are <em>independant</em> of each other. If your application spends a lot of time waiting for I/O, <code>threading</code> can help you with doing calculations in one thread while the other is waiting for I/O.</p>

<p>But neither are free in terms of complexity. For example with <code>threading</code> you have to protect reading and writing of your dataframes with locks so that only one thread at a time can read or modify said dataframe. With <code>multiprocessing</code> you have to send data from the worker processes back to the parent process.</p>

<p>In this case, I think that <code>multiprocessing</code> would be most useful. You could set up a number of processes, each responsible for part of the beds/patients. If rabbitmq can have multiple listeners, you can have each worker process only handle the messages from patients that it is responsible for. Otherwise you have to distribute the messages to the appropriate process. Each worker process now processes the messages (and keeps the dataframes) for a number of patients. When an alert is triggered based on the calcutations done on the data, the worker only has to send a message detailing the identifier of the patient and the nature of the alert to the parent process.</p>
","1","","0","35699","643","139","2437","60017013","60017551","<p>I am new to Python multi-threading/processing and RabbitMQ. Basically i have a RabbitMQ consumer which feeds me real time hospital data . Each message comprises patients's vitals per patient. I need to store at least five such messages per patient in order to run my logic and use to set off an alarm. Also since number of the patients are unknown,i am thinking of Multi threading or Multiprocessing in order to keep my alarm almost real-time and scale up. My approach is to create a global dataframe for each patient and then append the messages pertaining that patient into the dataframe .But now I am having problem creating the Multi thread/process and sending the data to respective patient dataframe . Here is my code </p>

<pre><code>
bed_list=[]
thread_list=[]
bed_df={}
alarms=0

def spo2(body,bed):
    body_data= body.decode()
    print(body_data)
    packet= json.loads(body_data)
    bed_id= packet['beds'][0]['bedId']
    if bed_id=bed:
        primary_attributes= json_normalize(packet)
         '''some logic'''
        global bed_df
        bed_df[bed_id]= bed_df[bed_id].append(packet) # creating the global dataframe to store five messages
        print(bed_df[bed_id])

        ''' some other calcuation'''

            phy_channel.basic_publish(body=json.dumps(truejson),exchange='nicu')# throwing out the alarm with another queue
            bed_df[bed_id]= bed_df[bed_id].tail(4)  # resets the size of the dataframe 


def callback(ch, method, properties, body):
    body_data= body.decode()
    packet= json.loads(body_data)
    bed_id= packet['beds'][0]['bedId']
    print(bed_id)
    global bed_list
    if bed_id not in bed_list:
      bed_list.append(bed_id)


#pseudo code
 for bed in bed_list:
     proc = Process(target=spo2, args=(bed,))
     procs.append(proc)
     proc.start()

</code></pre>

<p>I am not able to figure a way out where i can create a thread/process for each patient(bed_id) so that whenever i receive the message for that patient(bed_id) i can direct it to that thread. I have checked Queues but the documentation is not very clear as to implement this case.</p>
"
"60017956","<p>Plotting 3d images in <code>matplotlib</code> is a little tricky. Generally you plot whole surfaces at once instead of plotting one line at a time. You do so by passing three 2d arrays, one for each position dimension (x, y, z). But you can't just pass any old 2d arrays either; the points themselves have to be in a precise order!</p>

<p>Sometimes you can do something that just works, but I find it easier to explicitly parameterize plots using <code>u</code> and <code>v</code> dimensions. Here's what I was able to get working here:</p>

<pre><code># Abstract u and v parameters describing surface coordinates
u_plt = np.arange(x.shape[1])
v_plt = np.arange(x.shape[0])

# The outer products here produce 2d arrays. We multiply by
# ones in this case for an identity transformation, but in 
# general, you could use any broadcasted operation on `u`
# and `v`.
x_plt = np.outer(np.ones(np.size(v_plt)), u_plt)
y_plt = np.outer(v_plt, np.ones(np.size(u_plt)))

# In this case, our `x` array gives the `z` values directly.
z_plt = x

fig = plt.figure(figsize=(16, 10))
ax = fig.add_subplot(111, projection='3d')

ax.set_zmargin(1)  # Add a bit more space around the plot.
ax.plot_wireframe(x_plt, y_plt, z_plt,
                  rstride=1, cstride=1,  # ""Resolution"" of the plot
                  color='blue', linewidth=1.0,
                  alpha=0.7, antialiased=True)

# Tilt the view to match the example.
ax.view_init(elev = 45, azim = -45)

plt.xlabel('i')
plt.ylabel('x')
plt.title('test')
plt.show()
</code></pre>

<p>And here's the resulting image. I had to reduce <code>n</code> to 80 to make this comprehensible at all, and I have no idea what I am looking at, so I am not sure it's correct. But I think it looks broadly similar to the example you gave.</p>

<p><a href=""https://i.stack.imgur.com/ObOTm.jpg"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/ObOTm.jpg"" alt=""wireframe plot""></a></p>

<p>Just to illustrate the power of this approach, here's a nautilus shell. It uses a two-stage parameterization, which could be compressed, but which I find conceptually clearer:</p>

<pre><code>n_ticks = 100

# Abstract u and v parameters describing surface coordinates
u_plt = np.arange(n_ticks // 2) * 2
v_plt = np.arange(n_ticks)

# theta is the angle along the leading edge of the shell
# phi is the angle along the spiral of the shell
# r is the distance of the edge from the origin
theta_plt = np.pi * ((u_plt / n_ticks) * 0.99 + 0.005)
phi_plt = np.pi * v_plt / (n_ticks / 5)
r_plt = v_plt / (n_ticks / 5)

# These formulas are based on the formulas for rendering
# a sphere parameterized by theta and phi. The only difference
# is that r is variable here too.
x_plt = r_plt[:, None] * np.cos(phi_plt[:, None]) * np.sin(theta_plt[None, :])
y_plt = r_plt[:, None] * np.sin(phi_plt[:, None]) * np.sin(theta_plt[None, :])
z_plt = r_plt[:, None] * \ 
    (np.ones(np.shape(phi_plt[:, None])) * np.cos(theta_plt[None, :]))

# This varies the color along phi
colors = cm.inferno(1 - (v_plt[:, None] / max(v_plt))) * \
    np.ones(np.shape(u_plt[None, :, None])) 

fig = plt.figure(figsize=(8, 8))
ax = fig.add_subplot(111, projection='3d')

ax.set_zmargin(1)
ax.plot_surface(x_plt, y_plt, z_plt,
                rstride=1, cstride=1,
                facecolors=colors, linewidth=1.0,
                alpha=0.3, antialiased=True)
ax.view_init(elev = 45, azim = -45)

plt.show()
</code></pre>

<p><a href=""https://i.stack.imgur.com/a4oJN.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/a4oJN.png"" alt=""plot of a nautilus shell""></a></p>
","1","2020-02-01 18:13:51","1","123320","2200","152","5846","60017049","60017956","<p>I'm trying to show my 2D data on a 3D space.</p>

<p>Here is my code below:</p>

<pre><code>import numpy as np
import matplotlib.pyplot as plt

i = 60
n = 1000
r = 3.8   
eps = 0.7

y = np.ones((n, i))

# random numbers on the first row of array x
np.random.seed(1)
x = np.ones((n+1, i))
x[0, :] = np.random.random(i)


def logistic(r, x):
    return r * x * (1 - x)

present_indi = np.arange(i)        
next_indi = (present_indi + 1) % i
prev_indi = (present_indi - 1) % i  

for n in range(1000):

    y[n, :] = logistic(r, x[n, :])

    x[n+1, :] = (1-eps)*y[n, present_indi] + 0.5*eps*(y[n, prev_indi] + y[n, next_indi])  
#print(x)

# the above logic generates a 2D array 'x'. with i columns and n rows.    


fig, ax = plt.subplots()
for i in range(60):
       for n in range(1000):
           if n&gt;=900:
                ax.plot(i,x[n,i],'*k',ms=0.9)
plt.xlabel('i')
plt.ylabel('x')
plt.title('test')        
plt.show()
</code></pre>

<p>The above code perfectly displays i and x graph. I have plotted all the elements of 1st column of X, then all elements of second column, then the third and so on....., using the nested for loop logic (refer to the code) </p>

<p><strong>Now what I need to do is, extend the plotting to 3D, i.e use Xaxis = i, Yaxis= n, Zaxis= array 'x'</strong></p>

<p>I want to plot something like this: 
<a href=""https://i.stack.imgur.com/0BR4O.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/0BR4O.png"" alt=""Something like this""></a></p>

<p>I know I have to use mplot3D
But doing the following won't give me any result:</p>

<pre><code>fig = plt.figure()
ax = fig.add_subplot(111, projection='3d')
for i in range(60):
       for n in range(1000):
           if n&gt;=900:
                ax.plot_wireframe(i,n,x[n,i],rstride=1,cstride=1)
</code></pre>
"
"60024424","<p>To resolve this problem, I have executed sort_index and the code above worked</p>

<pre><code>df.sort_index(inplace= True)
</code></pre>
","0","","0","107","7","0","9","60017052","63252466","<p>have some problem to execute an additive model right.</p>
<p>I have that data frame:
<a href=""https://i.stack.imgur.com/NEhGF.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/NEhGF.png"" alt=""enter image description here"" /></a></p>
<p>And when I run this code:</p>
<pre><code>   import statsmodels as sm
   import statsmodels.api as sm
   decomposition = sm.tsa.seasonal_decompose(df, model = 'additive')
   fig = decomposition.plot()
   matplotlib.rcParams['figure.figsize'] = [9.0,5.0]
</code></pre>
<p>I got that message:</p>
<p>ValueError: You must specify a period or x must be a pandas object with a DatetimeIndex with a freq not set to None</p>
<p>What should I do in order to get that example:
<a href=""https://i.stack.imgur.com/bkbFK.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/bkbFK.png"" alt=""enter image description here"" /></a></p>
<p>The screen above I took from this place <a href=""https://towardsdatascience.com/analyzing-time-series-data-in-pandas-be3887fdd621"" rel=""noreferrer"">https://towardsdatascience.com/analyzing-time-series-data-in-pandas-be3887fdd621</a></p>
"
"63252466","<p>Having the same ValueError, this is just the result of some testing and little research on my own, without the claim to be complete or professional about it. Please comment or answer whoever finds something wrong.</p>
<p>Of course, your data should be in the right order of the index values, which you would assure with <code>df.sort_index(inplace=True)</code>, as you state it in your answer. This is not wrong as such, though the error message is not about the sort order, and I have checked this: the error does not go away in my case when I sort the index of a huge dataset I have at hand. It is true, I also have to sort the df.index, but the decompose() can handle unsorted data as well where items jump here and there in time: then you simply get a lot of blue lines from left to the right and back, until the whole graph is full of it. What is more, usually, the sorting is already in the right order anyway. In my case, sorting does not help fixing the error. Thus I also doubt that index sorting has fixed the error in your case, because: what does the error actually say?</p>
<p><strong>ValueError: You must specify:</strong></p>
<ol>
<li><strong>[either] a period</strong></li>
<li><strong>or x must be a pandas object with a DatetimeIndex with a freq not set to None</strong></li>
</ol>
<p>Before all, in case you have a <em>list column</em> so that your time series is nested up to now, see <a href=""https://stackoverflow.com/questions/63246938/convert-pandas-df-with-data-in-a-list-column-into-a-time-series-in-long-format"">Convert pandas df with data in a &quot;list column&quot; into a time series in long format. Use three columns: [list of data] + [timestamp] + [duration]</a> for details how to unnest a <em>list column</em>. This would be needed for both 1.) and 2.).</p>
<p><em>Details of 1.:</em></p>
<p><em>Definition of period</em></p>
<p>&quot;period, int, optional&quot; from <a href=""https://www.statsmodels.org/stable/generated/statsmodels.tsa.seasonal.seasonal_decompose.html"" rel=""noreferrer"">https://www.statsmodels.org/stable/generated/statsmodels.tsa.seasonal.seasonal_decompose.html</a>:</p>
<blockquote>
<p>Period of the series. Must be used if x is not a pandas object or if
the index of x does not have a frequency. Overrides default
periodicity of x if x is a pandas object with a timeseries index.</p>
</blockquote>
<p>The period parameter that is set with an integer means the number of cycles which you expect to be in the data. If you have a df with 1000 rows with a <em>list column</em> in it (call it df_nested), and each list with for example 100 elements, then you will have 100 elements per cycle. It is probably smart taking <code>period = len(df_nested)</code> (= number of cycles) in order to get the best split of seasonality and trend. If your elements per cycle vary over time, other values may be better.</p>
<p>The &quot;period&quot; parameter of option 1.) has a big advantage over option 2.). Though it uses the time index (DatetimeIndex) for its x-axis, it does not require an item to hit the frequency exactly, in contrast to option 2.). Instead, it just joins together whatever is in a row, with the advantage that you do not need to fill any gaps: the last value of the previous event is just joined with the next value of the following event, whether it is already in the next second or on the next day.</p>
<p>What is the max possible &quot;period&quot; value? In case you have a <em>list column</em> (call the df &quot;df_nested&quot; again), you should first <em>unnest</em> the <em>list column</em> to a <em>normal column</em>. The max period is <code>len(df_unnested)/2</code>.</p>
<p>Example1: 20 items in x (x is the amount of all items of df_unnested) can maximally have a <code>period = 10</code>.</p>
<p>Example2: Having the 20 items and taking <code>period=20</code> instead, this throws the following error:</p>
<blockquote>
<p>ValueError: x must have 2 complete cycles requires 40
observations. x only has 20 observation(s)</p>
</blockquote>
<p>Another side-note:
To get rid of the error in question, <code>period = 1</code> should already take it away, but for time series analysis, &quot;=1&quot; does not reveal anything new, every cycle is just 1 item then, the trend is the same as the original data, the seasonality is 0, and the residuals are always 0.</p>
<p>####</p>
<p><em>Example borrowed from <a href=""https://stackoverflow.com/questions/63246938/convert-pandas-dataframe-with-a-nested-list-in-the-data-column-timestamp-and-du:"">Convert pandas df with data in a &quot;list column&quot; into a time series in long format. Use three columns: [list of data] + [timestamp] + [duration]</a></em></p>
<pre><code>df_test = pd.DataFrame({'timestamp': [1462352000000000000, 1462352100000000000, 1462352200000000000, 1462352300000000000],
                'listData': [[1,2,1,9], [2,2,3,0], [1,3,3,0], [1,1,3,9]],
                'duration_sec': [3.0, 3.0, 3.0, 3.0]})
tdi = pd.DatetimeIndex(df_test.timestamp)
df_test.set_index(tdi, inplace=True)
df_test.drop(columns='timestamp', inplace=True)
df_test.index.name = 'datetimeindex'

df_test = df_test.explode('listData') 
sizes = df_test.groupby(level=0)['listData'].transform('size').sub(1)
duration = df_test['duration_sec'].div(sizes)
df_test.index += pd.to_timedelta(df_test.groupby(level=0).cumcount() * duration, unit='s') 
</code></pre>
<p>The resulting df_test['listData'] looks as follows:</p>
<pre><code>2016-05-04 08:53:20    1
2016-05-04 08:53:21    2
2016-05-04 08:53:22    1
2016-05-04 08:53:23    9
2016-05-04 08:55:00    2
2016-05-04 08:55:01    2
2016-05-04 08:55:02    3
2016-05-04 08:55:03    0
2016-05-04 08:56:40    1
2016-05-04 08:56:41    3
2016-05-04 08:56:42    3
2016-05-04 08:56:43    0
2016-05-04 08:58:20    1
2016-05-04 08:58:21    1
2016-05-04 08:58:22    3
2016-05-04 08:58:23    9
</code></pre>
<p><strong>Now have a look at different period's integer values.</strong></p>
<p><code>period = 1</code>:</p>
<pre><code>result_add = seasonal_decompose(x=df_test['listData'], model='additive', extrapolate_trend='freq', period=1)
plt.rcParams.update({'figure.figsize': (5,5)})
result_add.plot().suptitle('Additive Decompose', fontsize=22)
plt.show()
</code></pre>
<p><a href=""https://i.stack.imgur.com/r0Hlz.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/r0Hlz.png"" alt=""enter image description here"" /></a></p>
<p><code>period = 2</code>:</p>
<pre><code>result_add = seasonal_decompose(x=df_test['listData'], model='additive', extrapolate_trend='freq', period=2)
plt.rcParams.update({'figure.figsize': (5,5)})
result_add.plot().suptitle('Additive Decompose', fontsize=22)
plt.show()
</code></pre>
<p><a href=""https://i.stack.imgur.com/cPzwP.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/cPzwP.png"" alt=""enter image description here"" /></a></p>
<p>If you take a quarter of all items as one cycle which is 4 (out of 16 items) here.</p>
<p><code>period = 4</code>:</p>
<pre><code>result_add = seasonal_decompose(x=df_test['listData'], model='additive', extrapolate_trend='freq', period=int(len(df_test)/4))
plt.rcParams.update({'figure.figsize': (5,5)})
result_add.plot().suptitle('Additive Decompose', fontsize=22)
plt.show()
</code></pre>
<p><a href=""https://i.stack.imgur.com/ZjLxG.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/ZjLxG.png"" alt=""enter image description here"" /></a></p>
<p>Or if you take the max possible size of a cycle which is 8 (out of 16 items) here.</p>
<p><code>period = 8</code>:</p>
<pre><code>result_add = seasonal_decompose(x=df_test['listData'], model='additive', extrapolate_trend='freq', period=int(len(df_test)/2))
plt.rcParams.update({'figure.figsize': (5,5)})
result_add.plot().suptitle('Additive Decompose', fontsize=22)
plt.show()
</code></pre>
<p><a href=""https://i.stack.imgur.com/WedRI.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/WedRI.png"" alt=""enter image description here"" /></a></p>
<p>Have a look at how the y-axes change their scale.</p>
<p>####</p>
<p>You will increase the period integer according to your needs. The max in your case of the question:</p>
<pre><code>sm.tsa.seasonal_decompose(df, model = 'additive', period = int(len(df)/2))
</code></pre>
<p><em>Details of 2.:</em></p>
<p>To get x to be a DatetimeIndex with a freq not set to None, you need to assign the freq of the DatetimeIndex using .asfreq('?') with ? being your choice among a wide range of offset aliases from <a href=""https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#offset-aliases"" rel=""noreferrer"">https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#offset-aliases</a>.</p>
<p>In your case, this option 2. is the better suited as you seem to have a list without gaps. Your monthly data then should probably be introduced as &quot;month start frequency&quot; --&gt; &quot;MS&quot; as offset alias:</p>
<pre><code>sm.tsa.seasonal_decompose(df.asfreq('MS'), model = 'additive')
</code></pre>
<p>See <a href=""https://stackoverflow.com/questions/54630027/how-to-set-frequency-with-pd-to-datetime?rq=1"">How to set frequency with pd.to_datetime()?</a> for more details, also about how you would deal with gaps.</p>
<p>If you have data that is highly scattered in time so that you have too many gaps to fill or if gaps in time are nothing important, option 1 of using &quot;period&quot; is probably the better choice.</p>
<p>In my example case of df_test, option 2. is not good. The data is totally scattered in time, and if I take a minute as the frequency, you get this:</p>
<p>Output of <code>df_test.asfreq('s')</code> (=frequency in seconds):</p>
<pre><code>2016-05-04 08:53:20      1
2016-05-04 08:53:21      2
2016-05-04 08:53:22      1
2016-05-04 08:53:23      9
2016-05-04 08:53:24    NaN
                      ...
2016-05-04 08:58:19    NaN
2016-05-04 08:58:20      1
2016-05-04 08:58:21      1
2016-05-04 08:58:22      3
2016-05-04 08:58:23      9
Freq: S, Name: listData, Length: 304, dtype: object
</code></pre>
<p>You see here that although my data is only 16 rows, introducing a frequency in seconds forces the df to be 304 rows only to reach out from &quot;08:53:20&quot; till &quot;08:58:23&quot;, 288 gaps are caused here. What is more, here you have to hit the exact time. If you have 0.1 or even 0.12314 seconds as your real frequency instead, you will not hit most of the items with your index.</p>
<p>Here an example with min as the offset alias, <code>df_test.asfreq('min')</code>:</p>
<pre><code>2016-05-04 08:53:20      1
2016-05-04 08:54:20    NaN
2016-05-04 08:55:20    NaN
2016-05-04 08:56:20    NaN
2016-05-04 08:57:20    NaN
2016-05-04 08:58:20      1
</code></pre>
<p>We see that only the first and the last minute are filled at all, the rest is not hit.</p>
<p>Taking the day as as the offset alias, <code>df_test.asfreq('d')</code>:</p>
<pre><code>2016-05-04 08:53:20    1
</code></pre>
<p>We see that you get only the first row as the resulting df, since there is only one day covered. It will give you the first item found, the rest is dropped.</p>
<p>The end of it all:</p>
<p>Putting together all of this, in your case, take option 2., while in my example case of df_test, option 1 is needed.</p>
","1","2020-08-08 15:38:21","8","1200","1262","12","429","60017052","63252466","<p>have some problem to execute an additive model right.</p>
<p>I have that data frame:
<a href=""https://i.stack.imgur.com/NEhGF.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/NEhGF.png"" alt=""enter image description here"" /></a></p>
<p>And when I run this code:</p>
<pre><code>   import statsmodels as sm
   import statsmodels.api as sm
   decomposition = sm.tsa.seasonal_decompose(df, model = 'additive')
   fig = decomposition.plot()
   matplotlib.rcParams['figure.figsize'] = [9.0,5.0]
</code></pre>
<p>I got that message:</p>
<p>ValueError: You must specify a period or x must be a pandas object with a DatetimeIndex with a freq not set to None</p>
<p>What should I do in order to get that example:
<a href=""https://i.stack.imgur.com/bkbFK.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/bkbFK.png"" alt=""enter image description here"" /></a></p>
<p>The screen above I took from this place <a href=""https://towardsdatascience.com/analyzing-time-series-data-in-pandas-be3887fdd621"" rel=""noreferrer"">https://towardsdatascience.com/analyzing-time-series-data-in-pandas-be3887fdd621</a></p>
"
"65295170","<p>I've had the same issue and it eventually turned out (in my case at lease) to be an issue of missing data points in my dataset. In example I have hourly data for a certain period of time and there where 2 separate hourly data points missing (in the middle of the dataset). So I got the same error. When testing on a different dataset with no missing data points, it worked without any error messages. Hope this helps. It's not exactly a solution.</p>
","0","","2","43","5","0","2","60017052","63252466","<p>have some problem to execute an additive model right.</p>
<p>I have that data frame:
<a href=""https://i.stack.imgur.com/NEhGF.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/NEhGF.png"" alt=""enter image description here"" /></a></p>
<p>And when I run this code:</p>
<pre><code>   import statsmodels as sm
   import statsmodels.api as sm
   decomposition = sm.tsa.seasonal_decompose(df, model = 'additive')
   fig = decomposition.plot()
   matplotlib.rcParams['figure.figsize'] = [9.0,5.0]
</code></pre>
<p>I got that message:</p>
<p>ValueError: You must specify a period or x must be a pandas object with a DatetimeIndex with a freq not set to None</p>
<p>What should I do in order to get that example:
<a href=""https://i.stack.imgur.com/bkbFK.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/bkbFK.png"" alt=""enter image description here"" /></a></p>
<p>The screen above I took from this place <a href=""https://towardsdatascience.com/analyzing-time-series-data-in-pandas-be3887fdd621"" rel=""noreferrer"">https://towardsdatascience.com/analyzing-time-series-data-in-pandas-be3887fdd621</a></p>
"
"60017183","<p>You can try <a href=""https://docs.python.org/3/library/itertools.html#itertools.groupby"" rel=""nofollow noreferrer""><code>itertools.groupby</code></a>:</p>

<pre><code>&gt;&gt;&gt; from itertools import groupby
&gt;&gt;&gt; x = [4, 4, 1, 6, 6, 6, 1, 1, 1, 1]
&gt;&gt;&gt; new_list = [list(group) for _, group in groupby(x)]
&gt;&gt;&gt; new_list
[[4, 4], [1], [6, 6, 6], [1, 1, 1, 1]]
&gt;&gt;&gt;
</code></pre>

<p>Another way would be:</p>

<pre><code>&gt;&gt;&gt; master_list, new_list = [], []
&gt;&gt;&gt; for elem in x:
...     if not new_list:
...             new_list.append(elem)
...     elif elem == new_list[-1]:
...             new_list.append(elem)
...     else:
...             master_list.append(new_list)
...             new_list = [elem]
&gt;&gt;&gt; master_list.append(new_list)
&gt;&gt;&gt; master_list
[[4, 4], [1], [6, 6, 6], [1, 1, 1, 1]]
</code></pre>
","0","2020-02-01 13:19:08","3","12268","1175","288","837","60017135","60017183","<p>I am learning algorithms and there was this problem:</p>
<blockquote>
<p>Given an array of integers, pack consecutive elements into sublists.</p>
<p>For example, given the list [4, 4, 1, 6, 6, 6, 1, 1, 1, 1], return [[4, 4], [1], [6, 6, 6], [1, 1, 1, 1]].</p>
<p>Note: If there's only one occurrence in the list it should still be in its own sublist.</p>
</blockquote>
<p>I have created the following solution:</p>
<pre><code>def solve(nums):
    packed = []
    lastElement = nums[0]
    currPack = []
    for i, num in enumerate(nums):
        newPack = []
        if lastElement == num:
            currPack.append(num)
        else:
            newPack.append(num)
            packed.append(currPack)
            currPack = newPack
            
        lastElement = num
    
    packed.append(currPack)
    return packed

 nums = [4,4,1,6,6,6,1,1,1,1]
 solve(nums)
 # [[4,4], [1], [6,6,6], [1,1,1,1]]
</code></pre>
<p>It's working but as you can see it is not very clean. How can I improve this?</p>
"
"60017192","<p>Try this:</p>

<pre><code>from itertools import groupby

a = [4, 4, 1, 6, 6, 6, 1, 1, 1, 1]
new_list=[] 
for k,g in groupby(a): 
    new_list.append(list(g))
</code></pre>

<p><code>new_list</code> will be your expected result.</p>
","0","","1","9243","1210","839","1256","60017135","60017183","<p>I am learning algorithms and there was this problem:</p>
<blockquote>
<p>Given an array of integers, pack consecutive elements into sublists.</p>
<p>For example, given the list [4, 4, 1, 6, 6, 6, 1, 1, 1, 1], return [[4, 4], [1], [6, 6, 6], [1, 1, 1, 1]].</p>
<p>Note: If there's only one occurrence in the list it should still be in its own sublist.</p>
</blockquote>
<p>I have created the following solution:</p>
<pre><code>def solve(nums):
    packed = []
    lastElement = nums[0]
    currPack = []
    for i, num in enumerate(nums):
        newPack = []
        if lastElement == num:
            currPack.append(num)
        else:
            newPack.append(num)
            packed.append(currPack)
            currPack = newPack
            
        lastElement = num
    
    packed.append(currPack)
    return packed

 nums = [4,4,1,6,6,6,1,1,1,1]
 solve(nums)
 # [[4,4], [1], [6,6,6], [1,1,1,1]]
</code></pre>
<p>It's working but as you can see it is not very clean. How can I improve this?</p>
"
"60017278","<p>Originally my answer only worked for one test case, this is quick (not the prettiest) but works for both:</p>

<pre><code>def delete_nth(x, e):
    x = x[::-1]
    for i in x:
        while x.count(i) &gt; e:
            x.remove(i)
    return x[::-1]
</code></pre>
","1","2020-02-01 13:31:03","-1","385","178","16","78","60017186","60017284","<p>How can I fix my code to pass the test case for <a href=""https://www.codewars.com/kata/delete-occurrences-of-an-element-if-it-occurs-more-than-n-times/python"" rel=""nofollow noreferrer"">Delete occurrences of an element if it occurs more than n times</a>?</p>

<p>My current code pass one test case and I'm sure that the problem is caused by <code>order.remove(check_list[i])</code>.</p>

<p>However, there is no way to delete the specific element with <code>pop()</code> because it is required to put an index number rather than the element in <code>pop()</code>.</p>

<p><strong>Test case</strong> </p>

<pre><code>Test.assert_equals(delete_nth([20,37,20,21], 1), [20,37,21])
Test.assert_equals(delete_nth([1,1,3,3,7,2,2,2,2], 3), [1, 1, 3, 3, 7, 2, 2, 2])
</code></pre>

<p><strong>Program</strong></p>

<pre class=""lang-py prettyprint-override""><code>def delete_nth(order, max_e):
    # code here
    check_list = [x for x in dict.fromkeys(order) if order.count(x) &gt; 1]
    print(check_list)
    print(order)

    for i in range(len(check_list)):
       while(order.count(check_list[i]) &gt; max_e):
           order.remove(check_list[i])
           #order.pop(index)


    return order
</code></pre>
"
"60017284","<p>Your assertions fails, because the order is not preserved. Here is a simple example of how this could be done without doing redundant internal loops to count the occurrences for each number:</p>

<pre><code>def delete_nth(order, max_e):
    # Get a new list that we will return
    result = []

    # Get a dictionary to count the occurences
    occurrences = {}

    # Loop through all provided numbers
    for n in order:

        # Get the count of the current number, or assign it to 0
        count = occurrences.setdefault(n, 0)

        # If we reached the max occurence for that number, skip it
        if count &gt;= max_e:
            continue

        # Add the current number to the list
        result.append(n)

        # Increase the 
        occurrences[n] += 1

    # We are done, return the list
    return result

assert delete_nth([20,37,20,21], 1) == [20, 37, 21]
assert delete_nth([1, 1, 1, 1], 2) == [1, 1]
assert delete_nth([1, 1, 3, 3, 7, 2, 2, 2, 2], 3) == [1, 1, 3, 3, 7, 2, 2, 2]
assert delete_nth([1, 1, 2, 2], 1) == [1, 2]
</code></pre>
","0","2020-02-01 14:39:08","2","972","24","5","77","60017186","60017284","<p>How can I fix my code to pass the test case for <a href=""https://www.codewars.com/kata/delete-occurrences-of-an-element-if-it-occurs-more-than-n-times/python"" rel=""nofollow noreferrer"">Delete occurrences of an element if it occurs more than n times</a>?</p>

<p>My current code pass one test case and I'm sure that the problem is caused by <code>order.remove(check_list[i])</code>.</p>

<p>However, there is no way to delete the specific element with <code>pop()</code> because it is required to put an index number rather than the element in <code>pop()</code>.</p>

<p><strong>Test case</strong> </p>

<pre><code>Test.assert_equals(delete_nth([20,37,20,21], 1), [20,37,21])
Test.assert_equals(delete_nth([1,1,3,3,7,2,2,2,2], 3), [1, 1, 3, 3, 7, 2, 2, 2])
</code></pre>

<p><strong>Program</strong></p>

<pre class=""lang-py prettyprint-override""><code>def delete_nth(order, max_e):
    # code here
    check_list = [x for x in dict.fromkeys(order) if order.count(x) &gt; 1]
    print(check_list)
    print(order)

    for i in range(len(check_list)):
       while(order.count(check_list[i]) &gt; max_e):
           order.remove(check_list[i])
           #order.pop(index)


    return order
</code></pre>
"
"60017371","<p>A version which maintains the order:</p>

<pre><code>from collections import defaultdict

def delete_nth(order, max_e):
    count = defaultdict(int)
    delet = []
    for i, v in enumerate(order):
        count[v] += 1
        if  count[v] &gt; max_e:
            delet.append(i)
    for i in reversed(delet): # start deleting from the end
        order.pop(i)
    return order

print(delete_nth([1,1,2,2], 1))
print(delete_nth([20,37,20,21], 1))
print(delete_nth([1,1,3,3,7,2,2,2,2], 3))
</code></pre>
","0","2020-02-01 14:35:13","1","7655","73","3","374","60017186","60017284","<p>How can I fix my code to pass the test case for <a href=""https://www.codewars.com/kata/delete-occurrences-of-an-element-if-it-occurs-more-than-n-times/python"" rel=""nofollow noreferrer"">Delete occurrences of an element if it occurs more than n times</a>?</p>

<p>My current code pass one test case and I'm sure that the problem is caused by <code>order.remove(check_list[i])</code>.</p>

<p>However, there is no way to delete the specific element with <code>pop()</code> because it is required to put an index number rather than the element in <code>pop()</code>.</p>

<p><strong>Test case</strong> </p>

<pre><code>Test.assert_equals(delete_nth([20,37,20,21], 1), [20,37,21])
Test.assert_equals(delete_nth([1,1,3,3,7,2,2,2,2], 3), [1, 1, 3, 3, 7, 2, 2, 2])
</code></pre>

<p><strong>Program</strong></p>

<pre class=""lang-py prettyprint-override""><code>def delete_nth(order, max_e):
    # code here
    check_list = [x for x in dict.fromkeys(order) if order.count(x) &gt; 1]
    print(check_list)
    print(order)

    for i in range(len(check_list)):
       while(order.count(check_list[i]) &gt; max_e):
           order.remove(check_list[i])
           #order.pop(index)


    return order
</code></pre>
"
"60017872","<p>This should do the trick:</p>

<pre class=""lang-py prettyprint-override""><code>from itertools import groupby
import numpy as np

def delete_nth(order, max_e):
    if(len(order)&lt;=max_e):
        return order
    elif(max_e&lt;=0):
        return []
    return np.array(
          sorted(
              np.concatenate(
                [list(v)[:max_e] 
                    for k,v in groupby(
                       sorted(
                          zip(order, list(range(len(order)))), 
                       key=lambda k: k[0]), 
                    key=lambda k: k[0])
                ]
              ), 
           key=lambda k: k[1])
         )[:,0].tolist()
</code></pre>

<p>Outputs:</p>

<pre class=""lang-py prettyprint-override""><code>
print(delete_nth([2,3,4,5,3,2,3,2,1], 2))
[2, 3, 4, 5, 3, 2, 1]

print(delete_nth([2,3,4,5,5,3,2,3,2,1], 1))
[2, 3, 4, 5, 1]

print(delete_nth([2,3,4,5,3,2,3,2,1], 3))
[2, 3, 4, 5, 3, 2, 3, 2, 1]

print(delete_nth([2,2,1,1], 1))
[2, 1]
</code></pre>
","4","2020-02-01 20:19:01","1","11365","152","50","745","60017186","60017284","<p>How can I fix my code to pass the test case for <a href=""https://www.codewars.com/kata/delete-occurrences-of-an-element-if-it-occurs-more-than-n-times/python"" rel=""nofollow noreferrer"">Delete occurrences of an element if it occurs more than n times</a>?</p>

<p>My current code pass one test case and I'm sure that the problem is caused by <code>order.remove(check_list[i])</code>.</p>

<p>However, there is no way to delete the specific element with <code>pop()</code> because it is required to put an index number rather than the element in <code>pop()</code>.</p>

<p><strong>Test case</strong> </p>

<pre><code>Test.assert_equals(delete_nth([20,37,20,21], 1), [20,37,21])
Test.assert_equals(delete_nth([1,1,3,3,7,2,2,2,2], 3), [1, 1, 3, 3, 7, 2, 2, 2])
</code></pre>

<p><strong>Program</strong></p>

<pre class=""lang-py prettyprint-override""><code>def delete_nth(order, max_e):
    # code here
    check_list = [x for x in dict.fromkeys(order) if order.count(x) &gt; 1]
    print(check_list)
    print(order)

    for i in range(len(check_list)):
       while(order.count(check_list[i]) &gt; max_e):
           order.remove(check_list[i])
           #order.pop(index)


    return order
</code></pre>
"
"60017369","<p>You can use nested list comprehension:</p>

<pre><code>l=[int(el) for s in li for el in s.split()]
print(l)
</code></pre>

<p>Output:</p>

<pre><code>[192, 245, 3, 881250949]
</code></pre>
","0","","1","37572","2148","0","2444","60017274","60017375","<p>I have  a list of type string li=['192 245 3 881250949']</p>

<p>if i print li it shows </p>

<pre><code>'196\t242\t3\t881250949'
</code></pre>

<p>How do i obtain the list li in the form of separate integers </p>

<p><code>li=[192 245 3 881250949]</code> i.e list of integers </p>

<p>I am getting error on using map</p>

<pre><code>results = list(map(int, li))
</code></pre>

<blockquote>
  <p>ValueError: invalid literal for int() with base 10:
  '196\t242\t3\t881250949'</p>
</blockquote>

<p>Can someone explain this and help to transform the list ?</p>
"
"60017375","<p>You are getting <code>ValueError</code> because <code>int()</code> can't convert a string which contains non-digit characters. Here, the string contains <code>'\t'</code>, so raising the error. </p>

<p>A simple way to convert it into list of integers will be to do this(the string contains numbers separated by <code>'\t'</code> then use <code>'\t'</code> instead of <code>' '</code> inside <code>split()</code>):</p>

<pre><code>lst = list(map(int, li[0].split(' ')))
</code></pre>

<p>If you have more than one such string in the list <code>li</code>, then you can use a loop to do the job. Let me know if I am able to answer your query.</p>
","5","2020-02-01 14:07:21","1","290","305","0","67","60017274","60017375","<p>I have  a list of type string li=['192 245 3 881250949']</p>

<p>if i print li it shows </p>

<pre><code>'196\t242\t3\t881250949'
</code></pre>

<p>How do i obtain the list li in the form of separate integers </p>

<p><code>li=[192 245 3 881250949]</code> i.e list of integers </p>

<p>I am getting error on using map</p>

<pre><code>results = list(map(int, li))
</code></pre>

<blockquote>
  <p>ValueError: invalid literal for int() with base 10:
  '196\t242\t3\t881250949'</p>
</blockquote>

<p>Can someone explain this and help to transform the list ?</p>
"
"60017398","<p>this code can help you.
first you must split the string with <code>split()</code> </p>

<p>then you can use <code>map</code> or <code>for loop</code> for convert string to int</p>

<pre><code># with map

li=['192 245 3 881250949']
a=li[0].split(' ')

a = list(map(int,a))


# with for loop

li=['192 245 3 881250949']
a=li[0].split(' ')

for i in range (len(a)):
    a[i] = int(a[i])
</code></pre>
","0","","1","91","11","0","19","60017274","60017375","<p>I have  a list of type string li=['192 245 3 881250949']</p>

<p>if i print li it shows </p>

<pre><code>'196\t242\t3\t881250949'
</code></pre>

<p>How do i obtain the list li in the form of separate integers </p>

<p><code>li=[192 245 3 881250949]</code> i.e list of integers </p>

<p>I am getting error on using map</p>

<pre><code>results = list(map(int, li))
</code></pre>

<blockquote>
  <p>ValueError: invalid literal for int() with base 10:
  '196\t242\t3\t881250949'</p>
</blockquote>

<p>Can someone explain this and help to transform the list ?</p>
"
"60017414","<pre><code>li=['192 245 3 881250949']

print(li)
</code></pre>
","0","2020-02-01 14:12:09","0","85","7","0","79","60017274","60017375","<p>I have  a list of type string li=['192 245 3 881250949']</p>

<p>if i print li it shows </p>

<pre><code>'196\t242\t3\t881250949'
</code></pre>

<p>How do i obtain the list li in the form of separate integers </p>

<p><code>li=[192 245 3 881250949]</code> i.e list of integers </p>

<p>I am getting error on using map</p>

<pre><code>results = list(map(int, li))
</code></pre>

<blockquote>
  <p>ValueError: invalid literal for int() with base 10:
  '196\t242\t3\t881250949'</p>
</blockquote>

<p>Can someone explain this and help to transform the list ?</p>
"
"60017417","<p>The solution for this is to use:</p>

<pre><code>g.add_argument('--start', metavar='&lt;instance-id&gt;')
</code></pre>
","0","2020-02-01 13:59:22","1","4996","389","69","364","60017342","60017417","<p>I have a terminal app, powered by <code>argparse</code>, which provides some mutually exclusive arguments:</p>

<pre><code>import argparse

parser = argparse.ArgumentParser(description='Control EC2 instances from your terminal.')
g = parser.add_mutually_exclusive_group()

g.add_argument('--create', help='Make a fresh instance.')
g.add_argument('--start')
# ...

args = parser.parse_args()
</code></pre>

<p>However the problem I have is, on the help output, it shows:</p>

<pre><code>[--create CREATE | --start START |
# ...
--create CREATE       Make a fresh instance.
--start START
</code></pre>

<p>What do I need to add to the <code>add_argument</code> line, so each one shows litterally:</p>

<pre><code>--start &lt;instance-id&gt;
</code></pre>

<p>Instead of the capitalized string <code>START</code>?</p>
"
"60018150","<p>What I can see is that the screens folder is on the root but not inside the accounts folder it's self. 
For that you have to explicitly mention in the templates configurations within settings. You have to mention the ""BASE_DIR, 'name of the folder where the templates are'"". Here how it has to be written.</p>

<pre><code>TEMPLATES = [
    {
        'BACKEND': 'django.template.backends.django.DjangoTemplates',
        'DIRS': [os.path.join(BASE_DIR,'screens')],
        'APP_DIRS': True,
        'OPTIONS': {
            'context_processors': [
                'django.template.context_processors.debug',
                'django.template.context_processors.request',
                'django.contrib.auth.context_processors.auth',
                'django.contrib.messages.context_processors.messages',
            ],
        },
    },
]
</code></pre>

<p>Secondly, you have to give the path of the file within in the views in such manner.</p>

<pre><code>    return render(request, 'screens/login_screen.dart', context)

</code></pre>

<p>Hope that helps.</p>
","0","2020-02-01 18:12:59","1","138","68","0","43","60017343","60018150","<p>I am trying to connect Flutter with Django. Flutter and Django alone seems to be fine,working without error. But when i am trying to combine both together, an error pops up that says:</p>

<blockquote>
  <p>TemplateDoesNotExist at /accounts/</p>
</blockquote>

<p>Here is the cause of the problem</p>

<pre><code>from django.shortcuts import render, HttpResponse


def home(request):
    return render(request, '../screens/login_screen.dart')
</code></pre>

<p>It says that directory does not exists.</p>

<p><a href=""https://i.stack.imgur.com/Relsu.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/Relsu.png"" alt=""enter image description here""></a></p>

<p>As you see above the directory exists. What is the problem can somebody help?</p>

<p>Template: </p>

<pre><code>TEMPLATES = [
    {
        'BACKEND': 'django.template.backends.django.DjangoTemplates',
        'DIRS': [],
        'APP_DIRS': True,
        'OPTIONS': {
            'context_processors': [
                'django.template.context_processors.debug',
                'django.template.context_processors.request',
                'django.contrib.auth.context_processors.auth',
                'django.contrib.messages.context_processors.messages',
            ],
        },
    },
]
</code></pre>
"
"60017381","<p>It deletes the variables:</p>

<pre><code>&gt;&gt;&gt; lid, tym = 1, 2
&gt;&gt;&gt; del (lid, tym)
&gt;&gt;&gt; lid
Traceback (most recent call last):
  File ""&lt;stdin&gt;"", line 1, in &lt;module&gt;
NameError: name 'lid' is not defined
&gt;&gt;&gt; tym
Traceback (most recent call last):
  File ""&lt;stdin&gt;"", line 1, in &lt;module&gt;
NameError: name 'tym' is not defined
</code></pre>

<p>From <a href=""https://docs.python.org/3/reference/simple_stmts.html#the-del-statement"" rel=""nofollow noreferrer"">the docs</a>:</p>

<blockquote>
  <h3>7.5. The <code>del</code> statement</h3>
  
  <p><code>del_stmt ::=  ""del"" target_list</code></p>
  
  <p>...</p>
  
  <p>Deletion of a target list recursively deletes each target, from left to right.</p>
</blockquote>
","0","2020-02-01 13:46:08","3","15664","4545","3291","2151","60017363","60017381","<p>Assume the following code:</p>

<pre><code>lid = foo(guz)
tym = bar(jug)

hig(lid, tym)

del (lid, tym)
</code></pre>

<p>Will the newly created anonymous tuple <code>(lid, tym)</code> be deleted and <code>lid</code> be still available?<br>
Or will both <code>lid</code> and <code>tym</code> be deleted?</p>
"
"60017391","<p>Using the <code>del (a, b)</code> will delete the variables.</p>

<pre class=""lang-py prettyprint-override""><code>&gt;&gt;&gt; a, b = 1, 2
&gt;&gt;&gt; t = (a, b)
&gt;&gt;&gt; del (a, b)
&gt;&gt;&gt; t
(1, 2)
&gt;&gt;&gt; a
Traceback (most recent call last):
  File ""&lt;stdin&gt;"", line 1, in &lt;module&gt;
NameError: name 'a' is not defined
&gt;&gt;&gt; b
Traceback (most recent call last):
  File ""&lt;stdin&gt;"", line 1, in &lt;module&gt;
NameError: name 'b' is not defined
&gt;&gt;&gt;
</code></pre>
","0","","0","1311","634","303","98","60017363","60017381","<p>Assume the following code:</p>

<pre><code>lid = foo(guz)
tym = bar(jug)

hig(lid, tym)

del (lid, tym)
</code></pre>

<p>Will the newly created anonymous tuple <code>(lid, tym)</code> be deleted and <code>lid</code> be still available?<br>
Or will both <code>lid</code> and <code>tym</code> be deleted?</p>
"
"60017484","<p>You need to add the following code at the end to actually write the replacement to the file:</p>

<pre><code>fin = open(""dates1.csv"", ""wt"")
fin.write(data)
fin.close()
</code></pre>
","0","","1","321","7","0","24","60017376","60017484","<p>I have a csv file that stores dates (format 12 june 2019,), i want to replace a date that a user chooses with 0 (basciaclly deleting it) when ever the function is called. The code runs with no errors however when i check the file again the date hasnt been replaced.</p>

<pre><code>from datetime import datetime


def Remove_event():
    date_string = input(""Enter date for event (Format: day month, year): "")

    date_object = datetime.strptime(date_string, ""%d %B, %Y"")  # converts inputted date into date time data type
    date_object = date_object.strftime(""%d %B, %Y"")  # formats the date
    date_object = date_object.replace("","", """")  # removes comma in the middle
    date_object1 = date_object + "",""  # adds comma at the end

    f = open(""dates1.csv"", ""rt"")
    data = f.read()
    data = data.replace(date_object1, '0')
    print(""yes"")
    f.close()


Remove_event()
</code></pre>
"
"60018323","<p>The data is actually present in the page source. See <code>view-source:https://www.smogon.com/dex/ss/pokemon/</code> (It is present inside on the script tag as a javascript variable).</p>

<pre><code>import requests
import re
import json


response = requests.get('https://www.smogon.com/dex/ss/pokemon/')

# The following regex will help you take the json string from the response text
data = """".join(re.findall(r'dexSettings = (\{.*\})', response.text))

# the above will only return a string, we need to parse that to json in order to process it as a regular json object using `json.loads()`
data = json.loads(data)

# now we can query json string like below.
data = data.get('injectRpcs', [])[1][1].get('items', [])

for row in data:
  print(row.get('name', ''))
  print(row.get('description', ''))

</code></pre>

<p>See it in action <a href=""https://repl.it/repls/AcademicRelevantSource"" rel=""nofollow noreferrer"">here</a></p>
","1","","3","2829","595","337","500","60017438","60018323","<p>My friend asked if I could write a web scraping script to collect data of pokemon from a specific website.</p>

<p>I've written the following code to render the javascript and get a particular class to collect data from the website (<a href=""https://www.smogon.com/dex/ss/pokemon/"" rel=""nofollow noreferrer"">https://www.smogon.com/dex/ss/pokemon/</a>).</p>

<p><strong>The issue is</strong>, the page loads more entries as you scroll down the page. Is there any way of scraping from this? I'm new to web scraping so I'm not entirely sure how this all works.</p>

<pre><code>from requests_html import HTMLSession

def getPokemon(link):
    session = HTMLSession()
    r = session.get(link)
    r.html.render()
    for pokemon in r.html.find(""div.PokemonAltRow""):
        print(pokemon)
    quit()

getPokemon('https://www.smogon.com/dex/ss/pokemon/')
</code></pre>
"
"60017804","<p>If you have declared column ID with Integer and Primary key then it will automatically auto increment using ROWID. Refer: <a href=""https://www.sqlite.org/faq.html#q1"" rel=""nofollow noreferrer"">https://www.sqlite.org/faq.html#q1</a></p>

<pre><code>CREATE TABLE login (
   id INTEGER PRIMARY KEY,
   username text NOT NULL,
   password text NOT NULL
);
</code></pre>

<p>And Insert by specifying the column names.</p>

<pre><code>INSERT INTO login (username, password) VALUES (?, ?);
</code></pre>
","0","2020-02-01 14:35:06","0","1893","10","1","120","60017441","60017804","<p>I am very new to python, sql and programming in general and am trying to create a function that takes the two values from the entry box than inserts them into the database and then updates the Treeview to show the updated database. </p>

<p>There are 3 fields in my database <code>id</code>, <code>username</code> and <code>password</code>. I do not know what to put for the ID either as I thought it would auto-increment but when I run the code it requires a value.</p>

<p>Here is my attempt:</p>

<pre><code>def add():
    with sqlite3.connect(""database.db"") as conn:
        c = conn.cursor()
    username=entry_username.get()
    password=entry_password.get()
    c.execute(""INSERT INTO logins VALUES (?, ?, ?)"", (username, password))
    rows = c.fetchall()
    for row in rows:
        print(row)
        tree.insert("""", tk.END, values=row)
    c.close()
</code></pre>

<p>Thank you for any help.</p>
"
"60021575","<p>May be this should work.</p>

<pre><code>#!/usr/bin/env python

import pandas as pd
import numpy as np
from numpy.linalg import inv

#%% Function

def PlaneFit(x, y, z):

    Mat1 = np.array([ [x.sum(),          y.sum(), x.size],
                      [(x**2).sum(), (x*y).sum(), x.sum()],
                      [(z*x).sum(),  (z*y).sum(), z.sum()],
                     ])

    Mat2 = np.array([ [z.sum()],  [(x*z).sum()], [(z**2).sum()] ])

    Mat = np.dot( inv(Mat1), Mat2 )

    m, n, d = float(Mat[0]), float(Mat[1]), float(Mat[2])

    return m, n, d

#%% values of z

df = pd.read_csv('output.csv', usecols=range(0, 31), header = None)
df_1 = df[0:31]

z = np.array(df_1)

#%% x and y

x = np.linspace(0, 1, 31)
y = np.linspace(0, 1, 31)

x, y = np.meshgrid(x, y)

#%% call function and make plane

m, n, d = PlaneFit(x, y, z)

Zplane = m* x + n* y + d

#%% Plotting

from mpl_toolkits.mplot3d import axes3d;
import matplotlib.pyplot as plt

fig = plt.figure()
ax = fig.add_subplot(111, projection='3d')
ax.plot_surface(x, y, z, edgecolor='k', cmap='viridis', alpha = 0.99 ,linewidth=0, rstride=1, cstride=1, 
                       antialiased=True, shade=False )
ax.plot_surface(x, y, Zplane, edgecolor='k', color='cyan' )
plt.show()
</code></pre>
","0","","1","158","52","0","21","60017450","60021575","<p>I am trying to fit the equation of plane on the 3d-surface plot as can be seen in Plot. I have also attached the data link. I don't have any idea of how to fit the functions on surface plots. It is a part of small project. Please do help me.</p>
<pre><code>%matplotlib qt
#%matplotlib notebook
import numpy as np
import pandas as pd
#import seaborn as sns
import math 
import matplotlib.pyplot as plt 
import csv
from mpl_toolkits.mplot3d import axes3d
from matplotlib import interactive
interactive(True)
from matplotlib import colors as mcolors
from scipy.optimize import leastsq
from scipy.optimize 


df = pd.read_csv('output.csv', usecols=range(0, 31), header = None)
#df.loc[0:30, 0:31]
#df = df[0:len(Data)-1]
df_3 = df


x,y = np.meshgrid(df.columns.astype(float), df_1.index, sparse=True)
z = df_3.values

def quadratic(x, y, a, b, c, d): 
    return a*x + b*y + c*z + d

def res(params, zData):
    residuals = [
    p[2] - quadratic(p[0], p[1], params[0], params[1], params[2], params[3]) for z in zData]
    return numpy.linalg.norm(residuals)

result = scipy.optimize.minimize(residuals,(1, 1, 0, 0, 0, 0),#starting point
                                 args=z)

fig = plt.figure(figsize=(14,15))
ax = fig.add_subplot(111, projection='3d')
surf = ax.plot_surface(x, y, z, edgecolor='k', cmap='viridis', alpha = 0.99 ,linewidth=0, rstride=1, cstride=1, 
                       antialiased=False, shade=False)
fig.colorbar(surf,ax=ax, shrink=0.5, aspect=20)
#plt.show()

ax.xaxis.pane.fill = False
ax.yaxis.pane.fill = False
ax.zaxis.pane.fill = False

# Now set color to white (or whatever is &quot;invisible&quot;)
ax.xaxis.pane.set_edgecolor('w')
ax.yaxis.pane.set_edgecolor('w')
ax.zaxis.pane.set_edgecolor('w')

plt.show()

</code></pre>
"
"60018053","<p>Seems you have a file in your codebase that interferes with python's own modules, this file is <code>code.py</code> and is being imported inside a system file (<code>pdb.py</code>), rename your <code>code.py</code> to something else and it will probably solve the issue.</p>
","0","","1","49475","2189","1361","6044","60017503","60018053","<p>I have TensorFlow installed of version 1.14.0 on my Ubuntu machine. I am trying to run a code with</p>
<pre><code>import keras 
</code></pre>
<p>and I get an error</p>
<pre><code>AttributeError: module 'keras.backend' has no attribute 'backend'  
</code></pre>
<p>Complete Traceback</p>
<blockquote>
<p>Traceback (most recent call last):<br />
File &quot;&quot;, line 1, in <br />
File
&quot;/home/amitbhanja/python-environments/env/lib/python3.6/site-packages/keras/<strong>init</strong>.py&quot;,
line 3, in <br />
from . import utils<br />
File
&quot;/home/amitbhanja/python-environments/env/lib/python3.6/site-packages/keras/utils/<strong>init</strong>.py&quot;,
line 6, in <br />
from . import conv_utils<br />
File
&quot;/home/amitbhanja/python-environments/env/lib/python3.6/site-packages/keras/utils/conv_utils.py&quot;,
line 3, in <br />
from .. import backend as K<br />
File
&quot;/home/amitbhanja/python-environments/env/lib/python3.6/site-packages/keras/backend/<strong>init</strong>.py&quot;,
line 83, in <br />
from .tensorflow_backend import *<br />
File
&quot;/home/amitbhanja/python-environments/env/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py&quot;,
line 1, in                                       import
tensorflow as tf<br />
File
&quot;/home/amitbhanja/python-environments/env/lib/python3.6/site-packages/tensorflow/<strong>init</strong>.py&quot;, line 28, in <br />
from tensorflow.python import pywrap_tensorflow  # pylint:
disable=unused-import<br />
File
&quot;/home/amitbhanja/python-environments/env/lib/python3.6/site-packages/tensorflow/python/<strong>init</strong>.py&quot;,
line 63, in                                            from
tensorflow.python.framework.framework_lib import *  # pylint:
disable=redefined-builtin<br />
File
&quot;/home/amitbhanja/python-environments/env/lib/python3.6/site-packages/tensorflow/python/framework/framework_lib.py&quot;,
line 25, in                             from
tensorflow.python.framework.ops import Graph<br />
File
&quot;/home/amitbhanja/python-environments/env/lib/python3.6/site-packages/tensorflow/python/framework/ops.py&quot;,
line 54, in                                       from
tensorflow.python.platform import app<br />
File
&quot;/home/amitbhanja/python-environments/env/lib/python3.6/site-packages/tensorflow/python/platform/app.py&quot;,
line 23, in                                        from
absl.app import run as _run<br />
File
&quot;/home/amitbhanja/python-environments/env/lib/python3.6/site-packages/absl/app.py&quot;,
line 35, in <br />
import pdb<br />
File &quot;/usr/lib/python3.6/pdb.py&quot;, line 76, in <br />
import code<br />
File &quot;/home/amitbhanja/RL-Deployment/Training/code.py&quot;, line 8, in
<br />
from keras.optimizers import Adam<br />
File
&quot;/home/amitbhanja/python-environments/env/lib/python3.6/site-packages/keras/optimizers.py&quot;,
line 11, in <br />
if K.backend() == 'tensorflow':<br />
AttributeError: module 'keras.backend' has no attribute 'backend'</p>
</blockquote>
<p>I have tried installing specific version of Keras (2.0.8) because I have seen an answer which says Keras 2.0.8 is required for TensorFlow 1.14.0 . But still I get the error.</p>
"
"60024854","<p>You are probably simply running the code by using the green arrow or any equivalent way of doing so. The problem is that this runs the script as a separate process and once it finishes, nothing remains from its environment.</p>
<hr />
<p>If you want to run like in IDLE, where you execute the script and then can access and modify the environment (variables and functions defined) - you want to <a href=""https://www.jetbrains.com/help/pycharm/loading-code-from-editor-into-console.html"" rel=""nofollow noreferrer""><strong><em>execute in console</em></strong></a>. You have a few ways to do that:</p>
<ol>
<li><p><code>Execute Selection in Console</code> - This will execute any highlighted code in the console:</p>
<p><a href=""https://i.stack.imgur.com/Wn7K2.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/Wn7K2.png"" alt=""enter image description here"" /></a>
<strong>Note</strong> that if no code is highlighted, this option will become <code>Execute Line in Console</code>.</p>
</li>
<li><p>One option below that is the <code>Run File in Console</code>. This will, obviously, run the whole script in the console:</p>
<p><a href=""https://i.stack.imgur.com/p2w82.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/p2w82.png"" alt=""enter image description here"" /></a></p>
<p><strong>Notice</strong> how now you have all the variables defined in the script available in the variables view on the right side.</p>
</li>
<li><p>The last way is to enable this in the Run configurations:</p>
<ul>
<li><p>Open the <code>Edit Configurations...</code>:</p>
<p><a href=""https://i.stack.imgur.com/uwESC.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/uwESC.png"" alt=""enter image description here"" /></a></p>
</li>
<li><p>Then, under <code>Execution</code>, mark the <code>Run with Python console</code> option:</p>
<p><a href=""https://i.stack.imgur.com/8c8xU.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/8c8xU.png"" alt=""enter image description here"" /></a></p>
</li>
<li><p>Now you can run the file regularly, by selecting <code>Run File</code> or using the green triangle.</p>
</li>
</ul>
</li>
</ol>
<p><strong>Note:</strong> using method <code>(2)</code> will <strong>automatically enable</strong> the configuration described in method <code>(3)</code>. So basically after running the file once in the console (as described in method <code>(2)</code>), you can go back to running the file regularly and all future runs will be in the console as well (until you un-check the box in the run configuration).</p>
","0","2020-12-17 21:24:28","4","11641","812","4462","4469","60017510","60024854","<p>I am new to PyCharm (coming from IDLE) and still trying to understand how it works. I'm running PyCharm Professional 2019.3.1 on MacOS Mojave.</p>

<p>What I'm asking is that when I run a code in PyCharm, the variables and data aren't stored in the Python console - it remains completely blank and I have to separately write in the console.</p>

<p>For instance, in IDLE:</p>

<p>When I write <code>x = 2</code> in my program and execute it, I can browse and manipulate the value of x in IDLE's console (by entering <code>&gt; x = 3</code>, <code>&gt; x = 0</code> etc.), but when I do the same in PyCharm's console it says that x is undefined.</p>
"
"60017915","<p>Somewhere (in code you haven't included, <code>views.py</code> most likely) you are trying to filter or query the <code>User</code> model over the field <code>is_active</code>. However that field doesn't exist on the model, it's a <code>property</code> of the model, and so can't be resolved.</p>

<p>Read the error message and it tells you exactly this:</p>

<pre><code>Cannot resolve keyword 'is_active' into field.
Choices are: active, admin, email, full_name, id, image, last_login, logentry, password, post, staff, timestamp
</code></pre>

<p>Those are the fields on <code>User</code> and consequently those are the fields available for querying over that model.</p>

<p>So, make sure the in arguments being passed to the query (wherever that is happening) uses <code>active</code> instead of <code>is_active</code> and it should succeed.</p>
","0","2020-02-02 15:46:58","0","1118","442","6","186","60017537","60017915","<p>After switching into django custom user model reset password is not working and showing these errors....</p>

<blockquote>
  <p>Internal Server Error: /password-reset/ Traceback (most recent call
  last):</p>
  
  <p>File
  ""/home/nasrullah/.local/lib/python3.6/site-packages/django/core/handlers/exception.py"",
  line 34, in inner
      response = get_response(request)</p>
  
  <p>File
  ""/home/nasrullah/.local/lib/python3.6/site-packages/django/core/handlers/base.py"",
  line 126, in _get_response
      response = self.process_exception_by_middleware(e, request)</p>
  
  <p>File
  ""/home/nasrullah/.local/lib/python3.6/site-packages/django/core/handlers/base.py"",
  line 124, in _get_response
      response = wrapped_callback(request, *callback_args, **callback_kwargs)</p>
  
  <p>File
  ""/home/nasrullah/.local/lib/python3.6/site-packages/django/views/generic/base.py"",
  line 68, in view
      return self.dispatch(request, *args, **kwargs)</p>
  
  <p>File
  ""/home/nasrullah/.local/lib/python3.6/site-packages/django/utils/decorators.py"",
  line 45, in _wrapper
      return bound_method(*args, **kwargs)</p>
  
  <p>File
  ""/home/nasrullah/.local/lib/python3.6/site-packages/django/utils/decorators.py"",
  line 142, in _wrapped_view
      response = view_func(request, *args, **kwargs)</p>
  
  <p>File
  ""/home/nasrullah/.local/lib/python3.6/site-packages/django/db/models/sql/query.py"",
  line 1263, in add_q
      clause, _ = self._add_q(q_object, self.used_aliases)</p>
  
  <p>File
  ""/home/nasrullah/.local/lib/python3.6/site-packages/django/db/models/sql/query.py"",
  line 1287, in _add_q
      split_subq=split_subq,</p>
  
  <p>File
  ""/home/nasrullah/.local/lib/python3.6/site-packages/django/db/models/sql/query.py"",
  line 1164, in build_filter
      lookups, parts, reffed_expression = self.solve_lookup_type(arg)</p>
  
  <p>File
  ""/home/nasrullah/.local/lib/python3.6/site-packages/django/db/models/sql/query.py"",
  line 1028, in solve_lookup_type
      _, field, _, lookup_parts = self.names_to_path(lookup_splitted, self.get_meta())</p>
  
  <p>File
  ""/home/nasrullah/.local/lib/python3.6/site-packages/django/db/models/sql/query.py"",</p>
  
  <p>line 1389, in names_to_path
      ""Choices are: %s"" % (name, "", "".join(available))) django.core.exceptions.FieldError: Cannot resolve keyword 'is_active'</p>
  
  <p>into field. Choices are: active, admin, email, full_name, id, image,</p>
  
  <p>last_login, logentry, password, post, staff, timestamp [01/Feb/2020</p>
  
  <p>13:03:45] ""POST /password-reset/ HTTP/1.1"" 500 149279</p>
</blockquote>

<p><strong>urls.py</strong></p>

<pre><code>from django.contrib import admin
from django.urls import path, include
from django.conf import settings
from django.conf.urls.static import static
from django.contrib.auth import views as auth_views
from users import views as user_views


urlpatterns = [
    path('admin/', admin.site.urls),
    path('register/', user_views.register, name='register'),
    path('profile/', user_views.profile, name='profile'),
    #path('login/',auth_views.LoginView.as_view(template_name= 'users/login.html'), name='login'),
    path('login/',user_views.login_page, name='login'),
    path('logout/', auth_views.LogoutView.as_view(template_name='users/logout.html'), name='logout'),
    path('password-reset/',
             auth_views.PasswordResetView.as_view(
             template_name='users/password_reset.html'
         ),
         name='password_reset'),
    path('password-reset/done/',
             auth_views.PasswordResetDoneView.as_view(
             template_name='users/password_reset_done.html'
         ),
         name='password_reset_done'),
    path('password-reset-confirm/&lt;uidb64&gt;/&lt;token&gt;/',
             auth_views.PasswordResetConfirmView.as_view(
             template_name='users/password_reset_confirm.html'
         ),
         name='password_reset_confirm'),
    path('password-reset-complete/',
             auth_views.PasswordResetCompleteView.as_view(
             template_name='users/password_reset_complete.html'
         ),
         name='password_reset_complete'),
    path('', include('blog.urls')),

]
</code></pre>

<p><strong>models.py</strong></p>

<pre><code>from django.db import models
from PIL import Image
from django.conf import settings
from django.contrib.auth.models import (
     AbstractBaseUser, BaseUserManager
)

class UserManager(BaseUserManager):

    def create_user(self, email, full_name, password, is_active=True,is_staff=False,is_admin=False):
        """"""
        Creates and saves a User with the given email and password.
        """"""
        if not email:
            raise ValueError('Users must have an email address')
        if not password:
            raise ValueError('Users must have a password')

        if not full_name:
            raise ValueError('Users must have a full name')

        user = self.model(
            email=self.normalize_email(email),
        )
        user.active = True
        user.set_password(password)
        user.save(using=self._db)
        return user

    def create_staffuser(self, email, full_name, password):
        """"""
        Creates and saves a staff user with the given email and password.
        """"""
        user = self.create_user(
            email,
            full_name,
            password=password,
        )
        user.staff = True
        user.save(using=self._db)
        return user

    def create_superuser(self, email, full_name, password):
        """"""
        Creates and saves a superuser with the given email and password.
        """"""
        user = self.create_user(
            email,
            full_name,
            password=password,
        )
        user.staff = True
        user.admin = True
        user.save(using=self._db)
        return user

class User(AbstractBaseUser):
    email    = models.EmailField(
            verbose_name='email address',
            max_length=255,
            unique=True,
        )
    full_name = models.CharField(max_length=255, blank=True, null=True)
    image = models.ImageField(default='default.jpg', upload_to='profile_pics/')
    active    = models.BooleanField(default=True)
    staff      = models.BooleanField(default=False)
    admin   = models.BooleanField(default=False)
    timestamp =models.DateTimeField(auto_now_add=True)


    USERNAME_FIELD = 'email'
    REQUIRED_FIELDS = ['full_name']

    objects = UserManager()

    def __str__(self):
        return self.email
    def save(self, *args, **kwargs):
        super(User, self).save(*args, **kwargs)


        img = Image.open(self.image.path)

        if img.height &gt; 300 or img.width &gt; 300:
            output_size = (300, 300)
            img.thumbnail(output_size)
            img.save(self.image.path)

    def get_full_name(self):
        if self.full_name:
            return self.full_name
        return self.email

    def get_short_name(self):
        return self.email




    @property
    def is_staff(self):
        return self.staff

    def has_perm(self, perm, obj=None):
       return self.is_admin

    def has_module_perms(self, app_label):
       return self.is_admin

    @property
    def is_admin(self):
        return self.admin

    @property
    def is_active(self):
        return self.active



class GuestEmail(models.Model):
    email = models.EmailField()
    active = models.BooleanField(default=True)
    update = models.DateTimeField(auto_now=True)
    timestamp = models.DateTimeField(auto_now_add=True)

    def __str__(self):
        return self.email
</code></pre>
"
"60017708","<p><code>inputs.shape</code> is not a list, hence it is throwing error. It gives you shape with type <code>tensorflow.python.framework.tensor_shape.TensorShape</code> which has a list of each dimension with type <code>Dimension</code></p>

<pre><code>print(inputs.shape)
# output TensorShape([Dimension(None), Dimension(256), Dimension(256), Dimension(1)])
</code></pre>

<p>You can use <code>as_list()</code> to get shapes as list:</p>

<pre><code># inputs.shape.as_list()
# output [None, 256, 256, 1]

x = InceptionV3(include_top = False, weights = None, input_shape=inputs.shape.as_list()[1:])(x)
</code></pre>
","1","2020-02-01 14:45:34","0","2224","522","191","151","60017583","60017708","<p>I am trying to implement a model which will take grayscale images as input and return a numeric value as output. I am using InceptionV3 (training from scratch) as feature extractor and then using some dense layers for the regression for the last stages.</p>

<p>Here is my code:</p>

<pre><code>from keras.applications.inception_v3 import InceptionV3
from keras.layers import Input, GlobalAveragePooling2D, Dense, Dropout, Flatten, BatchNormalization
from keras.models import Model
from keras.metrics import mean_absolute_error
from keras.utils import plot_model

inputs = Input(shape=(256, 256, 1))
x = BatchNormalization()(inputs)
x = InceptionV3(include_top = False, weights = None, input_shape=inputs.shape[1:])(x)
x = BatchNormalization()(x)
x = GlobalAveragePooling2D()(x)
x = Dense(1000, activation = 'relu' )(x)
x = Dense(1000, activation = 'relu' )(x)
outputs = Dense(1, activation = 'linear' )(x)
model = Model(inputs=inputs, outputs=outputs)

model.compile(optimizer = 'adam', loss = 'mse', metrics = [mae])

model.summary()
</code></pre>

<p>Now I am getting this error when I run the code:</p>

<pre><code>---------------------------------------------------------------------------
TypeError                                 Traceback (most recent call last)
&lt;ipython-input-36-50041eb640cc&gt; in &lt;module&gt;()
      7 inputs = Input(shape=(256, 256, 1))
      8 x = BatchNormalization()(inputs)
----&gt; 9 x = InceptionV3(include_top = False, weights = None, input_shape=inputs.shape[1:])(x)
     10 x = BatchNormalization()(x)
     11 x = GlobalAveragePooling2D()(x)

3 frames
/usr/local/lib/python3.6/dist-packages/keras_applications/imagenet_utils.py in _obtain_input_shape(input_shape, default_size, min_size, data_format, require_flatten, weights)
    273             default_shape = (input_shape[0], default_size, default_size)
    274         else:
--&gt; 275             if input_shape[-1] not in {1, 3}:
    276                 warnings.warn(
    277                     'This model usually expects 1 or 3 input channels. '

TypeError: unhashable type: 'Dimension'
</code></pre>

<p>I don't understand what is causing the error because it was absolutely fine when I was using sequential model. But it is not working for this functional model.</p>
"
"60017725","<p>It looks like when you open linkedin, the page is scrolled down a little bit. Try scrolling up <a href=""https://stackoverflow.com/questions/36647785/scroll-up-the-page-to-the-top-in-selenium"">to the top</a> or more precise - <a href=""https://stackoverflow.com/questions/3401343/scroll-element-into-view-with-selenium"">scrolling to the element</a></p>

<p>You could also just copy the link that 'sign in' button points to and go there straight away.</p>

<p>If signing in is not the whole point, you can also sign in manually and tell selenium to use your <a href=""https://stackoverflow.com/questions/14480717/load-chrome-profile-using-selenium-webdriver-using-java"">profile</a>, so you're already signed in when the script starts.</p>

<p><a href=""https://stackoverflow.com/questions/15058462/how-to-save-and-load-cookies-using-python-selenium-webdriver"">Exporting cookies</a> might also do the trick.</p>

<p>EDIT: closing the pop-up window solved it.</p>
","3","2020-02-01 14:40:44","0","3326","325","54","147","60017620","60017725","<p>I am trying to automate login in LinkedIn with Python and Selenium.</p>

<p>Where I am stuck so far is on the <code>Sign in</code> button. When I try to click it with </p>

<p><code>driver.find_element_by_xpath('//a[text()=""Sign in""]').click()</code> I get an error:</p>

<blockquote>
  <p>selenium.common.exceptions.ElementClickInterceptedException: Message:
  element click intercepted: Element ... is not clickable at point
  (1273, 80). Other element would receive the click: ...   (Session info:
  chrome=79.0.3945.130)</p>
</blockquote>

<p>Tried also <code>driver.find_element_by_xpath('//*[contains(concat( "" "", @class, "" "" ), concat( "" "", ""nav__button-secondary"", "" "" ))]').click()</code> which I generate by using <code>SelectorGadget</code> extension for Google Chrome and got the same error as mentioned above...</p>

<p>As for my Chrome version it is : <code>Version 79.0.3945.130 (Official Build) (64-bit)</code> same as my WebDriver version for Windows.</p>
"
"66017887","<p>I automated the login using Python 3 and Selenium 3.141.0 today (I don't know how long it will work) and I found a way to do it using <code>find_element_by_class_name</code> with the <code>sign-in-form__submit-button</code> class name:</p>
<pre><code>def run(email, password):
#Open Chrome web
driver = webdriver.Chrome()
driver.get('https://www.linkedin.com/')

#Login username/password
email_box = driver.find_element_by_id('session_key')
email_box.send_keys(email)
pass_box = driver.find_element_by_id('session_password')
pass_box.send_keys(password)
submit_button = driver.find_element_by_class_name('sign-in-form__submit-button')
submit_button.click()
</code></pre>
<p>I'm using Chrome Version 88.0.4324.96 (Official Build) (x86_64) on MacOS.</p>
","0","","0","382","110","2","32","60017620","60017725","<p>I am trying to automate login in LinkedIn with Python and Selenium.</p>

<p>Where I am stuck so far is on the <code>Sign in</code> button. When I try to click it with </p>

<p><code>driver.find_element_by_xpath('//a[text()=""Sign in""]').click()</code> I get an error:</p>

<blockquote>
  <p>selenium.common.exceptions.ElementClickInterceptedException: Message:
  element click intercepted: Element ... is not clickable at point
  (1273, 80). Other element would receive the click: ...   (Session info:
  chrome=79.0.3945.130)</p>
</blockquote>

<p>Tried also <code>driver.find_element_by_xpath('//*[contains(concat( "" "", @class, "" "" ), concat( "" "", ""nav__button-secondary"", "" "" ))]').click()</code> which I generate by using <code>SelectorGadget</code> extension for Google Chrome and got the same error as mentioned above...</p>

<p>As for my Chrome version it is : <code>Version 79.0.3945.130 (Official Build) (64-bit)</code> same as my WebDriver version for Windows.</p>
"
"60018586","<p>Added some permissions using pywin32 module.</p>

<pre><code>import win32security
import ntsecuritycon as con
from win32 import win32api

for f,bArr in depickle_.items():
        full_path = os.path.join(r""S:\test"", f) 
        # with open(full_path, ""wb+"") as fWr:
        fd = os.open(full_path, os.O_CREAT | os.O_WRONLY, 0o777) # will probably work for linux
        with open(fd, 'wb') as fWr:
            fWr.write(bytearray(bArr))
            fWr.close()

    # user, domain, type = win32security.LookupAccountName ("""", win32api.GetUserName())
    user, domain, type = win32security.LookupAccountName ("""", ""Everyone"")
    sd = win32security.GetFileSecurity(full_path, win32security.DACL_SECURITY_INFORMATION)
    dacl = sd.GetSecurityDescriptorDacl()

    # Delete all existing permissions        
    for index in range(0, dacl.GetAceCount()):
        dacl.DeleteAce(0)

    dacl.AddAccessAllowedAce(win32security.ACL_REVISION, con.FILE_ALL_ACCESS, user)
    sd.SetSecurityDescriptorDacl(1, dacl, 0) 
    win32security.SetFileSecurity(full_path, win32security.DACL_SECURITY_INFORMATION, sd)
</code></pre>
","0","","0","674","48","29","112","60017630","60018586","<p>I have deserialized file data in this dictionary arranged as follows -   </p>

<pre><code>[filename1 : bytearray with file contents]  
[filename2 : bytearray with file contents]  
[filename3 : bytearray with file contents]  
...
</code></pre>

<p>Now, when I write the data to disk at my destination folder using </p>

<pre><code>    for f,bArr in depickled_.items():
        with open(os.path.join(r""S:\test"", f), ""wb"") as fWr:
            fWr.write(bytearray(bArr))
            fWr.close() # &lt;- probably redundant
</code></pre>

<p>The files are getting written as expected, but they have no permissions applied to them by default which I find odd. Therefore, I cannot open any of the written files as is, but when I fiddle with the security settings to allow myself read access then they open as expected.</p>

<p>Any idea what's going wrong and how I can fix it? I am the sole administrator (and user) of this computer. </p>

<p>More info: </p>

<ul>
<li>Python version 3.7  </li>
<li>Windows 10 Home</li>
</ul>
"
"60017759","<p>Here's a variant that makes sure the substrings all match the given pattern:</p>

<pre><code>input_ = ""121212121212121212""
x = ""12""
res = []
while input_.startswith(x):
    res.append(x)
    input_ = input_[len(x):]
</code></pre>
","0","2020-02-01 14:53:34","0","306","34","9","20","60017683","60017781","<p>Input string has 'n' times of X. <code>Like this ""XXXXX""</code>
Need to split the string and make out a list in which each character of the string(X) is each element of list.</p>

<p>Constraints:<br>
0 &lt;= X &lt;= any number<br>
<strong>'n'</strong> is unknown </p>

<p><strong>Example 1</strong>: X is 12, </p>

<p>Input string : <code>""121212121212121212""</code><br>
Output list : <code>[12,12,12,12,12,12,12,12,12]</code></p>

<p><strong>Example 2</strong>: X is 2,</p>

<p>Input string : <code>""2222""</code><br>
Output list : <code>[2,2,2,2]</code></p>

<p><strong>Example 3</strong>: X is 489,</p>

<p>Input string : <code>""489489489""</code><br>
Output list : <code>[489,489,489]</code></p>

<p>I tried this approach
<code>my_list = list(input_string)</code></p>

<p>I am getting output like,
<code>[1,2,1,2,1,2,1,2,1,2,1,2,1,2,1,2,1,2]</code> </p>

<p>Can anyone help me to resolve this?</p>

<p><strong>Edit 1: I am new to stackoverflow. Please help me to edit this question properly.</strong></p>
"
"60017781","<p>To decode this string you need 'n' and X anyway.
Why not build it directly with:</p>

<pre><code>li = [X] * n
</code></pre>

<p>Edit:
If you don't have 'n', you could get it easily from the given string.
(Under the condition that givenString only consist of X)</p>

<pre><code>n = len(givenString) / len(str(X))
li = [X] * n
</code></pre>
","1","2020-02-01 14:38:20","2","36","2","0","1","60017683","60017781","<p>Input string has 'n' times of X. <code>Like this ""XXXXX""</code>
Need to split the string and make out a list in which each character of the string(X) is each element of list.</p>

<p>Constraints:<br>
0 &lt;= X &lt;= any number<br>
<strong>'n'</strong> is unknown </p>

<p><strong>Example 1</strong>: X is 12, </p>

<p>Input string : <code>""121212121212121212""</code><br>
Output list : <code>[12,12,12,12,12,12,12,12,12]</code></p>

<p><strong>Example 2</strong>: X is 2,</p>

<p>Input string : <code>""2222""</code><br>
Output list : <code>[2,2,2,2]</code></p>

<p><strong>Example 3</strong>: X is 489,</p>

<p>Input string : <code>""489489489""</code><br>
Output list : <code>[489,489,489]</code></p>

<p>I tried this approach
<code>my_list = list(input_string)</code></p>

<p>I am getting output like,
<code>[1,2,1,2,1,2,1,2,1,2,1,2,1,2,1,2,1,2]</code> </p>

<p>Can anyone help me to resolve this?</p>

<p><strong>Edit 1: I am new to stackoverflow. Please help me to edit this question properly.</strong></p>
"
"60017834","<p>You can use regular expressions:</p>

<pre><code>import re 

x = input('Enter Your X : ')
mystr = input('Enter Your Input String : ')

result = re.findall(x, mystr) 
print(result)
</code></pre>

<p>This outputs:</p>

<pre><code>Enter Your X : 12
Enter Your Input String : 121212121212
['12', '12', '12', '12', '12', '12']
</code></pre>
","0","2020-02-01 14:53:22","1","1623","53","47","157","60017683","60017781","<p>Input string has 'n' times of X. <code>Like this ""XXXXX""</code>
Need to split the string and make out a list in which each character of the string(X) is each element of list.</p>

<p>Constraints:<br>
0 &lt;= X &lt;= any number<br>
<strong>'n'</strong> is unknown </p>

<p><strong>Example 1</strong>: X is 12, </p>

<p>Input string : <code>""121212121212121212""</code><br>
Output list : <code>[12,12,12,12,12,12,12,12,12]</code></p>

<p><strong>Example 2</strong>: X is 2,</p>

<p>Input string : <code>""2222""</code><br>
Output list : <code>[2,2,2,2]</code></p>

<p><strong>Example 3</strong>: X is 489,</p>

<p>Input string : <code>""489489489""</code><br>
Output list : <code>[489,489,489]</code></p>

<p>I tried this approach
<code>my_list = list(input_string)</code></p>

<p>I am getting output like,
<code>[1,2,1,2,1,2,1,2,1,2,1,2,1,2,1,2,1,2]</code> </p>

<p>Can anyone help me to resolve this?</p>

<p><strong>Edit 1: I am new to stackoverflow. Please help me to edit this question properly.</strong></p>
"
"60018063","<p>If <code>X</code> is also unknown, you can use this:</p>

<pre><code>import textwrap

def find_shortest_pattern(input_):
     for len_ in range(1, int(len(input_) / 2) + 1):
          patterns = textwrap.wrap(input_, len_)
          if all(pattern == patterns[0] for pattern in patterns):
               return patterns[0]

find_shortest_pattern(""123123123"")
</code></pre>
","0","","0","306","34","9","20","60017683","60017781","<p>Input string has 'n' times of X. <code>Like this ""XXXXX""</code>
Need to split the string and make out a list in which each character of the string(X) is each element of list.</p>

<p>Constraints:<br>
0 &lt;= X &lt;= any number<br>
<strong>'n'</strong> is unknown </p>

<p><strong>Example 1</strong>: X is 12, </p>

<p>Input string : <code>""121212121212121212""</code><br>
Output list : <code>[12,12,12,12,12,12,12,12,12]</code></p>

<p><strong>Example 2</strong>: X is 2,</p>

<p>Input string : <code>""2222""</code><br>
Output list : <code>[2,2,2,2]</code></p>

<p><strong>Example 3</strong>: X is 489,</p>

<p>Input string : <code>""489489489""</code><br>
Output list : <code>[489,489,489]</code></p>

<p>I tried this approach
<code>my_list = list(input_string)</code></p>

<p>I am getting output like,
<code>[1,2,1,2,1,2,1,2,1,2,1,2,1,2,1,2,1,2]</code> </p>

<p>Can anyone help me to resolve this?</p>

<p><strong>Edit 1: I am new to stackoverflow. Please help me to edit this question properly.</strong></p>
"
"60018785","<p>The result of <em>value_counts()</em> is in this case a <em>Series</em> with:</p>

<ul>
<li>index - original <em>ID</em> values,</li>
<li>values - how many times this <em>ID</em> occurs in the source <em>Series</em>.</li>
</ul>

<p>A bit tricky detail is that the name of this Series (<em>ID</em>) refers actually
to (the only) column, containg the <strong>number of occurrences</strong> of particular
value it the original <em>ID</em> column.</p>

<p>So your task is to:</p>

<ul>
<li>Rename the index to <em>ID</em> (in place).</li>
<li>Rename the Series itself to <em>numberOfMonths</em> or whatever your name of choice
(also in place).</li>
<li>Reset the index, saving the result in a target variable. As <em>drop</em>
parameter is left with its default value (<em>False</em>), the so far
existing index becomes an ""ordinary"" column, keeping its name.</li>
</ul>

<p>The code to do it is:</p>

<pre><code>number_of_months.index.rename('ID', inplace=True)
number_of_months.rename('numberOfMonths', inplace=True)
df1 = number_of_months.reset_index()
</code></pre>

<p>The result, for your sample data, is:</p>

<pre><code>    ID  numberOfMonths
0  564              30
1  133              30
2  156              30
3  153              30
</code></pre>

<p>Now <em>ID</em> name pertains to original <em>ID</em> values and you can merge it with
another DataFrame just on <em>ID</em> column.</p>

<h1>Alternative solution</h1>

<p>If your intention is to add <em>numberOfMonths</em> column to <em>df</em>,
containing information how many times particular <em>ID</em> occurs
in this DataFrame, a quicker and simpler solution is:</p>

<pre><code>df['numberOfMonths'] = df.groupby('ID').transform('count')
</code></pre>
","0","2020-02-01 16:42:42","0","23982","8","2","1103","60017748","60018785","<p>I want to calculate number of months for each ID
<code>number_of_months=df.ID.value_counts()</code>
and I got pandas series</p>

<pre><code>        ID
    564 30
    133 30
    156 30
    153 30
</code></pre>

<p>with a single column ID</p>

<p>How can I get dataframe <code>df1</code> with two columns <code>(ID, numberofmonts)</code> to merge with other dataframe <code>df</code> based on ID</p>

<p><code>df = pd.merge(df, df1,  how='left', left_on=['ID'], right_on = ['ID'])</code></p>

<p>That is standard problem for feature engineering. I want to define some new feature with count or other function and then merge with dataframe</p>
"
"60019165","<p>One possible solution is to create another QGraphicsPathItem that is the child of the item so the relative coordinates will not change and the parent's QPen will not affect him.</p>

<pre class=""lang-py prettyprint-override""><code>def drawSymbol(self):
    path = QtGui.QPainterPath()
    path.moveTo(0, 40)
    path.lineTo(20, 40)
    path.addRect(QtCore.QRectF(20, 30, 40, 20))
    path.moveTo(60, 40)
    path.lineTo(80, 40)
    self.setPath(path)

    text_item = QtWidgets.QGraphicsPathItem(self)
    text_item.setBrush(QtGui.QColor(""black""))
    child_path = QtGui.QPainterPath()
    child_path.addText(20, 25, QtGui.QFont(""Times"", 20), self.__partName)
    text_item.setPath(child_path)
</code></pre>
","2","2020-02-02 20:59:40","1","184341","3940","32065","41961","60017848","60019165","<p>stack overflow community. Let me explain my question refering to the code snipped below</p>

<pre><code>from PyQt5 import QtCore, QtGui, QtWidgets


class PortItem(QtWidgets.QGraphicsPathItem):
    def __init__(self, parent=None):
        super().__init__(parent)
        pen=QtGui.QPen(QtGui.QColor(""black""), 2)
        self.setPen(pen)        
        self.end_ports = []
        self.setFlags(QtWidgets.QGraphicsItem.ItemIsMovable | QtWidgets.QGraphicsItem.ItemSendsGeometryChanges)


class Symbol_Z(PortItem):
    __partCounter=0

    def __init__(self):
        super().__init__()
        self.__partName= ""FixedTerms""
        self.__partCounter+=1
        self.drawSymbol()

    def drawSymbol(self):
        path=QtGui.QPainterPath()
        path.moveTo(0, 40)
        path.lineTo(20, 40)
        path.addRect(QtCore.QRectF(20, 30, 40, 20))
        path.moveTo(60, 40)
        path.lineTo(80, 40)
        path.addText(20, 25, QtGui.QFont('Times', 20), self.__partName)
        self.setPath(path)


class GraphicsView(QtWidgets.QGraphicsView):
    def __init__(self, scene=None, parent=None):
        super().__init__(scene, parent)
        self.setRenderHints(QtGui.QPainter.Antialiasing)


class MainWindow(QtWidgets.QMainWindow):
    def __init__(self, parent=None):
        super().__init__(parent)
        scene=QtWidgets.QGraphicsScene()
        graphicsview=GraphicsView(scene)

        item=Symbol_Z()
        item.setPos(QtCore.QPointF(0, 250))
        scene.addItem(item)

        self.setCentralWidget(graphicsview)


if __name__ == ""__main__"":
    import sys

    app = QtWidgets.QApplication(sys.argv)
    w = MainWindow()
    w.resize(640, 480)
    w.show()
    sys.exit(app.exec_())
</code></pre>

<p>My problem is that the lines: </p>

<ul>
<li>pen=QtGui.QPen(QtGui.QColor(""black""), 2)</li>
<li>self.setPen(pen)</li>
</ul>

<p>impact the line:</p>

<ul>
<li>path.addText(20, 25, QtGui.QFont('Times', 20), self.__partName)</li>
</ul>

<p>Do you know how to add text independet? When I tried to add it I had the problem that the drawing and the text are not connected and only the symbol could be mouved with the mouse and not both (drawing and text) together. </p>
"
"60017993","<p>Get slice for each year with contract langth and then sum <code>palyer_value</code>.</p>

<pre><code>import pandas as pd

df1 = pd.DataFrame({'player': ['AB','AB','AB'], 'contract_length':[2,3,1], 'year': [1998,2000,2003]})
df2 = pd.DataFrame({'player': ['AB','AB','AB','AB','AB','AB'], 'year':[1998,1999,2000,2001,2002,2003],'player_value': [4,3,7,10,9,2]})

data = []
for index, row in df1.iterrows():
    contract_data = df2[(df2['year'] &gt;= row['year']) &amp; (df2['year'] &lt;= row['year']+row['contract_length']-1)]
    sum = contract_data['player_value'].sum()
    data.append(sum)

df1['contract_value'] = data
</code></pre>

<p>Output:</p>

<pre><code>  player  contract_length  year  contract_value
0     AB                2  1998               7
1     AB                3  2000              26
2     AB                1  2003               2
</code></pre>
","0","","2","4584","259","83","602","60017866","60017993","<p>I have two dataframes:</p>

<pre><code>df1 = pd.DataFrame({'player': ['AB','AB','AB'], 'contract_length':[2,3,1], 'year': [1998,2000,2003]})
df2 = pd.DataFrame({'player': ['AB','AB','AB','AB','AB','AB'], 'year':[1998,1999,2000,2001,2002,2003],'player_value': [4,3,7,10,9,2]})

df1
  player    contract_length     year
0   AB            2             1998
1   AB            3             2000
2   AB            1             2003

df2
    player  year    player_value
0   AB      1998    4
1   AB      1999    3
2   AB      2000    7
3   AB      2001    10
4   AB      2002    9
5   AB      2003    2
</code></pre>

<p>The first dataframe lists the contracts that the player has signed.  Ex: In 1998, he signed a 2 year contract.</p>

<p>The second dataframe lists the individual seasons and a value that I have placed for each of them.  </p>

<p>I am trying to make a new column on df1 that sums the total player values from df2 based on the contract year and the length of the contract.  For example, the first row on df1 is 1998 and 2 years.  So the value would be 7, coming from the player values of 4 and 3 from 1998 and 1999 (2 year contract).  </p>

<p>I can't seem to figure out why this isn't returning the correct results: </p>

<pre><code>for i,row in df1.iterrows():
    year_list = list(range(row['year'],((row['year'])+(row['contract_length']))))
    player = row['player']
    df = pd.DataFrame(columns=['player_value'])
    for year in year_list:
        player_value = df2.loc[(df2['player']==player) &amp; (df2['year'] == year),['player_value']]
        df1['contract_value'] = sum(df['player_value'])
</code></pre>

<p>This is returned:</p>

<pre><code>player  contract_length year    contract_value
0   AB     2            1998    0
1   AB     3            2000    0
2   AB     1            2003    0
</code></pre>

<p>When it should be:</p>

<pre><code>player  contract_length year    contract_value
0   AB     2            1998    7
1   AB     3            2000    26
2   AB     1            2003    2
</code></pre>

<p>There are no errors returned.  Just the zeros in the last column. </p>
"
"60018448","<p>Consider <a href=""https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Index.repeat.html"" rel=""nofollow noreferrer""><code>repeating</code></a> the dataframe according to <code>contract_length</code> then <a href=""https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.assign.html"" rel=""nofollow noreferrer""><code>assigning</code></a> another column which <a href=""https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.core.groupby.GroupBy.cumcount.html"" rel=""nofollow noreferrer""><code>adds</code></a> the years based on the group and then merging with the second:</p>

<pre><code>final = (df1.loc[df1.index.repeat(df1['contract_length'])]
        .assign(year1 = lambda x: x['year']+x.groupby('year').cumcount())
        .merge(df2, left_on = ['player','year1'],right_on = ['player','year']
        ,suffixes = ('','_y')).groupby(['player','contract_length','year']
        ,sort=False,as_index=False)['player_value'].sum())
</code></pre>

<hr>

<pre><code>  player  contract_length  year  player_value
0     AB                2  1998             7
1     AB                3  2000            26
2     AB                1  2003             2
</code></pre>

<p>breaking this down to 2 steps:</p>

<pre><code>m = df1.loc[df1.index.repeat(df1['contract_length'])].assign(year1 = lambda x:
             x['year']+x.groupby('year').cumcount())
final1 = (m.merge(df2,left_on = ['player','year1'],right_on=['player','year']
         ,suffixes=('','_y').groupby(['player','contract_length','year']
          ,sort=False,as_index=False)['player_value'].sum())
</code></pre>

<hr>

<pre><code>   player  contract_length  year  player_value
0     AB                2  1998             7
1     AB                3  2000            26
2     AB                1  2003             2
</code></pre>

<p>Just so you know what we are merging the second dataframe with:</p>

<pre><code>print(m)

  player  contract_length  year  year1
0     AB                2  1998   1998
0     AB                2  1998   1999
1     AB                3  2000   2000
1     AB                3  2000   2001
1     AB                3  2000   2002
2     AB                1  2003   2003
</code></pre>
","0","2020-02-01 15:58:35","1","60867","6713","624","4957","60017866","60017993","<p>I have two dataframes:</p>

<pre><code>df1 = pd.DataFrame({'player': ['AB','AB','AB'], 'contract_length':[2,3,1], 'year': [1998,2000,2003]})
df2 = pd.DataFrame({'player': ['AB','AB','AB','AB','AB','AB'], 'year':[1998,1999,2000,2001,2002,2003],'player_value': [4,3,7,10,9,2]})

df1
  player    contract_length     year
0   AB            2             1998
1   AB            3             2000
2   AB            1             2003

df2
    player  year    player_value
0   AB      1998    4
1   AB      1999    3
2   AB      2000    7
3   AB      2001    10
4   AB      2002    9
5   AB      2003    2
</code></pre>

<p>The first dataframe lists the contracts that the player has signed.  Ex: In 1998, he signed a 2 year contract.</p>

<p>The second dataframe lists the individual seasons and a value that I have placed for each of them.  </p>

<p>I am trying to make a new column on df1 that sums the total player values from df2 based on the contract year and the length of the contract.  For example, the first row on df1 is 1998 and 2 years.  So the value would be 7, coming from the player values of 4 and 3 from 1998 and 1999 (2 year contract).  </p>

<p>I can't seem to figure out why this isn't returning the correct results: </p>

<pre><code>for i,row in df1.iterrows():
    year_list = list(range(row['year'],((row['year'])+(row['contract_length']))))
    player = row['player']
    df = pd.DataFrame(columns=['player_value'])
    for year in year_list:
        player_value = df2.loc[(df2['player']==player) &amp; (df2['year'] == year),['player_value']]
        df1['contract_value'] = sum(df['player_value'])
</code></pre>

<p>This is returned:</p>

<pre><code>player  contract_length year    contract_value
0   AB     2            1998    0
1   AB     3            2000    0
2   AB     1            2003    0
</code></pre>

<p>When it should be:</p>

<pre><code>player  contract_length year    contract_value
0   AB     2            1998    7
1   AB     3            2000    26
2   AB     1            2003    2
</code></pre>

<p>There are no errors returned.  Just the zeros in the last column. </p>
"
"60018564","<p>Another attempt, using <code>.explode()</code>:</p>

<pre><code>df1['contract_value'] = pd.merge(
        df1.assign(years=df1.apply(lambda x: [*range(x['year'], x['year'] + x['contract_length'])] ,axis=1)).explode('years'),
        df2, left_on=['player', 'years'], right_on=['player', 'year']
    ).groupby(['player', 'year_x'], as_index=False)['player_value'].sum()['player_value']

print(df1)
</code></pre>

<p>Prints:</p>

<pre><code>  player  contract_length  year  contract_value
0     AB                2  1998               7
1     AB                3  2000              26
2     AB                1  2003               2
</code></pre>
","0","","0","67907","1966","35","5948","60017866","60017993","<p>I have two dataframes:</p>

<pre><code>df1 = pd.DataFrame({'player': ['AB','AB','AB'], 'contract_length':[2,3,1], 'year': [1998,2000,2003]})
df2 = pd.DataFrame({'player': ['AB','AB','AB','AB','AB','AB'], 'year':[1998,1999,2000,2001,2002,2003],'player_value': [4,3,7,10,9,2]})

df1
  player    contract_length     year
0   AB            2             1998
1   AB            3             2000
2   AB            1             2003

df2
    player  year    player_value
0   AB      1998    4
1   AB      1999    3
2   AB      2000    7
3   AB      2001    10
4   AB      2002    9
5   AB      2003    2
</code></pre>

<p>The first dataframe lists the contracts that the player has signed.  Ex: In 1998, he signed a 2 year contract.</p>

<p>The second dataframe lists the individual seasons and a value that I have placed for each of them.  </p>

<p>I am trying to make a new column on df1 that sums the total player values from df2 based on the contract year and the length of the contract.  For example, the first row on df1 is 1998 and 2 years.  So the value would be 7, coming from the player values of 4 and 3 from 1998 and 1999 (2 year contract).  </p>

<p>I can't seem to figure out why this isn't returning the correct results: </p>

<pre><code>for i,row in df1.iterrows():
    year_list = list(range(row['year'],((row['year'])+(row['contract_length']))))
    player = row['player']
    df = pd.DataFrame(columns=['player_value'])
    for year in year_list:
        player_value = df2.loc[(df2['player']==player) &amp; (df2['year'] == year),['player_value']]
        df1['contract_value'] = sum(df['player_value'])
</code></pre>

<p>This is returned:</p>

<pre><code>player  contract_length year    contract_value
0   AB     2            1998    0
1   AB     3            2000    0
2   AB     1            2003    0
</code></pre>

<p>When it should be:</p>

<pre><code>player  contract_length year    contract_value
0   AB     2            1998    7
1   AB     3            2000    26
2   AB     1            2003    2
</code></pre>

<p>There are no errors returned.  Just the zeros in the last column. </p>
"
"60018364","<p>Chew on this until you figure it out lol.</p>

<pre class=""lang-py prettyprint-override""><code>import numpy as np
from numpy import cos,sin,pi
import matplotlib.pyplot as plt

# Convert data into floats, for 
sensor_data = tuple(map(lambda x: float(x),[10,0,5,1,10,1,20,1,20,1,15]))

# Start at 0,0 in a 2D plane and start out in x-Direction
Starting_Position = np.array((0.,0.))
Starting_Direction = np.array((1.,0.))



def Rotation_Matrix(direction):

    '''Can be expanded for any angle of rotation in a 2D plane. Google rotation matrix in 2D space.'''

    a = {'left':pi/2,'right':-pi/2}[direction]

    matrix = np.array(((round(cos(a),7),round(-sin(a),7)),
                       (round(sin(a),7),round(cos(a),7))))

    return matrix



def DronePosition(Number_input,Current_Position,Current_Direction):

    if Number_input == 1.:
        New_Direction = Current_Direction.dot(Rotation_Matrix('left'))
        New_Position = Current_Position
    elif Number_input == 0.:
        New_Direction = Current_Direction.dot(Rotation_Matrix('right'))
        New_Position = Current_Position
    else:
        New_Position = Current_Position + Current_Direction*Number_input
        New_Direction = Current_Direction


    return New_Position,New_Direction

Drone_Path = np.zeros(shape=(len(sensor_data),2))

for step in range(len(sensor_data)):
    Drone_Path[step,0] = Starting_Position[0] 
    Drone_Path[step,1] = Starting_Position[1] 
    Starting_Position, Starting_Direction = DronePosition(sensor_data[step],Starting_Position,Starting_Direction)


fig, ax = plt.subplots(figsize=(6,6))

ax.plot(Drone_Path[:,0],Drone_Path[:,1])
plt.show()
</code></pre>
","1","","1","133","29","0","71","60017943","60018364","<p>Suppose I have an array </p>

<p><code>sensor_data=[10,0,5,1,10,1,20,1,20,1,15]</code></p>

<p>Now in this: </p>

<p>0 means that the robot/drone has taken a right turn and</p>

<p>1 means that the robot/drone has taken a left turn. </p>

<p>The remaining of the digits are distances traveled.</p>

<p>So according to the above array, first the robot/drone travels a distance of 10 cm. Then it turn right. After turning right the robot/drone travels 5 cm and then it takes a left. After taking a left turn it travels 10 cm and so on. So initially the robot/drone is at (0,0). Then it travels straight i.e in the y direction.</p>

<p>Thus the coordinates would be (0,10). Then after the right turn and after traveling 5 cm, the coordinates would be (-5,10). Following such a pattern, the rest of the coordinates are: (-5,20),(15,20) and (15,0). What code can be written so that these coordinates can be generated from the above given array.</p>
"
"60018510","<p>If you have two <code>pd.Series</code>, where <code>dtype('bool')</code>. You can compare them in the following way. <em>Without knowing what your data looks like, I've created two <code>pd.Series</code> with either <code>True</code> or <code>False</code></em>. </p>

<pre><code>import pandas as pd
import numpy as np

condition1= pd.Series(np.random.choice([True, False], 100)) 
condition2= pd.Series(np.random.choice([True, False], 100)) 
</code></pre>

<p>Then you can compare by doing the following.</p>

<pre><code>(condition1) &amp; (condition2) # which returns a `pd.Series` where each row is either `True` or `False`.
</code></pre>

<p>To find any index position from each <code>pd.Series</code> where both values are <code>True</code>.</p>

<pre><code>((condition1) &amp; (condition2)).any() # Which returns either `True` or `False`
</code></pre>

<p>From your code, I would guess this line is the issue.</p>

<pre><code>if ((condition1).bool()&amp;(condition2).any()):
</code></pre>

<p>which should be</p>

<pre><code>if ((condition1) &amp; (condition2)).any():
</code></pre>
","2","","0","1378","466","12","86","60017982","60018510","<p>I am trying to calculate the candle stick pattern called Doji. It requires two calculation of two conditions
values is a pandas dataframe with the historical stock data with columns Date, High, Low, open and Close.</p>

<p>With the if condition I tried to explicitly make condition1 and condition2 bool and also tried it by typecasting it with any(). Both of them did not give the desired result.Printing condition1 and condition 2 separately give appropriate boolean value but combining it with '&amp;' goes horribly wrong.</p>

<pre><code>51315    True
51316    True
51317    True
51318    True
51319    True
         ... 
53790    True
53791    True
53792    True
53793    True
53794    True
Length: 2480, dtype: bool
</code></pre>

<hr>

<pre><code>ValueError                                Traceback (most recent call last)
&lt;ipython-input-58-3f42eed169f4&gt; in &lt;module&gt;
      4 values = pd.DataFrame(stocks_data.loc[stocks_data['Company']=='TCS'])
      5 values.reset_index()
----&gt; 6 study_candlesticks(values)

&lt;ipython-input-57-fd67b4117699&gt; in study_candlesticks(values)
     21 #     for row in values
     22 
---&gt; 23     if calc_doji(values):
     24         values['Pattern']='Doji'
     25 

&lt;ipython-input-57-fd67b4117699&gt; in calc_doji(values)
     81     condition2=((values['High'] - values['Low'])&gt;values['Close']*min_candle_size)
     82     print(condition2)
---&gt; 83     if ((condition1).bool()&amp;(condition2).any()):
     84         return True
     85     else:

~\Anaconda3\lib\site-packages\pandas\core\generic.py in bool(self)
   1581             )
   1582 
-&gt; 1583         self.__nonzero__()
   1584 
   1585     def __abs__(self):

~\Anaconda3\lib\site-packages\pandas\core\generic.py in __nonzero__(self)
   1553             ""The truth value of a {0} is ambiguous. ""
   1554             ""Use a.empty, a.bool(), a.item(), a.any() or a.all()."".format(
-&gt; 1555                 self.__class__.__name__
   1556             )
   1557         )
</code></pre>

<p>ValueError: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().</p>

<p>I am not sure where I am going wrong. Any suggestions?</p>

<p>Below is the code</p>

<pre><code>calc_doji(values)

def calc_doji(values):
    max_candle_size=0.1/100
    min_candle_size=1/100
    condition1 =(abs(values['Open'] - values['Close'])&lt;values['Close']*max_candle_size)
    print(condition1)
    condition2=((values['High'] - values['Low'])&gt;values['Close']*min_candle_size)
    print(condition2)
    if ((condition1).bool()&amp;(condition2).any()): 
        return True
    else:
        return False
</code></pre>
"
"60019847","<p>This is called <strong><a href=""https://en.wikipedia.org/wiki/Inverse_transform_sampling"" rel=""nofollow noreferrer"">inverse transform sampling</a></strong>:</p>

<blockquote>
  <p>is a basic method for pseudo-random number sampling, i.e., for
  generating sample numbers at random from any probability distribution
  given its <a href=""https://en.wikipedia.org/wiki/Cumulative_distribution_function"" rel=""nofollow noreferrer"">cumulative distribution function</a>.</p>
</blockquote>

<p>The best explanation I found is <a href=""https://matlabtricks.com/post-44/generate-random-numbers-with-a-given-distribution"" rel=""nofollow noreferrer"">this one</a>. Also discussed <a href=""https://stats.stackexchange.com/questions/321542/how-can-i-draw-a-value-randomly-from-a-kernel-density-estimate"">here</a>.</p>
","8","","-1","5121","178","13","664","60017994","60019847","<p>I have an array, vox_betas, that contains 21600 floats (ranging from ~0 to ~2), and when sorted by the array, features, you can see that there is a structure to the data (see 1st pic).</p>

<p>I want to have a single array that reflects this structure -- essentially I want to call sns.distplot() and have that produce the same plot as the first picture. Right now sns.distplot(vox_betas) depicts the 2nd picture, which is not what I want.</p>

<p>I was able to accomplish this in the third picture by creating the array, dist, but the way I accomplished this was sloppy and even loses some information (my code is below). </p>

<p>How would you transform vox_betas and features into dist? Does anyone have any ideas?</p>

<pre><code>plt.scatter(features,vox_betas)
</code></pre>

<p><a href=""https://i.stack.imgur.com/HYJJC.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/HYJJC.png"" alt=""enter image description here""></a></p>

<pre><code>sns.distplot(vox_betas)
</code></pre>

<p><a href=""https://i.stack.imgur.com/8nU1i.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/8nU1i.png"" alt=""enter image description here""></a></p>

<pre><code>dist=[]
for f in np.unique(features):
    dist = np.concatenate((dist,
                np.repeat(f,
                np.sum(
                [vox_betas[j]*10 for j in np.where(features==f)[0]]))))

sns.distplot(dist)
</code></pre>

<p><a href=""https://i.stack.imgur.com/kGGwU.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/kGGwU.png"" alt=""enter image description here""></a></p>
"
"60018033","<p>You didn't assign the return value in your function.</p>

<pre><code>        get_random_word(max_length)

    return word
</code></pre>

<p>should be:</p>

<pre><code>    if len(word) &gt; max_length:
        word = get_random_word(max_length)

    return word
</code></pre>
","0","","0","1619","93","3","128","60017995","60018295","<p>I am trying to get random work in python using <code>random</code> module. My function is as below:</p>

<pre><code>import random

word_file = ""/usr/share/dict/words""
WORDS = open(word_file).read().splitlines()


def get_random_word(max_length=None):
    word = random.choice(WORDS)
    print(word)

    if not max_length:
        return word

    if len(word) &gt; max_length:
        get_random_word(max_length)

    return word
</code></pre>

<p>When I import this function in <code>ipython</code> console and run as <code>get_random_word(max_length=5)</code>, I get this result:</p>

<pre><code>Latasha's
Hammond's
evacuated
aviary
misconducted
airfare's
controllable
unduly
gaunt
Out[32]: ""Latasha's""
</code></pre>

<p>As you see from output, function calls itself until it finds the word with length less than 5. But at the end it returns very first random word. What is wrong with my function?</p>
"
"60018043","<p>In the if statement you need return the value </p>

<pre><code>if len(word) &gt; max_length:
        return get_random_word(max_length)
</code></pre>

<p>the last <code>return word</code> will return the last word in memory in this case is the first recursion case of you don't have coincidences because you never return from the base case.</p>
","0","2020-02-01 15:02:09","0","23","3","0","22","60017995","60018295","<p>I am trying to get random work in python using <code>random</code> module. My function is as below:</p>

<pre><code>import random

word_file = ""/usr/share/dict/words""
WORDS = open(word_file).read().splitlines()


def get_random_word(max_length=None):
    word = random.choice(WORDS)
    print(word)

    if not max_length:
        return word

    if len(word) &gt; max_length:
        get_random_word(max_length)

    return word
</code></pre>

<p>When I import this function in <code>ipython</code> console and run as <code>get_random_word(max_length=5)</code>, I get this result:</p>

<pre><code>Latasha's
Hammond's
evacuated
aviary
misconducted
airfare's
controllable
unduly
gaunt
Out[32]: ""Latasha's""
</code></pre>

<p>As you see from output, function calls itself until it finds the word with length less than 5. But at the end it returns very first random word. What is wrong with my function?</p>
"
"60018060","<p>This is a simple recursion error. The value of the variable word is not retained through recursive calls. You have to assign the return value.</p>

<pre><code>word = get_random_word(max_length)
</code></pre>
","0","","0","1","0","0","1","60017995","60018295","<p>I am trying to get random work in python using <code>random</code> module. My function is as below:</p>

<pre><code>import random

word_file = ""/usr/share/dict/words""
WORDS = open(word_file).read().splitlines()


def get_random_word(max_length=None):
    word = random.choice(WORDS)
    print(word)

    if not max_length:
        return word

    if len(word) &gt; max_length:
        get_random_word(max_length)

    return word
</code></pre>

<p>When I import this function in <code>ipython</code> console and run as <code>get_random_word(max_length=5)</code>, I get this result:</p>

<pre><code>Latasha's
Hammond's
evacuated
aviary
misconducted
airfare's
controllable
unduly
gaunt
Out[32]: ""Latasha's""
</code></pre>

<p>As you see from output, function calls itself until it finds the word with length less than 5. But at the end it returns very first random word. What is wrong with my function?</p>
"
"60018088","<p>I think your code works, you don't need at all this line <code>return word</code> and also you don't need to call <code>get_random_word</code> inside print (if you do).</p>
","0","","0","672","30","0","17","60017995","60018295","<p>I am trying to get random work in python using <code>random</code> module. My function is as below:</p>

<pre><code>import random

word_file = ""/usr/share/dict/words""
WORDS = open(word_file).read().splitlines()


def get_random_word(max_length=None):
    word = random.choice(WORDS)
    print(word)

    if not max_length:
        return word

    if len(word) &gt; max_length:
        get_random_word(max_length)

    return word
</code></pre>

<p>When I import this function in <code>ipython</code> console and run as <code>get_random_word(max_length=5)</code>, I get this result:</p>

<pre><code>Latasha's
Hammond's
evacuated
aviary
misconducted
airfare's
controllable
unduly
gaunt
Out[32]: ""Latasha's""
</code></pre>

<p>As you see from output, function calls itself until it finds the word with length less than 5. But at the end it returns very first random word. What is wrong with my function?</p>
"
"60018295","<p>Recursion in Python is inefficient, due to repeated calls to user-defined functions, and limited, in that you will eventually overflow the stack if you don't terminate the recursion soon enough. As such, while the fix to your problem is trivial (return the return value of the recursive call), it's a moot point because recursion is the wrong approach to begin with.</p>

<p>Instead, use a <code>while</code> loop to call <code>random.choice</code> until you get a word that fits your condition.</p>

<pre><code>import random

word_file = ""/usr/share/dict/words""
WORDS = open(word_file).read().splitlines()


def get_random_word(max_length=None):
    while True:
        word = random.choice(WORDS)
        if max_length is None or len(word) &lt;= max_length:
            return word
</code></pre>
","0","","0","383179","18330","5892","20227","60017995","60018295","<p>I am trying to get random work in python using <code>random</code> module. My function is as below:</p>

<pre><code>import random

word_file = ""/usr/share/dict/words""
WORDS = open(word_file).read().splitlines()


def get_random_word(max_length=None):
    word = random.choice(WORDS)
    print(word)

    if not max_length:
        return word

    if len(word) &gt; max_length:
        get_random_word(max_length)

    return word
</code></pre>

<p>When I import this function in <code>ipython</code> console and run as <code>get_random_word(max_length=5)</code>, I get this result:</p>

<pre><code>Latasha's
Hammond's
evacuated
aviary
misconducted
airfare's
controllable
unduly
gaunt
Out[32]: ""Latasha's""
</code></pre>

<p>As you see from output, function calls itself until it finds the word with length less than 5. But at the end it returns very first random word. What is wrong with my function?</p>
"
"60018092","<p>Try:</p>

<pre><code>df.groupby(['out'])['out'].count()
</code></pre>
","2","2020-02-01 15:06:53","0","1421","369","4","94","60017998","60018092","<p>I have a dataframe like below</p>

<pre><code>no  out
20  True
3   False
3   False
</code></pre>

<p>How to get the counts of True and False</p>

<pre><code>df.groupby(['out']).agg({'out':sum})



         out
out 
False   0.0
True    26.0
</code></pre>

<p>I am getting False count as 0</p>
"
"60041067","<p>Thanks everyone. Looks like the best way to do it is this in case anyone stumbles across my post:</p>

<pre><code>p = model.get_prediction(pd.DataFrame([{""lotsize"":20000,""sqrft"": 2500, ""bdrms"": 4}]))
p.summary_frame()
</code></pre>
","0","","0","1","0","0","3","60018011","60041067","<p>I have an OLS model to estimate housing prices </p>

<pre><code>import numpy as np
import statsmodels.formula.api as sm

model = sm.ols('np.log(price) ~ np.log(lotsize) + np.log(sqrft) + bdrms', data = df).fit()
</code></pre>

<p>I want to plug in the following values for the betas into the estimated equation which will predict y (price): </p>

<p>lotsize = 20000, sqrft = 2500, bdrms = 4</p>

<p>There's an elegant way to accomplish this in R and I'm trying to replicate this in Python but have had little luck so far: </p>

<p>My goal is to accomplish something like this in Python code to predict y-value</p>

<pre><code>predictY &lt;- predict.lm(linearModel, data.frame(lotsize = c(20000), sqrft = c(2500), bdrms = c(4)))
exp(predictY)
</code></pre>
"
"60126370","<p>I figured it out CrawlerRunner was not able to access settings file of my scrapy project that could enable pipelines.py of scrapy which in turn would save the data in Django MOdels file.The modified code of views.py file of django which calls spider is:</p>

<pre><code>import os
import sys
from newscrawler.spiders import news_spider
from newscrawler.pipelines import NewscrawlerPipeline
from scrapy import signals
from twisted.internet import reactor
from scrapy.crawler import Crawler,CrawlerRunner
from scrapy.settings import Settings
from scrapy.utils.project import get_project_settings
from newscrawler import settings as my_settings 
from scrapy.utils.log import configure_logging
from crochet import setup

@csrf_exempt
@require_http_methods(['POST', 'GET'])
def scrape(request):
    Headline.objects.all().delete()
    crawler_settings = Settings()

    setup()
    configure_logging()
    crawler_settings.setmodule(my_settings)
    runner= CrawlerRunner(settings=crawler_settings)
    d=runner.crawl(news_spider.NewsSpider)
    time.sleep(8)
    return redirect(""../getnews/"")
</code></pre>

<p>Hope this helps anyone wanting to call scrapy spider from within the django views.py file and save the scraped data in Django Models.Thank You</p>
","0","","1","11","0","0","3","60018191","60126370","<p>I am trying to call scrapy spider from Django Views.py file.The spider does gets invoked but its output is shown in command prompt and is not saved in Django models to render it onto the page.I checked running spider separately to verify that scrapy and Django are connected and it does work correctly,but when automated using CrawlerRunner() script it doesn't.So some component is missing in CrawlerRunner() implementation from Django views.py file.
Below is the Django Views.py file which calls the spider:</p>
<pre><code>@csrf_exempt
@require_http_methods(['POST', 'GET'])
def scrape(request):
import sys
from newscrawler.spiders import news_spider
from newscrawler.pipelines import NewscrawlerPipeline
from scrapy import signals
from twisted.internet import reactor
from scrapy.crawler import Crawler,CrawlerRunner
from scrapy.settings import Settings
from scrapy.utils.project import get_project_settings
from scrapy.utils.log import configure_logging
from crochet import setup

setup()
configure_logging()

runner= CrawlerRunner(get_project_settings())
d=runner.crawl(news_spider.NewsSpider)

return redirect(&quot;../getnews/&quot;)
</code></pre>
<p>My spider does the work of crawling news website and saves Url,Image and Title of top news.But output is that rather than saving this three fields in models.py file it is printing in cmd.
Can Anyone help?</p>
<h1>items file from scrapy</h1>
<pre><code>import scrapy
from scrapy_djangoitem import DjangoItem

import sys

import os
os.environ['DJANGO_SETTINGS_MODULE'] = 'News_Aggregator.settings'

from news.models import Headline

class NewscrawlerItem(DjangoItem):
    # define the fields for your item here like:
    django_model = Headline
</code></pre>
<h1>Pipelines file</h1>
<pre><code>class NewscrawlerPipeline(object):
    def process_item(self, item, spider):
        print(&quot;10000000000000000&quot;)
        item.save()
        return item
</code></pre>
"
"60048617","<p>Instead of trying to find horizontal/vertical lines to detect the text document, a simple contour filtering approach should work here. The idea is to threshold the image to obtain a binary image then find contours and sort using contour area. The largest contour should be the text document. We can then apply a <a href=""https://www.pyimagesearch.com/2014/08/25/4-point-opencv-getperspective-transform-example/"" rel=""nofollow noreferrer"">four point perspective transform</a> to obtain a birds eye view of the image. Here's the results:</p>

<p>Input image:</p>

<p><img src=""https://i.stack.imgur.com/UL5MB.jpg"" height=""700""></p>

<p>Output:</p>

<p><img src=""https://i.stack.imgur.com/NVLFl.jpg"" height=""700""></p>

<p>Notice how the output image only has the desired text document and is aligned without a skewed angle.</p>

<p>Code</p>

<pre><code>from imutils.perspective import four_point_transform
import cv2
import numpy

# Load image, grayscale, Gaussian blur, Otsu's threshold
image = cv2.imread(""1.jpg"")
gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
blur = cv2.GaussianBlur(gray, (3,3), 0)
thresh = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]

# Find contours and sort for largest contour
cnts = cv2.findContours(thresh, cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)
cnts = cnts[0] if len(cnts) == 2 else cnts[1]
cnts = sorted(cnts, key=cv2.contourArea, reverse=True)
displayCnt = None

for c in cnts:
    # Perform contour approximation
    peri = cv2.arcLength(c, True)
    approx = cv2.approxPolyDP(c, 0.02 * peri, True)
    if len(approx) == 4:
        displayCnt = approx
        break

# Obtain birds' eye view of image
warped = four_point_transform(image, displayCnt.reshape(4, 2))

cv2.imshow(""thresh"", thresh)
cv2.imshow(""warped"", warped)
cv2.imshow(""image"", image)
cv2.waitKey()
</code></pre>
","2","","0","25600","1364","21","7558","60018244","60048617","<p>Using OpenCV (python) I am trying to remove the section of image which is above the border line (white area in this sample image where ORIGINAL is writtn) in the image shown below 
<a href=""https://i.stack.imgur.com/jmtAM.jpg"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/jmtAM.jpg"" alt=""Invoice Image""></a></p>

<p>Using horizontal and vertical kernels I am able to draw the wireframe, however that does not work many times because many times due to scanning quality few horizontal or vertical lines appear outside the wireframe which causes wrong contour detection. In this image also you can see on top right there is noise which I am detecting as topmost horizontal line.</p>

<p>What I want is, once I get the actual box then I can simply use x, y coordinates for OCR scanning of needed fields (like reference number, Issued In etc).</p>

<p>Following is what I have been able to extract using the code below. However not able to clip the outer extra section of image due to noisy horizontal or vertical lines outside this wireframe. Also tried filling outside section with black and then detecting the contours.<br>
Suggestions please...
<a href=""https://i.stack.imgur.com/3c5s7.jpg"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/3c5s7.jpg"" alt=""Wireframe""></a></p>

<pre><code>    kernel_length = np.array(image).shape[1]//40 
# A verticle kernel of (1 X kernel_length), which will detect all the verticle lines from the image.
verticle_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1, kernel_length))
# A horizontal kernel of (kernel_length X 1), which will help to detect all the horizontal line from the image.
hori_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (kernel_length, 1))
# A kernel of (3 X 3) ones.
kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))
# Morphological operation to detect verticle lines from an image
img_temp1 = cv2.erode(gray, verticle_kernel, iterations=3)
verticle_lines_img = cv2.dilate(img_temp1, verticle_kernel, iterations=3)
</code></pre>
"
"60018909","<blockquote>
<p>QWidget::adjustSize()</p>
<p>Adjusts the size of the widget to fit its contents.</p>
</blockquote>
<pre><code>import sys
from PyQt5.QtWidgets import QApplication, QWidget, QLabel, QFileDialog, QPushButton
from PyQt5.QtGui import QIcon, QPixmap
from PyQt5.QtCore import pyqtSlot
#import TurkceOcr as ocr

class App(QWidget):

    def __init__(self):
        super().__init__()
        self.title = 'Resimden Texte'
        self.left = 50
        self.top = 50
        self.width = 640
        self.height = 480
        self.initUI()

    def initUI(self):
        self.setWindowTitle(self.title)
        self.setGeometry(self.left, self.top, self.width, self.height)

        # Create widget

        button = QPushButton('Resim Yükle', self)
        button.setToolTip('This is load picture button')
        button.move(10, 10)
        button.clicked.connect(self.on_click)

        self.label = QLabel(self)
        self.label.move(10,50)


        #self.resize(pixmap.width(), pixmap.height())

        self.show()

    @pyqtSlot()
    def on_click(self):
        print('PyQt5 button click')
        image = QFileDialog.getOpenFileName(None, 'OpenFile', '', &quot;Image file(*.jpg)&quot;)
        imagePath = image[0]
        pixmap = QPixmap(imagePath)
        self.label.setPixmap(pixmap)
        
        self.label.adjustSize()                       # &lt;---
        
        #print(ocr.resimden_yaziya(imagePath))
        print(imagePath)


if __name__ == '__main__':
    app = QApplication(sys.argv)
    ex = App()
    sys.exit(app.exec_())
</code></pre>
<p><a href=""https://i.stack.imgur.com/GR6M9.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/GR6M9.png"" alt=""enter image description here"" /></a></p>
","0","2020-06-20 09:12:55","0","10346","2781","297","1100","60018299","60018909","<p>I want to show a image on form after clicking the button.But the code below didn't work. I have defined a function.</p>

<pre><code>import sys
from PyQt5.QtWidgets import QApplication, QWidget, QLabel, QFileDialog, QPushButton
from PyQt5.QtGui import QIcon, QPixmap
from PyQt5.QtCore import pyqtSlot
import TurkceOcr as ocr

class App(QWidget):

    def __init__(self):
        super().__init__()
        self.title = 'Resimden Texte'
        self.left = 50
        self.top = 50
        self.width = 640
        self.height = 480
        self.initUI()

    def initUI(self):
        self.setWindowTitle(self.title)
        self.setGeometry(self.left, self.top, self.width, self.height)

        # Create widget

        button = QPushButton('Resim Yükle', self)
        button.setToolTip('This is load picture button')
        button.move(10, 10)
        button.clicked.connect(self.on_click)

        self.label = QLabel(self)
        self.label.move(10,50)


        #self.resize(pixmap.width(), pixmap.height())

        self.show()

    @pyqtSlot()
    def on_click(self):
        print('PyQt5 button click')
        image = QFileDialog.getOpenFileName(None, 'OpenFile', '', ""Image file(*.jpg)"")
        imagePath = image[0]
        pixmap = QPixmap(imagePath)
        self.label.setPixmap(pixmap)
        #print(ocr.resimden_yaziya(imagePath))
        print(imagePath)


if __name__ == '__main__':
    app = QApplication(sys.argv)
    ex = App()
    sys.exit(app.exec_())
</code></pre>
"
"60022391","<p>If both databases located on a same computer, <code>asyncio</code> won't speedup a process: there's no network overhead to parallelize. Quite opposite: overhead for using coroutines will make program a bit slower.</p>

<p>Please, read <a href=""https://stackoverflow.com/a/51180506/1113207"">this answer</a> for detailed explanation.</p>
","0","","0","26899","1876","27","2057","60018305","60022391","<p>I have a script to migrate database from Sqlite to Postgres. My original scipt works, but when I try to use Asyncio to speed up program, my new code even running slower than the original a few seconds. The transfer speed of tables is very slow. Can anyone suggest to me, where am I wrong ?</p>

<p>My original code :</p>

<pre><code>import psycopg2, sqlite3, sys
import time

start_time = time.time()

sqdb=""D://Python//SqliteToPostgreFull//testmydb6.db"" #folder contain sqlite db
sqlike=""table""
pgdb=""testmydb7"" #postgres db
pguser=""postgres""
pgpswd=""1234""
pghost=""127.0.0.1""
pgport=""5432""

consq=sqlite3.connect(sqdb)
cursq=consq.cursor()

tabnames=[]
print() 
cursq.execute('SELECT name FROM sqlite_master WHERE type=""table"" AND name LIKE ""%table%"";')
tabgrab = cursq.fetchall()
for item in tabgrab:
    tabnames.append(item[0])
print(tabgrab)
for table in tabnames:
    print(table)
    cursq.execute(""SELECT sql FROM sqlite_master WHERE type='table' AND name = ?;"", (table,))
    create = cursq.fetchone()[0]
    cursq.execute(""SELECT * FROM %s;"" %table)
    rows=cursq.fetchall()
    colcount=len(rows[0])
    pholder='%s,'*colcount
    newholder=pholder[:-1]

    try:
        conpg = psycopg2.connect(database=pgdb, user=pguser, password=pgpswd,
                               host=pghost, port=pgport)
        curpg = conpg.cursor()
        curpg.execute(""DROP TABLE IF EXISTS %s;"" %table)
        create = create.replace(""AUTOINCREMENT"", """")
        curpg.execute(create)
        curpg.executemany(""INSERT INTO %s VALUES (%s);"" % (table, newholder),rows)
        conpg.commit()

        if conpg:
            conpg.close()

    except psycopg2.DatabaseError as e:
        print ('Error %s' % e) 
        sys.exit(1)

    finally:
        print(""Complete"")


consq.close()

duration = time.time() - start_time
print(f""Duration {duration} seconds"")
</code></pre>

<p>My code with Asyncio module :</p>

<pre><code>import psycopg2, sqlite3, sys
import time
import asyncio


sqdb=""D://Python//SqliteToPostgreFull//testmydb6.db""
sqlike=""table""
pgdb=""testmydb9""
pguser=""postgres""
pgpswd=""1234""
pghost=""127.0.0.1""
pgport=""5432""


consq=sqlite3.connect(sqdb)
cursq=consq.cursor()

tabnames=[]
print() 
cursq.execute('''SELECT name FROM sqlite_master WHERE type=""table"" AND name LIKE ""'''+sqlike+'''%"";''')
tabgrab = cursq.fetchall()
for item in tabgrab:
    tabnames.append(item[0])
print(tabgrab)

async def copyTable(table):
    cursq.execute(""SELECT sql FROM sqlite_master WHERE type='table' AND name = ?;"", (table,))
    create = cursq.fetchone()[0]
    cursq.execute(""SELECT * FROM %s;"" %table)
    rows=cursq.fetchall()
    colcount=len(rows[0])
    pholder='%s,'*colcount
    newholder=pholder[:-1]

    try:

        conpg = psycopg2.connect(database=pgdb, user=pguser, password=pgpswd,
                               host=pghost, port=pgport)
        curpg = conpg.cursor()
        curpg.execute(""DROP TABLE IF EXISTS %s;"" %table)
        create = create.replace(""AUTOINCREMENT"", """")
        curpg.execute(create)
        curpg.executemany(""INSERT INTO %s VALUES (%s);"" % (table, newholder),rows)
        conpg.commit()

        if conpg:
            conpg.close()

    except psycopg2.DatabaseError as e:
        print ('Error %s' % e) 
        sys.exit(1)

    finally:
        print(""Complete"")

async def main():
    for table in tabnames:
        a = loop.create_task(copyTable(table,))
    await asyncio.wait([a])

if __name__ == ""__main__"":
    start_time = time.time()
    loop = asyncio.get_event_loop()
    loop.run_until_complete(main())
    loop.close()      
    duration = time.time() - start_time
    print(f""Duration {duration} seconds"")
</code></pre>
"
"60018427","<p>I believe you're only missing an indent, try this:</p>

<pre class=""lang-py prettyprint-override""><code>def wordcounts():
word_frequencies = dict()
totaal = dict()
for bestand in glob.glob('*.txt'):
    word_list = clean_text(bestand)
    for i in word_list:
        if i in word_frequencies:
            word_frequencies[i] += 1
        else:
            word_frequencies[i] = 1
    totaal[bestand] = word_frequencies  # &lt; Added an indent here
return totaal
</code></pre>
","1","","0","329","26","2","18","60018389","60018465","<p>This part of code adds up all the times a word exists throughout all my .txt files:</p>

<pre><code>def wordcounts():
word_frequencies = dict()
totaal = dict()
for bestand in glob.glob('*.txt'):
    word_list = clean_text(bestand)
    for i in word_list:
        if i in word_frequencies:
            word_frequencies[i] += 1
        else:
            word_frequencies[i] = 1
totaal[bestand] = word_frequencies
return totaal
</code></pre>

<p>The output is:</p>

<pre><code>{'test3.txt': {'aap': 4, 'mies': 4, 'wim': 1, 'noot': 2}}
</code></pre>

<p>The output I need is:</p>

<pre><code>{'test1.txt': {'aap': 1, 'noot': 1, 'mies': 1}, 'test2.txt': {'aap': 1, 'noot': 1}, 'test3.txt': {'aap': 1, 'mies': 2}, 'test4.txt': {'aap': 1, 'mies': 1, 'wim': 1}}
</code></pre>

<p>Does anyone have an idea what I need to do to make sure it does this for each file individual?</p>

<p>(clean_text() is a function I made to process .txt files)</p>
"
"60018465","<p>In your code, you have the result dictionary (totaal) sitting outside of the for loop</p>

<pre><code>def wordcounts():
    word_frequencies = dict()
    totaal = dict()
    for bestand in glob.glob('*.txt'):
        word_list = clean_text(bestand)
        for i in word_list:
            if i in word_frequencies:
                word_frequencies[i] += 1
            else:
                word_frequencies[i] = 1
    totaal[bestand] = word_frequencies
    return totaal
</code></pre>

<p>So what's happening is you're loading totaal with one key (the final bestand) and loading it with all the word_frequencies.</p>

<p>If you indent the totaal line to be included in the for loop, it will populate the dictionary with a key for each bestand, like you expected.</p>

<p>You'll also want to move word_frequencies inside the loop, so that you only get the frequencies for each bestand:</p>

<pre><code>def wordcounts():
    totaal = dict()
    for bestand in glob.glob('*.txt'):
        # MOVED WORD_FREQUENCIES HERE
        word_frequencies = dict()
        word_list = clean_text(bestand)
        for i in word_list:
            if i in word_frequencies:
                word_frequencies[i] += 1
            else: 
                word_frequencies[i] = 1
         # NOTE THAT THIS IS NOW PROPERLY INDENTED
         totaal[bestand] = word_frequencies
    return totaal
</code></pre>
","0","2020-02-01 15:51:37","0","20","3","0","5","60018389","60018465","<p>This part of code adds up all the times a word exists throughout all my .txt files:</p>

<pre><code>def wordcounts():
word_frequencies = dict()
totaal = dict()
for bestand in glob.glob('*.txt'):
    word_list = clean_text(bestand)
    for i in word_list:
        if i in word_frequencies:
            word_frequencies[i] += 1
        else:
            word_frequencies[i] = 1
totaal[bestand] = word_frequencies
return totaal
</code></pre>

<p>The output is:</p>

<pre><code>{'test3.txt': {'aap': 4, 'mies': 4, 'wim': 1, 'noot': 2}}
</code></pre>

<p>The output I need is:</p>

<pre><code>{'test1.txt': {'aap': 1, 'noot': 1, 'mies': 1}, 'test2.txt': {'aap': 1, 'noot': 1}, 'test3.txt': {'aap': 1, 'mies': 2}, 'test4.txt': {'aap': 1, 'mies': 1, 'wim': 1}}
</code></pre>

<p>Does anyone have an idea what I need to do to make sure it does this for each file individual?</p>

<p>(clean_text() is a function I made to process .txt files)</p>
"
"60018818","<p>This seems to do what you want - replace this one line (swap y and x in for loops):</p>

<pre><code>grid_points = [ shapely.geometry.Point(x,y) for y in range(100) for x in range(100)]
</code></pre>

<hr>

<p>Couple of notes:</p>

<p>My installation of shapely has this module name (geometry spelled differently so you may need to change name in above line):</p>

<pre><code>  import shapely.geometry
</code></pre>

<p>And thanks for adding the second plot command - that helped a bunch.</p>

<p>Something along the way has differing major orders (row-vs-column) so the above line changes to column-major.</p>

<p>And it may be you'd want to compensate by doing the inverse on the exterior plot.</p>

<p>(original (with new random shape), updated, with exterior)</p>

<p><a href=""https://i.stack.imgur.com/pSt07.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/pSt07.png"" alt=""enter image description here""></a> 
<a href=""https://i.stack.imgur.com/B0gk0.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/B0gk0.png"" alt=""enter image description here""></a> 
<a href=""https://i.stack.imgur.com/YVPBl.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/YVPBl.png"" alt=""enter image description here""></a></p>
","1","2020-02-01 16:59:32","0","3071","627","340","535","60018423","60018818","<p>Lets say we have a 100x100 grid that contains a polygon.
Now if we color all possible (x,y) points [x,y are integers] that are contained in the polygon we should expect the polygon to be somewhat painted/filled</p>

<p>But the image that i'm getting never properly falls within and fills the polygon! Is this a limitation of shapely or am I doing something wrong?!
(please note I need this to work for other purposes and not just paiting a polygon)</p>

<p><a href=""https://i.stack.imgur.com/RcDQJ.png"" rel=""nofollow noreferrer"">polygon and filled area not overlapping</a></p>

<pre><code>import numpy as np
import matplotlib.pyplot as plt
import shapely.geometry

points = np.random.randint(0,100, (10,2)) # 10 random points
poly   = shapely.geometry.MultiPoint(points).convex_hull.buffer(1) # a polygon 
grid_points = [ shapely.geometry.Point(x,y) for x in range(100) for y in range(100)]
in_poly = np.array([poly.contains(point) for point in grid_points])

#plot
plt.imshow(in_poly.reshape(100,100), origin='lower')
plt.plot(*poly.exterior.xy)
</code></pre>
"
"60021170","<p>(<em>Spyder maintainer here</em>) Sorry, that's not possible.</p>
","0","","0","26479","1538","48","6624","60018449","60021170","<p>I know you can disable both warnings and error flags from <code>Tools &gt; Preferences &gt; Completion and linting &gt; disable basic linting</code> but is it possible to disable only the warnings?</p>
"
"60018531","<p>You can use ""eval"" to evaluate expressions given as strings.</p>

<pre><code>a = ""/""
res = eval(""10"" + a + ""5"")
print(res)
</code></pre>
","2","","-2","300","6","2","11","60018472","60018531","<p>How do I perform calculations with strings? Like <strong><em>suppose</em></strong> I have:</p>

<pre><code>a=('/')
print(10, a, 5)
</code></pre>

<p>How do I get the answer as '2'? Because 10/5 is 2.</p>
"
"60018602","<p>There are multiple ways to do this.</p>

<p>The most common way, I guess, is using the operator module and a map (dictionary) to turn your strings into operators, as the next example.</p>

<pre><code>import operator

run_ops = {
  '+' : operator.add,
  '-' : operator.sub,
  '*' : operator.mul,
  '/' : operator.truediv,
  '%' : operator.mod,
  '^' : operator.xor,
}.get

print(run_ops('/')(10, 5))
</code></pre>

<p>Or go with lambdas:</p>

<pre><code>run_ops= {'+': lambda x, y: x + y,
    '-': lambda x, y: x - y,
    # ...
    '/': lambda x, y: x / y
}

run_ops['/'] (10,5)
</code></pre>

<p>Cheers</p>
","0","","1","29","1","0","7","60018472","60018531","<p>How do I perform calculations with strings? Like <strong><em>suppose</em></strong> I have:</p>

<pre><code>a=('/')
print(10, a, 5)
</code></pre>

<p>How do I get the answer as '2'? Because 10/5 is 2.</p>
"
"60018813","<p>A nice method has been posted by epap. </p>

<p>However if you want to stick to the order of the expression where the ""/"", comes between the two numbers then one of the ways you can do it, is as below. </p>

<p>You can wrap (Number_1, ""/"", Number_2) and send it to a class and then print it. Something like below.</p>

<pre class=""lang-py prettyprint-override""><code>class Divide(object):

    def __new__(cls, a, symbol, b):
        result = None
        if symbol == ""/"":
            result = a/b        
        return result


print(Divide(5,""/"",2))
</code></pre>

<p>This yields the below output</p>

<pre class=""lang-py prettyprint-override""><code>2.5
</code></pre>
","0","","0","1809","104","9","372","60018472","60018531","<p>How do I perform calculations with strings? Like <strong><em>suppose</em></strong> I have:</p>

<pre><code>a=('/')
print(10, a, 5)
</code></pre>

<p>How do I get the answer as '2'? Because 10/5 is 2.</p>
"
"60018489","<p>If <code>NaN</code>s are missing values you can pass columns names like <code>list</code>:</p>

<pre><code>cols = ['Col1','Col2','Col3']
df[cols]=df[cols].bfill()
</code></pre>

<p>If <code>NaN</code>s are strings first replace strings to numeric with missing values for non numbers:</p>

<pre><code>cols = ['Col1','Col2','Col3']
df[cols]=df[cols].apply(lambda x: pd.to_numeric(x, errors='coerce')).bfill()
</code></pre>

<p>If want use your solution:</p>

<pre><code>for col in ['Col1','Col2','Col3']:
    df[col]= pd.to_numeric(df[col], errors='coerce').bfill()

print (df)
     Criteria  Col1  Col2  Col3
0  Jan10Sales  12.0  13.0   4.0
1  Feb10Sales   1.0   3.0   4.0
2  Mar10Sales   5.0  13.0  14.0
3  Apr10Sales   5.0  18.0  12.0
4  May10Sales   6.0  18.0  19.0
</code></pre>

<p>But if last rows has missing values, back filling not repalce them, because not exist next non missing value:</p>

<pre><code>print (df)
     Criteria Col1 Col2 Col3
0  Jan10Sales   12   13  NAN
1  Feb10Sales    1    3    4
2  Mar10Sales  NAN   13   14
3  Apr10Sales    5  NAN   12
4  May10Sales    6   18  NaN

cols = ['Col1','Col2','Col3']
df[cols]=df[cols].apply(lambda x: pd.to_numeric(x, errors='coerce')).bfill()
print (df)

     Criteria  Col1  Col2  Col3
0  Jan10Sales  12.0  13.0   4.0
1  Feb10Sales   1.0   3.0   4.0
2  Mar10Sales   5.0  13.0  14.0
3  Apr10Sales   5.0  18.0  12.0
4  May10Sales   6.0  18.0   NaN
</code></pre>

<p>Then is possible chain <code>bfill</code> and <code>ffill</code>:</p>

<pre><code>df[cols]=df[cols].apply(lambda x: pd.to_numeric(x, errors='coerce')).bfill().ffill()
print (df)
     Criteria  Col1  Col2  Col3
0  Jan10Sales  12.0  13.0   4.0
1  Feb10Sales   1.0   3.0   4.0
2  Mar10Sales   5.0  13.0  14.0
3  Apr10Sales   5.0  18.0  12.0
4  May10Sales   6.0  18.0  12.0
</code></pre>
","8","2020-02-01 16:02:12","4","615041","23439","1483","126104","60018473","60018489","<p>Some of my NANs are strings and some of my NANs are numeric missing values, how to use bfill and ffill in both cases? </p>

<p>df</p>

<pre><code>Criteria      Col1   Col2   Col3     Col4
Jan10Sales     12      13     NAN     NAN
Feb10Sales     1        3      4      ABC
Mar10Sales      NAN      13     14    XY
Apr10Sales      5      NAN     12      V 
May10Sales      6      18     19      AB
</code></pre>
"
"60018588","<p>You may try this:</p>

<pre><code>for cols in ['Col1','Col2','Col3']:
    df[cols].fillna(method='bfill', inplace=True)
</code></pre>

<p><a href=""https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.fillna.html"" rel=""nofollow noreferrer"">pandas.DataFrame.fillna</a></p>
","0","","1","667","321","50","200","60018473","60018489","<p>Some of my NANs are strings and some of my NANs are numeric missing values, how to use bfill and ffill in both cases? </p>

<p>df</p>

<pre><code>Criteria      Col1   Col2   Col3     Col4
Jan10Sales     12      13     NAN     NAN
Feb10Sales     1        3      4      ABC
Mar10Sales      NAN      13     14    XY
Apr10Sales      5      NAN     12      V 
May10Sales      6      18     19      AB
</code></pre>
"
"60018647","<blockquote>
<pre><code>I guess string 'NAN' does not mean Non-Value Nan, you already got the solution, you can check my code too
</code></pre>
</blockquote>

<pre><code>df = df[df.ne('NAN')].bfill()

     Criteria Col1 Col2 Col3
0  Jan10Sales   12   13    4
1  Feb10Sales    1    3    4
2  Mar10Sales    5   13   14
3  Apr10Sales    5   18   12
4  May10Sales    6   18   19
</code></pre>
","0","","1","444","28","5","38","60018473","60018489","<p>Some of my NANs are strings and some of my NANs are numeric missing values, how to use bfill and ffill in both cases? </p>

<p>df</p>

<pre><code>Criteria      Col1   Col2   Col3     Col4
Jan10Sales     12      13     NAN     NAN
Feb10Sales     1        3      4      ABC
Mar10Sales      NAN      13     14    XY
Apr10Sales      5      NAN     12      V 
May10Sales      6      18     19      AB
</code></pre>
"
"60018540","<p>You can use <a href=""https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.isin.html"" rel=""nofollow noreferrer"">pandas.DataFrame.isin</a> followed by <a href=""https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.any.html"" rel=""nofollow noreferrer"">pandas.DataFrame.any</a>:</p>

<pre><code>df[df.isin([10]).any(axis = 1)]

   A    B   C   D   F
0   abc 10  24  32  54
1   cdf 9   10  34  98
3   fgd 1   9   2   10
</code></pre>
","0","","1","4004","1850","24","762","60018478","60018546","<p>I have a unstructured Xslx file. I want to get the full row if the values are present in the sheet. For example</p>

<pre><code>A     B    C    D   F  

abc  10   24   32   54
cdf  9    10   34   98
mgl  11   90   21   98
fgd  1    9     2   10

</code></pre>

<p>I want to get if the 10 value present in the sheet to get the full row values</p>

<p>output =>  </p>

<pre><code>
abc  10   24   32   54

cdf  9    10   34   98

fgd  1    9     2   10
</code></pre>

<p>thanks for the contributions</p>
"
"60018546","<p>Use <a href=""http://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.eq.html"" rel=""nofollow noreferrer""><code>DataFrame.eq</code></a> with <a href=""http://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.any.html"" rel=""nofollow noreferrer""><code>DataFrame.any</code></a> for test if at least one <code>True</code> per rows:</p>

<pre><code>df = pd.read_excel('file.xlsx')

df1 = df[df.eq(10).any(axis=1)]
</code></pre>

<p>Or:</p>

<pre><code>df1 = df[(df == 10).any(axis=1)]

print (df1)
     A   B   C   D   F
0  abc  10  24  32  54
1  cdf   9  10  34  98
3  fgd   1   9   2  10
</code></pre>
","14","2020-02-01 16:03:28","2","615041","23439","1483","126104","60018478","60018546","<p>I have a unstructured Xslx file. I want to get the full row if the values are present in the sheet. For example</p>

<pre><code>A     B    C    D   F  

abc  10   24   32   54
cdf  9    10   34   98
mgl  11   90   21   98
fgd  1    9     2   10

</code></pre>

<p>I want to get if the 10 value present in the sheet to get the full row values</p>

<p>output =>  </p>

<pre><code>
abc  10   24   32   54

cdf  9    10   34   98

fgd  1    9     2   10
</code></pre>

<p>thanks for the contributions</p>
"
"60020092","<p>add a file called <code>__init__.py</code> to you folder</p>

<p>this tells python that the folder is importable</p>
","0","2020-02-04 12:06:24","1","131","8","1","37","60018518","60020092","<p>I had a Django project in which I had a file named <code>itemA.py</code>. Then I deleted that file and instead created a foldern with an identical name in which I placed files. So the new structure looked something like this:</p>

<pre><code>itemA
   itemB.py
   itemC.py
   ...
</code></pre>

<p>Before that change, when <code>itemA</code> was a file, it contained a definition for a serializer which was imported elsewhere.</p>

<p>So after the change, when I ran the project on my local PC, I ran into an error saying:</p>

<blockquote>
  <p>ImportError: No module named 'rest_main.serializers.sms';
  'rest_main.serializers' is not a package</p>
</blockquote>

<p>On my local PC, I fixed the issue instantly removing the <code>itemA.pyc</code> file. But when I pushed the changes to the remote server, the same trick did not help. I also ran the  <code>find . -name ""*.pyc"" -exec rm -f {} \;</code> command. But still no success...In bitbucket, all the pyc files are under gitignore...</p>
"
"60018643","<p>I believe you can use a Poisson distribution:</p>

<pre><code>from numpy.random import poisson
index = poisson()
return sample[min(len(sample, index)]
</code></pre>

<p>See <a href=""https://en.wikipedia.org/wiki/Poisson_distribution"" rel=""nofollow noreferrer"">Wikipedia</a> for more details on this distribution.</p>

<p>Note: This is valid only if you don't have any requirements for how the prioritization is done.</p>
","0","","0","88","4","0","9","60018532","60018908","<p>I have an array of objects with a corresponding probability for each, say</p>

<pre><code>sample = [a, b, c, d, e, f]
probability = [0.1, 0.15, 0.6, 0.05, 0.03, 0.07]
</code></pre>

<p>For most functions in my class this is perfect to use with np.random.choice as I want to select the values with the highest percentage chance.</p>

<p>On one of the functions though, I need it to be biased to the values with a lower probability (i.e. more likely to pick e and d in the sample than c).</p>

<p>Is there a function that can do this or do I need to consider converting the probability to some inverse probability like</p>

<pre><code>inverse_probability = [(1-x) for x in probability]
inverse_probability = [x/sum(inverse_probability) for x in probability]
</code></pre>

<p>and then use this in the np.random.choice function?</p>

<p>Thanks in advance!</p>
"
"60018908","<p>This is a simple solution but should solve your problem:</p>

<pre><code>sample = ['a', 'b', 'c', 'd', 'e', 'f']
probability = [0.1, 0.15, 0.6, 0.05, 0.03, 0.07]
np.random.choice(a=sample, p=probability)

</code></pre>

<p>Solution 1:</p>

<pre><code>inverse_probability = [(1-x) for x in probability]
inverse_probability = [x/sum(inverse_probability) for x in inverse_probability]
np.random.choice(a=sample, p=inverse_probability)
</code></pre>

<p>Solution 2:</p>

<pre><code>inverse_probability = [1/x for x in probability]
inverse_probability = [x/sum(inverse_probability) for x in inverse_probability]
np.random.choice(a=sample, p=inverse_probability)
</code></pre>
","0","","0","1821","28","5","119","60018532","60018908","<p>I have an array of objects with a corresponding probability for each, say</p>

<pre><code>sample = [a, b, c, d, e, f]
probability = [0.1, 0.15, 0.6, 0.05, 0.03, 0.07]
</code></pre>

<p>For most functions in my class this is perfect to use with np.random.choice as I want to select the values with the highest percentage chance.</p>

<p>On one of the functions though, I need it to be biased to the values with a lower probability (i.e. more likely to pick e and d in the sample than c).</p>

<p>Is there a function that can do this or do I need to consider converting the probability to some inverse probability like</p>

<pre><code>inverse_probability = [(1-x) for x in probability]
inverse_probability = [x/sum(inverse_probability) for x in probability]
</code></pre>

<p>and then use this in the np.random.choice function?</p>

<p>Thanks in advance!</p>
"
"60018985","<p><strong>Here's a simple modification of your code that handles part 1 &amp; 2</strong></p>

<p>Mods based upon the following</p>

<ol>
<li>Use Python variable naming convention <a href=""https://www.python.org/dev/peps/pep-0008/#naming-conventions"" rel=""nofollow noreferrer"">Pep
8</a></li>
<li>Use tab delimited line to avoid having to work with fixed field
widths</li>
<li>Use <a href=""https://www.programiz.com/python-programming/methods/string/lower"" rel=""nofollow noreferrer"">lower()</a> to provide case insensitive comparison</li>
<li>Use string <a href=""https://www.geeksforgeeks.org/title-in-python/"" rel=""nofollow noreferrer"">title()</a>
to ensure the first letter of each word is capitalized for author
and book name</li>
</ol>

<p><strong>Refactored Code</strong></p>

<pre><code>while True:
  menu = input(""1. Add a new book\n2. Search for a new book by a given author\n3. End\n"")
  if menu in ('1', '2', '3'):
    menu = int(menu)
  else:
    print('Error -- Menu needs to be 1, 2, or 3')
    continue

  if menu == 1:
      author = input(""Author: "")
      book = input(""Book: "")
      price = input(""Price: "")
      copies = input(""Copies: "")

      line = '\t'.join([author.title(), book.title(), price, copies])
      with  open(""BOOKS.txt"",""a"") as books:
        print(line)
        books.write(line + ""\n"")

  elif menu == 2:
      author_search = input(""Author name for search: "")
      if not author_search:
        print(""Need author's name"")
        continue  # quit on blank line for author

      author_search = author_search.lower()
      with open(""BOOKS.txt"",""r"") as books:
        found = False
        for line in books:
          # Will print all books by this author
          book_info = line.rstrip().split(""\t"")

          if author_search == book_info[0].lower(): # use lower to make case insensitive match
            found = True
            print('&gt;&gt;&gt; Found Author')
            author, bookname, price, copies = book_info
            print(f'Author name: {author.title()}') # capitable firs letter of each name
            print(f'Book: {bookname.title()}')
            print(f'Price: {price}')
            print(f'Copies: {copies}')
        if not found:
          print('Author not found')
  else:
    break
</code></pre>
","2","2020-02-01 18:49:59","0","10876","714","1","925","60018556","60018985","<p>The aim of my program is to display a menu that will be able to provide you with the ability to add a new ""Book"" with it's details like author, price and copies to a text file. The second part of the program should ask a user for an input of an Author's name which then the program has to look for that Author's name in the text file and display the books, prices and copies related to that Author. My issue is I am not sure exactly how to do the second part.A ""line"" is divided into 4 parts, Author, book, Price and Copies. Author holds 16 characters, book holds 20 characters, price holds 5 and copies hold 2. Let's say the author is J.K. Rowling, that is 12 characters, I have a function that adds "" ""(spaces) to satisfy the condition of it being 16. Same goes for all the divisions. By the end of it let's say it's J.K. Rowling    Harry Potter Book 2 12.9912. 
Author: ""J.K. Rowling    ""
Book: ""Harry Potter Book 2 ""
Price: ""12.99""
Copies: ""12""
That's technically the explanation for the first part. The second part should search for ""J.K. Rowling"" and then get the results of:</p>

<p>Author: ""J.K. Rowling    ""
Book: ""Harry Potter Book 2 ""
Price: ""12.99""
Copies: ""12""</p>

<p>If there is a much more efficient way than this then it would be greatly appreciated but for now part 2 is the main issue.</p>

<p>p.s. It has to be done through the text file</p>

<p>Full Program(part 1 works):</p>

<pre><code>def AddSpaces(auth,numb):
    print(""Runs"")
    while len(auth) &lt; numb:
        auth = auth + "" ""
    return (auth)



menu = 1
while menu &lt;= 2:
    menu = int(input(""1. Add a new book\n2. Search for a new book by a given author\n3. End""))
    if menu ==1:

        BOOKS = open(""BOOKS.txt"",""a"")

        Author = str(input(""Author: ""))
        if len(Author) &lt; 16:
            Author = AddSpaces(Author,16)
        while len(Author) &gt; 16:
            Author = str(input(""Author: ""))
            Author = AddSpaces(Author,16)
        print(Author)

        Book = str(input(""Book: ""))
        if len(Book) &lt; 20:
            Book = AddSpaces(Book,20)
        while len(Book) &gt; 16:
            Book = str(input(""Book: ""))
            Book = AddSpaces(Book,20)
        print(Book)

        Price = str(input(""Price: ""))
        while len(Price)&gt;5:
            Price = str(input(""Price: ""))

        Copies = str(input(""Copies: ""))
        while len(Copies)&gt;2:
            Copies = str(input(""Copies: ""))

        line = Author + Book + Price + Copies +""\n""
        print(line)
        BOOKS.write(line)
        BOOKS.close()


    elif menu == 2:
        BOOKS = open(""BOOKS.txt"",""r"")
        while True:
            AuthorSearch = str(input(""Author name for search: ""))
            if len(AuthorSearch) &lt; 16:
                AuthorSearch = AddSpaces(AuthorSearch,16)
            while len(AuthorSearch) &gt; 16:
                AuthorSearch = str(input(""Author name for search: ""))
                AuthorSearch = AddSpaces(AuthorSearch,16)
            print(AuthorSearch)

            n = BOOKS.read()
            if n == """":
                print(""End of file, no books found"")
                break
            if AuthorSearch == line[:16]:
                print (""Author found."")
                print (""Author name: "") + (line[:16])
                print (""Book name: "") + (line[17:36])
                print (""Price: "") + (line[37:41])
                print (""Copies: "") + (line[42:43])
</code></pre>
"
"60018731","<p><code>model.eval()</code> is a kind of switch for some specific layers/parts of the model that behave differently during training and inference (evaluating) time. For example, Dropouts Layers, BatchNorm Layers etc. You need to turn off them during model evaluation, and <code>.eval()</code> will do it for you. In addition, the common practice for evaluating/validation is using <code>torch.no_grad()</code> in pair with <code>model.eval()</code> to turn off gradients computation:</p>

<pre class=""lang-py prettyprint-override""><code># evaluate model:
model.eval()

with torch.no_grad():
    ...
    out_data = model(data)
    ...
</code></pre>

<p>BUT, don't forget to turn back to <code>training</code> mode after eval step:</p>

<pre class=""lang-py prettyprint-override""><code># training step
...
model.train()
...
</code></pre>
","8","","101","4203","546","8","215","60018578","60018731","<p>I am using <a href=""https://github.com/natanielruiz/deep-head-pose/blob/master/code/train_hopenet.py"" rel=""noreferrer"">this code</a>, and saw <code>model.eval()</code> in some cases.</p>
<p>I understand it is supposed to allow me to &quot;evaluate my model&quot;, but I don't understand when I should and shouldn't use it, or how to turn if off.</p>
<p>I would like to run the above code to train the network, and also be able to run validation every epoch. I wasn't able to do it still.</p>
"
"63970021","<p><a href=""https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.eval"" rel=""nofollow noreferrer""><code>model.eval</code></a> is a method of <a href=""https://pytorch.org/docs/stable/generated/torch.nn.Module.html"" rel=""nofollow noreferrer""><code>torch.nn.Module</code></a>:</p>
<blockquote>
<h3><code>eval()</code></h3>
<p>Sets the module in evaluation mode.</p>
<p>This has any effect only on certain modules. See documentations of particular modules for details of their behaviors in training/evaluation mode, if they are affected, e.g. <a href=""https://pytorch.org/docs/stable/generated/torch.nn.Dropout.html#torch.nn.Dropout"" rel=""nofollow noreferrer""><code>Dropout</code></a>, <code>BatchNorm</code>, etc.</p>
<p>This is equivalent with <a href=""https://pytorch.org/docs/stable/generated/torch.nn.Module.html?highlight=eval#torch.nn.Module.train"" rel=""nofollow noreferrer""><code>self.train(False)</code></a>.</p>
</blockquote>
<p>The opposite method is <a href=""https://stackoverflow.com/a/51433411/5884955"">model.train</a> explained nicely by Umang Gupta.</p>
","0","2021-03-25 08:18:36","6","25764","1013","177","3051","60018578","60018731","<p>I am using <a href=""https://github.com/natanielruiz/deep-head-pose/blob/master/code/train_hopenet.py"" rel=""noreferrer"">this code</a>, and saw <code>model.eval()</code> in some cases.</p>
<p>I understand it is supposed to allow me to &quot;evaluate my model&quot;, but I don't understand when I should and shouldn't use it, or how to turn if off.</p>
<p>I would like to run the above code to train the network, and also be able to run validation every epoch. I wasn't able to do it still.</p>
"
"65762803","<p>An extra addition to the above answers:</p>
<p>I recently started working with <a href=""https://pypi.org/project/pytorch-lightning/"" rel=""nofollow noreferrer"">Pytorch-lightning</a>, which wraps much of the boilerplate in the training-validation-testing pipelines.</p>
<p>Among other things, it makes <code>model.eval()</code> and <code>model.train()</code> near redundant by allowing the <code>train_step</code> and <code>validation_step</code> callbacks which wrap the <code>eval</code> and <code>train</code> so you never forget to.</p>
","2","","1","8768","1847","39","1003","60018578","60018731","<p>I am using <a href=""https://github.com/natanielruiz/deep-head-pose/blob/master/code/train_hopenet.py"" rel=""noreferrer"">this code</a>, and saw <code>model.eval()</code> in some cases.</p>
<p>I understand it is supposed to allow me to &quot;evaluate my model&quot;, but I don't understand when I should and shouldn't use it, or how to turn if off.</p>
<p>I would like to run the above code to train the network, and also be able to run validation every epoch. I wasn't able to do it still.</p>
"
"66843176","<h3><a href=""https://stackoverflow.com/a/66526891/9067615""><code>model.train()</code></a></h3>
<p>Sets your model in <strong>train</strong>ing mode:</p>
<ul>
<li>makes Normalisation layers use per-batch statistics (e.g. <code>BatchNorm</code>, <code>InstanceNorm</code>)</li>
<li>activates <code>Dropout</code> layers (including sub-modules of RNN modules <a href=""https://stackoverflow.com/questions/66534762/which-pytorch-modules-are-affected-by-model-eval-and-model-train"">etc</a>)</li>
</ul>
<h3><code>model.eval()</code></h3>
<p>Sets your model in <strong>eval</strong>uation (inference) mode:</p>
<ul>
<li>makes Normalisation layers use running statistics</li>
<li>de-activates <code>Dropout</code> layers</li>
</ul>
<p>Equivalent to <code>model.train(False)</code>.</p>
<hr />
<p>You can turn off evaluation mode by running <code>model.train()</code>. You should use it when running your model as an inference engine - i.e. when testing, validating, and predicting (though practically it will make no difference if your model does not include any of the <a href=""https://stackoverflow.com/a/66526891/9067615"">differently behaving layers</a>).</p>
","0","2021-03-29 06:56:48","0","6005","1870","96","595","60018578","60018731","<p>I am using <a href=""https://github.com/natanielruiz/deep-head-pose/blob/master/code/train_hopenet.py"" rel=""noreferrer"">this code</a>, and saw <code>model.eval()</code> in some cases.</p>
<p>I understand it is supposed to allow me to &quot;evaluate my model&quot;, but I don't understand when I should and shouldn't use it, or how to turn if off.</p>
<p>I would like to run the above code to train the network, and also be able to run validation every epoch. I wasn't able to do it still.</p>
"
"60018962","<p>They have the same hame since all the processes are forked from the same master process. </p>

<p>You need to use dedicated system tools to rename process name. E.g. <code>setproctitle</code> module:
<code>pip install setproctitle</code></p>

<p>Then in in the process function call <code>setproctitle.setproctitle(""new child process name"")</code>.</p>

<p>Here is a small example:</p>

<pre><code>from multiprocessing import Process
import setproctitle
import time

def a_worker():
    setproctitle.setproctitle(""procA"")
    time.sleep(10)

def b_worker():
    setproctitle.setproctitle(""procB"")
    time.sleep(10)

if __name__ == ""__main__"":
    print(""Master process title:"", setproctitle.getproctitle())

    a_proc = Process(target=a_worker)
    b_proc = Process(target=b_worker)

    # Spawn processes
    a_proc.start() 
    b_proc.start()

    # Wait for processes to terminate
    a_proc.join()
    b_proc.join()

    print(""Master process title after kids:"", setproctitle.getproctitle())
</code></pre>

<p>Output of <code>ps -fu</code>:</p>

<pre><code>363  5.2  0.1  29736 10524 tty1     S    01:25   0:00  \_ python3 ab.py
370  0.0  0.0  29736  4424 tty1     S    01:25   0:00      \_ procA
371  0.2  0.0  29736  4216 tty1     S    01:25   0:00      \_ procB
</code></pre>
","0","","0","1405","93","2","60","60018603","60018962","<p>I am using Python's multiprocessing library. Inside the main process, I create another process. When I do <code>ps aux</code>  on terminal I get two entries with same name</p>

<pre><code>ps aux | grep multithreadTest
abhishek  9017 57.6  0.1 121888 11412 pts/8    Rl+  21:09   0:04 python multithreadTest.py
abhishek  9018 16.2  0.0  48156  7096 pts/8    R+   21:09   0:01 python multithreadTest.py
</code></pre>

<p>Both these processes need to communicate with each other and are doing two different tasks. It is slightly confusing which pid is doing what because they show exact same name. This is bad for troubleshooting purposes. My code is going to be deployed on production servers and will be managed by SRE guys. It might be confusing for them that why there are two instances of same task.</p>

<p>Is there a way I can provide a more descriptive name to be displayed on ps aux for the process that I am creating?  I know it is possible in C++.</p>

<p>One way is to write two python scripts with different names and have a manager bash script that calls both of them. But in this way, both of them will become unrelated and managing and communicating between them will be difficult.</p>

<p>Any help will be appreciated.</p>
"
"60018712","<p><code>sum(foo)</code> simply uses the definition of <code>+</code> for the initial value. By default, the initial value is <code>0</code>, so <code>sum(g)</code> would fail for a list since addition of lists and ints isn't defined. By passing an explicit initial value of <code>[]</code>, this forces <code>sum(foo, [])</code> to be equal to <code>foo[0] + foo[1] + ... + foo[n-1] + []</code>, as observed.</p>

<pre><code>&gt;&gt;&gt; sum([[1], [2]])
Traceback (most recent call last):
  File ""&lt;stdin&gt;"", line 1, in &lt;module&gt;
TypeError: unsupported operand type(s) for +: 'int' and 'list'
&gt;&gt;&gt; sum([[1], [2]], [])
[1, 2]
</code></pre>

<p>The exception to this definition is that you cannot use <code>sum</code> with a list of <code>str</code> values, even if you specify <code>""""</code> as the initial value. This is a hard-coded exception, resulting in a <code>TypeError</code> with a suggestion to use <code>str.join</code> instead.</p>

<pre><code>&gt;&gt;&gt; sum([""foo"", ""bar""])
Traceback (most recent call last):
  File ""&lt;stdin&gt;"", line 1, in &lt;module&gt;
TypeError: unsupported operand type(s) for +: 'int' and 'str'
&gt;&gt;&gt; sum([""foo"", ""bar""], """")
Traceback (most recent call last):
  File ""&lt;stdin&gt;"", line 1, in &lt;module&gt;
TypeError: sum() can't sum strings [use ''.join(seq) instead]
</code></pre>
","0","","3","383179","18330","5892","20227","60018656","60022923","<p>When I finished leetcode 1313, I find a special usage of built-in <code>sum</code> function.</p>

<h2>The Leetcode Problem 1313</h2>

<p>We are given a list <code>nums</code> of integers representing a list compressed with run-length encoding.</p>

<p>Consider each adjacent pair of elements <code>[a, b] = [nums[2*i], nums[2*i+1]] (with i &gt;= 0)</code>.  For each such pair, there are <code>a</code> elements with value <code>b</code> in the decompressed list.</p>

<p>Return the decompressed list.</p>

<p> </p>

<p>Example 1:</p>

<blockquote>
<pre><code>Input: nums = [1,2,3,4]
Output: [2,4,4,4]
Explanation: The first pair [1,2] means we have freq = 1 and val = 2 so we generate the array [2].
The second pair [3,4] means we have freq = 3 and val = 4 so we generate [4,4,4].
At the end the concatenation [2] + [4,4,4,4] is [2,4,4,4].
</code></pre>
</blockquote>

<h2>There is a solution using <code>sum</code></h2>

<pre><code>nums = [1,2,3,4]
g = ([b] * a for a, b in zip(nums[::2], nums[1::2]))
print(list(g))
g = ([b] * a for a, b in zip(nums[::2], nums[1::2]))
print(sum(g,[]))
</code></pre>

<p>Output:</p>

<blockquote>
<pre><code>[[2], [4, 4, 4]]
[2, 4, 4, 4]
</code></pre>
</blockquote>

<h2>My question</h2>

<p>I can't tell why <code>sum</code> can deal with a nested list in this situation. Can any one tell me about it? Or some other functions behavior like this?</p>

<p>Here is the <a href=""https://docs.python.org/3/library/functions.html#sum"" rel=""nofollow noreferrer"">official guide</a> for built-in <code>sum</code>.</p>
"
"60022923","<h2>Short-answer</h2>

<p>The given code-fragment runs successive list concatenations.</p>

<h2>How it works</h2>

<p>Roughly the built-in <a href=""https://docs.python.org/3/library/functions.html#sum"" rel=""nofollow noreferrer""><em>sum()</em></a> function works like this:</p>

<pre><code>def sum(iterable, /, start=0):
    total = start
    for x in iterable:
        total = total + x
    return total
</code></pre>

<p>The <code>+</code> operator calls <code>__add__</code> on the left-hand operand so that <code>3 + 4</code> runs as <code>(3).__add__(4)</code>, an addition operation on integers.  Likewise, <code>[10, 20] + [30, 40, 50]</code> runs as <code>[10, 20].__add__([30, 40, 50])</code>, a concatenation operation on lists.</p>

<p>Here's how it plays out in the given example:</p>

<pre><code>&gt;&gt;&gt; nums = [1,2,3,4]
&gt;&gt;&gt; g = ([b] * a for a, b in zip(nums[::2], nums[1::2]))
&gt;&gt;&gt; result = []
&gt;&gt;&gt; x = next(g)
&gt;&gt;&gt; result = result + x
&gt;&gt;&gt; result
[2]
&gt;&gt;&gt; x = next(g)
&gt;&gt;&gt; result = result + x
&gt;&gt;&gt; result
[2, 4, 4, 4]
</code></pre>

<h2>Why it is not a good idea</h2>

<p>Successive list concatenations make next list after each addition, so they run at <a href=""https://en.wikipedia.org/wiki/Big_O_notation#Orders_of_common_functions"" rel=""nofollow noreferrer""><code>O(n**2)</code></a> speed, meaning that this a quadratic algorithm that runs excessively slow when given large inputs.</p>

<h2>Better way</h2>

<p>Instead of building new lists at each step, just <a href=""https://docs.python.org/3/library/stdtypes.html#mutable-sequence-types"" rel=""nofollow noreferrer"">extend</a> the base list in-place.  This runs at <a href=""https://en.wikipedia.org/wiki/Big_O_notation#Orders_of_common_functions"" rel=""nofollow noreferrer""><code>O(n)</code></a> linear speed:</p>

<pre><code>&gt;&gt;&gt; nums = [1,2,3,4]
&gt;&gt;&gt; g = ([b] * a for a, b in zip(nums[::2], nums[1::2]))
&gt;&gt;&gt; result = []                 # new list
&gt;&gt;&gt; for x in g:
        result.extend(x)        # extend in-place

&gt;&gt;&gt; result
[2, 4, 4, 4]
</code></pre>

<h2>Even better way</h2>

<p>The <a href=""https://docs.python.org/3/library/itertools.html"" rel=""nofollow noreferrer"">itertools module</a> provides <a href=""https://docs.python.org/3/library/itertools.html#itertools.chain.from_iterable"" rel=""nofollow noreferrer"">a tool for chaining together iterators</a>.  This makes short-work of the problem:</p>

<pre><code>&gt;&gt;&gt; nums = [1,2,3,4]
&gt;&gt;&gt; g = ([b] * a for a, b in zip(nums[::2], nums[1::2]))
&gt;&gt;&gt; list(chain.from_iterable(g))
[2, 4, 4, 4]
</code></pre>

<p>This solution is short, fast and works well even with large inputs.</p>
","0","2020-02-02 03:20:37","4","180179","2778","395","33067","60018656","60022923","<p>When I finished leetcode 1313, I find a special usage of built-in <code>sum</code> function.</p>

<h2>The Leetcode Problem 1313</h2>

<p>We are given a list <code>nums</code> of integers representing a list compressed with run-length encoding.</p>

<p>Consider each adjacent pair of elements <code>[a, b] = [nums[2*i], nums[2*i+1]] (with i &gt;= 0)</code>.  For each such pair, there are <code>a</code> elements with value <code>b</code> in the decompressed list.</p>

<p>Return the decompressed list.</p>

<p> </p>

<p>Example 1:</p>

<blockquote>
<pre><code>Input: nums = [1,2,3,4]
Output: [2,4,4,4]
Explanation: The first pair [1,2] means we have freq = 1 and val = 2 so we generate the array [2].
The second pair [3,4] means we have freq = 3 and val = 4 so we generate [4,4,4].
At the end the concatenation [2] + [4,4,4,4] is [2,4,4,4].
</code></pre>
</blockquote>

<h2>There is a solution using <code>sum</code></h2>

<pre><code>nums = [1,2,3,4]
g = ([b] * a for a, b in zip(nums[::2], nums[1::2]))
print(list(g))
g = ([b] * a for a, b in zip(nums[::2], nums[1::2]))
print(sum(g,[]))
</code></pre>

<p>Output:</p>

<blockquote>
<pre><code>[[2], [4, 4, 4]]
[2, 4, 4, 4]
</code></pre>
</blockquote>

<h2>My question</h2>

<p>I can't tell why <code>sum</code> can deal with a nested list in this situation. Can any one tell me about it? Or some other functions behavior like this?</p>

<p>Here is the <a href=""https://docs.python.org/3/library/functions.html#sum"" rel=""nofollow noreferrer"">official guide</a> for built-in <code>sum</code>.</p>
"
"60076165","<p>The problem was my windows defender firewall. I had to disable it for ""Guest or public networks"" I guess somehow the Ethernet cable connection was classified as public network. </p>
","0","","0","304","35","0","94","60018734","60076165","<p>I'm trying to simulate a network that continuously (at least 24h) exchange data, therefore I connected two Laptops (OS Windows) through Ethernet cable and give each Ethernet port a static IP address (192.168.0.1 and 192.168.0.2). The cable are connected with a switch and on the switch there is a port mirroring the data on Raspi because with Wireshark I would like to analyse the traffic and do some tests.   </p>

<p>I found the code to simulate server and client <a href=""https://github.com/realpython/materials/tree/master/python-sockets-tutorial"" rel=""nofollow noreferrer"">here</a> and I'm using multiconn-client.py and multiconn-server.py. If I test the code on localhost it does work fine but if I change the host with the static IP address of the machine simulating the server than I get WinError 10060.
I read many other similar topics, but since my development environment is peculiar no solution was working for me.    </p>

<p>Maybe it is worth to mention that the laptops are also connected to wifi, at the beginning I thought this was the problem, but when I turned the wifi off I had the same issue.  </p>

<p>EDIT:  </p>

<p>This is the Traceback for client. </p>

<pre><code>Traceback (most recent call last):

File ""&lt;ipython-input-7-1885b422d65a&gt;"", line 1, in &lt;module&gt;
    runfile('C:.../MultiConnectionClient.py', wdir='C.../pyscript')

  File ""C:...Anaconda3\lib\site-packages\spyder_kernels\customize\spydercustomize.py"", line 827, in runfile
    execfile(filename, namespace)

  File ""C:...Anaconda3\lib\site-packages\spyder_kernels\customize\spydercustomize.py"", line 110, in execfile
    exec(compile(f.read(), filename, 'exec'), namespace)

  File ""C:.../MultiConnectionClient.py"", line 68, in &lt;module&gt;
    service_connection(key, mask)

  File ""C:.../MultiConnectionClient.py"", line 49, in service_connection
    sent = sock.sendall(data.outb)  # Send message

OSError: [WinError 10057] Eine Anforderung zum Senden oder Empfangen von Daten wurde verhindert, da der Socket nicht verbunden ist und (beim Senden über einen Datagrammsocket mit einem sendto-Aufruf) keine Adresse angegeben wurde
</code></pre>

<p>Concerning the server I tried some debugging with TCPView and although the server seems to start and the code is executed I find no trace of it on TCPView. </p>
"
"60018761","<p>Do not include the parentheses in the function passed to:</p>

<pre><code>schedule.every(interval).minutes.do()
</code></pre>

<p>So,  this this line:</p>

<pre><code>schedule.every(interval).minutes.do(self.trigger_testsuite())
</code></pre>

<p>Should be:</p>

<pre><code>schedule.every(interval).minutes.do(self.trigger_testsuite)
</code></pre>

<p>And same for all the others. Final code becomes:</p>

<pre><code>import schedule
    import time


class Scheduler():

    def trigger_testsuite(self):
        print(""I am working as expected."")

    def scheule_a_job(self, type=""Secs"", interval=5):

        if (type == ""Mins""):
            schedule.every(interval).minutes.do(self.trigger_testsuite)

        if (type == ""Secs""):
            schedule.every(interval).seconds.do(self.trigger_testsuite)

        if (interval == ""Hrs""):
            schedule.every().hour.do(self.trigger_testsuite)

        if (interval == ""Daily""):
            schedule.every().day.at(""10:00"").do(self.trigger_testsuite)

        while True:
            schedule.run_pending()
            time.sleep(1)


if __name__ == ""__main__"":
    run = Scheduler()
    run.scheule_a_job()
</code></pre>
","0","","1","3981","1105","97","457","60018745","60018761","<p>I am getting the following error while running scheduler library. I did go through similar question and answers but somehow not able to identify the root cuase the error. Could some help where I am going wrong?</p>

<blockquote>
  <p><em>TypeError: the first argument must be callable</em>  </p>
</blockquote>

<pre><code>import schedule
    import time


class Scheduler():

    def trigger_testsuite(self):
        print(""I am working as expected."")

    def scheule_a_job(self, type=""Secs"", interval=5):

        if (type == ""Mins""):
            schedule.every(interval).minutes.do(self.trigger_testsuite())

        if (type == ""Secs""):
            schedule.every(interval).seconds.do(self.trigger_testsuite())

        if (interval == ""Hrs""):
            schedule.every().hour.do(self.trigger_testsuite())

        if (interval == ""Daily""):
            schedule.every().day.at(""10:00"").do(self.trigger_testsuite())

        while True:
            schedule.run_pending()
            time.sleep(1)


if __name__ == ""__main__"":
    run = Scheduler()
    run.scheule_a_job()
</code></pre>

<p><strong>TraceBack:-</strong></p>

<pre><code>I am working as expected.
Traceback (most recent call last):
  File ""foo/Scheduler.py"", line 31, in &lt;module&gt;
    run.scheule_a_job()
  File ""foo/Scheduler.py"", line 16, in scheule_a_job
    schedule.every(interval).seconds.do(self.trigger_testsuite())
  File ""foo\Python\Python38-32\lib\site-packages\schedule\__init__.py"", line 440, in do
    self.job_func = functools.partial(job_func, *args, **kwargs)
TypeError: the first argument must be callable

Process finished with exit code 1
</code></pre>
"
"60019013","<p>Avoid <code>DataFrame.apply</code> (which is usually run as a <a href=""https://github.com/pandas-dev/pandas/blob/master/pandas/core/apply.py"" rel=""nofollow noreferrer"">hidden loop</a>) and instead consider nested conditional logic with <a href=""https://docs.scipy.org/doc/numpy/reference/generated/numpy.where.html"" rel=""nofollow noreferrer""><code>numpy.where</code></a> on columns:</p>

<pre><code>match['Winning Team'] = np.where(match['home_team_goal'] &gt; match['away_team_goal'],
                                 match['Home Team'],
                                 np.where(match['home_team_goal'] &lt; match['away_team_goal'],
                                          match['Away Team'],
                                          np.nan
                                         )
                                )
</code></pre>
","2","","1","86379","5219","102","7124","60018771","60019016","<p>I have an dataframe of football results, and am attempting to make a new column at the end of the dataframe which shows which team won. I'm attempting to do this using <code>df.apply</code>. Here is what i have so far:</p>

<pre><code>def match_winner(winner,home_team,away_team,home_goals,away_goals):

    if home_goals&gt;away_goals:
        winner = home_team
    elif home_goals&lt;away_goals:
        winner = away_team
    else:
        winner = ""None""

match['Winning Team'] =""""
match['Winning Team'].apply(match_winner,args=[match['Home Team'],match['Away Team'],match['home_team_goal'],match['away_team_goal']])
</code></pre>

<p>And here is the structure of the <code>match</code> dataframe:</p>

<pre><code>&lt;bound method DataFrame.info of           id  country_id  league_id     season  stage                 date  \
145      146           1          1  2008/2009     24  2009-02-27 00:00:00   
153      154           1          1  2008/2009     25  2009-03-08 00:00:00   
155      156           1          1  2008/2009     25  2009-03-07 00:00:00   
162      163           1          1  2008/2009     26  2009-03-13 00:00:00   
168      169           1          1  2008/2009     26  2009-03-14 00:00:00   
...      ...         ...        ...        ...    ...                  ...   
25972  25973       24558      24558  2015/2016      8  2015-09-13 00:00:00   
25974  25975       24558      24558  2015/2016      9  2015-09-22 00:00:00   
25975  25976       24558      24558  2015/2016      9  2015-09-23 00:00:00   
25976  25977       24558      24558  2015/2016      9  2015-09-23 00:00:00   
25978  25979       24558      24558  2015/2016      9  2015-09-23 00:00:00   

       match_api_id  home_team_api_id  away_team_api_id  home_team_goal  \
145          493017              8203              9987               2   
153          493025              9984              8342               1   
155          493027              8635             10000               2   
162          493034              8203              8635               2   
168          493040             10000              9999               0   
...             ...               ...               ...             ...   
25972       1992089             10243             10191               3   
25974       1992091             10190             10191               1   
25975       1992092              9824             10199               1   
25976       1992093              9956             10179               2   
25978       1992095             10192              9931               4   

       away_team_goal  goal shoton shotoff foulcommit  card cross corner  \
145                 1  None   None    None       None  None  None   None   
153                 3  None   None    None       None  None  None   None   
155                 0  None   None    None       None  None  None   None   
162                 1  None   None    None       None  None  None   None   
168                 0  None   None    None       None  None  None   None   
...               ...   ...    ...     ...        ...   ...   ...    ...   
25972               3  None   None    None       None  None  None   None   
25974               0  None   None    None       None  None  None   None   
25975               2  None   None    None       None  None  None   None   
25976               0  None   None    None       None  None  None   None   
25978               3  None   None    None       None  None  None   None   

      possession   BSA                Home Team         Away Team  \
145         None  2.25              KV Mechelen          KRC Genk   
153         None  2.38        KSV Cercle Brugge    Club Brugge KV   
155         None  7.00           RSC Anderlecht  SV Zulte-Waregem   
162         None  1.75              KV Mechelen    RSC Anderlecht   
168         None  4.33         SV Zulte-Waregem     KSV Roeselare   
...          ...   ...                      ...               ...   
25972       None   NaN                FC Zürich           FC Thun   
25974       None   NaN            FC St. Gallen           FC Thun   
25975       None   NaN                 FC Vaduz         FC Luzern   
25976       None   NaN  Grasshopper Club Zürich           FC Sion   
25978       None   NaN           BSC Young Boys          FC Basel   

                         League      Country  home_player_1  home_player_2  \
145      Belgium Jupiler League      Belgium          False          False   
153      Belgium Jupiler League      Belgium          False          False   
155      Belgium Jupiler League      Belgium          False          False   
162      Belgium Jupiler League      Belgium          False          False   
168      Belgium Jupiler League      Belgium          False          False   
...                         ...          ...            ...            ...   
25972  Switzerland Super League  Switzerland          False          False   
25974  Switzerland Super League  Switzerland          False          False   
25975  Switzerland Super League  Switzerland          False          False   
25976  Switzerland Super League  Switzerland          False          False   
25978  Switzerland Super League  Switzerland          False          False   

       home_player_3  home_player_4  home_player_5  home_player_6  \
145            False          False          False          False   
153            False          False          False          False   
155            False          False          False          False   
162            False          False          False          False   
168            False          False          False          False   
...              ...            ...            ...            ...   
25972          False          False          False          False   
25974          False          False          False          False   
25975          False          False          False          False   
25976          False          False          False          False   
25978          False          False          False          False   

       home_player_7  home_player_8  home_player_9  home_player_10  \
145            False          False          False           False   
153            False          False          False           False   
155            False          False          False           False   
162            False          False          False           False   
168            False          False          False           False   
...              ...            ...            ...             ...   
25972          False          False          False           False   
25974          False          False          False           False   
25975          False          False          False           False   
25976          False          False          False           False   
25978          False          False          False           False   

       home_player_11  away_player_1  away_player_2  away_player_3  \
145             False          False          False          False   
153             False          False          False          False   
155             False          False          False          False   
162             False          False          False          False   
168             False          False          False          False   
...               ...            ...            ...            ...   
25972           False          False          False          False   
25974           False          False          False          False   
25975           False          False          False          False   
25976           False          False          False          False   
25978           False          False          False          False   

       away_player_4  away_player_5  away_player_6  away_player_7  \
145            False          False          False          False   
153            False          False          False          False   
155            False          False          False          False   
162            False          False          False          False   
168            False          False          False          False   
...              ...            ...            ...            ...   
25972          False          False          False          False   
25974          False          False          False          False   
25975          False          False          False          False   
25976          False          False          False          False   
25978          False          False          False          False   

       away_player_8  away_player_9  away_player_10  away_player_11  \
145            False          False           False           False   
153            False          False           False           False   
155            False          False           False           False   
162            False          False           False           False   
168            False          False           False           False   
...              ...            ...             ...             ...   
25972          False          False           False           False   
25974          False          False           False           False   
25975          False          False           False           False   
25976          False          False           False           False   
25978          False          False           False           False   

      Winning Team  
145                 
153                 
155                 
162                 
168                 
...            ...  
25972               
25974               
25975               
25976               
25978               

[21374 rows x 47 columns]&gt;
</code></pre>

<p>I need to send multiple columns as input arguements in order to find who's won but i'm not sure if <code>.apply()</code> allows you to pass in a series as an argument? Is it possible to do this using <code>.apply()</code>. If so a solution would be helpful, but if anyone knows a better alternative that would also be useful.</p>
"
"60019016","<p>Use <a href=""https://docs.scipy.org/doc/numpy/reference/generated/numpy.select.html"" rel=""nofollow noreferrer""><code>numpy.select</code></a> instead <code>apply</code>, which should be not good idea here (loops under the hood):</p>

<pre><code>match = pd.DataFrame({
        'Home Team':list('abcdef'),
        'Away Team':list('ghijkl'),
         'home_team_goal':[14,5,4,5,5,4],
         'away_team_goal':[7,8,2,4,8,4],
})

m1 = match.home_team_goal&gt;match.away_team_goal
m2 = match.home_team_goal&lt;match.away_team_goal
match['winner'] = np.select([m1, m2], [match['Home Team'],  match['Away Team']], default=None)
print (match)
  Home Team Away Team  home_team_goal  away_team_goal winner
0         a         g              14               7      a
1         b         h               5               8      h
2         c         i               4               2      c
3         d         j               5               4      d
4         e         k               5               8      k
5         f         l               4               4   None
</code></pre>
","1","2020-02-01 18:12:40","2","615041","23439","1483","126104","60018771","60019016","<p>I have an dataframe of football results, and am attempting to make a new column at the end of the dataframe which shows which team won. I'm attempting to do this using <code>df.apply</code>. Here is what i have so far:</p>

<pre><code>def match_winner(winner,home_team,away_team,home_goals,away_goals):

    if home_goals&gt;away_goals:
        winner = home_team
    elif home_goals&lt;away_goals:
        winner = away_team
    else:
        winner = ""None""

match['Winning Team'] =""""
match['Winning Team'].apply(match_winner,args=[match['Home Team'],match['Away Team'],match['home_team_goal'],match['away_team_goal']])
</code></pre>

<p>And here is the structure of the <code>match</code> dataframe:</p>

<pre><code>&lt;bound method DataFrame.info of           id  country_id  league_id     season  stage                 date  \
145      146           1          1  2008/2009     24  2009-02-27 00:00:00   
153      154           1          1  2008/2009     25  2009-03-08 00:00:00   
155      156           1          1  2008/2009     25  2009-03-07 00:00:00   
162      163           1          1  2008/2009     26  2009-03-13 00:00:00   
168      169           1          1  2008/2009     26  2009-03-14 00:00:00   
...      ...         ...        ...        ...    ...                  ...   
25972  25973       24558      24558  2015/2016      8  2015-09-13 00:00:00   
25974  25975       24558      24558  2015/2016      9  2015-09-22 00:00:00   
25975  25976       24558      24558  2015/2016      9  2015-09-23 00:00:00   
25976  25977       24558      24558  2015/2016      9  2015-09-23 00:00:00   
25978  25979       24558      24558  2015/2016      9  2015-09-23 00:00:00   

       match_api_id  home_team_api_id  away_team_api_id  home_team_goal  \
145          493017              8203              9987               2   
153          493025              9984              8342               1   
155          493027              8635             10000               2   
162          493034              8203              8635               2   
168          493040             10000              9999               0   
...             ...               ...               ...             ...   
25972       1992089             10243             10191               3   
25974       1992091             10190             10191               1   
25975       1992092              9824             10199               1   
25976       1992093              9956             10179               2   
25978       1992095             10192              9931               4   

       away_team_goal  goal shoton shotoff foulcommit  card cross corner  \
145                 1  None   None    None       None  None  None   None   
153                 3  None   None    None       None  None  None   None   
155                 0  None   None    None       None  None  None   None   
162                 1  None   None    None       None  None  None   None   
168                 0  None   None    None       None  None  None   None   
...               ...   ...    ...     ...        ...   ...   ...    ...   
25972               3  None   None    None       None  None  None   None   
25974               0  None   None    None       None  None  None   None   
25975               2  None   None    None       None  None  None   None   
25976               0  None   None    None       None  None  None   None   
25978               3  None   None    None       None  None  None   None   

      possession   BSA                Home Team         Away Team  \
145         None  2.25              KV Mechelen          KRC Genk   
153         None  2.38        KSV Cercle Brugge    Club Brugge KV   
155         None  7.00           RSC Anderlecht  SV Zulte-Waregem   
162         None  1.75              KV Mechelen    RSC Anderlecht   
168         None  4.33         SV Zulte-Waregem     KSV Roeselare   
...          ...   ...                      ...               ...   
25972       None   NaN                FC Zürich           FC Thun   
25974       None   NaN            FC St. Gallen           FC Thun   
25975       None   NaN                 FC Vaduz         FC Luzern   
25976       None   NaN  Grasshopper Club Zürich           FC Sion   
25978       None   NaN           BSC Young Boys          FC Basel   

                         League      Country  home_player_1  home_player_2  \
145      Belgium Jupiler League      Belgium          False          False   
153      Belgium Jupiler League      Belgium          False          False   
155      Belgium Jupiler League      Belgium          False          False   
162      Belgium Jupiler League      Belgium          False          False   
168      Belgium Jupiler League      Belgium          False          False   
...                         ...          ...            ...            ...   
25972  Switzerland Super League  Switzerland          False          False   
25974  Switzerland Super League  Switzerland          False          False   
25975  Switzerland Super League  Switzerland          False          False   
25976  Switzerland Super League  Switzerland          False          False   
25978  Switzerland Super League  Switzerland          False          False   

       home_player_3  home_player_4  home_player_5  home_player_6  \
145            False          False          False          False   
153            False          False          False          False   
155            False          False          False          False   
162            False          False          False          False   
168            False          False          False          False   
...              ...            ...            ...            ...   
25972          False          False          False          False   
25974          False          False          False          False   
25975          False          False          False          False   
25976          False          False          False          False   
25978          False          False          False          False   

       home_player_7  home_player_8  home_player_9  home_player_10  \
145            False          False          False           False   
153            False          False          False           False   
155            False          False          False           False   
162            False          False          False           False   
168            False          False          False           False   
...              ...            ...            ...             ...   
25972          False          False          False           False   
25974          False          False          False           False   
25975          False          False          False           False   
25976          False          False          False           False   
25978          False          False          False           False   

       home_player_11  away_player_1  away_player_2  away_player_3  \
145             False          False          False          False   
153             False          False          False          False   
155             False          False          False          False   
162             False          False          False          False   
168             False          False          False          False   
...               ...            ...            ...            ...   
25972           False          False          False          False   
25974           False          False          False          False   
25975           False          False          False          False   
25976           False          False          False          False   
25978           False          False          False          False   

       away_player_4  away_player_5  away_player_6  away_player_7  \
145            False          False          False          False   
153            False          False          False          False   
155            False          False          False          False   
162            False          False          False          False   
168            False          False          False          False   
...              ...            ...            ...            ...   
25972          False          False          False          False   
25974          False          False          False          False   
25975          False          False          False          False   
25976          False          False          False          False   
25978          False          False          False          False   

       away_player_8  away_player_9  away_player_10  away_player_11  \
145            False          False           False           False   
153            False          False           False           False   
155            False          False           False           False   
162            False          False           False           False   
168            False          False           False           False   
...              ...            ...             ...             ...   
25972          False          False           False           False   
25974          False          False           False           False   
25975          False          False           False           False   
25976          False          False           False           False   
25978          False          False           False           False   

      Winning Team  
145                 
153                 
155                 
162                 
168                 
...            ...  
25972               
25974               
25975               
25976               
25978               

[21374 rows x 47 columns]&gt;
</code></pre>

<p>I need to send multiple columns as input arguements in order to find who's won but i'm not sure if <code>.apply()</code> allows you to pass in a series as an argument? Is it possible to do this using <code>.apply()</code>. If so a solution would be helpful, but if anyone knows a better alternative that would also be useful.</p>
"
"60019174","<p>Here's another way: </p>

<p>Creating dataframe with the teams: </p>

<pre><code>results_di = {
    ""Home Team"": [
        ""KV Mechelen"",
        ""KSV Cercle Brugge"",
        ""RSC Anderlecht"",
        ""KV Mechelen"",
        ""SV Zulte-Waregem"",
        ""FC Zürich"",
        ""FC St. Gallen"",
        ""FC Vaduz"",
        ""Grasshopper Club Zürich"",
        ""BSC Young Boys"",
    ],
    ""Away Team"": [
        ""KRC Genk"",
        ""Club Brugge KV"",
        ""SV Zulte-Waregem"",
        ""RSC Anderlecht"",
        ""KSV Roeselare"",
        ""FC Thun"",
        ""FC Thun"",
        ""FC Luzern"",
        ""FC Sion"",
        ""FC Basel"",
    ],
    ""home_team_goal"": [2, 1, 2, 2, 0, 3, 1, 1, 2, 4],
    ""away_team_goal"": [1, 3, 0, 1, 0, 3, 0, 2, 0, 3],
}

df = pd.DataFrame(results_di)
df['winner'] = 'none'
home_win = df['home_team_goal'] - df[""away_team_goal""] &gt; 0
away_win = df[""away_team_goal""] - df['home_team_goal'] &gt; 0

df.loc[home_win, ""winner""] = df.loc[home_win, 'Home Team']
df.loc[away_win, ""winner""] = df.loc[away_win, 'Away Team']
</code></pre>

<p>print(df)</p>

<pre><code>                 Home Team         Away Team  home_team_goal  away_team_goal  \
0              KV Mechelen          KRC Genk               2               1   
1        KSV Cercle Brugge    Club Brugge KV               1               3   
2           RSC Anderlecht  SV Zulte-Waregem               2               0   
3              KV Mechelen    RSC Anderlecht               2               1   
4         SV Zulte-Waregem     KSV Roeselare               0               0   
5                FC Zürich           FC Thun               3               3   
6            FC St. Gallen           FC Thun               1               0   
7                 FC Vaduz         FC Luzern               1               2   
8  Grasshopper Club Zürich           FC Sion               2               0   
9           BSC Young Boys          FC Basel               4               3   

                    winner  
0              KV Mechelen  
1           Club Brugge KV  
2           RSC Anderlecht  
3              KV Mechelen  
4                     none  
5                     none  
6            FC St. Gallen  
7                FC Luzern  
8  Grasshopper Club Zürich  
9           BSC Young Boys  
</code></pre>
","0","","1","2736","261","24","281","60018771","60019016","<p>I have an dataframe of football results, and am attempting to make a new column at the end of the dataframe which shows which team won. I'm attempting to do this using <code>df.apply</code>. Here is what i have so far:</p>

<pre><code>def match_winner(winner,home_team,away_team,home_goals,away_goals):

    if home_goals&gt;away_goals:
        winner = home_team
    elif home_goals&lt;away_goals:
        winner = away_team
    else:
        winner = ""None""

match['Winning Team'] =""""
match['Winning Team'].apply(match_winner,args=[match['Home Team'],match['Away Team'],match['home_team_goal'],match['away_team_goal']])
</code></pre>

<p>And here is the structure of the <code>match</code> dataframe:</p>

<pre><code>&lt;bound method DataFrame.info of           id  country_id  league_id     season  stage                 date  \
145      146           1          1  2008/2009     24  2009-02-27 00:00:00   
153      154           1          1  2008/2009     25  2009-03-08 00:00:00   
155      156           1          1  2008/2009     25  2009-03-07 00:00:00   
162      163           1          1  2008/2009     26  2009-03-13 00:00:00   
168      169           1          1  2008/2009     26  2009-03-14 00:00:00   
...      ...         ...        ...        ...    ...                  ...   
25972  25973       24558      24558  2015/2016      8  2015-09-13 00:00:00   
25974  25975       24558      24558  2015/2016      9  2015-09-22 00:00:00   
25975  25976       24558      24558  2015/2016      9  2015-09-23 00:00:00   
25976  25977       24558      24558  2015/2016      9  2015-09-23 00:00:00   
25978  25979       24558      24558  2015/2016      9  2015-09-23 00:00:00   

       match_api_id  home_team_api_id  away_team_api_id  home_team_goal  \
145          493017              8203              9987               2   
153          493025              9984              8342               1   
155          493027              8635             10000               2   
162          493034              8203              8635               2   
168          493040             10000              9999               0   
...             ...               ...               ...             ...   
25972       1992089             10243             10191               3   
25974       1992091             10190             10191               1   
25975       1992092              9824             10199               1   
25976       1992093              9956             10179               2   
25978       1992095             10192              9931               4   

       away_team_goal  goal shoton shotoff foulcommit  card cross corner  \
145                 1  None   None    None       None  None  None   None   
153                 3  None   None    None       None  None  None   None   
155                 0  None   None    None       None  None  None   None   
162                 1  None   None    None       None  None  None   None   
168                 0  None   None    None       None  None  None   None   
...               ...   ...    ...     ...        ...   ...   ...    ...   
25972               3  None   None    None       None  None  None   None   
25974               0  None   None    None       None  None  None   None   
25975               2  None   None    None       None  None  None   None   
25976               0  None   None    None       None  None  None   None   
25978               3  None   None    None       None  None  None   None   

      possession   BSA                Home Team         Away Team  \
145         None  2.25              KV Mechelen          KRC Genk   
153         None  2.38        KSV Cercle Brugge    Club Brugge KV   
155         None  7.00           RSC Anderlecht  SV Zulte-Waregem   
162         None  1.75              KV Mechelen    RSC Anderlecht   
168         None  4.33         SV Zulte-Waregem     KSV Roeselare   
...          ...   ...                      ...               ...   
25972       None   NaN                FC Zürich           FC Thun   
25974       None   NaN            FC St. Gallen           FC Thun   
25975       None   NaN                 FC Vaduz         FC Luzern   
25976       None   NaN  Grasshopper Club Zürich           FC Sion   
25978       None   NaN           BSC Young Boys          FC Basel   

                         League      Country  home_player_1  home_player_2  \
145      Belgium Jupiler League      Belgium          False          False   
153      Belgium Jupiler League      Belgium          False          False   
155      Belgium Jupiler League      Belgium          False          False   
162      Belgium Jupiler League      Belgium          False          False   
168      Belgium Jupiler League      Belgium          False          False   
...                         ...          ...            ...            ...   
25972  Switzerland Super League  Switzerland          False          False   
25974  Switzerland Super League  Switzerland          False          False   
25975  Switzerland Super League  Switzerland          False          False   
25976  Switzerland Super League  Switzerland          False          False   
25978  Switzerland Super League  Switzerland          False          False   

       home_player_3  home_player_4  home_player_5  home_player_6  \
145            False          False          False          False   
153            False          False          False          False   
155            False          False          False          False   
162            False          False          False          False   
168            False          False          False          False   
...              ...            ...            ...            ...   
25972          False          False          False          False   
25974          False          False          False          False   
25975          False          False          False          False   
25976          False          False          False          False   
25978          False          False          False          False   

       home_player_7  home_player_8  home_player_9  home_player_10  \
145            False          False          False           False   
153            False          False          False           False   
155            False          False          False           False   
162            False          False          False           False   
168            False          False          False           False   
...              ...            ...            ...             ...   
25972          False          False          False           False   
25974          False          False          False           False   
25975          False          False          False           False   
25976          False          False          False           False   
25978          False          False          False           False   

       home_player_11  away_player_1  away_player_2  away_player_3  \
145             False          False          False          False   
153             False          False          False          False   
155             False          False          False          False   
162             False          False          False          False   
168             False          False          False          False   
...               ...            ...            ...            ...   
25972           False          False          False          False   
25974           False          False          False          False   
25975           False          False          False          False   
25976           False          False          False          False   
25978           False          False          False          False   

       away_player_4  away_player_5  away_player_6  away_player_7  \
145            False          False          False          False   
153            False          False          False          False   
155            False          False          False          False   
162            False          False          False          False   
168            False          False          False          False   
...              ...            ...            ...            ...   
25972          False          False          False          False   
25974          False          False          False          False   
25975          False          False          False          False   
25976          False          False          False          False   
25978          False          False          False          False   

       away_player_8  away_player_9  away_player_10  away_player_11  \
145            False          False           False           False   
153            False          False           False           False   
155            False          False           False           False   
162            False          False           False           False   
168            False          False           False           False   
...              ...            ...             ...             ...   
25972          False          False           False           False   
25974          False          False           False           False   
25975          False          False           False           False   
25976          False          False           False           False   
25978          False          False           False           False   

      Winning Team  
145                 
153                 
155                 
162                 
168                 
...            ...  
25972               
25974               
25975               
25976               
25978               

[21374 rows x 47 columns]&gt;
</code></pre>

<p>I need to send multiple columns as input arguements in order to find who's won but i'm not sure if <code>.apply()</code> allows you to pass in a series as an argument? Is it possible to do this using <code>.apply()</code>. If so a solution would be helpful, but if anyone knows a better alternative that would also be useful.</p>
"
"60018965","<p>Overriding functions in that way is not suggested, especially for what are considered protected functions in Qt, which is the case of any <code>*Event()</code> function of QObjects and QWidgets.  </p>

<p>Also, in your case you're just overwriting the method with the same signature, which would never allow you to get the source of the function call.<br>
A possible solution would be to use a lambda with the source as a keyword argument:</p>

<pre><code>self.label_ligne_1_1.mousePressEvent = lambda ev, label=self.label_ligne_1_1: self.label_click(label)
</code></pre>

<p>But I wouldn't suggest you to do that.
A better approach, instead, would be to install an <a href=""https://doc.qt.io/qt-5/qobject.html#eventFilter"" rel=""nofollow noreferrer"">event filter</a> on each label, and then set the pixmap each time a mouse press event is captured:</p>

<pre><code>class Squares(QtWidgets.QWidget):
    def __init__(self):
        super().__init__()
        layout = QtWidgets.QGridLayout(self)
        layout.setSpacing(0)

        for row in range(4):
            for col in range(4):
                square = QtWidgets.QLabel()
                square.setPixmap(QtGui.QPixmap('tab.png'))
                layout.addWidget(square, row, col)
                setattr(self, 'label_ligne_{}_{}'.format(row + 1, col + 1), square)
                square.installEventFilter(self)

    def eventFilter(self, source, event):
        if event.type() == QtCore.QEvent.MouseButtonPress:
            source.setPixmap(QtGui.QPixmap('tabx.png'))
        return super().eventFilter(source, event)
</code></pre>
","4","2020-02-01 16:48:10","1","18223","101","602","1897","60018773","60018965","<p>I have all this labels declared in a initUi
They are constructed like that:</p>

<pre><code>        ligne_1_left_cord = 300
        self.label_ligne_1_1 = QtWidgets.QLabel(self)
        pic_signe_tab =QPixmap('img/tab.png')
        self.label_ligne_1_1.setPixmap(pic_signe_tab)
        self.label_ligne_1_1.move(ligne_1_left_cord,300)
        self.label_ligne_1_1.mousePressEvent = self.label_click

        self.label_ligne_1_2 = QtWidgets.QLabel(self)
        self.label_ligne_1_2.setPixmap(pic_signe_tab)
        self.label_ligne_1_2.move( ligne_1_left_cord +85,300)

</code></pre>

<p>When I click label_ligne_1_1 the function label_click does this:</p>

<pre><code>def label_click(self,event):
        signe_pixmap = QPixmap('img/tabx.png')
        self.label_ligne_1_1.setPixmap(signe_pixmap)
</code></pre>

<p><a href=""https://i.stack.imgur.com/e7dpD.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/e7dpD.png"" alt=""enter image description here""></a></p>

<p>Is there anyway I could pass a variable when I'm calling label_click in order to bind it to all labels and use the same function?
Something like this?:</p>

<pre><code>def label_click(name_of_the_lable):
    name_of_the_lable.setPixmap(x)
</code></pre>

<p>Meaning of course that no matter on what square you click, the pixmap will change and an X will appear</p>
"
"60020752","<p>Solved:</p>

<p>Here is the working code simplified with notation. Hopefully others will find it instructive. This example uses the model of College Program>Terms>Courses</p>

<pre><code>#import tkinter and ttk modules
from tkinter import *
from tkinter import ttk

#Make the root widget
root = Tk()

#Make the first notebook
program = ttk.Notebook(root) #Create the program notebook
program.pack()

#Make the terms frames for the program notebook
for r in range(1,4):
    termName = 'Term'+str(r) #concatenate term name(will come from dict)
    term = Frame(program)   #create frame widget to go in program nb
    program.add(term, text=termName)# add the newly created frame widget to the program notebook
    nbName=termName+'courses'#concatenate notebook name for each iter
    nbName = ttk.Notebook(term)#Create the notebooks to go in each of the terms frames
    nbName.pack()#pack the notebook

    for a in range (1,6):
        courseName = termName+""Course""+str(a)#concatenate coursename(will come from dict)
        course = Frame(nbName) #Create a course frame for the newly created term frame for each iter
        nbName.add(course, text=courseName)#add the course frame to the new notebook 

root.mainloop()
</code></pre>
","4","2020-02-06 02:30:48","1","23","0","0","4","60018778","60020752","<p>I am attempting to nest one ttk notebook within another so that I can have multiple tab levels.</p>

<p>Imagine an upper notebook with a tab for each food group, and within each of those foodgroup tabs, a tab for examples of foods in that group.  A tabbed hierarchy.</p>

<p>Is it possible with ttk notebooks?  I have not been able to find any reference or examples that deal with this question.</p>

<p>It seems like this code should work. I get no errors, but I can't see the second level tabs.  Any help would be appreciated.</p>

<pre><code>#import tkinter and ttk modules
from tkinter import *
from tkinter import ttk

#Make the root widget
root = Tk()

#Make the first notebook
nb1 = ttk.Notebook(root)
nb1.pack()
f0 = Frame(nb1)
f0.pack(expand=1, fill='both')

###Make the second notebook
nb2 = ttk.Notebook(f0)
nb2.pack()

#Make 1st tab
f1 = Frame(nb1)
#Add the tab to notebook 1
nb1.add(f1, text=""First tab"")

#Make 2nd tab
f2 = Frame(nb1)
#Add 2nd tab to notebook 1
nb1.add(f2, text=""Second tab"")

###Make 3rd tab
f3 = Frame(nb2)
#Add 3rd tab to notebook 2
nb2.add(f3, text=""First tab"")

###Make 4th tab
f4 = Frame(nb2)
#Add 4th tab to notebook 2
nb2.add(f4, text=""Second tab"")

root.mainloop()
</code></pre>
"
"60019059","<p>TLDR; Make all green pixels white with Numpy:</p>

<pre><code>import numpy as np

pixels[np.all(pixels == (0, 255, 0), axis=-1)] = (255,255,255)
</code></pre>

<hr>

<p>I have made some examples of other ways of changing colours here. First I'll cover exact, specific RGB values like you asked in your question, using this image. It has three big blocks of exactly red, exactly green and exactly blue on the left and three gradual transitions between those colours on the right:</p>

<p><a href=""https://i.stack.imgur.com/D1kEY.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/D1kEY.png"" alt=""enter image description here""></a></p>

<p>Here's the initial answer as above again:</p>

<pre><code>#!/usr/bin/env python3

import cv2
import numpy as np

# Load image
im = cv2.imread('image.png')

# Make all perfectly green pixels white
im[np.all(im == (0, 255, 0), axis=-1)] = (255,255,255)

# Save result
cv2.imwrite('result1.png',im)
</code></pre>

<p><a href=""https://i.stack.imgur.com/huzrN.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/huzrN.png"" alt=""enter image description here""></a></p>

<hr>

<p>This time I define the colour names for extra readability and maintainability. The final line is the important point:</p>

<pre><code># Define some colours for readability - these are in OpenCV **BGR** order - reverse them for PIL
red   = [0,0,255]
green = [0,255,0]
blue  = [255,0,0]
white = [255,255,255]
black = [0,0,0]

# Make all perfectly green pixels white
im[np.all(im == green, axis=-1)] = white
</code></pre>

<p>Same result.</p>

<hr>

<p>This time I make a re-usable mask of red pixels which I can use in subsequent operations. The final line with the assignment <code>im[Rmask] = black</code> is now particularly easy to read :</p>

<pre><code># Define some colours for readability - these are in OpenCV **BGR** order - reverse them for PIL
red   = [0,0,255]
green = [0,255,0]
blue  = [255,0,0]
white = [255,255,255]
black = [0,0,0]

# Make mask of all perfectly red pixels
Rmask = np.all(im == red, axis=-1)

# Make all red pixels black
im[Rmask] = black
</code></pre>

<p><a href=""https://i.stack.imgur.com/cdGUf.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/cdGUf.png"" alt=""enter image description here""></a></p>

<hr>

<p>This time I <strong>combine</strong> a mask of red and blue pixels so you can see the power of masks. The final line is the important point:</p>

<pre><code># Define some colours for readability - these are in OpenCV **BGR** order - reverse them for PIL
red   = [0,0,255]
green = [0,255,0]
blue  = [255,0,0]
white = [255,255,255]
black = [0,0,0]

# Make mask of all perfectly red pixels and all perfectly blue pixels
Rmask = np.all(im == red,  axis=-1)
Bmask = np.all(im == blue, axis=-1)

# Make all red or blue pixels black
im[Rmask | Bmask] = black
</code></pre>

<p><a href=""https://i.stack.imgur.com/8qcLL.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/8qcLL.png"" alt=""enter image description here""></a></p>

<hr>

<p>And this time I make all non-red pixels into black - hopefully you are appreciating the power of masks now. The final line is the important point:</p>

<pre><code># Define some colours for readability - these are in OpenCV **BGR** order - reverse them for PIL
red   = [0,0,255]
green = [0,255,0]
blue  = [255,0,0]
white = [255,255,255]
black = [0,0,0]

# Make mask of all perfectly red pixels
Rmask = np.all(im == red,  axis=-1)

# Make all non-red pixels black
im[~Rmask] = black
</code></pre>

<p><a href=""https://i.stack.imgur.com/p3bYg.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/p3bYg.png"" alt=""enter image description here""></a></p>

<hr>

<p>Up till now, we have only made some selection of pixels into a single new colour. What if we want to make some pixels one colour and all other pixels a different colour in a single pass? The final line is the important point:</p>

<pre><code># Define some colours for readability - these are in OpenCV **BGR** order - reverse them for PIL
red   = [0,0,255]
green = [0,255,0]
blue  = [255,0,0]
white = [255,255,255]
black = [0,0,0]

# Make mask of all perfectly red pixels
Rmask = np.all(im == red,  axis=-1)

# Make all red pixels white AND at same time everything else black
im = np.where(np.all(im == red, axis=-1, keepdims=True), white, black)
</code></pre>

<p><a href=""https://i.stack.imgur.com/po4K8.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/po4K8.png"" alt=""enter image description here""></a></p>

<hr>

<p>If you want to affect a whole <strong>range</strong> of colours, rather than a specific RGB value, have a look <a href=""https://stackoverflow.com/a/50215020/2836621"">here</a> and <a href=""https://stackoverflow.com/a/52183666/2836621"">here</a>.</p>

<p><strong>Keywords</strong>: Image processing, Python, prime, change colour, change color, prime.</p>
","3","2020-02-02 21:02:57","7","143615","5750","44","11812","60018903","60019059","<p>I need to be able to replace all pixels that have a certain RGB value with another color in OpenCV.</p>
<p>I’ve tried some of the solutions but none of them worked for me.</p>
<p>What is the best way to achieve this?</p>
"
"60019010","<p>I would use <code>sklearn</code> framework.</p>

<p>It isn't a part of python base packages, so you will need to install it (<code>pip install sklearn</code>). </p>

<p>than, import the <code>CountVectorizer</code>:</p>

<pre><code>from sklearn.feature_extraction.text import CountVectorizer
</code></pre>

<p>read you files and store them in a list.
let's say you will call it <code>my_corpus</code>. now  you have a list named <code>my_corpus</code> with 4 members.</p>

<p>just use:</p>

<pre><code>vectorizer =  CountVectorizer()    
matrix = vectorizer.fit_transform(my_corpus)
</code></pre>

<p>Alternativly, if you wouldn't like to use a oter packages, just do:
corpus = [""I like dogs"", ""I like cats"", ""cats like milk"", ""You likes me""]<br>
token_corpus = [s.split() for s in corpus]                                           </p>

<pre><code>vocabulary = {}                                                                      
for i, f in enumerate(token_corpus):                                                 
    for t in f:                                                                      
        if t not in vocabulary:                                                      
             vocabulary[t] = [0]*len(corpus)                                         
        vocabulary[t][i]+=1                                                          

vocabulary
{'I': [1, 1, 0, 0], 'like': [1, 1, 1, 0], 'dogs': [1, 0, 0, 0], 'cats': [0, 1, 1, 0], 'milk': [0, 0, 1, 0], 'You': [0, 0, 0, 1], 'likes': [0, 0, 0, 1], 'me': [0, 0, 0, 1]}
</code></pre>

<p>if you want to save it in a list just use:</p>

<pre><code>list(map(list, vocabulary.items()))
[['I', [1, 1, 0, 0]], ['like', [1, 1, 1, 0]], ['dogs', [1, 0, 0, 0]], ['cats', [0, 1, 1, 0]], ['milk', [0, 0, 1, 0]], ['You', [0, 0, 0, 1]], ['likes', [0, 0, 0, 1]], ['me', [0, 0, 0, 1]]]
</code></pre>
","1","2020-02-01 17:29:32","2","1805","1172","161","335","60018917","60019010","<p>I have the following code for a total of four text files all containing a few different keywords. They are called test1.txt, test2.txt, test3.txt and test4.txt. I want to transform it into a matrix/list of lists. I have the following code.</p>

<pre><code>temp = [''] + list(sample_collection)
values = list(sample_collection['test1.txt'])

sample_collection = [temp] + [[x] + [v.get(x, 0) for v in sample_collection.values()] for x in values]

</code></pre>

<p>However, I want to modify it to include not only the keywords from test1, but all other unique keywords from the other files. I have no clue how to do so. Is there a way to do so with that piece of code?</p>

<p>expected output:</p>

<pre><code>[['', 'test1.txt', 'test2.txt', 'test3.txt', 'test4.txt'],
['apple', 1, 0, 2, 1],
['banana', 1, 1, 1, 1],
['lemon', 1, 1, 0, 0],
['grape', 0, 0, 0, 1]]
</code></pre>
"
"60019132","<p>A naive sieve implementation would have a <code>is_prime</code> array that represents all <code>n</code> numbers we want to check. So its size would be <code>n</code>. Then for each <code>p</code>, we start at <code>2*p</code> and mark it as ""not prime"" then go to <code>3*p</code>, <code>4*p</code>, <code>5*p</code>, etc, marking each one as ""not prime"". So for example, when <code>p = 2</code>, we mark 4, 6, 8, 10, 12, etc as ""not prime"". Then when <code>p = 3</code> we mark 6, 9, 12, 15 as ""not prime"". </p>

<p>I suggest that you implement this algorithm yourself to understand how it works before moving on to implementations. The code you are looking at uses some tricks to reduce the work done. But to understand those tricks, you need to understand the base algorithm.</p>

<blockquote>
  <p>how did they come up with the formula for the size</p>
</blockquote>

<p>This comes from solving the formula <code>n = i * 2 + 3</code> for <code>i</code> where <code>n</code> is the largest number we will check for primeness. It gives an upper bound for the value of <code>i</code> for all of the numbers we want to test.</p>

<blockquote>
  <p>how did they get p = i * 2 + 3</p>
</blockquote>

<p>This allows us to test only odd numbers starting at 3. Note that even numbers are <strong>not</strong> prime, so we can easily skip them with this formula.</p>

<blockquote>
  <p>what does the following mean Sieving from p^2, where p^2 = (4i^2 + 12i + 9). The index in is_prime is (2i^2 + 6i + 3) because is_prime[i] represents 2i + 3</p>
</blockquote>

<p>Notice how in our naive algorithm, we marked 6 and 12 as ""not prime"" twice. We clearly do some extra work here. We can avoid this extra work by realizing that for <code>p</code>, we have already marked all composite numbers less than <code>p^2</code> as ""not prime"" when we determined each prime less than <code>p</code>.</p>

<p>So we only have to start at <code>p^2</code> instead of at <code>p</code>. Now for <code>p = 2</code>, we mark 4, 6, 8, 10, 12, etc as before. But then for <code>p = 3</code>, we mark 9, 12, 15, 18, etc, avoiding the double work of marking 6 as ""not prime"". For these two examples, the amount of double-marking avoided is pretty small, but as <code>p</code> gets larger, this technique adds up to a significant performance increase.</p>

<p>As for the formula <code>p^2 = (4i^2 + 12i + 9)</code>, you can derive this from what we call the FOIL method when multiplying <code>(2*i+3)*(2*i+3)</code>. For your code, this doesn't really matter, because if you do <code>p = 2*i + 3</code>, then you can calculate <code>p*p</code> directly without worrying about the underlying algebraic manipulations.</p>

<blockquote>
  <p>why does the range of j begin with 2 * i**2 + 6 * i + 3</p>
</blockquote>

<p>We have <code>p^2 = (4i^2 + 12i + 9)</code> and we need to find the index <code>j</code> in <code>is_prime</code> where <code>p^2 = j * 2 + 3</code>. We set these equal and solve for <code>j</code>.</p>
","0","2020-02-01 17:15:54","2","68812","12541","1216","18431","60018974","60019268","<p>I am going through the ""Elements of Programming Interview"" in python currently and have gotten stuck at this part. The code below generates primes up to n. The explanation is rather lacking and i do not have the mathematical background to make sense of it.</p>

<blockquote>
  <p>We can improve run-time by sieving p's multiples from p^2 instead of
  p, since all numbers of the form kp, where k &lt; p have already been
  sieved out.</p>
</blockquote>

<p>The code is below:</p>

<pre><code>def generate_primesII(n):

    if n &lt; 2:
        return []

    size = (n - 3) // 2 + 1
    primes = [2]  # stores the primes from 1 to n

    # is_prime[i] represents (2i + 2) is prime or not
    # Initially set each to true. Then use sieving to eliminate nonprimes
    is_prime = [True] * size

    for i in range(size):
        if is_prime[i]:

            p = i * 2 + 3
            primes.append(p)

            # Sieving from p^2, where p^2 = (4i^2 + 12i + 9). The index in is_prime
            # is (2i^2 + 6i + 3) because is_prime[i] represents 2i + 3

            # note that we need to use long for j because p^2 might overflow
            for j in range(2 * i**2 + 6 * i + 3, size, p):
                is_prime[j] = False
    return primes
</code></pre>

<p>My questions are:</p>

<ol>
<li>how did they come up with the formula for the size</li>
<li>they say <code>is_prime[i] represents (2i + 3) is prime or not.</code> I cant make sense of why <code>2i + 3</code>.</li>
<li>how did they get <code>p = i * 2 + 3</code></li>
<li>what does the following mean <code>Sieving from p^2, where p^2 = (4i^2 + 12i + 9). The index in is_prime is (2i^2 + 6i + 3) because is_prime[i] represents 2i + 3</code></li>
<li>why does the range of j begin with  <code>2 * i**2 + 6 * i + 3</code></li>
</ol>

<p>Most of the numbers seem rather random to me</p>
"
"60019268","<p>There are two key tricks which are simultaneously done here. That, I believe, is the main reason behind your confusion. The first is a mathematical fact about the progression about the sieve algorithm. (i.e., starting to update from <code>p<sup>2</sup></code>) The other is a trick employed to use less space by not storing any <code>is_prime</code> data for even numbers)</p>

<p>Let's start with your first two questions. The <code>(2 * i + 3)</code> mapping used in <code>is_prime[i]</code> seems to be a spatial optimization to reduce the space used to half. (i.e., no even number is represented in <code>is_prime</code> list) The mapping helps iterate only the list of odd numbers starting from 3, up to <code>size</code>. If you actually replace the <code>i</code> variable in <code>(2i + 3)</code> with the initial value of <code>size</code>, you will see that you end up with <code>n</code>. (or <code>n-1</code>, depending on whether <code>n</code> is even or odd)</p>

<p>Your third question is relatively more straightforward. In the outer loop, <code>i</code> iterates over the space of odd integers up to <code>n</code>. As there is a mapping of <code>(2i + 3)</code> in <code>is_prime</code>, <code>p</code> is assigned that value. From that point on, <code>p</code> represents the actual prime value which is to be used in the inner loop.</p>

<p>The comment in your fourth question simply further explains the mathematical idea of starting to iterate from <code>p<sup>2</sup></code>. As the loop constitutes <code>i</code> to be part of a mapping (to actual values) the <code>p<sup>2</sup></code> is further expressed in terms of that variable <code>i</code>. I think that comment attempts to express the use of <code>2 * i**2 + 6 * i + 3</code> to initialize the range of <code>j</code>, but is quite unclear.</p>

<p>To answer your final question, we should consider what <code>j</code> actually represents. <code>j</code> represents the space of odd numbers to be updated. Similar with the loop for <code>i</code>, <strong><code>j</code> iterates not over the actual values, but on the odd numbers</strong>. The initial value of <code>j</code> is <code>2 * i**2 + 6 * i + 3</code>, because when you replace that value with the <code>i</code> variable in <code>(2*i + 3)</code> (i.e., the mapping from the odd numbers' space to the set of actual values), you obtain <code>4 * i**2 + 12 * i + 9</code>, which is <code>p<sup>2</sup></code>.</p>

<p>The inner loop is basically assigning <code>is_prime[j]=False</code> to <strong>all the cells that represent the multiples of the actual prime value <code>p</code></strong>, starting from the one representing the value <code>p<sup>2</sup></code>.</p>
","0","2020-02-01 17:25:15","2","4154","135","752","1342","60018974","60019268","<p>I am going through the ""Elements of Programming Interview"" in python currently and have gotten stuck at this part. The code below generates primes up to n. The explanation is rather lacking and i do not have the mathematical background to make sense of it.</p>

<blockquote>
  <p>We can improve run-time by sieving p's multiples from p^2 instead of
  p, since all numbers of the form kp, where k &lt; p have already been
  sieved out.</p>
</blockquote>

<p>The code is below:</p>

<pre><code>def generate_primesII(n):

    if n &lt; 2:
        return []

    size = (n - 3) // 2 + 1
    primes = [2]  # stores the primes from 1 to n

    # is_prime[i] represents (2i + 2) is prime or not
    # Initially set each to true. Then use sieving to eliminate nonprimes
    is_prime = [True] * size

    for i in range(size):
        if is_prime[i]:

            p = i * 2 + 3
            primes.append(p)

            # Sieving from p^2, where p^2 = (4i^2 + 12i + 9). The index in is_prime
            # is (2i^2 + 6i + 3) because is_prime[i] represents 2i + 3

            # note that we need to use long for j because p^2 might overflow
            for j in range(2 * i**2 + 6 * i + 3, size, p):
                is_prime[j] = False
    return primes
</code></pre>

<p>My questions are:</p>

<ol>
<li>how did they come up with the formula for the size</li>
<li>they say <code>is_prime[i] represents (2i + 3) is prime or not.</code> I cant make sense of why <code>2i + 3</code>.</li>
<li>how did they get <code>p = i * 2 + 3</code></li>
<li>what does the following mean <code>Sieving from p^2, where p^2 = (4i^2 + 12i + 9). The index in is_prime is (2i^2 + 6i + 3) because is_prime[i] represents 2i + 3</code></li>
<li>why does the range of j begin with  <code>2 * i**2 + 6 * i + 3</code></li>
</ol>

<p>Most of the numbers seem rather random to me</p>
"
"60822995","<p>I'm not clear on what data you're looking for, so I've provided two potential solutions:</p>

<h3>Backend:</h3>

<p>The auth will be present in the header of the request object in your backend.</p>

<pre class=""lang-py prettyprint-override""><code>b64user_pass = request.headers.get(""Authorization"")
</code></pre>

<h3>Frontend:</h3>

<p>If your endpoint is expecting <code>json</code> be sure to make the request with the <code>Content-Type</code> header</p>

<pre class=""lang-py prettyprint-override""><code>request = requests.post(url, data=payload, headers={""Content-Type"": ""application/json"", auth=(user, pass))

# Or even better:
request = requests.post(url, json=payload, auth=(user, pass))
</code></pre>
","0","","0","2068","476","17","358","60018992","60822995","<p>I have little problem with requests post and auth
In frontdend application is this code:</p>

<pre><code>url = ""http://localhost:9886/""
username = ""Admin""
password = ""SuperSecretPassword""
payload = {'sex' : 'male'}
request = requests.post(url, data = payload, auth = (username, password))
</code></pre>

<p>And in backend this:</p>

<pre><code>data = request.get_json()
return jsonify({""data"" : data})
</code></pre>

<p>But backend app don't receive any data, so can someone help?...Thanks in advance</p>
"
"60021397","<p>Altair features an <a href=""https://altair-viz.github.io/user_guide/marks.html#image-mark"" rel=""noreferrer"">image mark</a> that can be used if you want to plot images that are available at a URL; for example:</p>

<pre><code>import altair as alt
import pandas as pd

source = pd.DataFrame.from_records([
      {""x"": 0.5, ""y"": 0.5, ""img"": ""https://vega.github.io/vega-datasets/data/ffox.png""},
      {""x"": 1.5, ""y"": 1.5, ""img"": ""https://vega.github.io/vega-datasets/data/gimp.png""},
      {""x"": 2.5, ""y"": 2.5, ""img"": ""https://vega.github.io/vega-datasets/data/7zip.png""}
])

alt.Chart(source).mark_image(
    width=50,
    height=50
).encode(
    x='x',
    y='y',
    url='img'
)
</code></pre>

<p><a href=""https://i.stack.imgur.com/KUffc.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/KUffc.png"" alt=""enter image description here""></a></p>

<p>Altair is not as well suited to displaying 2-dimensional data arrays as images, because the grammar is primarily designed to work with structured tabular data. However, it is possible to do using a combination of <a href=""https://altair-viz.github.io/user_guide/transform/flatten.html"" rel=""noreferrer"">flatten transforms</a> and <a href=""https://altair-viz.github.io/user_guide/transform/window.html"" rel=""noreferrer"">window transforms</a>.</p>

<p>Here is an example using the data from the page you linked to:</p>

<pre><code>import altair as alt
import pandas as pd
from sklearn.datasets import fetch_lfw_people
faces = fetch_lfw_people(min_faces_per_person=60)

data = pd.DataFrame({
    'image': list(faces.images[:12])  # list of 2D arrays
})

alt.Chart(data).transform_window(
    index='count()'           # number each of the images
).transform_flatten(
    ['image']                 # extract rows from each image
).transform_window(
    row='count()',            # number the rows...
    groupby=['index']         # ...within each image
).transform_flatten(
    ['image']                 # extract the values from each row
).transform_window(
    column='count()',         # number the columns...
    groupby=['index', 'row']  # ...within each row &amp; image
).mark_rect().encode(
    alt.X('column:O', axis=None),
    alt.Y('row:O', axis=None),
    alt.Color('image:Q',
        scale=alt.Scale(scheme=alt.SchemeParams('greys', extent=[1, 0])),
        legend=None
    ),
    alt.Facet('index:N', columns=4)
).properties(
    width=100,
    height=120
)
</code></pre>

<p><a href=""https://i.stack.imgur.com/ekbPI.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/ekbPI.png"" alt=""enter image description here""></a></p>
","2","2020-02-02 01:08:28","17","51859","797","15","8125","60019006","60021397","<p>I am trying to plot image data in altair, specifically trying to replicate face recognition example in this link from Jake VDP's book - <a href=""https://jakevdp.github.io/PythonDataScienceHandbook/05.07-support-vector-machines.html"" rel=""noreferrer"">https://jakevdp.github.io/PythonDataScienceHandbook/05.07-support-vector-machines.html</a>.</p>

<p>Any one had luck plotting image data in altair?</p>
"
"60019107","<p>Something like this will work:</p>

<p>I have assumed your json object is one large string named 'data'.</p>

<pre><code>import pandas as pd    
import json

# json object:
json_string = """""" { ""PlanCoverages"": [ { ""PlanId"": 65860, ... """"""

# 1) load json object as python variable:
data = json.loads(json_string)

# 2) convert to dataframe:
plan_coverages = pd.DataFrame(data['PlanCoverages'])
</code></pre>
","0","2020-02-01 17:08:14","1","1842","112","6","198","60019043","60019107","<p>How can I convert the following list of dicts (json output) to a pandas DataFrame. I tried </p>

<pre class=""lang-py prettyprint-override""><code>res = {} 
for d in list_of_dict: 
    res.update(d)
</code></pre>

<p>It gives me the error: </p>

<pre><code>ValueError: dictionary update sequence element #0 has length 33; 2 is required
</code></pre>

<p>Example JSON output, needed converted to DataFrame.</p>

<pre><code>{
    ""PlanCoverages"": [
        {
            ""PlanId"": 65860,
            ""FormularyId"": 61855,
            ""PlanName"": ""CVS Caremark Performance Standard Control w/Advanced Specialty Control"",
            ""PlanTypeId"": 15,
            ""ChannelId"": 1,
            ""ProductId"": 237171,
            ""MonthId"": 202002,
            ""ControllerId"": 884,
            ""NoteId"": null,
            ""Lives"": 3814196,
            ""DrugListTierId"": 2,
            ""DrugListTierName"": ""Not reimbursed"",
            ""FormularyTierId"": 26,
            ""FormularyUnifiedTierId"": 13,
            ""UnifiedTierId"": 11,
            ""UnifiedTierName"": ""Not Covered"",
            ""UnifiedTierShortName"": ""Not Covered"",
            ""UnifiedTierSort"": 11,
            ""PromotionalTierId"": null,
            ""IsGeneric"": false,
            ""PriorAuthorization"": false,
            ""OtherNote"": false,
            ""StepTherapy"": false,
            ""QuantityLimit"": false,
            ""Variance"": false,
            ""Restrictions"": """",
            ""CoveredAlternatives"": 88,
            ""RecommendedAlternatives"": 0,
            ""SpecialtyPharmacy"": false,
            ""ConditionalPriorAuthorization"": false,
            ""DurableMedicalEquipment"": false,
            ""MedicalBenefit"": false,
            ""OverTheCounter"": false
        },
        {
            ""PlanId"": 69549,
            ""FormularyId"": 63811,
            ""PlanName"": ""CVS Caremark Performance Standard Opt-Out w/ Advanced Specialty Control "",
            ""PlanTypeId"": 15,
            ""ChannelId"": 1,
            ""ProductId"": 237171,
            ""MonthId"": 202002,
            ""ControllerId"": 884,
            ""NoteId"": null,
            ""Lives"": 1460242,
            ""DrugListTierId"": 2,
            ""DrugListTierName"": ""Not reimbursed"",
            ""FormularyTierId"": 26,
            ""FormularyUnifiedTierId"": 13,
            ""UnifiedTierId"": 11,
            ""UnifiedTierName"": ""Not Covered"",
            ""UnifiedTierShortName"": ""Not Covered"",
            ""UnifiedTierSort"": 11,
            ""PromotionalTierId"": null,
            ""IsGeneric"": false,
            ""PriorAuthorization"": false,
            ""OtherNote"": false,
            ""StepTherapy"": false,
            ""QuantityLimit"": false,
            ""Variance"": false,
            ""Restrictions"": """",
            ""CoveredAlternatives"": 121,
            ""RecommendedAlternatives"": 0,
            ""SpecialtyPharmacy"": false,
            ""ConditionalPriorAuthorization"": false,
            ""DurableMedicalEquipment"": false,
            ""MedicalBenefit"": false,
            ""OverTheCounter"": false
        } ]
}
</code></pre>

<p>Here' my full code. It connects to an API, and scraped information on pharmaceuticals. 
I need the PlanCoverages of 1330 plans. </p>

<pre class=""lang-py prettyprint-override""><code>import requests
import pandas as pd
from pandas.io.json import json_normalize 
import json

headers = {
    'Accept': '*/*',
    'X-Requested-With': 'XMLHttpRequest',
    'Access-Token': 'H-oa4ULGls2Cpu8U6hX4myixRoFIPxfj',
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/78.0.3904.87 Safari/537.36',
    'Is-Session-Expired': 'false',
    'Referer': 'https://formularylookup.com/',
}

response = requests.get('https://formularylookup.com/Formulary/Coverage/Controller?ProductId=237171&amp;ProductName=Rybelsus&amp;ControllerId=884&amp;ChannelId=1&amp;StateId=all&amp;DrugTypeId=3&amp;Options=PlanCoverages', headers=headers)
df = response.json()

df_normal =  json_normalize(df)[""PlanCoverages""]#[""ControllerCoverages""]
#dff = pd.DataFrame(df_normal)

#dff = json.dumps(df, indent=4, sort_keys=False)

res = {} 
for d in df_normal: 
    res.update(d)

print(res)
</code></pre>

<p>Ideal output is, 1 row per plan. So a total of 1330 rows. </p>
"
"60019394","<p>I think you need something like this    </p>

<pre><code>import pandas as pd    
import json


convert json to python dictionary:
my_dict = json.loads(json_string)

convert a dictionary my_dict to dataframe df:
df = pd.concat({k: pd.DataFrame(v).T for k, v in my_dict.items()}, axis=0)

#reset the index
df = df.reset_index()
</code></pre>
","0","","0","504","24","3","56","60019043","60019107","<p>How can I convert the following list of dicts (json output) to a pandas DataFrame. I tried </p>

<pre class=""lang-py prettyprint-override""><code>res = {} 
for d in list_of_dict: 
    res.update(d)
</code></pre>

<p>It gives me the error: </p>

<pre><code>ValueError: dictionary update sequence element #0 has length 33; 2 is required
</code></pre>

<p>Example JSON output, needed converted to DataFrame.</p>

<pre><code>{
    ""PlanCoverages"": [
        {
            ""PlanId"": 65860,
            ""FormularyId"": 61855,
            ""PlanName"": ""CVS Caremark Performance Standard Control w/Advanced Specialty Control"",
            ""PlanTypeId"": 15,
            ""ChannelId"": 1,
            ""ProductId"": 237171,
            ""MonthId"": 202002,
            ""ControllerId"": 884,
            ""NoteId"": null,
            ""Lives"": 3814196,
            ""DrugListTierId"": 2,
            ""DrugListTierName"": ""Not reimbursed"",
            ""FormularyTierId"": 26,
            ""FormularyUnifiedTierId"": 13,
            ""UnifiedTierId"": 11,
            ""UnifiedTierName"": ""Not Covered"",
            ""UnifiedTierShortName"": ""Not Covered"",
            ""UnifiedTierSort"": 11,
            ""PromotionalTierId"": null,
            ""IsGeneric"": false,
            ""PriorAuthorization"": false,
            ""OtherNote"": false,
            ""StepTherapy"": false,
            ""QuantityLimit"": false,
            ""Variance"": false,
            ""Restrictions"": """",
            ""CoveredAlternatives"": 88,
            ""RecommendedAlternatives"": 0,
            ""SpecialtyPharmacy"": false,
            ""ConditionalPriorAuthorization"": false,
            ""DurableMedicalEquipment"": false,
            ""MedicalBenefit"": false,
            ""OverTheCounter"": false
        },
        {
            ""PlanId"": 69549,
            ""FormularyId"": 63811,
            ""PlanName"": ""CVS Caremark Performance Standard Opt-Out w/ Advanced Specialty Control "",
            ""PlanTypeId"": 15,
            ""ChannelId"": 1,
            ""ProductId"": 237171,
            ""MonthId"": 202002,
            ""ControllerId"": 884,
            ""NoteId"": null,
            ""Lives"": 1460242,
            ""DrugListTierId"": 2,
            ""DrugListTierName"": ""Not reimbursed"",
            ""FormularyTierId"": 26,
            ""FormularyUnifiedTierId"": 13,
            ""UnifiedTierId"": 11,
            ""UnifiedTierName"": ""Not Covered"",
            ""UnifiedTierShortName"": ""Not Covered"",
            ""UnifiedTierSort"": 11,
            ""PromotionalTierId"": null,
            ""IsGeneric"": false,
            ""PriorAuthorization"": false,
            ""OtherNote"": false,
            ""StepTherapy"": false,
            ""QuantityLimit"": false,
            ""Variance"": false,
            ""Restrictions"": """",
            ""CoveredAlternatives"": 121,
            ""RecommendedAlternatives"": 0,
            ""SpecialtyPharmacy"": false,
            ""ConditionalPriorAuthorization"": false,
            ""DurableMedicalEquipment"": false,
            ""MedicalBenefit"": false,
            ""OverTheCounter"": false
        } ]
}
</code></pre>

<p>Here' my full code. It connects to an API, and scraped information on pharmaceuticals. 
I need the PlanCoverages of 1330 plans. </p>

<pre class=""lang-py prettyprint-override""><code>import requests
import pandas as pd
from pandas.io.json import json_normalize 
import json

headers = {
    'Accept': '*/*',
    'X-Requested-With': 'XMLHttpRequest',
    'Access-Token': 'H-oa4ULGls2Cpu8U6hX4myixRoFIPxfj',
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/78.0.3904.87 Safari/537.36',
    'Is-Session-Expired': 'false',
    'Referer': 'https://formularylookup.com/',
}

response = requests.get('https://formularylookup.com/Formulary/Coverage/Controller?ProductId=237171&amp;ProductName=Rybelsus&amp;ControllerId=884&amp;ChannelId=1&amp;StateId=all&amp;DrugTypeId=3&amp;Options=PlanCoverages', headers=headers)
df = response.json()

df_normal =  json_normalize(df)[""PlanCoverages""]#[""ControllerCoverages""]
#dff = pd.DataFrame(df_normal)

#dff = json.dumps(df, indent=4, sort_keys=False)

res = {} 
for d in df_normal: 
    res.update(d)

print(res)
</code></pre>

<p>Ideal output is, 1 row per plan. So a total of 1330 rows. </p>
"
"60020100","<p>One approach is to only give a label to scatter the first time in the loop:</p>

<pre class=""lang-py prettyprint-override""><code>for x, y, z, l, m in zip([data_ax, data_bx, data_cx], [data_ay, data_by, data_cy], [data_az, data_bz, data_cz], [lab_a, lab_b, lab_c], [mrk_a, mrk_b, mrk_c]):
    for ind, (x2, y2, z2) in enumerate(zip(x, y, z)):
        sc = ax.scatter(x2, y2, c=z2, label=l if ind == 0 else None,
                        marker=m, cmap=cm, norm=mplcol.Normalize(vmin=0, vmax=1))
</code></pre>

<p>Another approach is to convert all data to np.arrays (data_cx etc. is now a list of np.arrays), and then use <code>ravel</code> (or <code>flatten</code>) from numpy.</p>

<pre><code>import numpy as np
import matplotlib.pyplot as plt
import matplotlib.colors as mplcol

data_ax = np.random.rand(10,4)
data_bx = np.random.rand(7, 1)
data_cx = np.concatenate([np.random.rand(6,1), np.random.rand(5,1), np.random.rand(8,1)])

data_ay = np.random.rand(10,4)
data_by = np.random.rand(7, 1)
data_cy = np.concatenate( [np.random.rand(6,1), np.random.rand(5,1), np.random.rand(8,1)])

data_az = np.random.rand(10,4)
data_bz = np.random.rand(7, 1)
data_cz = np.concatenate( [np.random.rand(6,1), np.random.rand(5,1), np.random.rand(8,1)])

lab_a = 'Data A'
lab_b = 'Data B'
lab_c = 'Data C'

mrk_a = 'o'
mrk_b = 's'
mrk_c = 'D'

cm = plt.cm.get_cmap('viridis')

fig, ax = plt.subplots()

for x, y, z, l, m in zip([data_ax, data_bx, data_cx], [data_ay, data_by, data_cy], [data_az, data_bz, data_cz], [lab_a, lab_b, lab_c], [mrk_a, mrk_b, mrk_c]):
    sc = ax.scatter(x.ravel(), y.ravel(), c=z.ravel(), label=l, marker=m, cmap=cm, norm=mplcol.Normalize(vmin=0, vmax=1))
ax.legend()

cb = plt.colorbar(sc)

plt.show()
</code></pre>
","0","2020-02-01 18:54:12","1","34973","1481","136","1951","60019050","60020100","<p>I have datasets of different sizes that I want to include in a plot using <code>scatter</code> with a <code>colorbar</code> from <code>matplotlib</code>. In order to avoid having too many items in the legend (and not run out of marker-types), I would like to categorize all legend items into <code>lab_a</code>, <code>lab_b</code>, and <code>lab_c</code> occurring only one time each.</p>

<pre><code>import numpy as np
import matplotlib.pyplot as plt
import matplotlib.colors as mplcol

data_ax = np.random.rand(10,4)
data_bx = np.random.rand(7, 1)
data_cx = [np.random.rand(6,1), np.random.rand(5,1), np.random.rand(8,1)]

data_ay = np.random.rand(10,4)
data_by = np.random.rand(7, 1)
data_cy = [np.random.rand(6,1), np.random.rand(5,1), np.random.rand(8,1)]

data_az = np.random.rand(10,4)
data_bz = np.random.rand(7, 1)
data_cz = [np.random.rand(6,1), np.random.rand(5,1), np.random.rand(8,1)]

lab_a = 'Data A'
lab_b = 'Data B'
lab_c = 'Data C'

mrk_a = 'o'
mrk_b = 's'
mrk_c = 'D'

cm = plt.cm.get_cmap('viridis')

fig, ax = plt.subplots()

for x, y, z, l, m in zip([data_ax, data_bx, data_cx], [data_ay, data_by, data_cy], [data_az, data_bz, data_cz], [lab_a, lab_b, lab_c], [mrk_a, mrk_b, mrk_c]):
    #sc = ax.scatter(x, y, c=z, label=l, marker=m, cmap=cm, norm=mplcol.Normalize(vmin=0, vmax=1))
    for x2, y2, z2 in zip(x, y, z):
        sc = ax.scatter(x2, y2, c=z2, label=l, marker=m, cmap=cm, norm=mplcol.Normalize(vmin=0, vmax=1))

ax1.legend()

cb = plt.colorbar(sc)

plt.show()
</code></pre>

<p>When I run the code above, the labels in the legend repeat themselves. If I run only one loop (i.e. <code>#sc</code>), <code>data_cx</code>, <code>data_cy</code>, and <code>data_cz</code> generate a problem because the shape is not consistent and an error arises:</p>

<pre><code>ValueError: 'c' argument must either be valid as mpl color(s) or as numbers to be mapped to colors.
</code></pre>

<ul>
<li><p>Is there a way to group the labels so that I can run both loops and the legend only contains singular <code>lab_a</code>, <code>lab_b</code>, and <code>lab_c</code>?</p></li>
<li><p>Is there perhaps a better way to group the labels that I am unaware of?</p></li>
</ul>
"
"60020130","<p>I have found that your problem is equivalent to</p>

<pre><code>[np.any(arr[i]==values[i]) for i in range(len(values))]
</code></pre>

<p>I agree this is time consuming. Elementwise comparison can't be avoided here so <code>np.any(arr[i]==values[i])</code> or <code>values[i] in arr[i]</code> is must-do here. What about vectorizations, I found it quite difficult to replace list comprehension used here too. This is my way using <a href=""https://docs.scipy.org/doc/numpy/reference/generated/numpy.vectorize.html"" rel=""nofollow noreferrer""><code>np.vectorize</code></a>:</p>

<pre><code>def myfunc(i): return np.any(arr[i]==values[i])
vfunc = np.vectorize(myfunc)
vfunc(np.arange(len(values)))
# output: array([False, False,  True])
</code></pre>
","1","","1","3747","281","19","426","60019133","60020269","<p>I have a 1D array of length <em>k</em> with some arbitrary values and a 3D array of dimensions <em>k</em> * <em>i</em> * <em>j</em> with some data.</p>

<pre class=""lang-py prettyprint-override""><code>import numpy as np

# create 1D and 3D array
values = np.array([2, 5, 1], dtype=np.int)
arr = np.zeros((3, 4, 4), dtype=np.int)

# insert some random numbers in the 3D array
arr[0, 3, 2] = 5
arr[1, 1, 1] = 2
arr[2, 2, 3] = 1
</code></pre>

<pre><code>&gt;&gt;&gt; print(values)
[2 5 1]

&gt;&gt;&gt; print(arr)
[[[0 0 0 0]
  [0 0 0 0]
  [0 0 0 0]
  [0 0 5 0]]

 [[0 0 0 0]
  [0 2 0 0]
  [0 0 0 0]
  [0 0 0 0]]

 [[0 0 0 0]
  [0 0 0 0]
  [0 0 0 1]
  [0 0 0 0]]]
</code></pre>

<p>My goal is to determine if the i<sup>th</sup> element of <code>values</code> (<em>i.e.</em> a scalar) is present in the i<sup>th</sup> element of <code>arr</code> (<em>i.e.</em> a 2D array) and get a boolean array of length <em>k</em>.</p>

<p>In my example, I would expect to get an array <code>[False, False, True]</code> as <code>1</code> is the only number present in its correspondent 2D array (<code>arr[2]</code>).</p>

<p>As <code>np.isin</code> function is not an option, I have come up with two possible solutions so far.</p>

<p>1) Create a 3D array by repeating the numbers in <code>values</code> and then do an elementh-wise comparison:</p>

<pre class=""lang-py prettyprint-override""><code>rep = np.ones(arr.shape) * values.reshape(-1, 1, 1)
</code></pre>

<pre class=""lang-py prettyprint-override""><code>&gt;&gt;&gt; print(rep)
[[[2. 2. 2. 2.]
  [2. 2. 2. 2.]
  [2. 2. 2. 2.]
  [2. 2. 2. 2.]]

 [[5. 5. 5. 5.]
  [5. 5. 5. 5.]
  [5. 5. 5. 5.]
  [5. 5. 5. 5.]]

 [[1. 1. 1. 1.]
  [1. 1. 1. 1.]
  [1. 1. 1. 1.]
  [1. 1. 1. 1.]]]

&gt;&gt;&gt; np.any((arr == rep), axis=(1, 2))
array([False, False,  True])
</code></pre>

<p>However, this approach seems like a bad idea from a memory perspective if both <code>values</code> and <code>arr</code> have bigger shapes.</p>

<p>2) Iterate over each value in <code>values</code> and check if it is present in its correspondent 2D array of <code>arr</code>.</p>

<pre class=""lang-py prettyprint-override""><code>result = []
for i, value in enumerate(values):
    result.append(value in arr[i])
</code></pre>

<pre><code>&gt;&gt;&gt; print(result)
[False, False, True]
</code></pre>

<p>This approach is of course better from a memory perspective but again, when implemented with bigger arrays it can become time consuming (think of <em>k</em> being 1000000 instead of 3).</p>

<p>Is there any other <code>numpy</code> function I am missing or perhaps a better approach to accomplish my goal here?</p>

<p>I already took a look at the answers to a similar <a href=""https://stackoverflow.com/questions/31618336/pythonic-and-efficient-way-to-do-an-elementwise-in-using-numpy"">question</a> but they do not fit my use case.</p>
"
"60020269","<p>using <a href=""https://docs.scipy.org/doc/numpy/user/basics.broadcasting.html"" rel=""nofollow noreferrer"">broadcasting</a> might help:</p>

<pre><code>np.any(values[:,None,None] == arr, axis=(1,2))
</code></pre>

<p>is a one liner that gives <code>[False,False,True]</code>.  note that if you're storing <code>arr</code> then storing a similar <code>bool</code> array shouldn't be too bad</p>

<p>note that it's the <code>values[:,None,None] == arr</code> that's doing the broasting, strange <a href=""https://docs.scipy.org/doc/numpy/reference/arrays.indexing.html"" rel=""nofollow noreferrer"">indexing with <code>None</code></a> being equivalent to your <code>reshape</code> (but feels more idiomatic to me)</p>
","0","","2","10718","971","119","1114","60019133","60020269","<p>I have a 1D array of length <em>k</em> with some arbitrary values and a 3D array of dimensions <em>k</em> * <em>i</em> * <em>j</em> with some data.</p>

<pre class=""lang-py prettyprint-override""><code>import numpy as np

# create 1D and 3D array
values = np.array([2, 5, 1], dtype=np.int)
arr = np.zeros((3, 4, 4), dtype=np.int)

# insert some random numbers in the 3D array
arr[0, 3, 2] = 5
arr[1, 1, 1] = 2
arr[2, 2, 3] = 1
</code></pre>

<pre><code>&gt;&gt;&gt; print(values)
[2 5 1]

&gt;&gt;&gt; print(arr)
[[[0 0 0 0]
  [0 0 0 0]
  [0 0 0 0]
  [0 0 5 0]]

 [[0 0 0 0]
  [0 2 0 0]
  [0 0 0 0]
  [0 0 0 0]]

 [[0 0 0 0]
  [0 0 0 0]
  [0 0 0 1]
  [0 0 0 0]]]
</code></pre>

<p>My goal is to determine if the i<sup>th</sup> element of <code>values</code> (<em>i.e.</em> a scalar) is present in the i<sup>th</sup> element of <code>arr</code> (<em>i.e.</em> a 2D array) and get a boolean array of length <em>k</em>.</p>

<p>In my example, I would expect to get an array <code>[False, False, True]</code> as <code>1</code> is the only number present in its correspondent 2D array (<code>arr[2]</code>).</p>

<p>As <code>np.isin</code> function is not an option, I have come up with two possible solutions so far.</p>

<p>1) Create a 3D array by repeating the numbers in <code>values</code> and then do an elementh-wise comparison:</p>

<pre class=""lang-py prettyprint-override""><code>rep = np.ones(arr.shape) * values.reshape(-1, 1, 1)
</code></pre>

<pre class=""lang-py prettyprint-override""><code>&gt;&gt;&gt; print(rep)
[[[2. 2. 2. 2.]
  [2. 2. 2. 2.]
  [2. 2. 2. 2.]
  [2. 2. 2. 2.]]

 [[5. 5. 5. 5.]
  [5. 5. 5. 5.]
  [5. 5. 5. 5.]
  [5. 5. 5. 5.]]

 [[1. 1. 1. 1.]
  [1. 1. 1. 1.]
  [1. 1. 1. 1.]
  [1. 1. 1. 1.]]]

&gt;&gt;&gt; np.any((arr == rep), axis=(1, 2))
array([False, False,  True])
</code></pre>

<p>However, this approach seems like a bad idea from a memory perspective if both <code>values</code> and <code>arr</code> have bigger shapes.</p>

<p>2) Iterate over each value in <code>values</code> and check if it is present in its correspondent 2D array of <code>arr</code>.</p>

<pre class=""lang-py prettyprint-override""><code>result = []
for i, value in enumerate(values):
    result.append(value in arr[i])
</code></pre>

<pre><code>&gt;&gt;&gt; print(result)
[False, False, True]
</code></pre>

<p>This approach is of course better from a memory perspective but again, when implemented with bigger arrays it can become time consuming (think of <em>k</em> being 1000000 instead of 3).</p>

<p>Is there any other <code>numpy</code> function I am missing or perhaps a better approach to accomplish my goal here?</p>

<p>I already took a look at the answers to a similar <a href=""https://stackoverflow.com/questions/31618336/pythonic-and-efficient-way-to-do-an-elementwise-in-using-numpy"">question</a> but they do not fit my use case.</p>
"
"60020857","<p>You've basically identified the two options:</p>

<pre><code>In [35]: timeit [(i==a).any() for i,a in zip(values, arr)]                                     
29 µs ± 543 ns per loop (mean ± std. dev. of 7 runs, 10000 loops each)
In [36]: timeit (values[:,None,None]==arr).any(axis=(1,2))                                     
11.4 µs ± 10.5 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)
</code></pre>

<p>In this small case the big array approach is faster.  But for a larger case, the iteration might be better.  Memory management with the larger arrays may cancel out the time savings.  It's often the case that a few iterations on a complex problem are better than the fully 'vectorized' version.</p>

<p>If it's something you do repeatedly, you could take the time craft a hybrid solution, one that iterates on blocks.  But you'd have to judge that yourself.</p>

<p><code>isin</code> and related code either <code>ors</code> some tests, or using <code>sort</code> of some sort to put like values next to each other for easy comparison.  </p>

<p>The other approach is to write a fully iterative solution, and let <code>numba</code> compile it for you.</p>
","1","","1","172516","3363","73","13055","60019133","60020269","<p>I have a 1D array of length <em>k</em> with some arbitrary values and a 3D array of dimensions <em>k</em> * <em>i</em> * <em>j</em> with some data.</p>

<pre class=""lang-py prettyprint-override""><code>import numpy as np

# create 1D and 3D array
values = np.array([2, 5, 1], dtype=np.int)
arr = np.zeros((3, 4, 4), dtype=np.int)

# insert some random numbers in the 3D array
arr[0, 3, 2] = 5
arr[1, 1, 1] = 2
arr[2, 2, 3] = 1
</code></pre>

<pre><code>&gt;&gt;&gt; print(values)
[2 5 1]

&gt;&gt;&gt; print(arr)
[[[0 0 0 0]
  [0 0 0 0]
  [0 0 0 0]
  [0 0 5 0]]

 [[0 0 0 0]
  [0 2 0 0]
  [0 0 0 0]
  [0 0 0 0]]

 [[0 0 0 0]
  [0 0 0 0]
  [0 0 0 1]
  [0 0 0 0]]]
</code></pre>

<p>My goal is to determine if the i<sup>th</sup> element of <code>values</code> (<em>i.e.</em> a scalar) is present in the i<sup>th</sup> element of <code>arr</code> (<em>i.e.</em> a 2D array) and get a boolean array of length <em>k</em>.</p>

<p>In my example, I would expect to get an array <code>[False, False, True]</code> as <code>1</code> is the only number present in its correspondent 2D array (<code>arr[2]</code>).</p>

<p>As <code>np.isin</code> function is not an option, I have come up with two possible solutions so far.</p>

<p>1) Create a 3D array by repeating the numbers in <code>values</code> and then do an elementh-wise comparison:</p>

<pre class=""lang-py prettyprint-override""><code>rep = np.ones(arr.shape) * values.reshape(-1, 1, 1)
</code></pre>

<pre class=""lang-py prettyprint-override""><code>&gt;&gt;&gt; print(rep)
[[[2. 2. 2. 2.]
  [2. 2. 2. 2.]
  [2. 2. 2. 2.]
  [2. 2. 2. 2.]]

 [[5. 5. 5. 5.]
  [5. 5. 5. 5.]
  [5. 5. 5. 5.]
  [5. 5. 5. 5.]]

 [[1. 1. 1. 1.]
  [1. 1. 1. 1.]
  [1. 1. 1. 1.]
  [1. 1. 1. 1.]]]

&gt;&gt;&gt; np.any((arr == rep), axis=(1, 2))
array([False, False,  True])
</code></pre>

<p>However, this approach seems like a bad idea from a memory perspective if both <code>values</code> and <code>arr</code> have bigger shapes.</p>

<p>2) Iterate over each value in <code>values</code> and check if it is present in its correspondent 2D array of <code>arr</code>.</p>

<pre class=""lang-py prettyprint-override""><code>result = []
for i, value in enumerate(values):
    result.append(value in arr[i])
</code></pre>

<pre><code>&gt;&gt;&gt; print(result)
[False, False, True]
</code></pre>

<p>This approach is of course better from a memory perspective but again, when implemented with bigger arrays it can become time consuming (think of <em>k</em> being 1000000 instead of 3).</p>

<p>Is there any other <code>numpy</code> function I am missing or perhaps a better approach to accomplish my goal here?</p>

<p>I already took a look at the answers to a similar <a href=""https://stackoverflow.com/questions/31618336/pythonic-and-efficient-way-to-do-an-elementwise-in-using-numpy"">question</a> but they do not fit my use case.</p>
"
"60029255","<p>As hpaulj already mentioned <code>numba</code> can be an option here.</p>

<p><strong>Example</strong></p>

<pre><code>import numpy as np
import numba as nb

#Turn off parallelization for tiny problems
@nb.njit(parallel=True)
def example(values,arr):
    #Make sure that the first dimension is the same
    assert arr.shape[0]==values.shape[0]
    out=np.empty(values.shape[0],dtype=nb.bool_)

    for i in nb.prange(arr.shape[0]):
        out[i]=False
        for j in range(arr.shape[1]):
            if arr[i,j]==values[i]:
                out[i]=True
                break
    return out
</code></pre>

<p><strong>Timings (small arrays)</strong></p>

<pre><code>#your input data
%timeit example(values,arr.reshape(arr.shape[0],-1))# #parallel=True
#10.7 µs ± 34.5 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)
%timeit example(values,arr.reshape(arr.shape[0],-1))# #parallel=False
#2.15 µs ± 49.9 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)

#Methods from other answers
%timeit (values[:,None,None]==arr).any(axis=(1,2))
#9.52 µs ± 323 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)
%timeit [(i==a).any() for i,a in zip(values, arr)]
#23.9 µs ± 435 ns per loop (mean ± std. dev. of 7 runs, 10000 loops each)
</code></pre>

<p><strong>Timings (larger arrays)</strong></p>

<pre><code>values=np.random.randint(low=1,high=100_000,size=1_000_000)
arr=np.random.randint(low=1,high=10_00,size=1_000_000*100).reshape(1_000_000,10,10)

%timeit example(values,arr.reshape(arr.shape[0],-1)) #parallel=True
#48.2 ms ± 5.02 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)
%timeit example(values,arr.reshape(arr.shape[0],-1)) #parallel=False
#90.5 ms ± 618 µs per loop (mean ± std. dev. of 7 runs, 1 loop each)

#Methods from other answers
%timeit (values[:,None,None]==arr).any(axis=(1,2))
#186 ms ± 5.47 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)
%timeit [(i==a).any() for i,a in zip(values, arr)]
#6.63 s ± 69 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)
</code></pre>
","0","","1","5188","591","6","1183","60019133","60020269","<p>I have a 1D array of length <em>k</em> with some arbitrary values and a 3D array of dimensions <em>k</em> * <em>i</em> * <em>j</em> with some data.</p>

<pre class=""lang-py prettyprint-override""><code>import numpy as np

# create 1D and 3D array
values = np.array([2, 5, 1], dtype=np.int)
arr = np.zeros((3, 4, 4), dtype=np.int)

# insert some random numbers in the 3D array
arr[0, 3, 2] = 5
arr[1, 1, 1] = 2
arr[2, 2, 3] = 1
</code></pre>

<pre><code>&gt;&gt;&gt; print(values)
[2 5 1]

&gt;&gt;&gt; print(arr)
[[[0 0 0 0]
  [0 0 0 0]
  [0 0 0 0]
  [0 0 5 0]]

 [[0 0 0 0]
  [0 2 0 0]
  [0 0 0 0]
  [0 0 0 0]]

 [[0 0 0 0]
  [0 0 0 0]
  [0 0 0 1]
  [0 0 0 0]]]
</code></pre>

<p>My goal is to determine if the i<sup>th</sup> element of <code>values</code> (<em>i.e.</em> a scalar) is present in the i<sup>th</sup> element of <code>arr</code> (<em>i.e.</em> a 2D array) and get a boolean array of length <em>k</em>.</p>

<p>In my example, I would expect to get an array <code>[False, False, True]</code> as <code>1</code> is the only number present in its correspondent 2D array (<code>arr[2]</code>).</p>

<p>As <code>np.isin</code> function is not an option, I have come up with two possible solutions so far.</p>

<p>1) Create a 3D array by repeating the numbers in <code>values</code> and then do an elementh-wise comparison:</p>

<pre class=""lang-py prettyprint-override""><code>rep = np.ones(arr.shape) * values.reshape(-1, 1, 1)
</code></pre>

<pre class=""lang-py prettyprint-override""><code>&gt;&gt;&gt; print(rep)
[[[2. 2. 2. 2.]
  [2. 2. 2. 2.]
  [2. 2. 2. 2.]
  [2. 2. 2. 2.]]

 [[5. 5. 5. 5.]
  [5. 5. 5. 5.]
  [5. 5. 5. 5.]
  [5. 5. 5. 5.]]

 [[1. 1. 1. 1.]
  [1. 1. 1. 1.]
  [1. 1. 1. 1.]
  [1. 1. 1. 1.]]]

&gt;&gt;&gt; np.any((arr == rep), axis=(1, 2))
array([False, False,  True])
</code></pre>

<p>However, this approach seems like a bad idea from a memory perspective if both <code>values</code> and <code>arr</code> have bigger shapes.</p>

<p>2) Iterate over each value in <code>values</code> and check if it is present in its correspondent 2D array of <code>arr</code>.</p>

<pre class=""lang-py prettyprint-override""><code>result = []
for i, value in enumerate(values):
    result.append(value in arr[i])
</code></pre>

<pre><code>&gt;&gt;&gt; print(result)
[False, False, True]
</code></pre>

<p>This approach is of course better from a memory perspective but again, when implemented with bigger arrays it can become time consuming (think of <em>k</em> being 1000000 instead of 3).</p>

<p>Is there any other <code>numpy</code> function I am missing or perhaps a better approach to accomplish my goal here?</p>

<p>I already took a look at the answers to a similar <a href=""https://stackoverflow.com/questions/31618336/pythonic-and-efficient-way-to-do-an-elementwise-in-using-numpy"">question</a> but they do not fit my use case.</p>
"
"60019312","<p>You could first select a subset of your dataframe containing the rows for which the <code>Return</code> is maximum and then use <code>idxmin()</code> to return the index of the first occurrence of the minimum <code>Volatility</code>. </p>

<p>Here is a dataframe example:</p>

<pre><code>import pandas as pd
mydict = {'Return': [99999,1,1,99999, 809],
    'Volatility': [1, 2, 3, 4, 7]
    }

 df = pd.DataFrame(mydict, columns = ['Return', 'Volatility'])
</code></pre>

<p>For this example, <code>df[df.Return==df.Return.max()]</code> yields:</p>

<blockquote>
  <p>Return  Volatility<br>
  0    99999           1<br>
  3    99999           4</p>
</blockquote>

<p>And <code>df[df.Return==df.Return.max()].Volatility.idxmin()</code> returns:</p>

<blockquote>
  <p>0</p>
</blockquote>

<p>Which is the index associated with the <code>Volatility</code> of 1.</p>
","0","2020-02-01 17:33:06","0","1706","160","3","188","60019146","60019312","<p>Suppose I have a DataFrame that consists of three columns (index, return, volatility) and five rows.
I would like to receive the index number that maximizes value of return AND minimizes value of volatility however the second condition is less important than first. </p>

<p>How can I receive that? I tried to apply method .rank() for both columns and then sort by them but effect was poor.</p>
"
"60019278","<p>If no missing data in original DataFrame solution should be simplify a bit.</p>

<p>Also I think <code>inplace</code> is not good practice, check <a href=""https://www.dataschool.io/future-of-pandas/#inplace"" rel=""nofollow noreferrer"">this</a> and <a href=""https://github.com/pandas-dev/pandas/issues/16529"" rel=""nofollow noreferrer"">this</a>.</p>

<p>Also combine of all columns is nice solution, one of fastest, check <a href=""https://stackoverflow.com/a/36911306/2901002"">this</a>.</p>

<pre><code>df = pd.read_sql_query(""SELECT * FROM firstline_srs"", cnx)
df['Open_Date'] = pd.to_datetime(df['Open_Date'])

df['day'] = df['Open_Date'].dt.day
df['month'] = df['Open_Date'].dt.month

df['Product_Name'] = df['Product_Name'].replace('', 'N')
df['product_Type'] = df['product_Type'].replace('', 'A')


df['full_path'] = df['Type'] + ""/"" + df['Area'] + ""/"" + df['Sub_Area'] + ""/"" + df['product_Type'] + ""/"" + df['Product_Name']
</code></pre>

<p>If missing values:</p>

<pre><code>df = pd.read_sql_query(""SELECT * FROM firstline_srs"", cnx)
df['Open_Date'] = pd.to_datetime(df['Open_Date'])

df['day'] = df['Open_Date'].dt.day
df['month'] = df['Open_Date'].dt.month

df['Product_Name'] = df['Product_Name'].replace('', np.nan).fillna(""N"")
df['product_Type'] = df['product_Type'].replace('', np.nan).fillna(""A"")


df['full_path'] = df['Type'] + ""/"" + df['Area'] + ""/"" + df['Sub_Area'] + ""/"" + df['product_Type'] + ""/"" + df['Product_Name']
</code></pre>
","0","","0","615041","23439","1483","126104","60019224","60019278","<p>I'm trying to add 2 new columns to extract the day and the month from full date, my problem is currently my data set has about 1.2 M record and expected to be over 20 m at the end of the year, and adding the columns take very long time, so I'm asking what the best practice to do.</p>

<p>I'm using aqlite
and here is my code </p>

<pre><code>cnx = sqlite3.connect('data/firstline.db')
df = pd.read_sql_query(""SELECT * FROM firstline_srs"", cnx)
df['day'] = pd.DatetimeIndex(df['Open_Date']).day
df['month'] = pd.DatetimeIndex(df['Open_Date']).month

df['Product_Name'].replace('', np.nan, inplace=True)
df['Product_Name'].fillna(""N"", inplace = True) 

df['product_Type'].replace('', np.nan, inplace=True)
df['product_Type'].fillna(""A"", inplace = True) 

df['full_path'] = df['Type'] + ""/"" + df['Area'] + ""/"" + df['Sub_Area'] + ""/"" + df['product_Type'] + ""/"" + df['Product_Name']
</code></pre>

<p>Many thanks for your usual support :)</p>
"
"60019402","<p>You can use np.ix_() for this to create a map of which values you want by location. </p>

<pre><code>&gt;&gt;&gt; a = np.arange(1,10).reshape(3,3)
&gt;&gt;&gt; a
array([[1, 2, 3],
       [4, 5, 6],
       [7, 8, 9]])

&gt;&gt;&gt; b=np.ix_([0,2],[0, 2])
&gt;&gt;&gt; a[b]
array([[1, 3],
       [7, 9]])
</code></pre>
","0","","2","1323","92","59","106","60019225","60019402","<p>Assume I have the following numpy array :</p>

<pre><code>a = np.array([[4, 5, 8],
              [7, 2, 9],
              [1, 5, 3]])
</code></pre>

<p>and I want to extract points from the array 'a' to have this array :</p>

<pre><code>b = array([[4, 8],
           [1, 3]])
</code></pre>

<p>How can I do this ?</p>

<p>PS : In my real case I have 13*13 matrix and I want to create a 3*3 matrix from the first one</p>
"
"60019355","<p>Try this on for size</p>

<pre><code>print([[30*y + 10*x for x in range(3)] for y in range(3)])
</code></pre>

<p>What this does is swaps out the <code>0</code> you were using with <code>30*y + 10*x</code> which is exactly what you need to generate your array. For a more general solution that lets you scale to n by n matrices you can use</p>

<pre><code>n = k
print([[10*k*y + 10*x for x in range(k)] for y in range(k)])
</code></pre>

<p>For different rows and columns you can use</p>

<pre><code>rows = k
cols = j
print([[10*cols*y + 10*x for x in range(cols)] for y in range(rows)])
</code></pre>
","0","2020-02-01 17:55:33","1","239","7","0","9","60019226","60019355","<p>I would like to create a matrix with cells that increment by 10. For example, the output of a 3x3 matrix should be:</p>

<p><code>[[10, 20, 30], [40, 50, 60], [70, 80, 90]]</code> </p>

<p>The code I currently have creates a 3x3 matrix filled with 0s:</p>

<pre><code>print([[0 for x in range(3)] for y in range(3)])

output: [[0, 0, 0], [0, 0, 0], [0, 0, 0]]
</code></pre>
"
"60019372","<p>The code is not very compact but it gets the job done:</p>

<pre><code>matrix = []
bar = []
foo = 10
  for i in range(3):
    for i in range(3):
  bar.append(foo)
  foo = foo + 10
matrix.append(bar)
bar = []
print(matrix)
</code></pre>
","0","2020-05-20 12:10:04","0","148","4","2","12","60019226","60019355","<p>I would like to create a matrix with cells that increment by 10. For example, the output of a 3x3 matrix should be:</p>

<p><code>[[10, 20, 30], [40, 50, 60], [70, 80, 90]]</code> </p>

<p>The code I currently have creates a 3x3 matrix filled with 0s:</p>

<pre><code>print([[0 for x in range(3)] for y in range(3)])

output: [[0, 0, 0], [0, 0, 0], [0, 0, 0]]
</code></pre>
"
"60019374","<p><code>numpy</code> package is quite flexible for things you want:</p>

<pre><code>import numpy as np
m = np.arange(10, 100, 10) #array [10, 20, 30, 40, 50, 60, 70, 80, 90]
m = m.reshape(3,3) # array [[10, 20, 30], [40, 50, 60], [70, 80, 90]]
print(m.tolist()) # array converted to list if you need
</code></pre>

<h3>Output:</h3>

<pre><code>[[10, 20, 30], [40, 50, 60], [70, 80, 90]]
</code></pre>
","0","","1","3747","281","19","426","60019226","60019355","<p>I would like to create a matrix with cells that increment by 10. For example, the output of a 3x3 matrix should be:</p>

<p><code>[[10, 20, 30], [40, 50, 60], [70, 80, 90]]</code> </p>

<p>The code I currently have creates a 3x3 matrix filled with 0s:</p>

<pre><code>print([[0 for x in range(3)] for y in range(3)])

output: [[0, 0, 0], [0, 0, 0], [0, 0, 0]]
</code></pre>
"
"60019420","<pre><code>import numpy as np
x = np.array(range(10,100,10)).reshape(3,3)
print(x)

[[10 20 30]
 [40 50 60]
 [70 80 90]]
</code></pre>
","0","","0","444","28","5","38","60019226","60019355","<p>I would like to create a matrix with cells that increment by 10. For example, the output of a 3x3 matrix should be:</p>

<p><code>[[10, 20, 30], [40, 50, 60], [70, 80, 90]]</code> </p>

<p>The code I currently have creates a 3x3 matrix filled with 0s:</p>

<pre><code>print([[0 for x in range(3)] for y in range(3)])

output: [[0, 0, 0], [0, 0, 0], [0, 0, 0]]
</code></pre>
"
"60031624","<p>Check <a href=""https://discordpy.readthedocs.io/en/latest/api.html#discord.on_error"" rel=""nofollow noreferrer"">discord.py Event Reference</a> and <a href=""https://discordpy.readthedocs.io/en/latest/ext/commands/api.html#event-reference"" rel=""nofollow noreferrer"">Event Command Reference</a>, it allows you to create error handlers</p>
<p>An example for a <code>on_error</code> event handler which sends the traceback to it's owner:</p>
<pre><code>import discord

import traceback
import datetime

@bot.event
async def on_error(event, *args, **kwargs):
    embed = discord.Embed(title=':x: Event Error', colour=0xe74c3c) #Red
    embed.add_field(name='Event', value=event)
    embed.description = '```py\n%s\n```' % traceback.format_exc()
    embed.timestamp = datetime.datetime.utcnow()
    await bot.AppInfo.owner.send(embed=embed)
</code></pre>
","0","2020-09-12 07:01:58","0","593","66","0","48","60019371","60031624","<p>I want my bot to be printing all the error commands and the application logs into the chat, (basically whatever comes in my terminal when the bot runs), into a specific channel in my server, is there any way to do it? Error handlers wont be useful here, would they be?</p>
"
"60019748","<p>How about using a periodic function like sine?</p>

<pre><code>import numpy as np
import matplotlib.pyplot as plt
from numpy import sin

n_points = 10000
n_classes = 2

x = np.random.uniform(-10,10, size=(n_points, n_classes))
mask = np.logical_or(np.logical_and(sin(x[:,0]) &gt; 0.0, sin(x[:,1]) &gt; 0.0), \
np.logical_and(sin(x[:,0]) &lt; 0.0, sin(x[:,1]) &lt; 0.0))
y = np.eye(n_classes)[1*mask]

plt.scatter(x[:,0], x[:,1], c=y[:,0], cmap=""bwr"", alpha=0.5)
plt.show()
</code></pre>
","2","","5","1401","28","42","95","60019462","60019748","<p>I would like to create a checkerboard distribution in Python.</p>

<p>Currently I use the following script to create a <code>2 x 2</code> sized checkerboard:</p>

<pre><code>import numpy as np
import matplotlib.pyplot as plt

n_points = 1000
n_classes = 2

x = np.random.uniform(-1,1, size=(n_points, n_classes))
mask = np.logical_or(np.logical_and(x[:,0] &gt; 0.0, x[:,1] &gt; 0.0), \
np.logical_and(x[:,0] &lt; 0.0, x[:,1] &lt; 0.0))
y = np.eye(n_classes)[1*mask]

plt.scatter(x[:,0], x[:,1], c=y[:,0], cmap=""bwr"", alpha=0.5)
plt.show()
</code></pre>

<p>which creates</p>

<p><a href=""https://i.stack.imgur.com/1bW0Y.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/1bW0Y.png"" alt=""enter image description here""></a></p>

<p>I would like to know if there exists a simple way to generalize the above code to create a checkerboard distribution of size <code>n x n</code>?</p>

<p><strong>EDIT</strong></p>

<p>Using @jpf's great solution</p>

<pre><code>import numpy as np
import matplotlib.pyplot as plt
from numpy import sin

n_points = 10000
n_classes = 2
n = 8

x = np.random.uniform(-(n//2)*np.pi, (n//2)*np.pi, size=(n_points, n_classes))
mask = np.logical_or(np.logical_and(sin(x[:,0]) &gt; 0.0, sin(x[:,1]) &gt; 0.0), \
np.logical_and(sin(x[:,0]) &lt; 0.0, sin(x[:,1]) &lt; 0.0))
y = np.eye(n_classes)[1*mask]

plt.scatter(x[:,0], x[:,1], c=y[:,0], s=1, cmap=""bwr"", alpha=0.5)
plt.savefig(""test.png"", dpi=150)
plt.show()
</code></pre>

<p>I can now generate checkerboard distributions of arbitrary size:</p>

<p><a href=""https://i.stack.imgur.com/kgnHq.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/kgnHq.png"" alt=""enter image description here""></a></p>
"
"60019577","<p>you can't instantiate a <code>dict</code> with 3 arguments, the problem is the fact that you have 3 variables in the <code>zip</code>: <code>zip(number, name, position)</code> with which  you want to instantiate a <code>dict</code>, you should give only 2 arguments at a time, the key and the value</p>

<p>I've rewritten your las part of the code:</p>

<pre><code>from collections import defaultdict
data = {}
players = defaultdict(list)

for team_name, team_link in team.items():
    player_page = requests.get(team_link)
    cont = soup(player_page.text, 'lxml')
    clud_ele = cont.find_all('span', attrs={'class' : 'playerCardInfo'})
    for i in clud_ele:
        num = i.select('span.number')[0].get_text(strip=True)
        number = 100 if num == '-' else num
        name = i.select('h4.name')[0].get_text(strip=True)
        position = i.select('span.position')[0].get_text(strip=True)
        players[team_name].append({'number': number, 'position': position, 'name': name})
</code></pre>

<p><strong>output:</strong></p>

<pre><code>defaultdict(list,
            {'Arsenal': [{'number': '1',
               'position': 'Goalkeeper',
               'name': 'Bernd Leno'},
              {'number': '26',
               'position': 'Goalkeeper',
               'name': 'Emiliano Martínez'},
              {'number': '33', 'position': 'Goalkeeper', 'name': 'Matt Macey'},
              {'number': '2',
               'position': 'Defender',
               'name': 'Héctor Bellerín'},
                 .......................
</code></pre>
","10","2020-02-01 18:58:16","1","15189","2120","120","950","60019478","60020019","<p>Trying to create a dict that holds name,position and number for each player for each team. But when trying to create the final dictionary <code>players[team_name] =dict(zip(number,name,position))</code> it throws an error (see below). I can't seem to get it right, any thoughts on what I'm doing wrong here would be highly appreciated. Many thanks,</p>

<pre><code>from bs4 import BeautifulSoup as soup
import requests
from lxml import html


clubs_url = 'https://www.premierleague.com/clubs'
parent_url = clubs_url.rsplit('/', 1)[0]
data = requests.get(clubs_url).text
html = soup(data, 'html.parser')

team_name = []
team_link = []

for ul in html.find_all('ul', {'class': 'block-list-5 block-list-3-m block-list-1-s block-list-1-xs block-list-padding dataContainer'}):
    for a in ul.find_all('a'):
        team_name.append(str(a.h4).split('&gt;', 1)[1].split('&lt;')[0])
        team_link.append(parent_url+a['href'])
team_link = [item.replace('overview', 'squad') for item in team_link]
team = dict(zip(team_name, team_link))

data = {}
players = {}

for team_name, team_link in team.items():
    player_page = requests.get(team_link)
    cont = soup(player_page.content, 'lxml')
    clud_ele = cont.find_all('span', attrs={'class' : 'playerCardInfo'})
    for i in clud_ele:
        v_number = [100 if v == ""-"" else v.get_text(strip=True) for v in i.select('span.number')]
        v_name = [v.get_text(strip=True) for v in i.select('h4.name')]
        v_position = [v.get_text(strip=True) for v in i.select('span.position')]
        key_number = [key for element in i.select('span.number') for key in element['class']]
        key_name = [key for element in i.select('h4.name') for key in element['class']]
        key_position = [key for element in i.select('span.position') for key in element['class']]
        number = dict(zip(key_number,v_number))
        name = dict(zip(key_name,v_name))
        position = dict(zip(key_position,v_name))
        players[team_name] = dict(zip(number,name,position))

---&gt; 21         players[team_name] = dict(zip(number,name,position))
     22 
     23 

ValueError: dictionary update sequence element #0 has length 3; 2 is required
</code></pre>
"
"60020019","<p>There are many problems in your code. The one causing the error is that you are trying to instantiate a dictionary with a 3-items tuple in list which is not possible. See <a href=""https://docs.python.org/3/library/stdtypes.html?highlight=dict#dict"" rel=""nofollow noreferrer"">the dict doc</a> for details.</p>

<hr>

<p>That said, I would suggest to rework the whole nested loop.</p>

<p>First, you have in <code>clud_ele</code> a list of player info, each player info concerns only one player and provides only one position, only one name and only one number. So there is no need to store those informations in lists, you could use simple variables:</p>

<pre class=""lang-py prettyprint-override""><code>for player_info in clud_ele:
    number = player_info.select('span.number')[0].get_text(strip=True)
    if number == '-':
        number = 100
    name = player_info.select('h4.name')[0].get_text(strip=True)
    position = player_info.select('span.position')[0].get_text(strip=True)
</code></pre>

<p>Here, usage of <code>select</code> method returns a list but since you know that the list contains only one item, it's ok to get this item to call <code>get_text</code> on. But you could check that the <code>player_info.select('span.number')</code> length is actually 1 before continuing to work if you want to be sure...</p>

<p>This way, you get scalar data type which will be much easier to manipulate.
Also note that I renamed the <code>i</code> to <code>player_info</code> which is much more explicit.</p>

<p>Then you can easily add your player data to your <code>players</code> dict:</p>

<pre class=""lang-py prettyprint-override""><code>players[team_name].append({'name': name,
                           'position': position
                           'number': number})
</code></pre>

<p>This assume that you create the <code>players[team_name]</code> before the nested loop with <code>players[team_name] = []</code>.</p>

<p><em>Edit: as stated in the <a href=""https://stackoverflow.com/a/60019577/2696355"">@kederrac's answer</a>, usage of a <code>defaultdict</code> is a smart and convenient way to avoid the manual creation of each <code>players[team_name]</code> list</em></p>

<p>Finally, this will give you:</p>

<ul>
<li>a dictionary containing values for <code>name</code>, <code>position</code> and <code>number</code> keys for each player</li>
<li>a team list containg player dictionaries for each team</li>
<li>a players dictionary associating a team list for each <code>team_name</code></li>
</ul>

<hr>

<p>It is the data structure you seems to want, but other structures are possible. Remember to think about your data structure to make it logical AND easily manipulable.</p>
","2","2020-02-01 19:42:16","1","4899","456","27","210","60019478","60020019","<p>Trying to create a dict that holds name,position and number for each player for each team. But when trying to create the final dictionary <code>players[team_name] =dict(zip(number,name,position))</code> it throws an error (see below). I can't seem to get it right, any thoughts on what I'm doing wrong here would be highly appreciated. Many thanks,</p>

<pre><code>from bs4 import BeautifulSoup as soup
import requests
from lxml import html


clubs_url = 'https://www.premierleague.com/clubs'
parent_url = clubs_url.rsplit('/', 1)[0]
data = requests.get(clubs_url).text
html = soup(data, 'html.parser')

team_name = []
team_link = []

for ul in html.find_all('ul', {'class': 'block-list-5 block-list-3-m block-list-1-s block-list-1-xs block-list-padding dataContainer'}):
    for a in ul.find_all('a'):
        team_name.append(str(a.h4).split('&gt;', 1)[1].split('&lt;')[0])
        team_link.append(parent_url+a['href'])
team_link = [item.replace('overview', 'squad') for item in team_link]
team = dict(zip(team_name, team_link))

data = {}
players = {}

for team_name, team_link in team.items():
    player_page = requests.get(team_link)
    cont = soup(player_page.content, 'lxml')
    clud_ele = cont.find_all('span', attrs={'class' : 'playerCardInfo'})
    for i in clud_ele:
        v_number = [100 if v == ""-"" else v.get_text(strip=True) for v in i.select('span.number')]
        v_name = [v.get_text(strip=True) for v in i.select('h4.name')]
        v_position = [v.get_text(strip=True) for v in i.select('span.position')]
        key_number = [key for element in i.select('span.number') for key in element['class']]
        key_name = [key for element in i.select('h4.name') for key in element['class']]
        key_position = [key for element in i.select('span.position') for key in element['class']]
        number = dict(zip(key_number,v_number))
        name = dict(zip(key_name,v_name))
        position = dict(zip(key_position,v_name))
        players[team_name] = dict(zip(number,name,position))

---&gt; 21         players[team_name] = dict(zip(number,name,position))
     22 
     23 

ValueError: dictionary update sequence element #0 has length 3; 2 is required
</code></pre>
"
"60047954","<p>So the solution I ended up landing one involved a loop to create attributes for the form and a loop on the route for flask to capture the values.  The code looks like this:</p>

<pre><code>def map_csv():
    possible_columns = session['potential_columns']
    missing_columns = session['missing_columns']

    class MappingForm(FlaskForm):
        submit = SubmitField('Submit new mapping')
        pass

    possible_columns = [(x, x) for x in possible_columns]
    if missing_columns is not None:
        for name in missing_columns:
            setattr(MappingForm, name, SelectField(name, choices=possible_columns))

    form = MappingForm()
    if request.method == 'POST':
        if form.validate_on_submit:
            mapping = {}
            for x in missing_columns:
                column = getattr(form, x)
                mapping[column.data] = x
            session['mapping'] = mapping
            return redirect(url_for('main.upload'))
    return render_template('map_csv.html', form=form)

</code></pre>
","0","","0","117","14","0","14","60019479","60047954","<p>I am working on a Flask app where the main function is taking an uploaded CSV file, turning it into a Pandas dataframe, and then running a series of analyses on it.</p>

<p>The application works, but is somewhat rigid in the upload process requiring it to exactly match the column names and expected values.</p>

<p>I want to provide a fallback function that will dynamically generate forms that will ask the user questions in order to figure out column mappings back to the original template.</p>

<p>So for example if the template that worked was laid out like this:</p>

<p>['Name', 'Phone', 'Email']</p>

<p>and the uploaded version was:</p>

<p>['Customer Name', 'Phone Number', 'Email Address
]</p>

<p>I would want it to ask:</p>

<p>Which of ['Customer Name', 'Phone Number', 'Email Address'] correspond to Name.</p>

<p>Preferably I would like to use Flask-wtf to maintain consistency, unless there is a clearly better way to do this.</p>

<p>I imagine the way to do this would be to do something like:</p>

<pre><code>import pandas as pd
from flask_wtf import FlaskForm
from wtforms import SelectField

minimum_viable_columns = ['Name', 'Phone', 'Email']

data = pd.read_csv(uploaded_file)

potential_columns = []
    for x in data.columns.values.tolist():
        if x not in minimum_viable_columns:
            potential_columns.append(x)

missing_columns = []
for x in minimum_viable_columns:
    if x not in claims.columns.values.tolist():
        missing_columns.append(x)


class MatchingForm(FlaskForm):
     field_name = SelectField('Corresponding field name', choices=potential_columns)
</code></pre>

<p>I would have to generate these forms for each column in missing_columns, and I am trying to figure out a good way to do that and hopefully tie them all to a single submit button.</p>
"
"60019587","<p>This part of code <code>datetime.now().strftime(""%Y-%m-%d"")</code> return formated datetime <strong>string</strong>. You can find <code>strftime()</code> description <a href=""https://docs.python.org/3/library/datetime.html#datetime.date.strftime"" rel=""nofollow noreferrer"">here</a>. 
You need to substract timedelta first and then apply formatting to the result:</p>

<pre><code>yesterday = (datetime.now() -  timedelta(days=1)).strftime(""%Y-%m-%d"")
</code></pre>
","0","","1","37572","2148","0","2444","60019548","60019587","<p>I am trying to use datetime.now() with timedelta and soustract it so I get the time for yesterday.</p>

<pre><code>yesterday = datetime.now().strftime(""%Y-%m-%d"") -  timedelta(days=1)
</code></pre>

<p>But when I tried to do it, it gives me this error :</p>

<blockquote>
  <p>unsupported operand type(s) for -: 'str' and 'datetime.timedelta'</p>
</blockquote>

<p>So I tried to convert it to an int but with no success.</p>
"
"60019650","<p>Convert the number to a string, then use a list comprehension to extract each digit as a character.  This gives you the list of digit strings, e.g. <code>['2', '3', '5']</code>.</p>

<p>Use <code>permutations</code> to get the different arrangements, joining the result and converting them back to integers.</p>

<pre><code>from itertools import permutations

integer = 235
numbers = [i for i in str(integer)]  # ['2', '3', '5']

&gt;&gt;&gt; list(int(''.join(p)) for p in permutations(numbers))
[235, 253, 325, 352, 523, 532]

# Or just simply (no need for `numbers`):
# list(int(''.join(p)) for p in permutations(str(integer)))
</code></pre>
","0","2020-02-01 18:04:42","2","86106","1691","794","4699","60019549","60019685","<p>Suppose I have an integer (say <code>235</code>) and I want to reorder this number in all possible ways and get all other integers in a list or tuple. Is there a way to do it in python?
The desired output will consist of: <code>[235, 253, 325, 352, 523, 532]</code></p>

<p>And any other if I missed some.</p>

<p>I wanna create a list tuple or any other thing of all these values from where I can use these values somewhere else.</p>
"
"60019678","<p>Convert number into list of string numbers then do permutations.</p>

<pre><code>import itertools
number = 235
results = [int("""".join(x)) for x in list(itertools.permutations(list(str(number))))]
</code></pre>

<p>Output:</p>

<pre><code>[235, 253, 325, 352, 523, 532]
</code></pre>
","1","","3","4584","259","83","602","60019549","60019685","<p>Suppose I have an integer (say <code>235</code>) and I want to reorder this number in all possible ways and get all other integers in a list or tuple. Is there a way to do it in python?
The desired output will consist of: <code>[235, 253, 325, 352, 523, 532]</code></p>

<p>And any other if I missed some.</p>

<p>I wanna create a list tuple or any other thing of all these values from where I can use these values somewhere else.</p>
"
"60019685","<p>Use <code>itertools.permutation</code>, one-liners are good to show that you know python very well, but what actually matters is the maintainability. Here is a maintainable code, where every function is doing a single work and after reading the code we can get the logic(wherein the case of a one-liner, we need to spend time understanding the code):</p>

<pre><code>from itertools import permutations as perm

def to_int(p):
    return int(''.join(map(str, p)))

def all_perms(n):
    digits = list(map(int, str(n)))
    perms = []
    for p in perm(digits, len(digits)):
        perms.append(to_int(p))
    return perms

n = 235
print(all_perms(n))
</code></pre>
","0","2020-02-01 18:10:09","0","290","305","0","67","60019549","60019685","<p>Suppose I have an integer (say <code>235</code>) and I want to reorder this number in all possible ways and get all other integers in a list or tuple. Is there a way to do it in python?
The desired output will consist of: <code>[235, 253, 325, 352, 523, 532]</code></p>

<p>And any other if I missed some.</p>

<p>I wanna create a list tuple or any other thing of all these values from where I can use these values somewhere else.</p>
"
"60019798","<p>If I understand your issue, in your main routine</p>

<pre><code>error_tracker.track_func(transformation_with_error(app1='AA', app2='BB'), silent=True)
</code></pre>

<p>calls <code>transformation_with_error</code> before entering <code>error_tracker.track_func</code>. This happens just because you indeed are calling <code>transformation_with_error</code>. If you want your <code>error_tracker.track_func</code> to call <code>transformation_with_error</code>, you have to pass the later as an argument, like you would do for a callback.</p>

<p>For example:</p>

<pre><code>def test(var1, var2):
    print(""{} {}"".format(var1, var2))

def callFn(func, *vars):
    func(*vars)

callFn(test, ""foo"", ""bar"")
</code></pre>

<p>outputs <code>foo bar</code></p>
","0","","1","79","3","0","8","60019591","60019798","<p>In my main, I have a function with an error and a class that tracks errors in a list inside the class itself. In other words, instead of just calling the function, I would like to give this function to a class-method which then ""logs"" the error in a list and suppresses the error.</p>

<p>Here is my problem:<br>
This function has input arguments. When I hand-over my function to the class-method, I would like to hand-over the inputs, too. What happens is, that the function is being executed <strong><em>before</em></strong> going to the class method. Therefore, the class-method can't suppress the error which happens in the function.  </p>

<p>In the code below, I set the variable <code>silent=True</code>, therefore, it should not raise an error (because of the try/except clause within the method). Unfortunately, the code raises a TypeError which comes from the function. </p>

<p>Any advice would be much appreciated   </p>

<p>PS: I am not looking for a decorator solution :)</p>

<p>Here is the <strong>class</strong> with the class method which can suppress the error</p>

<pre><code>class ErrorTracker:
    def __init__(self):
        self.list = list()

    def track_func(self, func, silent=False):
        try:
            self.list.append('...in trying')
            print('....trying.....')
            return func
        except Exception as e:
            self.list.append('...in except')
            self.list.append(e)  # important line - here the error gets ""logged""
            if not silent:
                raise e
</code></pre>

<p>Here is the <strong>function with an error</strong></p>

<pre><code>def transformation_with_error(app1, app2):
    # DO STUFF HERE with inputs
    result = str(app1)+str(app2)
    print(result)
    print('TYPE ERROR here')
    raise TypeError
    return result
</code></pre>

<p>Here the <strong>main routine</strong>:</p>

<pre><code>if __name__ == ""__main__"":
    error_tracker = ErrorTracker()

    print('-- start transformation')
    error_tracker.track_func(transformation_with_error(app1='AA', app2='BB'), silent=True)
    print('-- end transformation')

    print(error_tracker.list)
</code></pre>
"
"60020884","<p>Thx VincentRG<br>
That was it<br>
Just for the record, below are the changes I did:<br>
(side note: I added the **kwargs, too, to be able to deal with default values)</p>

<p>thx mate</p>

<p><strong>class changes</strong></p>

<pre><code>class ErrorTracker:
    def __init__(self):
        self.list = list()

    def track_func(self, func, silent=False, *args, **kwargs):
        try:
            self.list.append('...in trying')
            print('....trying.....')
            return func(*args, **kwargs)
        except Exception as e:
            self.list.append('...in except')
            self.list.append(e)   # important line - here the error gets ""logged""
            if not silent:
                raise e
</code></pre>

<p><strong>change in call</strong></p>

<pre><code>if __name__ == ""__main__"":
    error_tracker = ErrorTracker()

    print('-- start transformation')
    error_tracker.track_func(transformation_with_error, silent=True, app1='AA', app2='BB')
    print('-- end transformation')

    print(error_tracker.list)
</code></pre>
","0","","0","27","1","0","7","60019591","60019798","<p>In my main, I have a function with an error and a class that tracks errors in a list inside the class itself. In other words, instead of just calling the function, I would like to give this function to a class-method which then ""logs"" the error in a list and suppresses the error.</p>

<p>Here is my problem:<br>
This function has input arguments. When I hand-over my function to the class-method, I would like to hand-over the inputs, too. What happens is, that the function is being executed <strong><em>before</em></strong> going to the class method. Therefore, the class-method can't suppress the error which happens in the function.  </p>

<p>In the code below, I set the variable <code>silent=True</code>, therefore, it should not raise an error (because of the try/except clause within the method). Unfortunately, the code raises a TypeError which comes from the function. </p>

<p>Any advice would be much appreciated   </p>

<p>PS: I am not looking for a decorator solution :)</p>

<p>Here is the <strong>class</strong> with the class method which can suppress the error</p>

<pre><code>class ErrorTracker:
    def __init__(self):
        self.list = list()

    def track_func(self, func, silent=False):
        try:
            self.list.append('...in trying')
            print('....trying.....')
            return func
        except Exception as e:
            self.list.append('...in except')
            self.list.append(e)  # important line - here the error gets ""logged""
            if not silent:
                raise e
</code></pre>

<p>Here is the <strong>function with an error</strong></p>

<pre><code>def transformation_with_error(app1, app2):
    # DO STUFF HERE with inputs
    result = str(app1)+str(app2)
    print(result)
    print('TYPE ERROR here')
    raise TypeError
    return result
</code></pre>

<p>Here the <strong>main routine</strong>:</p>

<pre><code>if __name__ == ""__main__"":
    error_tracker = ErrorTracker()

    print('-- start transformation')
    error_tracker.track_func(transformation_with_error(app1='AA', app2='BB'), silent=True)
    print('-- end transformation')

    print(error_tracker.list)
</code></pre>
"
"60020140","<p>The argument to the constructor <a href=""https://wxpython.org/Phoenix/docs/html/wx.adv.Animation.html"" rel=""nofollow noreferrer""><code>wx.adv.Animation</code></a> is the filename. So it has to be:</p>

<pre class=""lang-py prettyprint-override""><code>anim = wx.adv.Animation()
anim.LoadFile(r'C:\Users\yuval\PycharmProjects\MultiTyping\pictures\back_gif.gif')
</code></pre>

<p>or</p>

<pre class=""lang-py prettyprint-override""><code>anim = wx.adv.Animation(r'C:\Users\yuval\PycharmProjects\MultiTyping\pictures\back_gif.gif')
</code></pre>

<p>Furthermore, I recommend to add a <a href=""https://wxpython.org/Phoenix/docs/html/wx.BoxSizer.html"" rel=""nofollow noreferrer""><code>wx.BoxSizer</code></a> to the frame:</p>

<pre class=""lang-py prettyprint-override""><code>sizer = wx.BoxSizer(wx.VERTICAL)
sizer.Add(anim_ctrl)
frame.SetSizerAndFit(sizer)
</code></pre>

<p>See the example:</p>

<pre class=""lang-py prettyprint-override""><code>import wx
from wx.adv import AnimationCtrl, Animation

app=wx.App()
frame = wx.Frame(None, -1, title='2', pos=(0, 0), size=(200, 200))
app.SetTopWindow(frame)
anim = Animation(r'C:\Users\yuval\PycharmProjects\MultiTyping\pictures\back_gif.gif')
anim_ctrl = AnimationCtrl(frame, -1, anim)

sizer = wx.BoxSizer(wx.VERTICAL)
sizer.Add(anim_ctrl)
frame.SetSizerAndFit(sizer)

frame.Show()
anim_ctrl.Play()

app.MainLoop()
</code></pre>
","6","2020-02-01 19:02:31","1","136140","16645","626","8521","60019621","60020140","<p>I try to play a gif in my frame. I use this code in order to do it. Why doesn't it work?<br>
(I use the last version of wxPython - 4.0.7.post2)</p>

<pre><code>import wx
from wx.adv import AnimationCtrl

class Animate(wx.Frame):
    def __init__(self, parent, id, title):
        wx.Frame.__init__(self, parent, -1, title)
        self.animation = AnimationCtrl(self)
        self.animation.LoadFile('scan.gif')
        self.animation.Play()
        self.Show()

app = wx.App()
frame = Animate(None, -1, 'Animation')
app.MainLoop()
</code></pre>

<p><a href=""https://i.stack.imgur.com/zQGIc.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/zQGIc.png"" alt=""Frame""></a></p>
"
"60025340","<p>I see nothing wrong with the answer given by @Rabbid76, I suggest that you run the code from the command line, rather than from within some ide.<br>
Here is another take on your problem, it's as concise as I can make it and assumes a <code>local</code> file called <code>scan.gif</code>.    </p>

<pre><code>import wx
from wx.adv import AnimationCtrl

class Animate(wx.Frame):
    def __init__(self, parent, id, title):
        wx.Frame.__init__(self, parent, -1, title)
        self.animation = AnimationCtrl(self)
        self.animation.LoadFile('scan.gif')
        self.animation.Play()
        self.Show()

app = wx.App()
frame = Animate(None, -1, 'Animation')
app.MainLoop()
</code></pre>
","5","","1","16833","416","37","1242","60019621","60020140","<p>I try to play a gif in my frame. I use this code in order to do it. Why doesn't it work?<br>
(I use the last version of wxPython - 4.0.7.post2)</p>

<pre><code>import wx
from wx.adv import AnimationCtrl

class Animate(wx.Frame):
    def __init__(self, parent, id, title):
        wx.Frame.__init__(self, parent, -1, title)
        self.animation = AnimationCtrl(self)
        self.animation.LoadFile('scan.gif')
        self.animation.Play()
        self.Show()

app = wx.App()
frame = Animate(None, -1, 'Animation')
app.MainLoop()
</code></pre>

<p><a href=""https://i.stack.imgur.com/zQGIc.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/zQGIc.png"" alt=""Frame""></a></p>
"
"60021390","<p>It's almost certainly an adjustment for numerical error. To see why this might be necessary, look what happens when you take the <code>svd</code> of a rank-one 2x2 matrix. We can create a rank-one matrix by taking the outer product of a vector like so:</p>

<pre><code>&gt;&gt;&gt; a = numpy.arange(2) + 1
&gt;&gt;&gt; A = a[:, None] * a[None, :]
&gt;&gt;&gt; A
array([[1, 2],
       [2, 4]])
</code></pre>

<p>Although this is a 2x2 matrix, it only has one linearly independent column, and so its <a href=""https://en.wikipedia.org/wiki/Rank_(linear_algebra)"" rel=""nofollow noreferrer"">rank</a> is one instead of two. So we should expect that when we pass it to <code>svd</code>, one of the singular values will be zero. But look what happens:</p>

<pre><code>&gt;&gt;&gt; U, s, V = numpy.linalg.svd(A)
&gt;&gt;&gt; s
array([5.00000000e+00, 1.98602732e-16])
</code></pre>

<p>What we actually get is a singular value that is <em>not quite</em> zero. This result is inevitable in many cases given that we are working with finite-precision floating point numbers. So although the problem you have identified is a real one, we will not be able to tell in practice the difference between a matrix that really has a very small singular value and a matrix that ought to have a zero singular value but doesn't. Setting small values to zero is the safest practical way to handle that problem.</p>
","0","2020-02-03 15:06:46","2","123320","2200","152","5846","60019708","60021390","<p>I was going through the book called <em>Hands-On Machine Learning with Scikit-Learn, Keras and Tensorflow</em> and the author was explaining how the pseudo-inverse (Moore-Penrose inverse) of a matrix is calculated in the context of Linear Regression. I'm quoting verbatim here:</p>
<blockquote>
<p>The pseudoinverse itself is computed using a standard matrix
factorization technique called Singular Value Decomposition (SVD) that
can decompose the training set matrix <strong>X</strong> into the matrix
multiplication of three matrices <strong>U</strong> <strong>Σ</strong> <strong>V</strong>T (see numpy.linalg.svd()). The
pseudoinverse is calculated as <strong>X</strong>+ = <strong>V</strong> * <strong>Σ</strong>+ * <strong>U</strong>T. To compute the matrix
<strong>Σ</strong>+, the algorithm takes <strong>Σ</strong> and sets to zero all values smaller than a
tiny threshold value, then it replaces all nonzero values with their
inverse, and finally it transposes the resulting matrix. This approach
is more efficient than computing the Normal equation.</p>
</blockquote>
<p>I've got an understanding of how the pseudo-inverse and SVD are related from <a href=""https://math.stackexchange.com/questions/19948/pseudoinverse-matrix-and-svd"">this</a> post. But I'm not able to grasp the rationale behind setting all values less than the threshold to zero. The inverse of a diagonal matrix is obtained by taking the reciprocals of the diagonal elements. Then small values would be converted to large values in the inverse matrix, right? Then why are we removing the large values?</p>
<p>I went and looked into the numpy code, and it looks like follows, just for reference:</p>
<pre><code>@array_function_dispatch(_pinv_dispatcher)
def pinv(a, rcond=1e-15, hermitian=False):
    a, wrap = _makearray(a)
    rcond = asarray(rcond)
    if _is_empty_2d(a):
        m, n = a.shape[-2:]
        res = empty(a.shape[:-2] + (n, m), dtype=a.dtype)
        return wrap(res)
    a = a.conjugate()
    u, s, vt = svd(a, full_matrices=False, hermitian=hermitian)

    # discard small singular values
    cutoff = rcond[..., newaxis] * amax(s, axis=-1, keepdims=True)
    large = s &gt; cutoff
    s = divide(1, s, where=large, out=s)
    s[~large] = 0

    res = matmul(transpose(vt), multiply(s[..., newaxis], transpose(u)))
    return wrap(res)
</code></pre>
"
"60020046","<p>You are check to see if a list exists in an array of arrays. Convert your list to an array and it should work. </p>

<pre><code>&gt;&gt;&gt; x=np.array([np.array([5, 5, 5]), np.array([6, 6, 6])])
&gt;&gt;&gt; np.array([5, 5, 5]) in x
True
</code></pre>
","0","","2","1323","92","59","106","60019782","60020046","<p>I have a array of numpy arrays</p>

<p><code>[array([5, 5, 5]), array([6, 6, 6])]</code></p>

<p>However if I try to check if an object exists in that array </p>

<p><code>[5, 5, 5] in x</code></p>

<p>I get this error </p>

<p><code>ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()</code></p>

<p>Is there any way to fix this? Or am I doing something wrong?</p>
"
"60020854","<p>I was able to solve this issue by using <a href=""https://docs.scipy.org/doc/scipy/reference/generated/scipy.io.savemat.html"" rel=""nofollow noreferrer"">scipy.io.savemat()</a> and <a href=""https://docs.scipy.org/doc/scipy/reference/generated/scipy.io.loadmat.html"" rel=""nofollow noreferrer"">scipy.io.loadmat()</a>. I was using np.savz() and np.load() before and that was taking too much memory. </p>
","3","","0","549","0","0","70","60019795","60021116","<p>I am importing sparse matrices from .npz file. Below is the script of the code. The sparse matrices (Dx, Dy, ..., M) have 373248x373248 size with 746496 stored elements.  </p>

<pre><code>if runmode == 2:
        data = np.load('Operators2.npz', allow_pickle=True)

    Dx = data['Dx']
    Dy = data['Dy']
    Dz = data['Dz']
    Dxx = data['Dxx']
    Dyy = data['Dyy']
    Dzz = data['Dzz']
    Dxp = data['Dxp']
    Dyp = data['Dyp']
    Dzp = data['Dzp']
    M = data['M']
    del data
</code></pre>

<p>If I print one of the variable, for example Dx, I get below output:</p>

<pre><code>array(&lt;373248x373248 sparse matrix of type '&lt;class 'numpy.float64'&gt;'
    with 746496 stored elements in Compressed Sparse Column format&gt;,
      dtype=object)
</code></pre>

<p>But my system memory goes up and the program crashes. The program crashes when I execute the below line of code. I do not get any error, but the program crashes.</p>

<pre><code>DIV = Dx*u+Dy*v+Dz*w
</code></pre>

<p>Even if I execute below lines of code, the memory consumption goes up and the program crashes</p>

<pre><code>DIV = data['Dx']*u+data['Dy']*v+data['Dz']*w
</code></pre>

<p>Here u,v,w has 373248x1 shape. The shape of DIV is 373248x1. Since Dx, Dy, Dz are sparse matrices, Dx*u does matrix-vector multiplication and gives a vector. </p>

<p>If in the same code, I actually compute Dx, Dy,...,M there is no problem with the memory. If I am computing Dx then the output is as below:</p>

<pre><code>&lt;373248x373248 sparse matrix of type '&lt;class 'numpy.float64'&gt;'
    with 746496 stored elements in Compressed Sparse Column format&gt;
</code></pre>

<p>So I think the issue with creating an object while importing. Is there a way to avoid that? Or,am I doing something wrong while importing the sparse matrices? 
Thank you. </p>
"
"60021116","<p>Make a sparse matrix:</p>

<pre><code>In [38]: M = sparse.random(1000,1000,.2,'csr')                                                 
</code></pre>

<p>save it 3 different ways:</p>

<pre><code>In [39]: from scipy import io                                                                  
In [40]: np.savez('Msparse.npz', M=M)                                                          
In [41]: sparse.save_npz('M1sparse',M)                                                         

In [43]: io.savemat('Msparse.mat', {'M':M})                                                    
</code></pre>

<p>file sizes:</p>

<pre><code>In [47]: ll M1spa* Mspar*                                                                      
-rw-rw-r-- 1 paul 1773523 Feb  1 12:40 M1sparse.npz
-rw-rw-r-- 1 paul 2404208 Feb  1 12:41 Msparse.mat
-rw-rw-r-- 1 paul 2404801 Feb  1 12:39 Msparse.npz
</code></pre>

<p>Load the 3 matrices:</p>

<pre><code>In [48]: M1=sparse.load_npz('M1sparse.npz')                                                    
In [49]: M2=np.load('Msparse.npz',allow_pickle=True)['M']                                      
In [50]: M3=io.loadmat('Msparse.mat')['M']                                                     
In [51]: M1                                                                                    
Out[51]: 
&lt;1000x1000 sparse matrix of type '&lt;class 'numpy.float64'&gt;'
    with 200000 stored elements in Compressed Sparse Row format&gt;
In [52]: M2                                                                                    
Out[52]: 
array(&lt;1000x1000 sparse matrix of type '&lt;class 'numpy.float64'&gt;'
    with 200000 stored elements in Compressed Sparse Row format&gt;,
      dtype=object)
In [53]: M3                                                                                    
Out[53]: 
&lt;1000x1000 sparse matrix of type '&lt;class 'numpy.float64'&gt;'
    with 200000 stored elements in Compressed Sparse Column format&gt;
</code></pre>

<p><code>M1</code> and <code>M3</code> are the same - <code>csr</code> like <code>M</code> for <code>save_npz</code>, <code>csc</code> (the MATLAB format) for <code>.mat</code>.</p>

<p><code>M2</code> is has an object dtype wrapper.</p>

<pre><code>In [54]: (M1*np.ones((1000,1))).shape                                                          
Out[54]: (1000, 1)
In [55]: (M3*np.ones((1000,1))).shape                                                          
Out[55]: (1000, 1)
</code></pre>

<p>This took a lot longer; and I almost don't dare look at the result.</p>

<pre><code>In [56]: (M2*np.ones((1000,1))).shape                                                          
Out[56]: (1000, 1)
</code></pre>

<p>If I extract the matrix from the object array, the multiplication is fast</p>

<pre><code>In [57]: (M2.item()*np.ones((1000,1))).shape                                                   
Out[57]: (1000, 1)
In [58]: (M2.item()*np.ones((1000,1))).dtype                                                   
Out[58]: dtype('float64')
In [59]: (M3*np.ones((1000,1))).dtype                                                          
Out[59]: dtype('float64')
</code></pre>

<p>Looking more closely at the <code>M2</code> multiplication:</p>

<pre><code>In [60]: (M2*np.ones((1000,1))).dtype                                                          
Out[60]: dtype('O')
In [61]: (M2*np.ones((1000,1)))[:2,:]                                                          
Out[61]: 
array([[&lt;1000x1000 sparse matrix of type '&lt;class 'numpy.float64'&gt;'
    with 200000 stored elements in Compressed Sparse Row format&gt;],
       [&lt;1000x1000 sparse matrix of type '&lt;class 'numpy.float64'&gt;'
    with 200000 stored elements in Compressed Sparse Row format&gt;]],
      dtype=object)
</code></pre>

<p>It's performing a <code>M*1</code> multiplication for each element of <code>ones</code> - making 1000 sparse matrices.  That's where your memory consumption is going.</p>

<p>In sum, when using <code>savez</code> it wraps each sparse matrix in an object dtype array, and does the pickle.  So you shouldn't use `data['Dx'] directly</p>

<pre><code>Dx = data['Dx']  # wrong
Dx = data['Dx'].item()    # right
</code></pre>
","0","","1","172516","3363","73","13055","60019795","60021116","<p>I am importing sparse matrices from .npz file. Below is the script of the code. The sparse matrices (Dx, Dy, ..., M) have 373248x373248 size with 746496 stored elements.  </p>

<pre><code>if runmode == 2:
        data = np.load('Operators2.npz', allow_pickle=True)

    Dx = data['Dx']
    Dy = data['Dy']
    Dz = data['Dz']
    Dxx = data['Dxx']
    Dyy = data['Dyy']
    Dzz = data['Dzz']
    Dxp = data['Dxp']
    Dyp = data['Dyp']
    Dzp = data['Dzp']
    M = data['M']
    del data
</code></pre>

<p>If I print one of the variable, for example Dx, I get below output:</p>

<pre><code>array(&lt;373248x373248 sparse matrix of type '&lt;class 'numpy.float64'&gt;'
    with 746496 stored elements in Compressed Sparse Column format&gt;,
      dtype=object)
</code></pre>

<p>But my system memory goes up and the program crashes. The program crashes when I execute the below line of code. I do not get any error, but the program crashes.</p>

<pre><code>DIV = Dx*u+Dy*v+Dz*w
</code></pre>

<p>Even if I execute below lines of code, the memory consumption goes up and the program crashes</p>

<pre><code>DIV = data['Dx']*u+data['Dy']*v+data['Dz']*w
</code></pre>

<p>Here u,v,w has 373248x1 shape. The shape of DIV is 373248x1. Since Dx, Dy, Dz are sparse matrices, Dx*u does matrix-vector multiplication and gives a vector. </p>

<p>If in the same code, I actually compute Dx, Dy,...,M there is no problem with the memory. If I am computing Dx then the output is as below:</p>

<pre><code>&lt;373248x373248 sparse matrix of type '&lt;class 'numpy.float64'&gt;'
    with 746496 stored elements in Compressed Sparse Column format&gt;
</code></pre>

<p>So I think the issue with creating an object while importing. Is there a way to avoid that? Or,am I doing something wrong while importing the sparse matrices? 
Thank you. </p>
"
"60021136","<p>The calculation would be well-suited for in-place operations:</p>

<pre><code>np.multiply(data['Dx'], u, out=data['Dx']
np.multiply(data['Dy'], v, out=data['Dy']
np.multiply(data['Dz'], w, out=data['Dz']
numpy.add(data['Dx'], data['Dy'], out=data['Dx'])
numpy.add(data['Dx'], data['Dz'], out=data['Dx'])
</code></pre>

<p>which creates no additional temporary arrays. If you also avoid loading the other variables that are not required for this specific computation, you will save additional memory. Doing the work inside a function is a good way to ensure you clean-up / free memory once the work is done. In your case it is possibly better to pay a read penalty and just read in the specific data you need for each such calculation. Though like hpaulj said, there's not much more magic you can find; it's a large dataset and will require lots of memory. Any way to reduce the size / resolution of the problem, or work it in smaller blocks?</p>
","0","","0","10399","969","364","1560","60019795","60021116","<p>I am importing sparse matrices from .npz file. Below is the script of the code. The sparse matrices (Dx, Dy, ..., M) have 373248x373248 size with 746496 stored elements.  </p>

<pre><code>if runmode == 2:
        data = np.load('Operators2.npz', allow_pickle=True)

    Dx = data['Dx']
    Dy = data['Dy']
    Dz = data['Dz']
    Dxx = data['Dxx']
    Dyy = data['Dyy']
    Dzz = data['Dzz']
    Dxp = data['Dxp']
    Dyp = data['Dyp']
    Dzp = data['Dzp']
    M = data['M']
    del data
</code></pre>

<p>If I print one of the variable, for example Dx, I get below output:</p>

<pre><code>array(&lt;373248x373248 sparse matrix of type '&lt;class 'numpy.float64'&gt;'
    with 746496 stored elements in Compressed Sparse Column format&gt;,
      dtype=object)
</code></pre>

<p>But my system memory goes up and the program crashes. The program crashes when I execute the below line of code. I do not get any error, but the program crashes.</p>

<pre><code>DIV = Dx*u+Dy*v+Dz*w
</code></pre>

<p>Even if I execute below lines of code, the memory consumption goes up and the program crashes</p>

<pre><code>DIV = data['Dx']*u+data['Dy']*v+data['Dz']*w
</code></pre>

<p>Here u,v,w has 373248x1 shape. The shape of DIV is 373248x1. Since Dx, Dy, Dz are sparse matrices, Dx*u does matrix-vector multiplication and gives a vector. </p>

<p>If in the same code, I actually compute Dx, Dy,...,M there is no problem with the memory. If I am computing Dx then the output is as below:</p>

<pre><code>&lt;373248x373248 sparse matrix of type '&lt;class 'numpy.float64'&gt;'
    with 746496 stored elements in Compressed Sparse Column format&gt;
</code></pre>

<p>So I think the issue with creating an object while importing. Is there a way to avoid that? Or,am I doing something wrong while importing the sparse matrices? 
Thank you. </p>
"
"60029327","<p>(MongoEngine contributor here) MongoEngine indeed adds some metadata to the lists , it uses a subclass of the builtin <code>list</code> class behind the scene. Those aren't stored in MongoDB, they allow MongoEngine to deal with  auto de-referencing or track changes that are applied on the document instance. They should be harmless to your application since they can be manipulated as standard python lists.</p>

<p>Trying to get around it isn't a good idea as its part of the internals of MongoEngine.</p>
","0","","0","2992","486","22","162","60019803","60029327","<p>I am currently working with mongoengine in python. When I store a Document with a list variable and I ""get"" it after, mongoengine adds some metadata to the list. How can I get rid of the metadata?</p>

<pre><code>class Example(Document)
   key = StrinField(primary_key = True)
   lis1 = ListField()

lis2 = [1,2,3]

obj = Example(lis1 = lis2, key = ""123"")
obj.save()

obj0 = Example.objects.get(key = ""123"")
print(obj0.lis1)

&gt;&gt; Output is the list plus metadata like _dereferenced, _instance and _name

</code></pre>

<p>My approach is to save all the lists as serialized string, but there must be a better solution to this!</p>
"
"60021322","<p>Here are steps that is possible for you to do here:</p>

<ol>
<li>Get the tuples of ids of objects you have created on <code>canvas</code>. You can do it using <code>canvas.find_all()</code> method.</li>
<li>Get coordinates of these objects using <code>canvas.coords(id)</code>.</li>
</ol>

<p>I have checked out standard <code>find_overlapping</code> method of <code>canvas</code>. It helps to determine which object are overlapped with specific rectangle only and I guess you need to solve problem you mentioned using some mathematics with a help of this method. Although, I have found a nice alternative, not based on <code>find_overlapping</code>:</p>

<pre><code>def find_overlaps(self):
    r = 5
    X = []
    tags = self.canvas.find_all() #finds tags of all the object created
    for tag in tags:
        x0, y0, x1, y1 = self.canvas.coords(tag) # corresponding coordinates
        center = [(x0+x1)/2, (y0+y1)/2] #centers of objects
        X.append(center)

    tree = cKDTree(X)
    print(tree.query_pairs(2*r))
</code></pre>

<h3>Output</h3>

<p>This is a set of couples of tags:</p>

<pre><code>{(2, 63), (10, 93), (70, 82), (8, 45)}
</code></pre>

<h3>Note</h3>

<p><code>from scipy.spatial import cKDTree</code> is required</p>
","3","","1","3747","281","19","426","60019822","60021322","<p>is there any easy way to find the objects ids that are overlapped?
Here's an example of the code:</p>

<pre class=""lang-py prettyprint-override""><code>import tkinter as tk
import random as rand


class GUI:
    def __init__(self, master, width, height):
        self.master = master
        self.w = width
        self.h = height
        self.canvas = tk.Canvas(master, width=width, height=height)
        self.canvas.pack()
        self.create_objects()

    def create_objects(self):
        r = 5
        for i in range(100):
            x = rand.uniform(0,1)*width
            y = rand.uniform(0,1)*height
            self.canvas.create_oval(x-r,y-r,x+r,y+r, fill=""red"")

    def find_overlaps(self):
        pass


width = 800
height = 600

root = tk.Tk()
app = GUI(root, width, height)
root.mainloop()
</code></pre>

<p>I would like for the find_overlaps function to give me the pairs of the object ids that are overlapped (or tripplets if such case happen). Is there any easy/efficient way to do it?</p>
"
"60020120","<p>There's a couple issues here. First, you cannot read the file because you're opening it with <code>a+</code> and so you read from the last line, so instead you have to add:</p>

<pre><code>info.seek(0)
</code></pre>

<p>I'd also suggest adding a <code>,</code> to ensure the names don't mix:</p>

<pre><code>info.write(f""{user_name},"") 
</code></pre>

<p>Lastly, I'd suggest opening the file with a <code>with</code> statement so you don't accidentily leave it open:</p>

<pre><code>with open(""user_info.txt"", ""a+"") as info:
</code></pre>

<p>Putting it all together:</p>

<pre><code>with open(""user_info.txt"", ""a+"") as info:
    info.seek(0)
    user_status = input(""Are you a new user (Y)es or (N)o"")
    if user_status.lower() == (""y""):
        print(""Welcome To Login Master 1000"")
        user_name = input(""Type in user name"")
        if str(user_name) in info.read().split(','):
            print(""That Name Is Taken"")
        info.write(f""{user_name},"")
</code></pre>
","1","","1","3322","293","58","422","60019908","60020120","<p>I'm attempting to make a python program that simulates a login. The goal for the program is to write then read a text file to see if the username(User_name) and password(password) match then log you in!. <strong>My problem is its not reading the file and when it writes its on a single line</strong> for example the output to my text file  is usernameusernameusername, i'm unsure if that messes up the program when reading if the username already exists. </p>

<pre><code> info = open(""user_info.txt"", ""a+"")
user_status = input(""Are you a new user (Y)es or (N)o"")
if user_status.lower() == (""y""):
    print(""Welcome To Login Master 1000"")
    user_name = input(""Type in user name"")
    if str(user_name) in info.readlines():
        print(""That Name Is Taken"")
    info.write(user_name) 
</code></pre>
"
"60020293","<p>Great start to your program.  Couple things here... when you are manually opening files for modification, you have to manually close the file at the end of your program with <code>info.close()</code>. </p>

<p>The decision for how to store your data in a file has been changed since the beginning of computers.  For simplicity and learning sake, you may just want to store your usernames and passwords in a comma separated file, <code>.csv</code> Or space separated file.  This will allow you to read a line and then split the line into their individual strings for testing.</p>

<p>When writing to file I believe you can append strings with the <code>+</code> operator.  So to create a space separated file you could <code>info.write(user_name+“,”+”password”+”\n”)</code>. Now you have an comma to split off of and only one user and password saved in your file per line.</p>

<p>Your file may be reading already.  To see if the file is being read, before the if statement try <code>print(“Current line is -&gt; “,info.readline())</code> as readline will read only one line.  </p>

<p>If the file is not being read or there is no content in that print or you get an error, then it could be the permission on your file or its a simple option in your <code>a+</code> option needs to be changed.</p>

<p>Next, the keyword <code>in</code> is not checking the content as you intend although this is a good idea.<br>
<code>in</code> is better used to iterate every line of the file <code>for line in info:</code>
<code>Print(info.readline())</code>
The advantage to this method is you can split each line username and password into a list with split. So -></p>

<pre><code>For line in info:
    Print(line)
    Tokens = line.split(“,”) # if comma separated
    If user_name == tokens[0]:
        #Matched input username with file content
</code></pre>

<p>Now when you print tokens you will have a comma separated list looking like <code>[“Username”,”password”]</code> and then you can access <code>”Username”</code> with <code>Tokens[0]</code> and you can access <code>”password”</code> with <code>Tokens[1]</code> because list indexing starts with 0.  </p>
","1","","0","127","34","0","65","60019908","60020120","<p>I'm attempting to make a python program that simulates a login. The goal for the program is to write then read a text file to see if the username(User_name) and password(password) match then log you in!. <strong>My problem is its not reading the file and when it writes its on a single line</strong> for example the output to my text file  is usernameusernameusername, i'm unsure if that messes up the program when reading if the username already exists. </p>

<pre><code> info = open(""user_info.txt"", ""a+"")
user_status = input(""Are you a new user (Y)es or (N)o"")
if user_status.lower() == (""y""):
    print(""Welcome To Login Master 1000"")
    user_name = input(""Type in user name"")
    if str(user_name) in info.readlines():
        print(""That Name Is Taken"")
    info.write(user_name) 
</code></pre>
"
"60020000","<p>When the second argument is <code>-1</code>, it calculates the modular inverse of <code>a (mod c)</code>. Using other negative powers <code>-n</code> will return the modular inverse to the <code>n</code>-th power <code>(mod c)</code>.</p>

<p><a href=""https://en.wikipedia.org/wiki/Modular_multiplicative_inverse"" rel=""nofollow noreferrer"">https://en.wikipedia.org/wiki/Modular_multiplicative_inverse</a></p>
","0","","0","491","19","2","29","60019932","60020038","<p>Python allows a third argument in the built-in function <code>pow</code> that basically computes the  exponentiation modulo this third argument (<code>pow(a,b,c) = a**b % c</code>).</p>

<p>How does it work when the exponent is negative? E.g.:</p>

<pre><code>pow(6, -2, 13)
#-&gt; 4

pow(6, -2, 12)
#-&gt; Traceback (most recent call last):
#-&gt;  File ""&lt;stdin&gt;"", line 1, in &lt;module&gt;
#-&gt;  ValueError: base is not invertible for the given modulus
</code></pre>
"
"60020038","<p>From the python built-in functions documentation:</p>

<blockquote>
  <p>For int operands base and exp, if mod is present, mod must also be of integer type and mod must be nonzero. If mod is present and exp is negative, base must be relatively prime to mod. In that case, pow(inv_base, -exp, mod) is returned, where inv_base is an inverse to base modulo mod.</p>
</blockquote>

<p>which means that in your example, python calculates the inverse of 6 (so that <code>6 * inverse = 1</code>) and calculates <code>pow(inverse, 2, 13)</code>. In this case the inverse of 6 mod 13 is 11 (<code>6 * 11 = 66 = 1 mod 13</code>) and you calculate <code>11 ** 2 = 121 = 4 mod 13</code>.</p>
","0","","1","88","4","0","9","60019932","60020038","<p>Python allows a third argument in the built-in function <code>pow</code> that basically computes the  exponentiation modulo this third argument (<code>pow(a,b,c) = a**b % c</code>).</p>

<p>How does it work when the exponent is negative? E.g.:</p>

<pre><code>pow(6, -2, 13)
#-&gt; 4

pow(6, -2, 12)
#-&gt; Traceback (most recent call last):
#-&gt;  File ""&lt;stdin&gt;"", line 1, in &lt;module&gt;
#-&gt;  ValueError: base is not invertible for the given modulus
</code></pre>
"
"60020074","<p>Have you tried to check it out for yourself? Python used to not support negative exponents when the third argument was supplied, something they changed in version 3.8.x, and now what it does is allow you to compute the modular inverse (as opposed to the 'standard' inverse when dealing with the reals).</p>

<p>So, if example pow(2, -1, 3) would tell you the inverse in mod 3 which would be 2, because 2*2 =4 = 1 mod 3 </p>
","0","","0","23","4","0","3","60019932","60020038","<p>Python allows a third argument in the built-in function <code>pow</code> that basically computes the  exponentiation modulo this third argument (<code>pow(a,b,c) = a**b % c</code>).</p>

<p>How does it work when the exponent is negative? E.g.:</p>

<pre><code>pow(6, -2, 13)
#-&gt; 4

pow(6, -2, 12)
#-&gt; Traceback (most recent call last):
#-&gt;  File ""&lt;stdin&gt;"", line 1, in &lt;module&gt;
#-&gt;  ValueError: base is not invertible for the given modulus
</code></pre>
"
"60020122","<pre><code>pow(base, exp) =  base**exp
pow(12,2) = 144 = 12**2
</code></pre>

<p>Now computation of modular inverses in supported 3.8 afterwards. Before that they denied to inverse to base modulu</p>
","0","","0","1606","27","10","326","60019932","60020038","<p>Python allows a third argument in the built-in function <code>pow</code> that basically computes the  exponentiation modulo this third argument (<code>pow(a,b,c) = a**b % c</code>).</p>

<p>How does it work when the exponent is negative? E.g.:</p>

<pre><code>pow(6, -2, 13)
#-&gt; 4

pow(6, -2, 12)
#-&gt; Traceback (most recent call last):
#-&gt;  File ""&lt;stdin&gt;"", line 1, in &lt;module&gt;
#-&gt;  ValueError: base is not invertible for the given modulus
</code></pre>
"
"60020309","<p>Use this:</p>

<p><code>id_of_first_artist = result['artist-list'][0]['id']</code></p>
","0","","0","306","34","9","20","60019966","60020309","<p>Currently learning python to forgive me but I am using this musicbrainzngs API to grab the ID of an artist's name from user input. It should then take the ID and list 5 random songs from the artist in question. Right now I am trying to figure out to get the ID from the relevant artist so it can be then used in a separate search to return 5 songs from that artist. </p>

<p>documentation API: <a href=""https://python-musicbrainzngs.readthedocs.io/en/v0.7.1/usage/"" rel=""nofollow noreferrer"">https://python-musicbrainzngs.readthedocs.io/en/v0.7.1/usage/</a></p>

<p>Code as shown:</p>

<pre><code>from urllib.request import Request, urlopen
import musicbrainzngs
import sys
musicbrainzngs.set_useragent(""LyricsWordCount"", ""1.0"", ""azizn03"",)
#musicbrainzngs.set_hostname(""musicbrainz.org"", use_https=False)

artist = input(""Enter Artist Name "")

result = musicbrainzngs.search_artists(artist="""" + artist, type=""group"",
                                   country=""GB"")
for artist in result['artist-list']:
    print(""{name}: {id}"".format(name=artist[""name""], id=artist['id']))
</code></pre>

<p>results:</p>

<pre><code>Enter Artist Name coldplay
Coldplay: cc197bad-dc9c-440d-a5b5-d52ba2e14234
Viva La Coldplay: 62c54a75-265f-4e13-ad0a-0fb001559a2e
The Beatles: b10bbbfc-cf9e-42e0-be17-e2c3e1d2600d
The Rolling Stones: b071f9fa-14b0-4217-8e97-eb41da73f598
Pink Floyd: 83d91898-7763-47d7-b03b-b92132375c47
George Frideric Handel: 27870d47-bb98-42d1-bf2b-c7e972e6befc
</code></pre>
"
"60020316","<p>This is how tkinter is designed to work. When you destroy a window, all of its children are destroyed. Since everything is a child of the root window or one of its children, when you destroy the root window all other widgets are destroyed along with it. </p>
","0","","0","304622","14209","14165","34310","60019993","60020316","<p>I made a gui programm with Tkinter. In the program are several buttons which open new main tkinter windows but when i click on the 'x' of one of these windows all the other ones close too although they are different windows. Only the Buttons, which cause the new tkinter main windows, are in the same main window.</p>

<p>please help :))</p>
"
"60020856","<p>You are passing values to the method in the wrong way. The first parameter is <code>xs</code> and should contain all the <strong><em>x</em></strong> series, but <em>not</em> any of the <strong><em>y</em></strong> series. Howefer you are passing <code>[x, y1]</code> for <code>xs</code>, which will plot the <code>y1</code> values as the x-coordinates for the second line. You probably intend this:</p>

<pre><code>p.multi_line([x, x], [y1, y2], ...)
</code></pre>
","0","","1","29791","466","194","3548","60020047","60020856","<p>I'm working with this dataframe:</p>

<p><a href=""https://i.stack.imgur.com/8ZdEi.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/8ZdEi.png"" alt=""enter image description here""></a></p>

<p>I'm trying to use Bokeh to generate a multi-line plot with <code>['Joined']</code> as the x-value:</p>

<pre><code># Split columns for multi-line plot
x = df['Joined'].tolist()
y1 = df['Mean_value'].tolist()
y2 = df['Median_value'].tolist()

# Set Figure and Plot

p = figure(height=600, width=900, toolbar_location=None, x_range=x)

p.multi_line([x, y1], [x, y2], color=['#CE1141', '#06BB6'], alpha=[0.54, 0.40], line_width=3)
</code></pre>

<p>It's giving me this right now:</p>

<p><a href=""https://i.stack.imgur.com/bwBQh.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/bwBQh.png"" alt=""enter image description here""></a></p>

<p>I can get the desired result by plotting separate lines, but it makes using the HoverTool very complicated.</p>

<p>Any ideas?</p>

<p>Thanks!</p>
"
"60020095","<p>If you just want a list of sets you can do:</p>

<pre><code>[set() for i in range(12)]
</code></pre>

<hr>

<p>In your code you're both looping through <code>roll</code> and modifying the elements. </p>

<p>Also <code>{}</code> makes a <code>dict</code> not a <code>set</code>.</p>
","1","2020-02-01 18:52:22","0","2489","54","19","236","60020057","60020216","<p>I am fairly new to programming and now I want to create a simple craps game in Python.
However, I instantly run into a problem. I want to make a list of 12 elements and then make all of them empty sets.</p>

<pre><code>roll = [i for i in range(12)]   
for i in roll:  
   roll[i] = {}  
print(roll)
</code></pre>

<p>Sure it works, but there is some issue. It indicates <code>i</code> in the for-loop and says unexpected types, which makes me think there is a more legitimate way of doing this, and I'd like to know why it doesn't work. I did the test to make roll a list of 12 sets in the first place by changing the function, sure it avoids the problem, but doesn't make me learn anything about this issue.</p>
"
"60020129","<pre><code>roll = [i for i in range(12)]
</code></pre>

<p><code>roll</code> is a list of integers, from 0 - 11 inclusive.</p>

<pre><code>for i in roll:
</code></pre>

<p>For every integer in the list...</p>

<pre><code>roll[i] = {} 
</code></pre>

<p>Treat the current integer as an index to the list, and replace the integer at that index with a dictionary (The literal <code>{}</code> is not a set). This happens to work the way you intended because the integers in the list happen to be the same values as the indices at which they appear in the list.</p>

<p>The whole thing is redundant to begin with - you don't need to create 12 integers to ""allocate"" space for the sets later on, just create the sets in the list comprehension:</p>

<pre><code>roll = [set() for _ in range(12)]
</code></pre>
","1","","1","6892","83","2","671","60020057","60020216","<p>I am fairly new to programming and now I want to create a simple craps game in Python.
However, I instantly run into a problem. I want to make a list of 12 elements and then make all of them empty sets.</p>

<pre><code>roll = [i for i in range(12)]   
for i in roll:  
   roll[i] = {}  
print(roll)
</code></pre>

<p>Sure it works, but there is some issue. It indicates <code>i</code> in the for-loop and says unexpected types, which makes me think there is a more legitimate way of doing this, and I'd like to know why it doesn't work. I did the test to make roll a list of 12 sets in the first place by changing the function, sure it avoids the problem, but doesn't make me learn anything about this issue.</p>
"
"60020216","<ul>
<li><p>you can define an empty set in the following way: <code>set()</code></p></li>
<li><p><code>{}</code> it is used for an empty dictionary</p></li>
</ul>

<p>you can use in your example:</p>

<pre><code>roll = [i for i in range(12)]   
for i in roll:  
   roll[i] = set()
print(roll)
</code></pre>
","2","","0","15189","2120","120","950","60020057","60020216","<p>I am fairly new to programming and now I want to create a simple craps game in Python.
However, I instantly run into a problem. I want to make a list of 12 elements and then make all of them empty sets.</p>

<pre><code>roll = [i for i in range(12)]   
for i in roll:  
   roll[i] = {}  
print(roll)
</code></pre>

<p>Sure it works, but there is some issue. It indicates <code>i</code> in the for-loop and says unexpected types, which makes me think there is a more legitimate way of doing this, and I'd like to know why it doesn't work. I did the test to make roll a list of 12 sets in the first place by changing the function, sure it avoids the problem, but doesn't make me learn anything about this issue.</p>
"
"60020454","<p>IIUC, you want to map the values in commentID_parentID with the values of usernameChannelId associated to the same Id. You can try:</p>

<pre><code>#create the mapper
s_map = df.loc[df.Id.ne('NULL'), :].set_index(['Id'])['usernameChannelId']

# create the column by mapping the values where comment_parentID is not NULL, otherwise channelID
df['userChannelId_Target'] = np.where( df['commentID_parentID'].ne('NULL'), 
                                       df['commentID_parentID'].map(s_map), df['channelId'])

# see result
print (df[['usernameChannelId', 'userChannelId_Target' ]])
  usernameChannelId userChannelId_Target
0                 a                    g
1                 b                    k
2                 a                    a
3                 c                    a
4                 d                    h
5                 g                    b
</code></pre>
","0","","0","21768","2176","28","1062","60020141","60020454","<p>Same as <a href=""https://stackoverflow.com/questions/60019276/get-column-value-if-it-matches-another-column-value-in-the-same-table"">Get column value if it matches another column value in the same table</a> but with Python/pandas than with SQL because the query takes too long to run.</p>

<p>I have a df with:</p>

<pre><code>Id   | replyId | commentID_parentID | usernameChannelId | channelId
1    | NULL    | NULL               | a                 | g
2    | NULL    | NULL               | b                 | k
NULL | 1.k     | 1                  | a                 | p
NULL | 1.p     | 1                  | c                 | i
3    | NULL    | NULL               | d                 | h
NULL | 2.k     | 2                  | g                 | g
</code></pre>

<p>and a table with channels like:</p>

<p>I want to know which user (userChannelId) replied to which user.</p>

<p>So I take a row with a comment and check if:</p>

<pre><code>Id == NULL? Then it's a reply -&gt; get userChannelId where commentID_parentID == Id
Id != NULL? Then it's a main comment -&gt; userChannelId replied to channelId
</code></pre>

<p>And result should be:</p>

<pre><code>userChannelId_Source | userChannelId_Target
a                    | g
b                    | k
a                    | a
c                    | a
g                    | b
</code></pre>

<p>Comment ""d"" has no entry where commentID_parentID == Id so it's left out.</p>

<p>My code so far:</p>

<pre><code>cm[""usernameChannelId_reply""] = None

for row in cm.itertuples():
    if cm.commentID_parentID is None: # comment is a main comment
        cm.at[row.Index, 'usernameChannelId_reply'] = cm.channelId
    else: # comment is a reply comment
        temp = cm.loc[cm.Id == row.commentID_parentID][""usernameChannelId""][0]
        #temp = cm.query(""Id == commentID_parentID"").head(1).loc[:, 'usernameChannelId']
        print(temp)
        if len(set(temp)) == 0:
            print(0, row.Index)
            #cm.at[row.Index, 'usernameChannelId_reply'] = temp
        else:
            cm.at[row.Index, 'usernameChannelId_reply'] = temp
</code></pre>

<p>But I get a</p>

<blockquote>
  <p>KeyError: 0</p>
</blockquote>

<p>Removing the [0] prints e.g:</p>

<blockquote>
  <p>997    UCOYb6iKhuCHKDwvd_iBnIBw Name: usernameChannelId, dtype: object</p>
</blockquote>
"
"60020272","<p>You can use <a href=""https://docs.python.org/3/library/functions.html#ord"" rel=""nofollow noreferrer""><code>ord(c)</code></a> to get the ordinary number, that represents a character. e.g:</p>

<pre class=""lang-py prettyprint-override""><code>ch = 'a'

while True:

    for event in pygame.event.get():
        if event.type == pygame.KEYDOWN:

            if event.key == ord(ch):
                # [...]

</code></pre>

<p>But note, <code>if event.unicode == ch:</code>, would do the same.  </p>
","0","2020-02-01 19:18:34","1","136140","16645","626","8521","60020192","60020272","<p>For my game I need to take a string, consisting of one character, and check, if a key with this character was pressed (I'm using pygame). 
For example, if the string was 'a', I would need to have something like this:</p>

<pre><code>for event in pygame.event.get():
    if event.type == pygame.QUIT:
        pygame.quit()
        quit()
    elif event.type == pygame.KEYDOWN:
        if event.key == K_a:
   [...]
</code></pre>

<p>I can just make a lot of <code>if</code> statements for each key, but I hope there's a faster way</p>

<p>[Edit] I tried to use the <code>ord</code> function:</p>

<pre><code>[...]
  if event.key == ord(key): #key is my string's name
[...]
</code></pre>

<p>but now, for some reason, no matter I press w or s, event.key is the same number</p>
"
"60020303","<p>You need to create <a href=""https://matplotlib.org/api/colors_api.html#module-matplotlib.colors"" rel=""nofollow noreferrer"">valid colors</a>. </p>

<p>Your <code>colors</code> looks like this <code>[0.005 0.005 0.005 0.2   0.2   0.2  ]</code>.</p>

<p>For example:</p>

<pre><code>colors = np.asarray(['r'] * len(listeAlpha) + ['b'] * len(listeBeta))
</code></pre>

<p>creates <code>colors</code> with <code>['r' 'r' 'r' 'b' 'b' 'b']</code> and gives blue and red dots in your plot:</p>

<p><a href=""https://i.stack.imgur.com/UPXfS.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/UPXfS.png"" alt=""enter image description here""></a></p>
","0","2020-02-01 19:20:01","2","71005","1633","51","3469","60020203","60020303","<p>Consider the following code:</p>

<pre><code>import numpy as np
from numpy import *
from matplotlib.pyplot import *
import matplotlib.pyplot as plt
from mpmath import *
import random

def graphMesure(listeAlpha,listeBeta):
    # Compute areas and colors
    r = np.asarray([1]*len(listeAlpha)+[0.5]*len(listeBeta))
    colors = np.asarray([0.005]*len(listeAlpha)+[0.2]*len(listeBeta))
    area = 200*r**2

    fig = plt.figure()

    ax = fig.add_subplot(111, projection='polar')
    ax.set_ylim([0,1.25])
    c = ax.scatter(listeAlpha+listeBeta, r, c=colors, s=area, cmap='hsv', alpha=1)

graphMesure([0.5,0.2,0.3],[0.7,0.8,0.2])
</code></pre>

<p>All the color on my polarplot are the same. I thought that specifying float number for colors like I did would make them of different colors.</p>

<p>How can I for example have the first list given in parameter be plotted as blue and the second one as red ?</p>
"
"60020422","<p>It's not very elegant but it do his job.</p>

<pre><code>data = {'test1.txt': {'apple': 1, 'banana': 1, 'lemon': 1},
'test2.txt': {'apple': 1, 'banana': 1},
'test3.txt': {'apple': 1, 'lemon': 2},
'test4.txt': {'apple': 1, 'lemon': 1, 'grape': 1}}

lemon = ['lemon']
apple = ['apple']
banana = ['banana']
grape = ['grape']
for key, value in data.items():
    print(key, value)
    if 'lemon' in value:
        lemon.append(value.get('lemon'))
    else:
        lemon.append(0)
    if 'apple' in value:
        apple.append(value.get('apple'))
    else:
        apple.append(0)
    if 'banana' in value:
        banana.append(value.get('banana'))
    else:
        banana.append(0)
    if 'grape' in value:
        grape.append(value.get('grape'))
    else:
        grape.append(0)

result = [list(data.keys()), lemon, apple, banana, grape]
</code></pre>

<p>Output:</p>

<pre><code>[['test1.txt', 'test2.txt', 'test3.txt', 'test4.txt'], ['lemon', 1, 0, 2, 1], ['apple', 1, 1, 1, 1], ['banana', 1, 1, 0, 0], ['grape', 0, 0, 0, 1]]
</code></pre>
","0","","1","4584","259","83","602","60020243","60020529","<p>I have the following dictionary:</p>

<pre><code>dictionary = {'test1.txt': {'apple': 1, 'banana': 1, 'lemon': 1},
'test2.txt': {'apple': 1, 'banana': 1},
'test3.txt': {'apple': 1, 'lemon': 2},
'test4.txt': {'apple': 1, 'lemon': 1, 'grape': 1}}
</code></pre>

<p>which should become:</p>

<pre><code>[['', 'test1.txt', 'test2.txt', 'test3.txt', 'test4.txt'],
['lemon', 1, 0, 2, 1],
['apple', 1, 1, 1, 1],
['banana', 1, 1, 0, 0],
['grape', 0, 0, 0, 1]]
</code></pre>

<p>I have tried the following code, but I keep running into errors:</p>

<pre><code>keycount = []                                                                      
for i, f in enumerate(dictionary):                                                 
    for t in f:                                                                      
        if t not in keycount:                                                      
             keycount[t] = [0]*len(dictionary)                                         
        vocabulary[t][i]+=1 
</code></pre>

<p>Does anyone have a clue how to solve this? <strong>without external libraries please, I am simply practising with this :)</strong></p>
"
"60020446","<pre><code># Data.
d = {'test1.txt': {'apple': 1, 'banana': 1, 'lemon': 1},
     'test2.txt': {'apple': 1, 'banana': 1},
     'test3.txt': {'apple': 1, 'lemon': 2},
     'test4.txt': {'apple': 1, 'lemon': 1, 'grape': 1}}

vocab = {}
for i, words in enumerate(d.values()):
    seen = set()
    for word, word_count in words.items():
        seen.add(word)
        if word not in vocab:
            vocab[word] = [0] * i  # If first time word is seen, add zero count for previously read files.
        vocab[word].append(word_count)
    # Add zero for previously encountered words not seen in file.
    for word in vocab:
        if word not in seen:
            vocab[word].append(0)

&gt;&gt;&gt; [[''] + list(d.keys())] 
     + [[word] + word_counts for word, word_counts in vocab.items()]
[['', 'test1.txt', 'test2.txt', 'test3.txt', 'test4.txt'],
 ['apple', 1, 1, 1, 1],
 ['banana', 1, 1, 0, 0],
 ['lemon', 1, 0, 2, 1],
 ['grape', 0, 0, 0, 1]]
</code></pre>
","0","","2","86106","1691","794","4699","60020243","60020529","<p>I have the following dictionary:</p>

<pre><code>dictionary = {'test1.txt': {'apple': 1, 'banana': 1, 'lemon': 1},
'test2.txt': {'apple': 1, 'banana': 1},
'test3.txt': {'apple': 1, 'lemon': 2},
'test4.txt': {'apple': 1, 'lemon': 1, 'grape': 1}}
</code></pre>

<p>which should become:</p>

<pre><code>[['', 'test1.txt', 'test2.txt', 'test3.txt', 'test4.txt'],
['lemon', 1, 0, 2, 1],
['apple', 1, 1, 1, 1],
['banana', 1, 1, 0, 0],
['grape', 0, 0, 0, 1]]
</code></pre>

<p>I have tried the following code, but I keep running into errors:</p>

<pre><code>keycount = []                                                                      
for i, f in enumerate(dictionary):                                                 
    for t in f:                                                                      
        if t not in keycount:                                                      
             keycount[t] = [0]*len(dictionary)                                         
        vocabulary[t][i]+=1 
</code></pre>

<p>Does anyone have a clue how to solve this? <strong>without external libraries please, I am simply practising with this :)</strong></p>
"
"60020450","<p>This uses no external libraries and generalizes to any input dictionary of the nature indicated.</p>

<pre><code>dictionary={'test1.txt': {'apple': 1, 'banana': 1, 'lemon': 1},
'test2.txt': {'apple': 1, 'banana': 1},
'test3.txt': {'apple': 1, 'lemon': 2},
'test4.txt': {'apple': 1, 'lemon': 1, 'grape': 1}}

row_keys=[]
for x,v in dictionary.items():
  row_keys+=v.keys()
row_keys=list(set(row_keys))
dkeys=list(dictionary.keys())
header=['']+dkeys
rows=[]
for rk in row_keys:
  rows.append([rk])
  for k in dkeys:
    if rk in list(dictionary[k].keys()): rows[-1].append(dictionary[k][rk])
    else: rows[-1].append(0)
out=[header]+rows
print(out)
</code></pre>
","0","","1","1401","28","42","95","60020243","60020529","<p>I have the following dictionary:</p>

<pre><code>dictionary = {'test1.txt': {'apple': 1, 'banana': 1, 'lemon': 1},
'test2.txt': {'apple': 1, 'banana': 1},
'test3.txt': {'apple': 1, 'lemon': 2},
'test4.txt': {'apple': 1, 'lemon': 1, 'grape': 1}}
</code></pre>

<p>which should become:</p>

<pre><code>[['', 'test1.txt', 'test2.txt', 'test3.txt', 'test4.txt'],
['lemon', 1, 0, 2, 1],
['apple', 1, 1, 1, 1],
['banana', 1, 1, 0, 0],
['grape', 0, 0, 0, 1]]
</code></pre>

<p>I have tried the following code, but I keep running into errors:</p>

<pre><code>keycount = []                                                                      
for i, f in enumerate(dictionary):                                                 
    for t in f:                                                                      
        if t not in keycount:                                                      
             keycount[t] = [0]*len(dictionary)                                         
        vocabulary[t][i]+=1 
</code></pre>

<p>Does anyone have a clue how to solve this? <strong>without external libraries please, I am simply practising with this :)</strong></p>
"
"60020529","<p>Without external libraries</p>

<pre><code>dictionary = {'test1.txt': {'apple': 1, 'banana': 1, 'lemon': 1},
'test2.txt': {'apple': 1, 'banana': 1},
'test3.txt': {'apple': 1, 'lemon': 2},
'test4.txt': {'apple': 1, 'lemon': 1, 'grape': 1}}

# all the keys used by all dictionaries
#all_keys = set().union(*(d.keys() for d in dictionary.values()))
# update using @JonClements suggestion
all_keys = set().union(*dictionary.values())

# Start with list of keys
lst = [list(dictionary.keys())]

# Add item count from each dictionary
lst += [[k] + [d.get(k, 0) for d in dictionary.values()] for k in all_keys]
print(lst)
</code></pre>

<p><strong>Output</strong></p>

<pre><code>[['test1.txt', 'test2.txt', 'test3.txt', 'test4.txt'], 
 ['banana', 1, 1, 0, 0], 
 ['apple', 1, 1, 1, 1], 
 ['lemon', 1, 0, 2, 1], 
 ['grape', 0, 0, 0, 1]]
</code></pre>
","1","2020-02-01 20:34:09","3","10876","714","1","925","60020243","60020529","<p>I have the following dictionary:</p>

<pre><code>dictionary = {'test1.txt': {'apple': 1, 'banana': 1, 'lemon': 1},
'test2.txt': {'apple': 1, 'banana': 1},
'test3.txt': {'apple': 1, 'lemon': 2},
'test4.txt': {'apple': 1, 'lemon': 1, 'grape': 1}}
</code></pre>

<p>which should become:</p>

<pre><code>[['', 'test1.txt', 'test2.txt', 'test3.txt', 'test4.txt'],
['lemon', 1, 0, 2, 1],
['apple', 1, 1, 1, 1],
['banana', 1, 1, 0, 0],
['grape', 0, 0, 0, 1]]
</code></pre>

<p>I have tried the following code, but I keep running into errors:</p>

<pre><code>keycount = []                                                                      
for i, f in enumerate(dictionary):                                                 
    for t in f:                                                                      
        if t not in keycount:                                                      
             keycount[t] = [0]*len(dictionary)                                         
        vocabulary[t][i]+=1 
</code></pre>

<p>Does anyone have a clue how to solve this? <strong>without external libraries please, I am simply practising with this :)</strong></p>
"
"60020562","<p>You can try this.</p>

<pre><code>dictionary = {'test1.txt': {'apple': 1, 'banana': 1, 'lemon': 1},
'test2.txt': {'apple': 1, 'banana': 1},
'test3.txt': {'apple': 1, 'lemon': 2},
'test4.txt': {'apple': 1, 'lemon': 1, 'grape': 1}}
val=list(dictionary.values())
uni=set()
for d in val:
    for i in d:
        uni.add(i) 
#uni will contain all the unique fruits

for key in uni:
    for d in val:
        new_dict.setdefault(key,[]).append(d.get(key,0))

res=['']+list(dictionary.keys())
out=[[k]+val for k,val in new_dict.items()]
fin=[res]+out
'''fin is 
['', 'test1.txt', 'test2.txt', 'test3.txt', 'test4.txt']
['grape', 0, 0, 0, 1]
['banana', 1, 1, 0, 0]
['apple', 1, 1, 1, 1]
['lemon', 1, 0, 2, 1]'''
</code></pre>
","0","","1","14733","1831","61","1931","60020243","60020529","<p>I have the following dictionary:</p>

<pre><code>dictionary = {'test1.txt': {'apple': 1, 'banana': 1, 'lemon': 1},
'test2.txt': {'apple': 1, 'banana': 1},
'test3.txt': {'apple': 1, 'lemon': 2},
'test4.txt': {'apple': 1, 'lemon': 1, 'grape': 1}}
</code></pre>

<p>which should become:</p>

<pre><code>[['', 'test1.txt', 'test2.txt', 'test3.txt', 'test4.txt'],
['lemon', 1, 0, 2, 1],
['apple', 1, 1, 1, 1],
['banana', 1, 1, 0, 0],
['grape', 0, 0, 0, 1]]
</code></pre>

<p>I have tried the following code, but I keep running into errors:</p>

<pre><code>keycount = []                                                                      
for i, f in enumerate(dictionary):                                                 
    for t in f:                                                                      
        if t not in keycount:                                                      
             keycount[t] = [0]*len(dictionary)                                         
        vocabulary[t][i]+=1 
</code></pre>

<p>Does anyone have a clue how to solve this? <strong>without external libraries please, I am simply practising with this :)</strong></p>
"
"60020649","<p>Given your initial data as:</p>

<pre><code>d = {'test1.txt': {'apple': 1, 'banana': 1, 'lemon': 1},
'test2.txt': {'apple': 1, 'banana': 1},
'test3.txt': {'apple': 1, 'lemon': 2},
'test4.txt': {'apple': 1, 'lemon': 1, 'grape': 1}}
</code></pre>

<p>You can get the unique values and do a little bit of transposing of values, eg:</p>

<pre><code># Get all unique row_labels
keys = set().union(*d.values())
# Build up the rows to include zero values for items not present
rows = [[values.get(key, 0) for key in keys] for values in d.values()]
# Build the table with the header row and then each row_label with
# the transposed version of the values
table = [
    ['', *d], 
    *([key, *vals] for key, vals in zip(keys, zip(*rows)))
]
</code></pre>

<p>This'll give you <code>table</code> as:</p>

<pre><code>[['', 'test1.txt', 'test2.txt', 'test3.txt', 'test4.txt'],
 ['lemon', 1, 0, 2, 1],
 ['banana', 1, 1, 0, 0],
 ['apple', 1, 1, 1, 1],
 ['grape', 0, 0, 0, 1]]
</code></pre>
","0","","2","123002","2821","1151","28415","60020243","60020529","<p>I have the following dictionary:</p>

<pre><code>dictionary = {'test1.txt': {'apple': 1, 'banana': 1, 'lemon': 1},
'test2.txt': {'apple': 1, 'banana': 1},
'test3.txt': {'apple': 1, 'lemon': 2},
'test4.txt': {'apple': 1, 'lemon': 1, 'grape': 1}}
</code></pre>

<p>which should become:</p>

<pre><code>[['', 'test1.txt', 'test2.txt', 'test3.txt', 'test4.txt'],
['lemon', 1, 0, 2, 1],
['apple', 1, 1, 1, 1],
['banana', 1, 1, 0, 0],
['grape', 0, 0, 0, 1]]
</code></pre>

<p>I have tried the following code, but I keep running into errors:</p>

<pre><code>keycount = []                                                                      
for i, f in enumerate(dictionary):                                                 
    for t in f:                                                                      
        if t not in keycount:                                                      
             keycount[t] = [0]*len(dictionary)                                         
        vocabulary[t][i]+=1 
</code></pre>

<p>Does anyone have a clue how to solve this? <strong>without external libraries please, I am simply practising with this :)</strong></p>
"
"60020989","<p>No Usage of Library </p>

<pre><code>dictionary = {'test1.txt': {'apple': 1, 'banana': 1, 'lemon': 1},
'test2.txt': {'apple': 1, 'banana': 1},
'test3.txt': {'apple': 1, 'lemon': 2},
'test4.txt': {'apple': 1, 'lemon': 1, 'grape': 1}}

keycount = [['']]
keycount[0].extend(list(dictionary.keys()))
keys = dict()
for d_key in dictionary.keys():
    for i_key in dictionary[d_key].keys():
        if not i_key in keys:
            keys.update({i_key: True})

for key in keys:
    lists = [key]
    for d_key in dictionary.keys():
        lists.append(dictionary[d_key].get(key, 0))
    keycount.append(lists)
print(keycount)
</code></pre>
","0","","1","11","0","0","1","60020243","60020529","<p>I have the following dictionary:</p>

<pre><code>dictionary = {'test1.txt': {'apple': 1, 'banana': 1, 'lemon': 1},
'test2.txt': {'apple': 1, 'banana': 1},
'test3.txt': {'apple': 1, 'lemon': 2},
'test4.txt': {'apple': 1, 'lemon': 1, 'grape': 1}}
</code></pre>

<p>which should become:</p>

<pre><code>[['', 'test1.txt', 'test2.txt', 'test3.txt', 'test4.txt'],
['lemon', 1, 0, 2, 1],
['apple', 1, 1, 1, 1],
['banana', 1, 1, 0, 0],
['grape', 0, 0, 0, 1]]
</code></pre>

<p>I have tried the following code, but I keep running into errors:</p>

<pre><code>keycount = []                                                                      
for i, f in enumerate(dictionary):                                                 
    for t in f:                                                                      
        if t not in keycount:                                                      
             keycount[t] = [0]*len(dictionary)                                         
        vocabulary[t][i]+=1 
</code></pre>

<p>Does anyone have a clue how to solve this? <strong>without external libraries please, I am simply practising with this :)</strong></p>
"
"60041027","<h2>I know its late but since I solved it I want to share it.</h2>

<pre><code>fruits = ['lemon', 'apple', 'banana', 'grape']
fi = []
fi.append(fruits)
for k, v in d.items():
    li = []
    for i in ['lemon', 'apple', 'banana', 'grape']:
        li.append(v.get(i,0))
    fi.append(li)

print ([[i for i, v in d.items()]] + list(map(list, zip(*fi))))

# Result: [['test1.txt', 'test2.txt', 'test3.txt', 'test4.txt'], ['lemon', 1, 0, 2, 1], ['apple', 1, 1, 1, 1], ['banana', 1, 1, 0, 0], ['grape', 0, 0, 0, 1]]
</code></pre>

<p>I hope this helps and counts! :)</p>
","0","","1","514","46","1","136","60020243","60020529","<p>I have the following dictionary:</p>

<pre><code>dictionary = {'test1.txt': {'apple': 1, 'banana': 1, 'lemon': 1},
'test2.txt': {'apple': 1, 'banana': 1},
'test3.txt': {'apple': 1, 'lemon': 2},
'test4.txt': {'apple': 1, 'lemon': 1, 'grape': 1}}
</code></pre>

<p>which should become:</p>

<pre><code>[['', 'test1.txt', 'test2.txt', 'test3.txt', 'test4.txt'],
['lemon', 1, 0, 2, 1],
['apple', 1, 1, 1, 1],
['banana', 1, 1, 0, 0],
['grape', 0, 0, 0, 1]]
</code></pre>

<p>I have tried the following code, but I keep running into errors:</p>

<pre><code>keycount = []                                                                      
for i, f in enumerate(dictionary):                                                 
    for t in f:                                                                      
        if t not in keycount:                                                      
             keycount[t] = [0]*len(dictionary)                                         
        vocabulary[t][i]+=1 
</code></pre>

<p>Does anyone have a clue how to solve this? <strong>without external libraries please, I am simply practising with this :)</strong></p>
"
"60020544","<p>You can use Python's builtin sum method, and a generator expression:</p>

<pre><code>def series_sum(N):
    return sum(1.0 / 2**k for k in range(1, N + 1))
</code></pre>

<p>This works as follows:</p>

<ul>
<li><code>range(1, N + 1)</code> produces an <em>iterable</em> whose elements are the values 1, 2, ..., N sequentially.<br>
Reference:  <a href=""https://docs.python.org/3/library/functions.html#func-range"" rel=""nofollow noreferrer"">builtin range()</a>.</li>
<li><code>1.0 / 2**k for k in range(1, N + 1)</code> produces a new iterable that transforms this into 1/2, 1/4, ..., 1/(2^N).<br>
Reference:  <a href=""https://docs.python.org/3/reference/expressions.html#generator-expressions"" rel=""nofollow noreferrer"">generator
expressions</a>.</li>
<li><code>sum(...)</code> computes the sum of all the elements of the iterable that it is passed.<br>
Reference:  <a href=""https://docs.python.org/3/library/functions.html#sum"" rel=""nofollow noreferrer"">builtin <code>sum()</code></a>.</li>
</ul>

<p>The nice thing about Python is that if you read the code out loud, you would say something very similar to the words you would say while reading the mathematical expression.</p>
","1","2020-02-01 19:51:22","0","3743","4114","321","256","60020266","60020544","<p>I have been trying to create the code for a homework assignment and have had no success.</p>

<p>Essentially we have to encode the following formula into python;</p>

<p>Equation to be encoded</p>

<p><img src=""https://i.stack.imgur.com/WEzbo.png"" alt=""""></p>

<p>I've tried messing about with the sum() function and have checked other threads with more complicated examples although these haven't been of much help.</p>

<pre><code> #x=sum(1/2^k)for krange(1,int(input())
 #k=range(1,(int(input('Enter N:'))))
 #for k in range(1,3,1):
 num_range=list(range(1,3,1))#
 total=0
 for i in num_range:
 total +=i
 total
 sum(num_range)
 print(sum(num_range))



 #k=list(1,3)
 #x=1/pow(2,k)
 #sum(x)
 #print(sum(x))
 #x=sum(k)

 #k=range(1,3)
 #x=sum(1/pow(2,k))
 #sum(x)
 #print(x)



 #sum+=([1/2**k])
 #print(sum(1/pow(2,k)))'
</code></pre>
"
"60026030","<p>Try this.</p>

<pre><code>from simplified_scrapy.request import req
from simplified_scrapy.simplified_doc import SimplifiedDoc
url = 'https://avito.ru/saransk?q=asus'
html = req.get(url) 
doc = SimplifiedDoc(html)
print(doc.listA(url=url))
</code></pre>

<p>Here is an example of using frame simplified_scrapy.</p>

<pre><code>from simplified_scrapy.spider import Spider, SimplifiedDoc
class MySpider(Spider):
  name = 'avito.ru'
  allowed_domains = ['avito.ru']
  # concurrencyPer1s=1
  refresh_urls = True # For debug. If efresh_urls = True, start_urls will be crawled again.
  def __init__(self):
    host = 'https://avito.ru/saransk'
    search_words = ['asus', 'lenovo', 'xiaomi', 'apple', 'ipad']
    self.start_urls = [host+'?q='+w for w in search_words] # Initialize variable start_urls
    Spider.__init__(self,self.name) #necessary

  def extract(self, url, html, models, modelNames):
    doc = SimplifiedDoc(html)
    print (doc.listA(url=url['url']))
    # return {""Urls"": doc.listA(url=url['url']), ""Data"": None} # Return data to framework
    return True

from simplified_scrapy.simplified_main import SimplifiedMain
SimplifiedMain.startThread(MySpider()) # Start crawling
</code></pre>

<p>Here are more examples:<a href=""https://github.com/yiyedata/simplified-scrapy-demo"" rel=""nofollow noreferrer"">https://github.com/yiyedata/simplified-scrapy-demo</a></p>
","0","","1","2231","56","0","189","60020288","60026030","<p>I need parse all links from several pages. I write simple script, which uses asyncronous approach.</p>

<p>At moment it return empty list <code>links</code>. But i expect put all links from pages to list <code>links</code> and display it to console.</p>

<p>My script does not have any error messages.</p>

<pre><code>import asyncio
import aiohttp
from bs4 import BeautifulSoup


links = []
host = 'https://avito.ru/saransk'
search_words = [
    'asus',
    'lenovo',
    'xiaomi',
    'apple',
    'ipad',
]


def get_data(html_text):
    paths = []
    soup = BeautifulSoup(html_text, 'lxml')
    link_obj = soup.find_all('a')

    for path in link_obj:
        paths.append(path['href'])

    links.extend(paths)

    return links


async def get_html(search_word):
    async with aiohttp.ClientSession() as session:
        resp = await session.get(host + '?q=' + search_word)   
        assert resp.status == 200
        # print(await resp.text())
        resp2 = await get_data(resp.text())
        print('----------', resp2)


def main():
    ioloop = asyncio.get_event_loop()
    tasks = [ioloop.create_task(get_html(word)) for word in search_words]
    ioloop.run_until_complete(asyncio.wait(tasks))
    ioloop.close()
    print(links)


main()
</code></pre>

<p>I use python 3.8 and follow requirements:</p>

<pre><code>aiohttp==3.6.2
  - async-timeout [required: &gt;=3.0,&lt;4.0, installed: 3.0.1]
  - attrs [required: &gt;=17.3.0, installed: 19.3.0]
  - chardet [required: &gt;=2.0,&lt;4.0, installed: 3.0.4]
  - multidict [required: &gt;=4.5,&lt;5.0, installed: 4.7.4]
  - yarl [required: &gt;=1.0,&lt;2.0, installed: 1.4.2]
    - idna [required: &gt;=2.0, installed: 2.8]
    - multidict [required: &gt;=4.0, installed: 4.7.4]
bs4==0.0.1
  - beautifulsoup4 [required: Any, installed: 4.8.2]
    - soupsieve [required: &gt;=1.2, installed: 1.9.5]
fake-useragent==0.1.11
lxml==4.5.0
requests==2.22.0
  - certifi [required: &gt;=2017.4.17, installed: 2019.11.28]
  - chardet [required: &gt;=3.0.2,&lt;3.1.0, installed: 3.0.4]
  - idna [required: &gt;=2.5,&lt;2.9, installed: 2.8]
  - urllib3 [required: &gt;=1.21.1,&lt;1.26,!=1.25.1,!=1.25.0, installed: 1.25.8]
</code></pre>
"
"60021890","<pre><code>cd /path/to/my/file

for file in *.csv
do
cut -d, -f3,4,5,6,7 ""$file"" &gt; ""new_$file""
done
</code></pre>

<p>this actually did the job. </p>
","1","","-1","591","75","2","111","60020294","60021973","<p>I'm wondering what would be the best approach to remove first two and last column from multiple CSV files that have the same column structure. </p>

<p>I've tried with awk and pandas but it seems that it gives me only an option to remove columns from one input.csv file at the time and save it as output.csv. How could I remove columns 1,2,7 in multiple files without creating output.csv but overwriting existing files?</p>

<p>My CSV files look like this, where Col1, Col2, Col7 are completely empty (including column header).</p>

<pre><code>Col1,Col2,  Col3   ,  Col4   ,  Col5   ,   Col6  ,Col7
    ,    ,some_data,some_data,some_data,some_data,
    ,    ,some_data,some_data,some_data,some_data,
    ,    ,some_data,some_data,some_data,some_data,
</code></pre>

<p>and desired output: </p>

<pre><code>  Col3   ,  Col4   ,  Col5   ,   Col6
some_data,some_data,some_data,some_data
some_data,some_data,some_data,some_data
some_data,some_data,some_data,some_data
</code></pre>

<p>My code so far... </p>

<pre><code>import pandas as pd
import os
import fileinput
from dateutil import parser
# specifying directory and determining files for my loop 
path = r'/path/to/my/files'
files = [os.path.join(path,data_file) for data_file in sorted(os.listdir(path))]
#trying to read each csv file separately and delete columns from it
df = pd.read_csv(files)
# specifying columns to delete
first_column = df.columns[0]
second_column = df.columns[1]
last_column = df.columns[7]
# Delete my columns
df = df.drop([first_column, second_column, last_column], axis=1)
# trying to overwrite existing files after column removal instead of creating new files i.e. output.csv
df.to_csv(files, index=False)
</code></pre>
"
"60021973","<p>If not creating a temporary file is not a strinct requirement (<a href=""https://stackoverflow.com/a/60021890/5825294"">your self answer</a> creates new files indeed), this is oneliner.</p>

<pre><code>find /path/to/your/dir -name '*.csv' -exec sh -c 'cut -d, -f3-6 $0 &gt; $0.new &amp;&amp; mv $0.new $0' {} \;
</code></pre>
","0","2020-02-01 23:31:29","2","11070","4964","1209","1187","60020294","60021973","<p>I'm wondering what would be the best approach to remove first two and last column from multiple CSV files that have the same column structure. </p>

<p>I've tried with awk and pandas but it seems that it gives me only an option to remove columns from one input.csv file at the time and save it as output.csv. How could I remove columns 1,2,7 in multiple files without creating output.csv but overwriting existing files?</p>

<p>My CSV files look like this, where Col1, Col2, Col7 are completely empty (including column header).</p>

<pre><code>Col1,Col2,  Col3   ,  Col4   ,  Col5   ,   Col6  ,Col7
    ,    ,some_data,some_data,some_data,some_data,
    ,    ,some_data,some_data,some_data,some_data,
    ,    ,some_data,some_data,some_data,some_data,
</code></pre>

<p>and desired output: </p>

<pre><code>  Col3   ,  Col4   ,  Col5   ,   Col6
some_data,some_data,some_data,some_data
some_data,some_data,some_data,some_data
some_data,some_data,some_data,some_data
</code></pre>

<p>My code so far... </p>

<pre><code>import pandas as pd
import os
import fileinput
from dateutil import parser
# specifying directory and determining files for my loop 
path = r'/path/to/my/files'
files = [os.path.join(path,data_file) for data_file in sorted(os.listdir(path))]
#trying to read each csv file separately and delete columns from it
df = pd.read_csv(files)
# specifying columns to delete
first_column = df.columns[0]
second_column = df.columns[1]
last_column = df.columns[7]
# Delete my columns
df = df.drop([first_column, second_column, last_column], axis=1)
# trying to overwrite existing files after column removal instead of creating new files i.e. output.csv
df.to_csv(files, index=False)
</code></pre>
"
"60020452","<p>Following <a href=""https://matplotlib.org/3.1.0/gallery/subplots_axes_and_figures/axis_equal_demo.html"" rel=""nofollow noreferrer"">this documentation</a>, you need to add some settings to axes. Your script works for me in a right ways if I insert these rows after creation of <code>fig</code>:</p>

<pre><code>ax = plt.gca()
ax.set_aspect('equal', 'box')
</code></pre>
","0","","1","3747","281","19","426","60020325","60020452","<p>I have a code to plot a figure.
When I run this code without adding plt.colorbar(), I can get a figure which looks more like a rectangle. However, if I add colorbar, the shape change to look like a square.</p>

<p>How can I add colorbar and maintain the original shape of the figure? Thanks!!!</p>

<pre><code>#%%
import numpy as np
import matplotlib.pyplot as plt
fig = plt.figure()

x = np.random.rand(10000)
y = np.random.rand(10000)
plt.scatter(x,y,c=y)
#plt.colorbar()

plt.show()
</code></pre>

<p><a href=""https://i.stack.imgur.com/cAPd7.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/cAPd7.png"" alt=""enter image description here""></a></p>

<p><a href=""https://i.stack.imgur.com/7Hbi9.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/7Hbi9.png"" alt=""enter image description here""></a></p>
"
"60020644","<p>Actually what is happening is that both Series <code>df['Date_start']</code> and <code>df['Date_end']</code> are of type <em>datetime64[ns]</em>, but when you show the dataframe, if all the time values of the columns are zero, it doesn't show them. What you can try, if you need a formatted output, is to convert them to object types again, and give them format with <a href=""https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.dt.strftime.html"" rel=""nofollow noreferrer"">dt.strftime</a>:</p>

<pre><code>df['Date_start'] = pd.to_datetime(df['Date_start']).dt.strftime('%Y/%m/%d %H:%M:%S')
df['Date_end'] = pd.to_datetime(df['Date_end']).dt.strftime('%Y/%m/%d %H:%M:%S')
print (df)
</code></pre>

<p>Outputs:</p>

<pre><code>   Id_sensor           Date_start             Date_end
0          1  2018/01/04 00:00:00  2018/01/05 00:00:00
1          2  2018/01/04 00:00:10  2018/01/06 00:00:00
2          3  2018/01/04 00:14:00  2017/01/06 00:00:00
3          4  2018/01/04 00:00:00  2018/01/05 00:00:00
</code></pre>
","0","2020-02-01 20:30:18","1","340","154","1","49","60020418","60020644","<p>I have the following dataframe:</p>

<pre><code>      import pandas as pd
      from datetime import datetime

      df = pd.DataFrame({'Id_sensor': [1, 2, 3, 4], 
                         'Date_start': ['2018-01-04 00:00:00.0', '2018-01-04 00:00:10.0',
                                        '2018-01-04 00:14:00.0', '2018-01-04'],
                         'Date_end': ['2018-01-05', '2018-01-06', '2017-01-06', '2018-01-05']})
</code></pre>

<p>The columns (Date_start and Date_end) are of type Object. I would like to transform to the data type of dates. And make the columns look the same. That is, in other words, fill in the date, hour and minute fields with zeros that the column (Date_end) does not have.</p>

<p>I tried to make the following code:</p>

<pre><code>      df['Date_start'] = pd.to_datetime(df['Date_start'], format='%Y/%m/%d %H:%M:%S')
      df['Date_end'] = pd.to_datetime(df['Date_end'], format='%Y/%m/%d %H:%M:%S')
</code></pre>

<p>My output:</p>

<pre><code>        Id_sensor     Date_start         Date_end
           1       2018-01-04 00:00:00  2018-01-05
           2       2018-01-04 00:00:10  2018-01-06
           3       2018-01-04 00:14:00  2017-01-06
           4       2018-01-04 00:00:00  2018-01-05
</code></pre>

<p>But I would like the output to be like this:</p>

<pre><code>           Id_sensor      Date_start         Date_end
           1       2018-01-04 00:00:00    2018-01-05 00:00:00
           2       2018-01-04 00:00:10    2018-01-06 00:00:00
           3       2018-01-04 00:14:00    2017-01-06 00:00:00
           4       2018-01-04 00:00:00    2018-01-05 00:00:00
</code></pre>
"
"60020824","<p>You can first convert your columns to <code>datetime</code> datatype using <a href=""https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.to_datetime.html"" rel=""nofollow noreferrer""><code>to_datetime</code></a>, and subsequently use <a href=""https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.dt.strftime.html"" rel=""nofollow noreferrer""><code>dt.strftime</code></a> to convert the columns to string datatype with your desired format:</p>

<pre><code>import pandas as pd
from datetime import datetime

df = pd.DataFrame({
    'Id_sensor': [1, 2, 3, 4], 
    'Date_start': ['2018-01-04 00:00:00.0', '2018-01-04 00:00:10.0',
                   '2018-01-04 00:14:00.0', '2018-01-04'],
    'Date_end': ['2018-01-05', '2018-01-06', '2017-01-06', '2018-01-05']})

df['Date_start'] = pd.to_datetime(df['Date_start']).dt.strftime('%Y-%m-%d %H:%M:%S')
df['Date_end'] = pd.to_datetime(df['Date_end']).dt.strftime('%Y-%m-%d %H:%M:%S')

print(df)
# Output:
#
#    Id_sensor           Date_start             Date_end
# 0          1  2018-01-04 00:00:00  2018-01-05 00:00:00
# 1          2  2018-01-04 00:00:10  2018-01-06 00:00:00
# 2          3  2018-01-04 00:14:00  2017-01-06 00:00:00
# 3          4  2018-01-04 00:00:00  2018-01-05 00:00:00
</code></pre>
","0","","1","5765","1277","231","409","60020418","60020644","<p>I have the following dataframe:</p>

<pre><code>      import pandas as pd
      from datetime import datetime

      df = pd.DataFrame({'Id_sensor': [1, 2, 3, 4], 
                         'Date_start': ['2018-01-04 00:00:00.0', '2018-01-04 00:00:10.0',
                                        '2018-01-04 00:14:00.0', '2018-01-04'],
                         'Date_end': ['2018-01-05', '2018-01-06', '2017-01-06', '2018-01-05']})
</code></pre>

<p>The columns (Date_start and Date_end) are of type Object. I would like to transform to the data type of dates. And make the columns look the same. That is, in other words, fill in the date, hour and minute fields with zeros that the column (Date_end) does not have.</p>

<p>I tried to make the following code:</p>

<pre><code>      df['Date_start'] = pd.to_datetime(df['Date_start'], format='%Y/%m/%d %H:%M:%S')
      df['Date_end'] = pd.to_datetime(df['Date_end'], format='%Y/%m/%d %H:%M:%S')
</code></pre>

<p>My output:</p>

<pre><code>        Id_sensor     Date_start         Date_end
           1       2018-01-04 00:00:00  2018-01-05
           2       2018-01-04 00:00:10  2018-01-06
           3       2018-01-04 00:14:00  2017-01-06
           4       2018-01-04 00:00:00  2018-01-05
</code></pre>

<p>But I would like the output to be like this:</p>

<pre><code>           Id_sensor      Date_start         Date_end
           1       2018-01-04 00:00:00    2018-01-05 00:00:00
           2       2018-01-04 00:00:10    2018-01-06 00:00:00
           3       2018-01-04 00:14:00    2017-01-06 00:00:00
           4       2018-01-04 00:00:00    2018-01-05 00:00:00
</code></pre>
"
"60020565","<p>Assuming you are using python 3.6 or above you should use format strings (also known as f strings) to construct strings from variables. Start the string with the letter ""f"" and then put whatever variables you want in curly brackets {}. Also if you use single quotes as the outer quote then you don't have to escape double quotes and vice versa.</p>

<p>Code:</p>

<pre class=""lang-py prettyprint-override""><code>db_name = ""'home/user/output/prueba.gpkg'""
table_name = '""prueba""'
outputlayer = f'ogr:dbname={db_name} table={table_name} (geom) sql='
outputlayer
</code></pre>

<p>Output: </p>

<pre><code>'ogr:dbname=\'home/user/output/prueba.gpkg\' table=""prueba"" (geom) sql='
</code></pre>
","1","","2","341","24","1","24","60020453","60115622","<p>I need to construct a chain of text like this:    </p>

<pre><code> out = 'ogr:dbname=\'C:\\output\\2020.gpkg\' table=\""2020\"" (geom) sql='
</code></pre>

<p>Here is my code: </p>

<pre><code>import glob, time, sys, threading, os
from datetime import date, timedelta, datetime
import time, threading

#Parameters
layer = 'C:\\layer.gpkg' 
n ='2020'
outdir = 'C:\\output'

#Process
l = os.path.realpath(layer)
pn = os.path.realpath(outdir + '/' + n + '.gpkg')
p = f""'{pn}'""
f = f""'{n}'""
o = f'ogr:dbname={p} table={f} (geom) sql='

#Test
out = 'ogr:dbname=\'C:\\output\\2020.gpkg\' table=\""2020\"" (geom) sql='
o == out
</code></pre>

<p>The goal is to get o == out.</p>

<p>What do I need to change in the #Process part in order to get this as True ?</p>

<p>Moreover I need to run this either in linux or windows. </p>

<p>My final goal is to create a function that give 3 strings returns the complex string line shown above.</p>
"
"60024883","<p>Another option is to use a triple quoted string:</p>

<pre><code>dbname = """"""/home/user/output/prueba.gpkg""""""
outputlayer = """"""ogr:dbname='""""""+dbname+""""""' table=""prueba"" (geom) sql=""""""
</code></pre>

<p>which gives:</p>

<pre><code>'ogr:dbname=\'/home/user/output/prueba.gpkg\' table=""prueba"" (geom) sql='
</code></pre>
","3","2020-02-02 10:53:35","1","7952","1225","24","1037","60020453","60115622","<p>I need to construct a chain of text like this:    </p>

<pre><code> out = 'ogr:dbname=\'C:\\output\\2020.gpkg\' table=\""2020\"" (geom) sql='
</code></pre>

<p>Here is my code: </p>

<pre><code>import glob, time, sys, threading, os
from datetime import date, timedelta, datetime
import time, threading

#Parameters
layer = 'C:\\layer.gpkg' 
n ='2020'
outdir = 'C:\\output'

#Process
l = os.path.realpath(layer)
pn = os.path.realpath(outdir + '/' + n + '.gpkg')
p = f""'{pn}'""
f = f""'{n}'""
o = f'ogr:dbname={p} table={f} (geom) sql='

#Test
out = 'ogr:dbname=\'C:\\output\\2020.gpkg\' table=\""2020\"" (geom) sql='
o == out
</code></pre>

<p>The goal is to get o == out.</p>

<p>What do I need to change in the #Process part in order to get this as True ?</p>

<p>Moreover I need to run this either in linux or windows. </p>

<p>My final goal is to create a function that give 3 strings returns the complex string line shown above.</p>
"
"60115622","<p>I think one of the issues that this isn't working is your path here <code>pn = os.path.realpath(outdir + '/' + n + '.gpkg')</code>. This is trying to combine UNIX path <code>/</code> with windows path <code>\\</code>. A more robust solution in terms of portability between linux and windows would be to use the <code>path.join</code> function in os module.</p>

<p>Additionally, python f strings will only add escapes to whichever quote character you used to open the string (<code>'</code> or <code>""</code>). If the escaped quotes around both strings are necessary, you're probably better off hard coding it into an f-string instead of setting 2 new variables with different quote types.</p>

<pre><code>import glob, time, sys, threading, os
from datetime import date, timedelta, datetime
import time, threading

#Parameters
layer = 'C:\\layer.gpkg' 
n ='2020'
outdir = 'C:\\output'

#Process
l = os.path.realpath(layer)
pn = os.path.realpath(os.path.join(outdir, f""{n}.gpkg""))
o = f'ogr:dbname=\'{pn}\' table=\""{n}\"" (geom) sql='

#Test
out = 'ogr:dbname=\'C:\\output\\2020.gpkg\' table=\""2020\"" (geom) sql='
o == out
</code></pre>

<p>A version of this (different path) has been tested to work on my linux machine.</p>
","2","","1","76","2","0","1","60020453","60115622","<p>I need to construct a chain of text like this:    </p>

<pre><code> out = 'ogr:dbname=\'C:\\output\\2020.gpkg\' table=\""2020\"" (geom) sql='
</code></pre>

<p>Here is my code: </p>

<pre><code>import glob, time, sys, threading, os
from datetime import date, timedelta, datetime
import time, threading

#Parameters
layer = 'C:\\layer.gpkg' 
n ='2020'
outdir = 'C:\\output'

#Process
l = os.path.realpath(layer)
pn = os.path.realpath(outdir + '/' + n + '.gpkg')
p = f""'{pn}'""
f = f""'{n}'""
o = f'ogr:dbname={p} table={f} (geom) sql='

#Test
out = 'ogr:dbname=\'C:\\output\\2020.gpkg\' table=\""2020\"" (geom) sql='
o == out
</code></pre>

<p>The goal is to get o == out.</p>

<p>What do I need to change in the #Process part in order to get this as True ?</p>

<p>Moreover I need to run this either in linux or windows. </p>

<p>My final goal is to create a function that give 3 strings returns the complex string line shown above.</p>
"
"60020513","<p>Consider this line in <code>GetAsciiListLC()</code>:</p>

<pre><code>num_list = [(num_list.append((str(num), chr(num)+"" ""))) for num in range(32, 42, 1)]
</code></pre>

<p><code>num_list.append((str(num), chr(num)+"" "")))</code> mutates the list and <em>returns <code>None</code></em>.</p>

<p>I think what you want is this:</p>

<pre><code>def GetAsciiListLC():
    """""" Return list of 2-tuples containing numbers and ASCII equivalents, both as strings. """"""
    return [(str(num), chr(num) + "" "") for num in range(32, 42)]
</code></pre>

<p>See this question for the rationale of returning None from the list.append() method:
<a href=""https://stackoverflow.com/questions/16641119/why-does-append-always-return-none-in-python"">Why does append() always return None in Python?</a></p>
","0","","2","3743","4114","321","256","60020484","60020513","<p>This for loop works fine but not as a list comprehension. 
The comprehension creates empty elements for each iteration.
Can someone explain what is wrong and how to fix it?</p>

<pre><code>def GetAsciiList():
    num_list = []
    for num in range(32, 42, 1):
        num_list.append((str(num), chr(num)+"" ""))
    return num_list

def GetAsciiListLC():
    num_list = []
    num_list = [(num_list.append((str(num), chr(num)+"" ""))) for num in range(32, 42, 1)]
    return num_list

print GetAsciiList()
print GetAsciiListLC()
</code></pre>

<hr>

<p>console output:</p>

<pre><code>[('32', '  '), ('33', '! '), ('34', '"" '), ('35', '# '), ('36', '$ '), ('37', '% '), ('38', '&amp; '), ('39', ""' ""), ('40', '( '), ('41', ') ')]
[None, None, None, None, None, None, None, None, None, None]
</code></pre>
"
"60106976","<p>web3py is not still fully compatible with solidity version 0.6.x. 
check out the link.
<a href=""https://github.com/ethereum/web3.py/issues/1566"" rel=""nofollow noreferrer"">https://github.com/ethereum/web3.py/issues/1566</a>
you can use solidity 0.5.x till then and track the progress through the link.</p>
","0","","1","26","1","0","2","60020499","60106976","<p>I have compiled my code in remix ide. it is working fine there. I copied the bytecode and adi from compilation detail to my python code. I am using web3.py as an external library. but when I try to run my function, I am getting an error <code>keyerror</code>. I think I need to pass some key in function as an argument but am not able to find how.</p>

<p>This is my code</p>

<pre><code>from web3 import Web3,HTTPProvider
import json

web_link=""http://127.0.0.1:7545""


class FunderContract:
    web3 = Web3(Web3.HTTPProvider(web_link))

    def start(self,account_number):
        print(""local host is "",self.web3.isConnected())
        print(""first block at"",self.web3.eth.blockNumber)

        self.web3.eth.defaultAccount=account_number


        abi = json.loads('[{""inputs"":[],""stateMutability"":""payable"",""type"":""constructor""},{""anonymous"":false,""inputs"":[{""indexed"":false,""internalType"":""address"",""name"":""to"",""type"":""address""},{""indexed"":false,""internalType"":""address"",""name"":""from"",""type"":""address""},{""indexed"":false,""internalType"":""uint256"",""name"":""value"",""type"":""uint256""}],""name"":""FundsSended"",""type"":""event""},{""inputs"":[{""internalType"":""address"",""name"":""add"",""type"":""address""}],""name"":""endWithdrawal"",""outputs"":[],""stateMutability"":""nonpayable"",""type"":""function""},{""inputs"":[{""internalType"":""address"",""name"":""add"",""type"":""address""}],""name"":""initiateWithdrawal"",""outputs"":[],""stateMutability"":""nonpayable"",""type"":""function""},{""inputs"":[{""internalType"":""address"",""name"":""id"",""type"":""address""}],""name"":""isAllowedToWithdraw"",""outputs"":[{""internalType"":""bool"",""name"":"""",""type"":""bool""}],""stateMutability"":""payable"",""type"":""function""},{""inputs"":[{""internalType"":""string"",""name"":""name"",""type"":""string""}],""name"":""register"",""outputs"":[],""stateMutability"":""nonpayable"",""type"":""function""},{""inputs"":[{""internalType"":""address payable"",""name"":""add"",""type"":""address""}],""name"":""registerFundi"",""outputs"":[],""stateMutability"":""payable"",""type"":""function""},{""inputs"":[{""internalType"":""address"",""name"":""add"",""type"":""address""}],""name"":""sendFunds"",""outputs"":[],""stateMutability"":""payable"",""type"":""function""},{""inputs"":[],""name"":""stage"",""outputs"":[{""internalType"":""enum Funders.Stage"",""name"":"""",""type"":""uint8""}],""stateMutability"":""view"",""type"":""function""},{""inputs"":[{""internalType"":""address"",""name"":""fundee_id"",""type"":""address""},{""internalType"":""enum Funders.voteDetail"",""name"":""v"",""type"":""uint8""}],""name"":""vote"",""outputs"":[],""stateMutability"":""nonpayable"",""type"":""function""},{""stateMutability"":""payable"",""type"":""receive""}]')


        byte_code='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'
        # address = web3.toChecksumAddress(address)
       Greeter = self.web3.eth.contract(abi=abi, bytecode=bytecode)
       tx_hash = Greeter.constructor().transact()
       tx_receipt = self.web3.eth.waitForTransactionReceipt(tx_hash)
       contract = self.web3.eth.contract(
         address=tx_receipt.contractAddress,
         abi=abi,
       )

       print(tx_receipt.contractAddress)

       tx_hash = contract.functions.register('name').transact()

if __name__ == ""__main__"":


        b=FunderContract()

        b.start(""0x35286618aD7Ca934b0AA53FE110ec09569CAd507"")
        a=b.funder_contract.functions.register('my').transact()
      `
</code></pre>

<p>and I am getting error</p>

<pre><code>File ""main.py"", line 41, in &lt;module&gt;
    b.start(""0x35286618aD7Ca934b0AA53FE110ec09569CAd507"")
  File ""main.py"", line 25, in start
    self.funder_contract.functions.register('my').transact()
  File ""D:\mywork\ML\anaconda\envs\ethe_v\lib\site-packages\web3\contract.py"", line 819, in __call__
    clone._set_function_info()
  File ""D:\mywork\ML\anaconda\envs\ethe_v\lib\site-packages\web3\contract.py"", line 829, in _set_function_info
    self.kwargs
  File ""D:\mywork\ML\anaconda\envs\ethe_v\lib\site-packages\web3\_utils\contracts.py"", line 119, in find_matching_fn_abi
    function_candidates = pipe(abi, name_filter, arg_count_filter, encoding_filter)
  File ""cytoolz/functoolz.pyx"", line 669, in cytoolz.functoolz.pipe
    return c_pipe(data, funcs)
  File ""cytoolz/functoolz.pyx"", line 644, in cytoolz.functoolz.c_pipe
    data = func(data)
  File ""D:\mywork\ML\anaconda\envs\ethe_v\lib\site-packages\web3\_utils\abi.py"", line 98, in filter_by_name
    in contract_abi
  File ""D:\mywork\ML\anaconda\envs\ethe_v\lib\site-packages\web3\_utils\abi.py"", line 102, in &lt;listcomp&gt;
    abi['name'] == name  # type: ignore
KeyError: 'name'
</code></pre>

<p><strong>Edit</strong>
it works with solidity 0.5.x..</p>
"
"60020700","<p>1, It depends on how you want to define a ""region"", but looks like you just have feeling instead of strict definition. If you have a very clear definition of what kind of piece you want to cut out, you can try some method like ""matched filter""</p>

<p>2, You might want to detect the peak of absolute magnitude. If not working, try peak of absolute magnitude of first-order difference, even 2nd-order.</p>

<p>3, it is hard to work on the noisy data like this. My suggestion is to do filtering before you pick up sections (on unfiltered data). Filtering will give you smooth peaks so that the position of peaks can be detected by the change of derivative sign. For filtering, try just ""low-pass filter"" first. If it doesn't work, I also suggest ""Hilbert–Huang transform"".</p>

<p>*, Looks like you are using matlab. The methods mentioned are all included in matlab.</p>
","1","","0","245","10","0","25","60020521","60029969","<p>I am trying to segment the time-series data as shown in the figure. I have lots of data from the sensors, any of these data can have different number of isolated peaks region. In this figure, I have 3 of those. I would like to have a function that takes the time-series as the input and returns the segmented sections of equal length. </p>

<p>My initial thought was to have a sliding window that calculates the relative change in the amplitude. Since the window with the peaks will have relatively higher changes, I could just define certain threshold for the relative change that would help me take the window with isolated peaks. However, this will create problem when choosing the threshold as the relative change is very sensitive to the noises in the data.</p>

<p>Any suggestions?</p>

<p><a href=""https://i.stack.imgur.com/QZzaT.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/QZzaT.png"" alt=""Figure : Desired segmentation of the time-series data""></a>
<img src=""https://i.stack.imgur.com/9DXIZ.png"" alt=""figure with axes""></p>
"
"60029969","<p>To do this you need to find signal out of noise.</p>

<ol>
<li>get mean value of you signal and add some multiplayer that place borders on top and on bottom of noise - green dashed line</li>
<li>find peak values below bottom of noise -> array 2 groups of data</li>
<li>find peak values on top of noise -> array 2 groups of data</li>
<li>get min index of bottom first peak and max index of top of first peak to find first peak range</li>
<li>get min index of top second peak and max index of bottom of second peak to find second peak range</li>
</ol>

<p>Some description in code. With this method you can find other peaks.
One thing that you need to input by hand is to tell program the<code>x</code> value between peaks for splitting data into parts.</p>

<p>See graphic for summary.</p>



<pre><code>import numpy as np
from matplotlib import pyplot as plt


# create noise data
def function(x, noise):
    y = np.sin(7*x+2) + noise
    return y

def function2(x, noise):
    y = np.sin(6*x+2) + noise
    return y


noise = np.random.uniform(low=-0.3, high=0.3, size=(100,))
x_line0 = np.linspace(1.95,2.85,100)
y_line0 = function(x_line0, noise)
x_line = np.linspace(0, 1.95, 100)
x_line2 = np.linspace(2.85, 3.95, 100)
x_pik = np.linspace(3.95, 5, 100)
y_pik = function2(x_pik, noise)
x_line3 = np.linspace(5, 6, 100)

# concatenate noise data
x = np.linspace(0, 6, 500)
y = np.concatenate((noise, y_line0, noise, y_pik, noise), axis=0)

# plot data
noise_band = 1.1
top_noise = y.mean()+noise_band*np.amax(noise)
bottom_noise = y.mean()-noise_band*np.amax(noise)
fig, ax = plt.subplots()
ax.axhline(y=y.mean(), color='red', linestyle='--')
ax.axhline(y=top_noise, linestyle='--', color='green')
ax.axhline(y=bottom_noise, linestyle='--', color='green')
ax.plot(x, y)

# split data into 2 signals
def split(arr, cond):
  return [arr[cond], arr[~cond]]

# find bottom noise data indexes
botom_data_indexes = np.argwhere(y &lt; bottom_noise)
# split by visual x value
splitted_bottom_data = split(botom_data_indexes, botom_data_indexes &lt; np.argmax(x &gt; 3))

# find top noise data indexes
top_data_indexes = np.argwhere(y &gt; top_noise)
# split by visual x value
splitted_top_data = split(top_data_indexes, top_data_indexes &lt; np.argmax(x &gt; 3))

# get first signal range
first_signal_start = np.amin(splitted_bottom_data[0])
first_signal_end = np.amax(splitted_top_data[0])

# get x index of first signal
x_first_signal = np.take(x, [first_signal_start, first_signal_end])
ax.axvline(x=x_first_signal[0], color='orange')
ax.axvline(x=x_first_signal[1], color='orange')

# get second signal range
second_signal_start = np.amin(splitted_top_data[1])
second_signal_end = np.amax(splitted_bottom_data[1])

# get x index of first signal
x_second_signal = np.take(x, [second_signal_start, second_signal_end])
ax.axvline(x=x_second_signal[0], color='orange')
ax.axvline(x=x_second_signal[1], color='orange')

plt.show()
</code></pre>

<p><b>Output:</b></p>

<p>red line = mean value of all data</p>

<p>green line - top and bottom noise borders</p>

<p>orange line - selected peak data</p>

<p><a href=""https://i.stack.imgur.com/tpPW2.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/tpPW2.png"" alt=""enter image description here""></a></p>
","1","","1","4584","259","83","602","60020521","60029969","<p>I am trying to segment the time-series data as shown in the figure. I have lots of data from the sensors, any of these data can have different number of isolated peaks region. In this figure, I have 3 of those. I would like to have a function that takes the time-series as the input and returns the segmented sections of equal length. </p>

<p>My initial thought was to have a sliding window that calculates the relative change in the amplitude. Since the window with the peaks will have relatively higher changes, I could just define certain threshold for the relative change that would help me take the window with isolated peaks. However, this will create problem when choosing the threshold as the relative change is very sensitive to the noises in the data.</p>

<p>Any suggestions?</p>

<p><a href=""https://i.stack.imgur.com/QZzaT.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/QZzaT.png"" alt=""Figure : Desired segmentation of the time-series data""></a>
<img src=""https://i.stack.imgur.com/9DXIZ.png"" alt=""figure with axes""></p>
"
"60020612","<p>You can use the <code>key</code> argument to Python's <a href=""https://docs.python.org/3/library/functions.html#sorted"" rel=""nofollow noreferrer"">builtin <code>sorted</code> function</a>.</p>

<p>Assuming your records are tuples:</p>

<pre><code>records = [ 
  (""CHARLES"", 2, 4, ""DALLAS TX""),
  (""RICK"", 6, 9, ""AUSTIN TX""),
  (""BOB"", 9, 0, ""KELLER TX"")
] 

sorted(records, key=lambda rec: rec[0])

# Produces:                                                                                                                                    
[('BOB', 9, 0, 'KELLER TX'),
 ('CHARLES', 2, 4, 'DALLAS TX'),
 ('RICK', 6, 9, 'AUSTIN TX')]
</code></pre>

<p>My recommendation would be to use <a href=""https://docs.python.org/3/library/collections.html#collections.namedtuple"" rel=""nofollow noreferrer""><code>collections.namedtuple</code></a> to create a record class, and convert any text to the correct types (e.g. integers) as early as possible.  (The sample code below omits conversion to integers for simplicity.)</p>

<p>If you records are strings, you can call <code>line.split("" "")</code> on each element to produce lists.</p>

<pre><code>my_file = [ 
    ""CHARLES 2 4 DALLAS TX"", 
    ""RICK 6 9 AUSTIN TX"", 
    ""BOB 9 0 KELLER TX"", 
] 

Record = collections.namedtuple(""Record"", ""name, i, j, city, state"") 
records = [Record(*line.split("" "")) for line in my_file] 

sorted(records, key=lambda rec: rec.name)                                                                                                                                  
# Result: 
# [Record(name='BOB', i='9', j='0', city='KELLER', state='TX'),
#  Record(name='CHARLES', i='2', j='4', city='DALLAS', state='TX'),
#  Record(name='RICK', i='6', j='9', city='AUSTIN', state='TX')]
</code></pre>
","0","2020-02-01 20:07:14","3","3743","4114","321","256","60020582","60020612","<p>I am trying to sort records within a list using their 'key' (which is their name).
The records are formatted:</p>
<blockquote>
<p>CHARLES 2 4 DALLAS TX</p>
<p>RICK   6 9 AUSTIN TX</p>
<p>BOB    9 0 KELLER TX</p>
</blockquote>
<p>How can I sort these records within the last by their first name only? My code so far is:</p>
<pre><code>list_of_records = []
for line in my_file:
   list_of_records.append(line)
</code></pre>
<p>The file I am reading from contains only 3 records but they will always be unsorted by name and I can not manually sort the text file.</p>
"
"60020633","<p>Something like this?</p>

<pre><code>import os

# iterate over each file:
for file in os.walk('C:\\'):
    print(file)
</code></pre>
","0","","0","1842","112","6","198","60020596","60020633","<p>Is there a way to list and receive ALL but ALL the files in the C: drive in a computer with Python ?</p>
"
"60020635","<pre><code>import os

for result in os.walk('path_to_directory'):
  print(result)
</code></pre>
","1","","0","1489","27","6","129","60020596","60020633","<p>Is there a way to list and receive ALL but ALL the files in the C: drive in a computer with Python ?</p>
"
"60020704","<p>try this below code:</p>

<pre><code>df.groupby('ID_Customer')['ID_product'].count()
</code></pre>

<p>let me know if this works for you or not.</p>

<p>Thanks</p>
","0","","0","366","68","7","34","60020648","60020704","<p>I have the following code <code>df1 = df.groupby(['ID_Customer', 'ID_product']).size()</code>
for calculation of number of rows for each product for each customer. There is one single row for each product for each customer in dataset. The result is the following df1 (part of)</p>

<pre><code>    ID cust    ID prod   
    026        009               30
    027        009               1
    028        009               15
    030        009               30
    032        009               30
    ...
</code></pre>

<p>How to calculate the number of distinct product per customer? Or how to implement select distinct values groupby column</p>
"
"60020707","<p>You can simply use <a href=""https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.core.groupby.DataFrameGroupBy.nunique.html"" rel=""nofollow noreferrer""><code>nunique</code></a>:</p>

<pre><code>df.groupby(['ID_Customer'])['ID_product'].nunique()
</code></pre>
","2","","0","15706","461","31","1209","60020648","60020704","<p>I have the following code <code>df1 = df.groupby(['ID_Customer', 'ID_product']).size()</code>
for calculation of number of rows for each product for each customer. There is one single row for each product for each customer in dataset. The result is the following df1 (part of)</p>

<pre><code>    ID cust    ID prod   
    026        009               30
    027        009               1
    028        009               15
    030        009               30
    032        009               30
    ...
</code></pre>

<p>How to calculate the number of distinct product per customer? Or how to implement select distinct values groupby column</p>
"
"60029246","<p>The problem is caused, as stated by the error message, from <code>NaN</code> values in the <code>OH_X_test</code>. Those values are introduced in the <code>concat</code> statement since the indices of the dataframes are mixed up.</p>

<p>I've therefore added 3 fixes in the code below: look at the <code>###FIX</code> tag.</p>

<pre><code>#### DATASETS LOAD ####
import pandas as pd
from sklearn.model_selection import train_test_split

# Read the data
X = pd.read_csv('../input/train.csv', index_col='Id') 
X_test = pd.read_csv('../input/test.csv', index_col='Id')

# Remove rows with missing target, separate target from predictors
X.dropna(axis=0, subset=['SalePrice'], inplace=True)
y = X.SalePrice
X.drop(['SalePrice'], axis=1, inplace=True)

# To keep things simple, we'll drop columns with missing values
cols_with_missing = [col for col in X.columns if X[col].isnull().any()] 
X.drop(cols_with_missing, axis=1, inplace=True)
X_test.drop(cols_with_missing, axis=1, inplace=True)

# Break off validation set from training data
X_train, X_valid, y_train, y_valid = train_test_split(X, y,
                                                      train_size=0.8, test_size=0.2,
                                                      random_state=0)

#### IMPUTATION OF MISSING VALUES FOR X_TEST ####
from sklearn.impute import SimpleImputer

# All categorical columns
object_cols = [col for col in X_train.columns if X_train[col].dtype == ""object""]

# Columns that will be one-hot encoded
low_cardinality_cols = [col for col in object_cols if X_train[col].nunique() &lt; 10]

# Fill in the lines below: imputation
my_imputer = SimpleImputer(strategy='most_frequent')
imputed_X_test = pd.DataFrame(my_imputer.fit_transform(X_test))

# Fill in the lines below: imputation removed column names; put them back
imputed_X_test.columns = X_test.columns 
imputed_X_test.index = X_test.index ###FIX

#### ONEHOT ENCODING FOR DATA #####
from sklearn.preprocessing import OneHotEncoder

# Apply one-hot encoder to each column with categorical data
OH_encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)
OH_cols_train = pd.DataFrame(OH_encoder.fit_transform(X_train[low_cardinality_cols]))
OH_cols_valid = pd.DataFrame(OH_encoder.transform(X_valid[low_cardinality_cols]))
OH_cols_test = pd.DataFrame(OH_encoder.transform(imputed_X_test[low_cardinality_cols]))

# One-hot encoding removed index; put it back
OH_cols_train.index = X_train.index
OH_cols_valid.index = X_valid.index
OH_cols_test.index = imputed_X_test.index ####FIX

# Remove categorical columns (will replace with one-hot encoding)
num_X_train = X_train.drop(object_cols, axis=1)
num_X_valid = X_valid.drop(object_cols, axis=1)
num_X_test = imputed_X_test.drop(object_cols, axis=1) ####FIX

# Add one-hot encoded columns to numerical features
OH_X_train = pd.concat([num_X_train, OH_cols_train], axis=1)
OH_X_valid = pd.concat([num_X_valid, OH_cols_valid], axis=1)
OH_X_test = pd.concat([num_X_test, OH_cols_test], axis=1)

##### BUILD MODEL AND CREATE SUBMISSION ####
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_absolute_error

# normalize datatypes columns
#for colName in  ['BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', 'BsmtFullBath', 'BsmtHalfBath', 'GarageCars', 'GarageArea']:
#    OH_X_train[colName] = OH_X_train[colName].astype('float64')
#    OH_X_valid[colName] = OH_X_train[colName].astype('float64')

# Build model
model = RandomForestRegressor(n_estimators=100, random_state=0)
model.fit(OH_X_train, y_train)
preds_test = model.predict(OH_X_test)

# Save test predictions to file
output = pd.DataFrame({'Id': OH_X_test.index,
                       'SalePrice': preds_test})
output.to_csv('submission.csv', index=False)
</code></pre>
","0","","0","814","12","3","81","60020698","60029246","<p>While performing Step 5 of <em>Exercise: Categorical Variables</em> on Kaggle Learn, I got the <code>ValueError: Input contains NaN, infinity or a value too large for dtype('float32')</code> during the predict phase with the test set.</p>

<p>Full jupyter notebook available <a href=""https://www.kaggle.com/kernels/fork/3370279"" rel=""nofollow noreferrer"">here</a>.
Full code used displayed at the end of the post.</p>

<p>The code aims to prepare a submission dataset for the <a href=""https://www.kaggle.com/c/home-data-for-ml-course"" rel=""nofollow noreferrer"">""Housing Prices Competition for Kaggle Learn Users""</a>.</p>

<p>The problem is to pre-process the <code>X_test</code> dataset that contains the test set. At first I've used the <code>SimpleImputer</code> with a <code>most_frequent</code> strategy. Then performed a one hot encoding for categorical variables of the dataset.</p>

<p>I found that betwen the <code>X_train</code> (and <code>X_valid</code>) datasets and the <code>X_test</code>, a few features <strong>have different datatypes</strong>. Specifically columns <code>['BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', 'BsmtFullBath', 'BsmtHalfBath', 'GarageCars', 'GarageArea']</code> are of <code>int64</code> type in the training data (<code>X_train</code> and <code>X_valid</code>) while they are of 'float64' in the test data (<code>X_test</code>). I guess that the problem may be here but I'm unable to solve it. Tried by casting the values with the following chunk</p>

<pre><code># normalize datatypes columns
#for colName in  ['BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', 'BsmtFullBath', 'BsmtHalfBath', 'GarageCars', 'GarageArea']:
#    OH_X_train[colName] = OH_X_train[colName].astype('float64')
#    OH_X_valid[colName] = OH_X_train[colName].astype('float64')
</code></pre>

<p>but it didn't work. Any suggestions?</p>

<pre><code>#### DATASETS LOAD ####
import pandas as pd
from sklearn.model_selection import train_test_split

# Read the data
X = pd.read_csv('../input/train.csv', index_col='Id') 
X_test = pd.read_csv('../input/test.csv', index_col='Id')

# Remove rows with missing target, separate target from predictors
X.dropna(axis=0, subset=['SalePrice'], inplace=True)
y = X.SalePrice
X.drop(['SalePrice'], axis=1, inplace=True)

# To keep things simple, we'll drop columns with missing values
cols_with_missing = [col for col in X.columns if X[col].isnull().any()] 
X.drop(cols_with_missing, axis=1, inplace=True)
X_test.drop(cols_with_missing, axis=1, inplace=True)

# Break off validation set from training data
X_train, X_valid, y_train, y_valid = train_test_split(X, y,
                                                      train_size=0.8, test_size=0.2,
                                                      random_state=0)

#### IMPUTATION OF MISSING VALUES FOR X_TEST ####
from sklearn.impute import SimpleImputer

# All categorical columns
object_cols = [col for col in X_train.columns if X_train[col].dtype == ""object""]

# Columns that will be one-hot encoded
low_cardinality_cols = [col for col in object_cols if X_train[col].nunique() &lt; 10]

# Fill in the lines below: imputation
my_imputer = SimpleImputer(strategy='most_frequent')
imputed_X_test = pd.DataFrame(my_imputer.fit_transform(X_test))

# Fill in the lines below: imputation removed column names; put them back
imputed_X_test.columns = X_test.columns

#### ONEHOT ENCODING FOR DATA #####
from sklearn.preprocessing import OneHotEncoder

# Apply one-hot encoder to each column with categorical data
OH_encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)
OH_cols_train = pd.DataFrame(OH_encoder.fit_transform(X_train[low_cardinality_cols]))
OH_cols_valid = pd.DataFrame(OH_encoder.transform(X_valid[low_cardinality_cols]))
OH_cols_test = pd.DataFrame(OH_encoder.transform(imputed_X_test[low_cardinality_cols]))

# One-hot encoding removed index; put it back
OH_cols_train.index = X_train.index
OH_cols_valid.index = X_valid.index
OH_cols_test.index = X_test.index

# Remove categorical columns (will replace with one-hot encoding)
num_X_train = X_train.drop(object_cols, axis=1)
num_X_valid = X_valid.drop(object_cols, axis=1)
num_X_test = X_test.drop(object_cols, axis=1)

# Add one-hot encoded columns to numerical features
OH_X_train = pd.concat([num_X_train, OH_cols_train], axis=1)
OH_X_valid = pd.concat([num_X_valid, OH_cols_valid], axis=1)
OH_X_test = pd.concat([num_X_test, OH_cols_test], axis=1)

##### BUILD MODEL AND CREATE SUBMISSION ####
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_absolute_error

# normalize datatypes columns
#for colName in  ['BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', 'BsmtFullBath', 'BsmtHalfBath', 'GarageCars', 'GarageArea']:
#    OH_X_train[colName] = OH_X_train[colName].astype('float64')
#    OH_X_valid[colName] = OH_X_train[colName].astype('float64')

# Build model
model = RandomForestRegressor(n_estimators=100, random_state=0)
model.fit(OH_X_train, y_train)
preds_test = model.predict(OH_X_test)

# Save test predictions to file
#output = pd.DataFrame({'Id': OH_X_test.index,
#                       'SalePrice': preds_test})
#output.to_csv('submission.csv', index=False)
</code></pre>

<p>And here the full error log:</p>

<pre><code>---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
&lt;ipython-input-2-2d85be0f6b26&gt; in &lt;module&gt;
     74 model = RandomForestRegressor(n_estimators=100, random_state=0)
     75 model.fit(OH_X_train, y_train)
---&gt; 76 preds_test = model.predict(OH_X_test)
     77 
     78 # Save test predictions to file

/opt/conda/lib/python3.6/site-packages/sklearn/ensemble/forest.py in predict(self, X)
    691         check_is_fitted(self, 'estimators_')
    692         # Check data
--&gt; 693         X = self._validate_X_predict(X)
    694 
    695         # Assign chunk of trees to jobs

/opt/conda/lib/python3.6/site-packages/sklearn/ensemble/forest.py in _validate_X_predict(self, X)
    357                                  ""call `fit` before exploiting the model."")
    358 
--&gt; 359         return self.estimators_[0]._validate_X_predict(X, check_input=True)
    360 
    361     @property

/opt/conda/lib/python3.6/site-packages/sklearn/tree/tree.py in _validate_X_predict(self, X, check_input)
    389         """"""Validate X whenever one tries to predict, apply, predict_proba""""""
    390         if check_input:
--&gt; 391             X = check_array(X, dtype=DTYPE, accept_sparse=""csr"")
    392             if issparse(X) and (X.indices.dtype != np.intc or
    393                                 X.indptr.dtype != np.intc):

/opt/conda/lib/python3.6/site-packages/sklearn/utils/validation.py in check_array(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)
    540         if force_all_finite:
    541             _assert_all_finite(array,
--&gt; 542                                allow_nan=force_all_finite == 'allow-nan')
    543 
    544     if ensure_min_samples &gt; 0:

/opt/conda/lib/python3.6/site-packages/sklearn/utils/validation.py in _assert_all_finite(X, allow_nan)
     54                 not allow_nan and not np.isfinite(X).all()):
     55             type_err = 'infinity' if allow_nan else 'NaN, infinity'
---&gt; 56             raise ValueError(msg_err.format(type_err, X.dtype))
     57     # for object dtype data, we only check for NaNs (GH-13254)
     58     elif X.dtype == np.dtype('object') and not allow_nan:

ValueError: Input contains NaN, infinity or a value too large for dtype('float32').
</code></pre>
"
"60020873","<p>I wouldn't worry about the memory locations, they are simply an implementation detail here. It's really about function design, so if you want to set <code>object.three</code>, then do exactly that, otherwise, you can create a mapping to an index if you wanted to:</p>

<pre class=""lang-py prettyprint-override""><code>class MyClass:
    def __init__(self, *args):
        self.one, self.two, self.three, *_ = args

    # get an object by it's index
    def get_by_index(self, index):
        # here's how you could create such a mapping
        opts = dict(zip((1, 2, 3), ('one', 'two', 'three')))

        try:
            return getattr(self, opts[index])
        except KeyError as e:
            raise ValueError(f""Improper alias for attribute, select one of {', '.join(opts)}"") from e

    # if you want to set by an index, then do that this way
    def set_by_index(self, index, val):
        opts = dict(zip((1, 2, 3), ('one', 'two', 'three')))

        try:
            setattr(self, opts[index], val)
        except KeyError as e:
            raise ValueError(f""Improper alias for attribute, select one of {', '.join(opts)}"") from e



# otherwise, just set the attribute by the name
a = MyClass(0, 0, 0)
a.three = 55


</code></pre>

<p>The thing is, you're right, <code>is</code> will look at the three <code>0</code>'s the same way, because it never copied that data in the first place. <code>one, two, three</code> point to the same data because they were assigned the same data. Once you assign the attribute again, you've effectively re-binded that attribute to a <em>new</em> value, rather than updating an existing one.</p>

<p>Point being, don't worry about <em>where</em> the memory is for this implementation, just set explicitly against the attribute</p>
","1","","1","9059","762","165","821","60020749","60020873","<p>I have a class with several named attributes. I would like to be able to pass one of the classes attributes to itself and be able to determine specifically which attribute was passed.</p>

<p>Below is a trivial example of how I was doing it (using the ""is"" operator), until I discovered that special cached variable IDs are used for integer values between -5 and 256.</p>

<pre><code>class AClass:
    def __init__(self, one, two, three):
        self.one = one
        self.two = two
        self.three = three

    def getIndex(self, attribute):
        if attribute is self.one:
            return 1
        elif attribute is self.two:
            return 2
        elif attribute is self.three:
            return 3

    def setByIndex(self, i, value):
        if i == 1:
            self.one = value
        elif i == 2:
            self.two = value
        elif i == 3:
            self.three = value

    def setByAttrib(self, attribute, value):
        i = self.getIndex(attribute)
        self.setByIndex(i, value)


object = AClass(0, 0, 0)

object.setByAttrib(object.three, 10)
</code></pre>

<p>In the above example, the intention is to set <strong><em>object.three</em></strong> to <strong><em>10</em></strong>. However, since all attributes are pointing to the cached location of integer <strong><em>0</em></strong>, the getIndex function would evaluate true on any of them, and <strong><em>object.one</em></strong> (which appears first) will get set to <strong><em>10</em></strong>. If the object was initialized with values <strong><em>257, 257, 257</em></strong>, functionality would presumably be as intended.</p>

<p>So the question is, is there a way to either:</p>

<p>a) force the system to assign non-cached, unique memory locations for these attributes (even if they are set between -5 and 256), or</p>

<p>b) use some other method to check if an attribute passed as an argument is uniquely itself?</p>

<p><strong>EDIT:</strong></p>

<p>Since it was asked a couple times, one of the reasons I'm using this paradigm is due to the the lack of pointers in python. In the example above, the <strong>setByIndex</strong> function could be doing some complicated work on the attribute. Rather than write multiple identical functions for each variable (eg <strong>setOne, setTwo, setThree</strong>), I can write out a single generic function that is retrieving and setting by index (index is basically acting like a pointer). Yes, I could pass the attribute value as an argument and return the new set value and do the assignment in the scope where the specific attribute is known, but I am already returning a value. Yes, I could return a list, but it adds more complexity.</p>

<p>I do realize that there are better ways to implement what I need (eg key-value pairs for the attributes and index numbers) but it would be a lot of work to implement (thousands of changes). If there was a way to use the varaible ID as my unique identifier and continue to use the ""is"" operator (or similar), I wouldn't need to change too much. Not looking possible though. Appreciate the comments/responses.</p>
"
"60021262","<p>You can either use the <code>TextAreaField</code> field (<code>from wtforms import TextAreaField</code>), or change the widget for the <code>StringField</code> to a textarea:</p>

<pre><code>from wtforms.widgets import TextArea

my_field = StringField('My Field', widget=TextArea())
</code></pre>

<p>In any case, you can also pass <code>rows</code> and <code>cols</code> parameters in your template:</p>

<pre><code>{{ form.my_field(cols=50, rows=10) }}
</code></pre>
","1","","1","1692","43","14","107","60020791","60021262","<p>In Flask wtform's StringField which handles multiline text input, I could only have a long string of text, even through I need to put in multiple lines. If the original text I pasted in has multiple lines, it became a long one-line string as well.</p>

<p>Pressing enter in the text area (string field) does not create a new line, instead it confirms the input. How can I break up a chunk of text into multiple lines in StringField?</p>
"
"60020980","<p>You can check if autocommit is set to 1, this forces to commit every row and disabling it makes it somewhat faster</p>

<p>Instead of committing every insert try to bulk insert.</p>

<p>For that you should check
<a href=""https://dev.mysql.com/doc/refman/8.0/en/optimizing-innodb-bulk-data-loading.html"" rel=""nofollow noreferrer"">https://dev.mysql.com/doc/refman/8.0/en/optimizing-innodb-bulk-data-loading.html</a></p>

<p>and do something like</p>

<pre><code>data = [
('city 1', 'MAC', 'district 1', 16822),
('city 2', 'PSE', 'district 2', 15642),
('city 3', 'ZWE', 'district 3', 11642),
('city 4', 'USA', 'district 4', 14612),
('city 5', 'USA', 'district 5', 17672),
]

sql = ""insert into city(name, countrycode, district, population) 
VALUES(%s, %s, %s, %s)""

number_of_rows = cursor.executemany(sql, data)
db.commit()
</code></pre>
","6","","1","19057","673","1706","1943","60020847","60053608","<p>I'm having an issue with my application causing MySQL table to be locked due to inserts which take a long time, after reviewing online articles, it seems like it's related to auto increment, info below - </p>

<p>Python that inserts data (row at a time unfortunately as I need the auto incremented id for reference in future inserts) -</p>

<pre><code>for i, flightobj in stats[ucid]['flight'].items():
            flight_fk = None
            # Insert flights
            try:
                with mysqlconnection.cursor() as cursor:
                    sql = ""insert into cb_flights(ucid,takeoff_time,end_time,end_event,side,kills,type,map_fk,era_fk) values(%s,%s,%s,%s,%s,%s,%s,%s,%s);""
                    cursor.execute(sql, (
                    ucid, flightobj['start_time'], flightobj['end_time'], flightobj['end_event'], flightobj['side'],
                    flightobj['killnum'], flightobj['type'], map_fk, era_fk))
                    mysqlconnection.commit()
                    if cursor.lastrowid:
                        flight_fk = cursor.lastrowid
                    else:
                        flight_fk = 0
            except pymysql.err.ProgrammingError as e:
                logging.exception(""Error: {}"".format(e))
            except pymysql.err.IntegrityError as e:
                logging.exception(""Error: {}"".format(e))
            except TypeError as e:
                logging.exception(""Error: {}"".format(e))
            except:
                logging.exception(""Unexpected error:"", sys.exc_info()[0])
</code></pre>

<p>The above runs every 2 minutes on the same data and is supposed to insert only non duplicates as the MySQL would deny duplicates due to the unique ucid_takeofftime index.</p>

<p>MYSQL info, cb_flights table -</p>

<pre><code>  `pk` int(11) NOT NULL AUTO_INCREMENT,
  `ucid` varchar(50) NOT NULL,
  `takeoff_time` datetime DEFAULT NULL,
  `end_time` datetime DEFAULT NULL,
  `end_event` varchar(45) DEFAULT NULL,
  `side` varchar(45) DEFAULT NULL,
  `kills` int(11) DEFAULT NULL,
  `type` varchar(45) DEFAULT NULL,
  `map_fk` int(11) DEFAULT NULL,
  `era_fk` int(11) DEFAULT NULL,
  `round_fk` int(11) DEFAULT NULL,
  PRIMARY KEY (`pk`),
  UNIQUE KEY `ucid_takeofftime` (`ucid`,`takeoff_time`),
  KEY `ucid_idx` (`ucid`) /*!80000 INVISIBLE */,
  KEY `end_event` (`end_event`) /*!80000 INVISIBLE */,
  KEY `side` (`side`)
) ENGINE=InnoDB AUTO_INCREMENT=76023132 DEFAULT CHARSET=utf8;
</code></pre>

<p>Now inserts into the table from the Python code, can take sometimes over 60 seconds.
I beleive it might be related to the auto increment that is creating the lock on the table, if so, I'm looking for a workaround.</p>

<p>innodb info -</p>

<pre><code>innodb_autoinc_lock_mode    2
innodb_lock_wait_timeout    50
</code></pre>

<p>buffer is used up to 70% more or less.</p>

<p>Appreciate any assistance with this, either from application side or MySQL side.</p>

<p>EDIT
Adding the create statement for the cb_kills table which is also used with inserts but without an issue as far as I can see, this is in response to the comment on the 1st answer.</p>

<pre><code>CREATE TABLE `cb_kills` (
  `pk` int(11) NOT NULL AUTO_INCREMENT,
  `time` datetime DEFAULT NULL,
  `killer_ucid` varchar(50) NOT NULL,
  `killer_side` varchar(10) DEFAULT NULL,
  `killer_unit` varchar(45) DEFAULT NULL,
  `victim_ucid` varchar(50) DEFAULT NULL,
  `victim_side` varchar(10) DEFAULT NULL,
  `victim_unit` varchar(45) DEFAULT NULL,
  `weapon` varchar(45) DEFAULT NULL,
  `flight_fk` int(11) NOT NULL,
  `kill_id` int(11) NOT NULL,
  PRIMARY KEY (`pk`),
  UNIQUE KEY `ucid_killid_flightfk_uniq` (`killer_ucid`,`flight_fk`,`kill_id`),
  KEY `flight_kills_fk_idx` (`flight_fk`),
  KEY `killer_ucid_fk_idx` (`killer_ucid`),
  KEY `victim_ucid_fk_idx` (`victim_ucid`),
  KEY `time_ucid_killid_uniq` (`time`,`killer_ucid`,`kill_id`),
  CONSTRAINT `flight_kills_fk` FOREIGN KEY (`flight_fk`) REFERENCES `cb_flights` (`pk`)
) ENGINE=InnoDB AUTO_INCREMENT=52698582 DEFAULT CHARSET=utf8;
</code></pre>
"
"60053608","<p>I want to put in here some of the ways I worked on finding a solution to this problem. I'm not an expert in MySQL but I think these steps can help anyone looking to find out why he has lock wait timeouts.</p>

<p>So the troubleshooting steps I took are as follows - </p>

<p>1- Check if I can find in the MySQL slow log the relevant query that is locking my table. Usually it's possible to find queries that run a long time and also locks with the info below and the query right after it</p>

<pre><code># Time: 2020-01-28T17:31:48.634308Z
# User@Host: @ localhost [::1]  Id: 980397
# Query_time: 250.474040  Lock_time: 0.000000 Rows_sent: 10  Rows_examined: 195738
</code></pre>

<p>2- The above should give some clue on what's going on in the server and what might be waiting for a long time. Next I ran the following 3 queries to identify what is in use:</p>

<ul>
<li>check process list on which process are running - </li>
</ul>

<p><code>show full processlist;</code></p>

<ul>
<li>check tables in use currently -</li>
</ul>

<p><code>show open tables where in_use&gt;0;</code></p>

<ul>
<li>check running transactions -</li>
</ul>

<p><code>SELECT * FROM `information_schema`.`innodb_trx` ORDER BY `trx_started`;</code></p>

<p>3- The above 2 steps should give enough information on which query is locking the tables. in my case here I had a SP that ran an <code>insert into &lt;different table&gt; select from &lt;my locked table&gt;</code>, while it was inserting to a totally different table, this query was locking my table due to the select operation that took a long time.
To work around it, I changed the SP to work with temporary tables and now although the query is still not completely optimized, there are no locks on my table.</p>

<p>Adding here how I run the SP on temporary tables for async aggregated updates.</p>

<pre><code>CREATE DEFINER=`username`@`%` PROCEDURE `procedureName`()
BEGIN
    drop temporary table if exists scheme.temp1;
    drop temporary table if exists scheme.temp2;
    drop temporary table if exists scheme.temp3;
    create temporary table scheme.temp1 AS select * from scheme.live1;
    create temporary table scheme.temp2 AS select * from scheme.live2;
    create temporary table scheme.temp3 AS select * from scheme.live3;
    create temporary table scheme.emptytemp (
      `cName1` int(11) NOT NULL,
      `cName2` varchar(45) NOT NULL,
      `cName3` int(11) NOT NULL,
      `cName4` datetime NOT NULL,
      `cName5` datetime NOT NULL,
      KEY `cName1` (`cName1`)
    ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_0900_ai_ci;

    INSERT into scheme.emptytemp
    select t1.x,t2.y,t3.z
    from scheme.temp1 t1
    JOIN scheme.temp2 t2
    ON t1.x = t2.x
    JOIN scheme.temp3 t3
    ON t2.y = t3.y

    truncate table scheme.liveTable;
    INSERT into scheme.liveTable
    select * from scheme.emptytemp;
END
</code></pre>

<p>Hope this helps anyone that encounters this issue</p>
","1","","0","47","3","0","27","60020847","60053608","<p>I'm having an issue with my application causing MySQL table to be locked due to inserts which take a long time, after reviewing online articles, it seems like it's related to auto increment, info below - </p>

<p>Python that inserts data (row at a time unfortunately as I need the auto incremented id for reference in future inserts) -</p>

<pre><code>for i, flightobj in stats[ucid]['flight'].items():
            flight_fk = None
            # Insert flights
            try:
                with mysqlconnection.cursor() as cursor:
                    sql = ""insert into cb_flights(ucid,takeoff_time,end_time,end_event,side,kills,type,map_fk,era_fk) values(%s,%s,%s,%s,%s,%s,%s,%s,%s);""
                    cursor.execute(sql, (
                    ucid, flightobj['start_time'], flightobj['end_time'], flightobj['end_event'], flightobj['side'],
                    flightobj['killnum'], flightobj['type'], map_fk, era_fk))
                    mysqlconnection.commit()
                    if cursor.lastrowid:
                        flight_fk = cursor.lastrowid
                    else:
                        flight_fk = 0
            except pymysql.err.ProgrammingError as e:
                logging.exception(""Error: {}"".format(e))
            except pymysql.err.IntegrityError as e:
                logging.exception(""Error: {}"".format(e))
            except TypeError as e:
                logging.exception(""Error: {}"".format(e))
            except:
                logging.exception(""Unexpected error:"", sys.exc_info()[0])
</code></pre>

<p>The above runs every 2 minutes on the same data and is supposed to insert only non duplicates as the MySQL would deny duplicates due to the unique ucid_takeofftime index.</p>

<p>MYSQL info, cb_flights table -</p>

<pre><code>  `pk` int(11) NOT NULL AUTO_INCREMENT,
  `ucid` varchar(50) NOT NULL,
  `takeoff_time` datetime DEFAULT NULL,
  `end_time` datetime DEFAULT NULL,
  `end_event` varchar(45) DEFAULT NULL,
  `side` varchar(45) DEFAULT NULL,
  `kills` int(11) DEFAULT NULL,
  `type` varchar(45) DEFAULT NULL,
  `map_fk` int(11) DEFAULT NULL,
  `era_fk` int(11) DEFAULT NULL,
  `round_fk` int(11) DEFAULT NULL,
  PRIMARY KEY (`pk`),
  UNIQUE KEY `ucid_takeofftime` (`ucid`,`takeoff_time`),
  KEY `ucid_idx` (`ucid`) /*!80000 INVISIBLE */,
  KEY `end_event` (`end_event`) /*!80000 INVISIBLE */,
  KEY `side` (`side`)
) ENGINE=InnoDB AUTO_INCREMENT=76023132 DEFAULT CHARSET=utf8;
</code></pre>

<p>Now inserts into the table from the Python code, can take sometimes over 60 seconds.
I beleive it might be related to the auto increment that is creating the lock on the table, if so, I'm looking for a workaround.</p>

<p>innodb info -</p>

<pre><code>innodb_autoinc_lock_mode    2
innodb_lock_wait_timeout    50
</code></pre>

<p>buffer is used up to 70% more or less.</p>

<p>Appreciate any assistance with this, either from application side or MySQL side.</p>

<p>EDIT
Adding the create statement for the cb_kills table which is also used with inserts but without an issue as far as I can see, this is in response to the comment on the 1st answer.</p>

<pre><code>CREATE TABLE `cb_kills` (
  `pk` int(11) NOT NULL AUTO_INCREMENT,
  `time` datetime DEFAULT NULL,
  `killer_ucid` varchar(50) NOT NULL,
  `killer_side` varchar(10) DEFAULT NULL,
  `killer_unit` varchar(45) DEFAULT NULL,
  `victim_ucid` varchar(50) DEFAULT NULL,
  `victim_side` varchar(10) DEFAULT NULL,
  `victim_unit` varchar(45) DEFAULT NULL,
  `weapon` varchar(45) DEFAULT NULL,
  `flight_fk` int(11) NOT NULL,
  `kill_id` int(11) NOT NULL,
  PRIMARY KEY (`pk`),
  UNIQUE KEY `ucid_killid_flightfk_uniq` (`killer_ucid`,`flight_fk`,`kill_id`),
  KEY `flight_kills_fk_idx` (`flight_fk`),
  KEY `killer_ucid_fk_idx` (`killer_ucid`),
  KEY `victim_ucid_fk_idx` (`victim_ucid`),
  KEY `time_ucid_killid_uniq` (`time`,`killer_ucid`,`kill_id`),
  CONSTRAINT `flight_kills_fk` FOREIGN KEY (`flight_fk`) REFERENCES `cb_flights` (`pk`)
) ENGINE=InnoDB AUTO_INCREMENT=52698582 DEFAULT CHARSET=utf8;
</code></pre>
"
"60020905","<p>I think you are installing your modules on a vitualenv and the Jupyter notebook is running outside the virtualenv.</p>

<p>This happened to me once.</p>
","0","","1","69","4","0","8","60020874","60020905","<pre><code>ModuleNotFoundError                       Traceback (most recent call last)
&lt;ipython-input-2-c1d07d468637&gt; in &lt;module&gt;
----&gt; 1 import requests
      2 

ModuleNotFoundError: No module named 'requests'
</code></pre>

<ul>
<li>I first installed a module and was wondering why it was not working. </li>
<li>Then I tried with modules that ought to be installed, like pandas and requests. </li>
<li>On all modules, I get the same issue. </li>
<li>Then I checked if the modules really are not installed, or if they are not in the proper folder</li>
<li>After that, I uninstalled and reinstalled anaconda</li>
</ul>

<p>Nothing worked so far. I appreciate any help</p>

<p>Jupyter error message:</p>

<p><a href=""https://i.stack.imgur.com/AS1QO.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/AS1QO.png"" alt=""Jupyter error message""></a></p>

<p>Pip installed modules:</p>

<p><a href=""https://i.stack.imgur.com/rOMyf.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/rOMyf.png"" alt=""Pip installed modules""></a></p>
"
"60020995","<p>Maybe you forgot to append the path to your modules to sys.path.</p>

<p>Example from within your notebook, if u want to import some selfwritten module from some relative location:</p>

<pre><code>import sys
sys.path.append(""../../../"")
sys.path.append(""../../"")

# Rest of your code goes here, for example import $MODULE_NAME
</code></pre>

<p>Then you can <code>import $MODULE_NAME</code> (so, use the proper modulename of your desired module) iff. that module is in <code>../../</code> or in <code>../../../</code>.</p>

<p>HTH. :-)</p>
","0","","1","89","4","0","24","60020874","60020905","<pre><code>ModuleNotFoundError                       Traceback (most recent call last)
&lt;ipython-input-2-c1d07d468637&gt; in &lt;module&gt;
----&gt; 1 import requests
      2 

ModuleNotFoundError: No module named 'requests'
</code></pre>

<ul>
<li>I first installed a module and was wondering why it was not working. </li>
<li>Then I tried with modules that ought to be installed, like pandas and requests. </li>
<li>On all modules, I get the same issue. </li>
<li>Then I checked if the modules really are not installed, or if they are not in the proper folder</li>
<li>After that, I uninstalled and reinstalled anaconda</li>
</ul>

<p>Nothing worked so far. I appreciate any help</p>

<p>Jupyter error message:</p>

<p><a href=""https://i.stack.imgur.com/AS1QO.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/AS1QO.png"" alt=""Jupyter error message""></a></p>

<p>Pip installed modules:</p>

<p><a href=""https://i.stack.imgur.com/rOMyf.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/rOMyf.png"" alt=""Pip installed modules""></a></p>
"
"60021220","<p>Following produces file4 from file1, file2, file3;</p>

<pre><code>def load_file(filepath):
  "" Loads the files as dictionary ""
  with open(filepath, 'r') as f:
    return dict(line.rstrip().split() for line in f)

# Get keys
with open('file1.txt') as file1:
  keys = [line.rstrip() for line in file1]

# Produce output (file4)
with open('file4.txt', 'w') as file_out:
  dic1 = load_file('file2.txt')
  dic2 = load_file('file3.txt')

  for k in keys:
    v1 = int(dic1.get(k, 0))  # convert dic counts to int)
    v2 = int(dic2.get(k, 0))  # (use default to 0 if not present)
    v = max(v1, v2)
    if v &gt; 0:                 # only write if count &gt; 0
        file_out.write(f""{k} {v}\n"")
</code></pre>
","0","","1","10876","714","1","925","60021028","60021337","<p>I have three files:</p>

<p>file:1</p>

<pre><code>mango
banana
orange
</code></pre>

<p>file:2 -> the count is in string, because when I wrote to file:2 -> write() only let me write strings.</p>

<pre><code>mango 2
banana 3
</code></pre>

<p>file:3 -> the count is in string, because when I wrote to file:3 -> write() only let me write strings.</p>

<pre><code>banana 4
orange 3
</code></pre>

<p>I want to take file:1 and check with file:2 &amp; file:3. If they are present, I want to take the entry with the biggest count and write to file:4.</p>

<p>Expected output in file:4</p>

<pre><code>mango 2
banana 4
orange 3
</code></pre>

<p>I tried writing file:2 and file:3 to a dictionary and do a dictionary compare, but I am getting lost with two many open() files.
I am new to python. Not being able to write an integer to file with write() itself threw me off.
Appreciate your help/hint.</p>
"
"60021337","<p>This works for as many files as you want for input.</p>

<pre><code>values = {}
def func(file):
    number_of_lines = file.readlines()
    for line in number_of_lines:
        elements = line.split()
        if (elements[0] in values):
            if (int(elements[1]) &gt; int(values[elements[0]])):
                values[elements[0]] = elements[1]
        else:
            values[elements[0]] = 0
    file.close()


f = open(""1.txt"", ""r"")
func(f)
f = open(""2.txt"", ""r"")
func(f)
f = open(""3.txt"", ""r"")
func(f)
f = open(""4.txt"", ""w+"")
for key, val in values.items():
    print (key, "" "", val)
    to_write = key + "" "" + val + ""\n""
    f.write(to_write)

f.close()
</code></pre>
","1","","0","22","0","0","4","60021028","60021337","<p>I have three files:</p>

<p>file:1</p>

<pre><code>mango
banana
orange
</code></pre>

<p>file:2 -> the count is in string, because when I wrote to file:2 -> write() only let me write strings.</p>

<pre><code>mango 2
banana 3
</code></pre>

<p>file:3 -> the count is in string, because when I wrote to file:3 -> write() only let me write strings.</p>

<pre><code>banana 4
orange 3
</code></pre>

<p>I want to take file:1 and check with file:2 &amp; file:3. If they are present, I want to take the entry with the biggest count and write to file:4.</p>

<p>Expected output in file:4</p>

<pre><code>mango 2
banana 4
orange 3
</code></pre>

<p>I tried writing file:2 and file:3 to a dictionary and do a dictionary compare, but I am getting lost with two many open() files.
I am new to python. Not being able to write an integer to file with write() itself threw me off.
Appreciate your help/hint.</p>
"
"60021157","<p>If you are reading your data from a csv file you can define <code>sep</code> to <code>;</code> and read it as:</p>

<pre><code>df=pd.read_csv('filename.csv', sep=';', index_col=False)
</code></pre>

<p>Output:</p>

<pre><code>    id  signin_count    status
0   353     20  done
1   374     94  pending
2   377     4   done
</code></pre>
","1","","2","2271","358","52","360","60021054","60021157","<p>I'm trying to split the dataframe header <code>id;signin_count;status</code> into more columns where I can put my data into. I've tried <code>df.columns.values</code>, but I couldn't get a string to use <code>.split</code> in, as I was hoping. Instead, I got:</p>

<pre><code>Index(['id;signin_count;status'], dtype='object')
</code></pre>

<p>Which returns <code>AttributeError: 'Index' object has no attribute 'split'</code> when I try <code>.split</code></p>

<p>In broader terms, I have:</p>

<pre><code>id;signin_count;status
0   353;20;done;
1   374;94;pending;
2   377;4;done;
</code></pre>

<p>And want:</p>

<pre><code>    id      signin_count  status
0   353     20            done
1   374     94            pending
2   377     4             done
</code></pre>

<p>Splitting the data itself is not the problem here, that I can do. The focus is on how to access the header names without hardcoding it, as I will have to do the same with any other dataset with the same format</p>

<p>From the get-go, thank you</p>
"
"60024750","<p>Here's a way to do this with a simple SPSS macro:</p>

<p>This will be the macro definition:</p>

<pre><code>define !doAnalysis (!pos=!cmdend)
!do !vr !in (!1)
!let !BL=!concat(!vr,""_BL"")
!let !PO=!concat(!vr,""_PO"")
EXAMINE VARIABLES=!BL !PO BY Treatment_Group
  /PLOT NONE
  /STATISTICS DESCRIPTIVES
  /CINTERVAL 95
  /MISSING LISTWISE
  /NOTOTAL.
UNIANOVA !PO BY Treatment_Group WITH !BL
  /METHOD=SSTYPE(3)
  /INTERCEPT=INCLUDE
  /PRINT ETASQ DESCRIPTIVE HOMOGENEITY
  /CRITERIA=ALPHA(.05)
  /DESIGN=!BL Treatment_Group.
!doend
!enddefine.
</code></pre>

<p>The macro is now built to take a list of items, loop through them one by one, creating two names from each item in the list - by adding ""BL"" or ""PO"", and using these names to run your analyses.<br>
This will be the macro call:</p>

<pre><code>!doAnalysis Brief2_Inhibit_T_SELF  Brief2_Completion_T_SELF  Brief2_Shift_T_SELF .
</code></pre>
","1","","0","8253","1930","18","733","60021100","60024750","<p>I have a list of Baseline and Post variables that I want to run descriptive statistics and ANCOVA. </p>

<pre><code>Baseline variables = [Brief2_Inhibit_T_SELF_BL, Brief2_Completion_T_SELF_BL, Brief2_Shift_T_SELF_BL]
Post variables = [Brief2_Inhibit_T_SELF_PO, Brief2_Completion_T_SELF_PO, Brief2_Shift_T_SELF_PO]
Treatment_Group is on variable with two labels [1 - Intervention, 0- Control]
</code></pre>

<p>Below is my SPSS syntax for each pair of variable.</p>

<pre><code>EXAMINE VARIABLES=Brief2_Inhibit_T_SELF_BL Brief2_Inhibit_T_SELF_PO BY Treatment_Group
  /PLOT NONE
  /STATISTICS DESCRIPTIVES
  /CINTERVAL 95
  /MISSING LISTWISE
  /NOTOTAL.

UNIANOVA Brief2_Inhibit_T_SELF_PO BY Treatment_Group WITH Brief2_Inhibit_T_SELF_BL
  /METHOD=SSTYPE(3)
  /INTERCEPT=INCLUDE
  /PRINT ETASQ DESCRIPTIVE HOMOGENEITY
  /CRITERIA=ALPHA(.05)
  /DESIGN=Brief2_Inhibit_T_SELF_BL Treatment_Group.
</code></pre>

<p>I found a helpful guide from UCLA to loop through two lists of variables to run regression.</p>

<pre><code>begin program.
import spss, spssaux
spssaux.OpenDataFile('d:\data\elemapi2.sav')
vdict=spssaux.VariableDict()
dlist=vdict.range(start=""api00"", end=""ell"")
ilist=vdict.range(start=""grad_sch"", end=""enroll"")
ddim = len(dlist)
idim = len(ilist)

if ddim != idim: 
     print ""The two sequences of variables don't have the same length.""
else: 
        for i in range(ddim): 
             mydvar = dlist[i]
             myivar = ilist[i]

             spss.Submit(r""""""
                    regression /dependent %s
                    /method = enter %s.
                                """""" %(mydvar, myivar))
end program.
</code></pre>

<p>How can I edit the above list to run my SPSS syntaxes?</p>
"
"60021420","<p>Remove <code>right_ax</code> from everywhere and at the end plot it onto <code>top_ax</code></p>

<pre><code>import numpy as np
import matplotlib.pyplot as plt
from mpl_toolkits.axes_grid1 import make_axes_locatable
from scipy.stats import multivariate_normal
import scipy

fig, main_ax = plt.subplots(figsize=(5, 5))
divider = make_axes_locatable(main_ax)
top_ax = divider.append_axes(""top"", 1.05, pad=0.1,sharex=main_ax)

top_ax.xaxis.set_tick_params(labelbottom=False)

main_ax.set_xlabel('dim 1')
main_ax.set_ylabel('dim 2')
top_ax.set_ylabel('Z profile')

x, y = np.mgrid[-1:1:.01, -1:1:.01]
pos = np.empty(x.shape + (2,))
pos[:, :, 0] = x; pos[:, :, 1] = y
rv = multivariate_normal([-0.2, 0.2], [[1, 1.5], [0.25, 0.25]])
z = rv.pdf(pos)
z_max = z.max()

cur_x = 110
cur_y = 40

main_ax.imshow(z, origin='lower')
main_ax.autoscale(enable=False)
top_ax.autoscale(enable=False)
top_ax.set_ylim(top=z_max)
v_line = main_ax.axvline(cur_x, color='r')
h_line = main_ax.axhline(cur_y, color='g')
h_prof, = top_ax.plot(np.arange(x.shape[0]), z[int(cur_y),:], 'g-')
v_prof, = top_ax.plot(np.arange(x.shape[1])[::-1], z[:,int(cur_x)], 'r-')

plt.show()
</code></pre>
","3","","1","1038","53","6","89","60021324","60021420","<p>I got this great code example online, it shows two cross-sections in two Z-profile.
<a href=""https://i.stack.imgur.com/jRMd8.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/jRMd8.png"" alt=""Original figure""></a>
Does anyone know how to draw the two cross-sections together? 
<a href=""https://i.stack.imgur.com/jHTwu.jpg"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/jHTwu.jpg"" alt=""This is the figure I want""></a></p>

<p>Thank you for your help!!!</p>

<pre><code>import numpy as np
import matplotlib.pyplot as plt
from mpl_toolkits.axes_grid1 import make_axes_locatable
from scipy.stats import multivariate_normal
import scipy

fig, main_ax = plt.subplots(figsize=(5, 5))
divider = make_axes_locatable(main_ax)
top_ax = divider.append_axes(""top"", 1.05, pad=0.1,sharex=main_ax)
right_ax = divider.append_axes(""right"", 1.05,pad=0.1,sharey=main_ax)

# make some labels invisible
top_ax.xaxis.set_tick_params(labelbottom=False)
right_ax.yaxis.set_tick_params(labelleft=False)

main_ax.set_xlabel('dim 1')
main_ax.set_ylabel('dim 2')
top_ax.set_ylabel('Z profile')
right_ax.set_xlabel('Z profile')

x, y = np.mgrid[-1:1:.01, -1:1:.01]
pos = np.empty(x.shape + (2,))
pos[:, :, 0] = x; pos[:, :, 1] = y
rv = multivariate_normal([-0.2, 0.2], [[1, 1.5], [0.25, 0.25]])
z = rv.pdf(pos)
z_max = z.max()

cur_x = 110
cur_y = 40

main_ax.imshow(z, origin='lower')
main_ax.autoscale(enable=False)
right_ax.autoscale(enable=False)
top_ax.autoscale(enable=False)
right_ax.set_xlim(right=z_max)
top_ax.set_ylim(top=z_max)
v_line = main_ax.axvline(cur_x, color='r')
h_line = main_ax.axhline(cur_y, color='g')
v_prof, = right_ax.plot(z[:,int(cur_x)],np.arange(x.shape[1]), 'r-')
h_prof, = top_ax.plot(np.arange(x.shape[0]),z[int(cur_y),:], 'g-')

plt.show()
</code></pre>
"
"60022208","<p>Your problem arises because you try to use the <em>Avro converter</em> to read data from a topic that is <em>not Avro</em>.</p>

<p>There are two possible solutions: </p>

<p><em>1. Switch Kafka Connect’s sink connector to use the correct converter</em></p>

<p>For example, if you’re consuming JSON data from a Kafka topic into a Kafka Connect sink:</p>

<pre><code>...
value.converter=org.apache.kafka.connect.json.JsonConverter. 
value.converter.schemas.enable=true/false
...
</code></pre>

<p><code>value.converter.schemas.enable</code> depends on whether the message contains a schema..</p>

<p><em>2. Switch the upstream format to Avro</em></p>

<p>For DatagenConnector to produce messages to Kafka where the message value format is <code>Avro</code>, set the <code>value.converter</code> and <code>value.converter.schema.registry.url</code> parameters:</p>

<pre><code>...
""value.converter"": ""io.confluent.connect.avro.AvroConverter"",
""value.converter.schema.registry.url"": ""http://localhost:8081"",
...
</code></pre>

<p>See kafka-connect-datagen <a href=""https://github.com/confluentinc/kafka-connect-datagen#confusion-about-schemas-and-avro"" rel=""nofollow noreferrer"">docs</a> for details.</p>

<hr>

<p>Great <a href=""https://www.confluent.io/blog/kafka-connect-deep-dive-converters-serialization-explained/"" rel=""nofollow noreferrer"">article</a> on Kafka Connect Converters and Serialization. </p>
","1","","1","2725","1241","6","266","60021343","60022237","<p>I deployed Kafka from <a href=""https://github.com/confluentinc/examples/blob/5.4.0-post/cp-all-in-one/docker-compose.yml"" rel=""nofollow noreferrer"">here</a>. Also I added to <code>docker-compose.yml</code> Postgres container like this:</p>

<pre><code>postgres:
    image: postgres
    hostname: kafka-postgres
    container_name: kafka-postgres
    depends_on:
      - ksql-server
      - broker
      - schema-registry
      - connect
    ports:
      - 5432:5432
</code></pre>

<p>Created a topic pageviews.</p>

<p>Further I created DatagenConnector with settings and ran it.</p>

<pre><code>{
  ""name"": ""datagen-pageviews"",
  ""connector.class"": ""io.confluent.kafka.connect.datagen.DatagenConnector"",
  ""key.converter"": ""org.apache.kafka.connect.storage.StringConverter"",
  ""kafka.topic"": ""pageviews"",
  ""max.interval"": ""100"",
  ""iterations"": ""999999999"",
  ""quickstart"": ""pageviews""
} 
</code></pre>

<p>As far as I can see the connector defined a schema for the topic:</p>

<pre><code>{
  ""type"": ""record"",
  ""name"": ""pageviews"",
  ""namespace"": ""ksql"",
  ""fields"": [
    {
      ""name"": ""viewtime"",
      ""type"": ""long""
    },
    {
      ""name"": ""userid"",
      ""type"": ""string""
    },
    {
      ""name"": ""pageid"",
      ""type"": ""string""
    }
  ],
  ""connect.name"": ""ksql.pageviews""
} 
</code></pre>

<p>My next step was to create JdbcSinkConnector that would transfer data from Kafka topic to Postgres table. That worked. The settings of connector:</p>

<pre><code>{
  ""name"": ""from-kafka-to-pg"",
  ""connector.class"": ""io.confluent.connect.jdbc.JdbcSinkConnector"",
  ""errors.tolerance"": ""all"",
  ""errors.log.enable"": ""true"",
  ""errors.log.include.messages"": ""true"",
  ""topics"": [
    ""pageviews""
  ],
  ""connection.url"": ""jdbc:postgresql://kafka-postgres:5432/postgres"",
  ""connection.user"": ""postgres"",
  ""connection.password"": ""********"",
  ""auto.create"": ""true"",
  ""auto.evolve"": ""true""
}
</code></pre>

<p>Then I try to send messages to that topic by myself. But failed with error:</p>

<blockquote>
  <p>[2020-02-01 21:16:11,750] ERROR Error encountered in task to-pg-0.
  Executing stage 'VALUE_CONVERTER' with class
  'io.confluent.connect.avro.AvroConverter', where consumed record is
  {topic='pageviews', partition=0, offset=23834,
  timestamp=1580591160374, timestampType=CreateTime}.
  (org.apache.kafka.connect.runtime.errors.LogReporter)
  org.apache.kafka.connect.errors.DataException: Failed to deserialize
  data for topic pageviews to Avro:     at
  io.confluent.connect.avro.AvroConverter.toConnectData(AvroConverter.java:110)
    at
  org.apache.kafka.connect.runtime.WorkerSinkTask.lambda$convertAndTransformRecord$1(WorkerSinkTask.java:487)
    at
  org.apache.kafka.connect.runtime.errors.RetryWithToleranceOperator.execAndRetry(RetryWithToleranceOperator.java:128)
    at
  org.apache.kafka.connect.runtime.errors.RetryWithToleranceOperator.execAndHandleError(RetryWithToleranceOperator.java:162)
    at
  org.apache.kafka.connect.runtime.errors.RetryWithToleranceOperator.execute(RetryWithToleranceOperator.java:104)
    at
  org.apache.kafka.connect.runtime.WorkerSinkTask.convertAndTransformRecord(WorkerSinkTask.java:487)
    at
  org.apache.kafka.connect.runtime.WorkerSinkTask.convertMessages(WorkerSinkTask.java:464)
    at
  org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:320)
    at
  org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:224)
    at
  org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:192)
    at
  org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:177)
    at
  org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:227)
    at
  java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
    at java.util.concurrent.FutureTask.run(FutureTask.java:266)     at
  java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
    at
  java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
    at java.lang.Thread.run(Thread.java:748) Caused by:
  org.apache.kafka.common.errors.SerializationException: Error
  deserializing Avro message for id -1 Caused by:
  org.apache.kafka.common.errors.SerializationException: Unknown magic
  byte!</p>
</blockquote>

<p>So the send method matters. This is how I do this (Python, confluent-kafka-python):</p>

<pre><code>producer = Producer({'bootstrap.servers': 'localhost:9092'})
producer.poll(0)
producer.produce(topic, json.dumps({
   'viewtime': 123,
   'userid': 'user_1',
   'pageid': 'page_1'
}).encode('utf8'), on_delivery=kafka_delivery_report)
producer.flush()
</code></pre>

<p>Maybe should I provide a schema with message (AvroProducer)? </p>
"
"60022237","<p>The topic expects a message in Avro type. </p>

<p><a href=""https://github.com/confluentinc/confluent-kafka-python"" rel=""nofollow noreferrer""><code>AvroProducer</code></a> from <a href=""https://github.com/confluentinc/confluent-kafka-python"" rel=""nofollow noreferrer""><code>confluent-kafka-python</code></a> does the trick: </p>

<pre><code>from confluent_kafka import avro
from confluent_kafka.avro import AvroProducer


value_schema_str = """"""
{
   ""namespace"": ""ksql"",
   ""name"": ""value"",
   ""type"": ""record"",
   ""fields"" : [
     {
       ""name"" : ""viewtime"",
       ""type"" : ""long""
     }, 
     {
       ""name"" : ""userid"",
       ""type"" : ""string""
     }, 
     {
       ""name"" : ""pageid"",
       ""type"" : ""string""
     }
   ]
}
""""""

key_schema_str = """"""
{
   ""namespace"": ""ksql"",
   ""name"": ""key"",
   ""type"": ""record"",
   ""fields"" : [
     {
       ""name"" : ""pageid"",
       ""type"" : ""string""
     }
   ]
}
""""""

value_schema = avro.loads(value_schema_str)
key_schema = avro.loads(key_schema_str)
value = {""name"": ""Value""}
key = {""name"": ""Key""}


def delivery_report(err, msg):
    """""" Called once for each message produced to indicate delivery result.
        Triggered by poll() or flush(). """"""
    if err is not None:
        print('Message delivery failed: {}'.format(err))
    else:
        print('Message delivered to {} [{}]'.format(msg.topic(), msg.partition()))


avroProducer = AvroProducer({
    'bootstrap.servers': 'mybroker,mybroker2',
    'on_delivery': delivery_report,
    'schema.registry.url': 'http://schema_registry_host:port'
    }, default_key_schema=key_schema, default_value_schema=value_schema)

avroProducer.produce(topic='my_topic', value=value, key=key)
avroProducer.flush()
</code></pre>
","7","2020-02-02 00:19:10","1","22983","1501","72","2832","60021343","60022237","<p>I deployed Kafka from <a href=""https://github.com/confluentinc/examples/blob/5.4.0-post/cp-all-in-one/docker-compose.yml"" rel=""nofollow noreferrer"">here</a>. Also I added to <code>docker-compose.yml</code> Postgres container like this:</p>

<pre><code>postgres:
    image: postgres
    hostname: kafka-postgres
    container_name: kafka-postgres
    depends_on:
      - ksql-server
      - broker
      - schema-registry
      - connect
    ports:
      - 5432:5432
</code></pre>

<p>Created a topic pageviews.</p>

<p>Further I created DatagenConnector with settings and ran it.</p>

<pre><code>{
  ""name"": ""datagen-pageviews"",
  ""connector.class"": ""io.confluent.kafka.connect.datagen.DatagenConnector"",
  ""key.converter"": ""org.apache.kafka.connect.storage.StringConverter"",
  ""kafka.topic"": ""pageviews"",
  ""max.interval"": ""100"",
  ""iterations"": ""999999999"",
  ""quickstart"": ""pageviews""
} 
</code></pre>

<p>As far as I can see the connector defined a schema for the topic:</p>

<pre><code>{
  ""type"": ""record"",
  ""name"": ""pageviews"",
  ""namespace"": ""ksql"",
  ""fields"": [
    {
      ""name"": ""viewtime"",
      ""type"": ""long""
    },
    {
      ""name"": ""userid"",
      ""type"": ""string""
    },
    {
      ""name"": ""pageid"",
      ""type"": ""string""
    }
  ],
  ""connect.name"": ""ksql.pageviews""
} 
</code></pre>

<p>My next step was to create JdbcSinkConnector that would transfer data from Kafka topic to Postgres table. That worked. The settings of connector:</p>

<pre><code>{
  ""name"": ""from-kafka-to-pg"",
  ""connector.class"": ""io.confluent.connect.jdbc.JdbcSinkConnector"",
  ""errors.tolerance"": ""all"",
  ""errors.log.enable"": ""true"",
  ""errors.log.include.messages"": ""true"",
  ""topics"": [
    ""pageviews""
  ],
  ""connection.url"": ""jdbc:postgresql://kafka-postgres:5432/postgres"",
  ""connection.user"": ""postgres"",
  ""connection.password"": ""********"",
  ""auto.create"": ""true"",
  ""auto.evolve"": ""true""
}
</code></pre>

<p>Then I try to send messages to that topic by myself. But failed with error:</p>

<blockquote>
  <p>[2020-02-01 21:16:11,750] ERROR Error encountered in task to-pg-0.
  Executing stage 'VALUE_CONVERTER' with class
  'io.confluent.connect.avro.AvroConverter', where consumed record is
  {topic='pageviews', partition=0, offset=23834,
  timestamp=1580591160374, timestampType=CreateTime}.
  (org.apache.kafka.connect.runtime.errors.LogReporter)
  org.apache.kafka.connect.errors.DataException: Failed to deserialize
  data for topic pageviews to Avro:     at
  io.confluent.connect.avro.AvroConverter.toConnectData(AvroConverter.java:110)
    at
  org.apache.kafka.connect.runtime.WorkerSinkTask.lambda$convertAndTransformRecord$1(WorkerSinkTask.java:487)
    at
  org.apache.kafka.connect.runtime.errors.RetryWithToleranceOperator.execAndRetry(RetryWithToleranceOperator.java:128)
    at
  org.apache.kafka.connect.runtime.errors.RetryWithToleranceOperator.execAndHandleError(RetryWithToleranceOperator.java:162)
    at
  org.apache.kafka.connect.runtime.errors.RetryWithToleranceOperator.execute(RetryWithToleranceOperator.java:104)
    at
  org.apache.kafka.connect.runtime.WorkerSinkTask.convertAndTransformRecord(WorkerSinkTask.java:487)
    at
  org.apache.kafka.connect.runtime.WorkerSinkTask.convertMessages(WorkerSinkTask.java:464)
    at
  org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:320)
    at
  org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:224)
    at
  org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:192)
    at
  org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:177)
    at
  org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:227)
    at
  java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
    at java.util.concurrent.FutureTask.run(FutureTask.java:266)     at
  java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
    at
  java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
    at java.lang.Thread.run(Thread.java:748) Caused by:
  org.apache.kafka.common.errors.SerializationException: Error
  deserializing Avro message for id -1 Caused by:
  org.apache.kafka.common.errors.SerializationException: Unknown magic
  byte!</p>
</blockquote>

<p>So the send method matters. This is how I do this (Python, confluent-kafka-python):</p>

<pre><code>producer = Producer({'bootstrap.servers': 'localhost:9092'})
producer.poll(0)
producer.produce(topic, json.dumps({
   'viewtime': 123,
   'userid': 'user_1',
   'pageid': 'page_1'
}).encode('utf8'), on_delivery=kafka_delivery_report)
producer.flush()
</code></pre>

<p>Maybe should I provide a schema with message (AvroProducer)? </p>
"
"60021501","<p>Maybe you can try this, function isnumeric return True if all characters in string are numeric.</p>

<pre><code> for i in first_numerical:
    if i == 'N':
        completed_frequency.append(i+ 'o Cap Per Day')
    if i == 'B':
        completed_frequency.append(i+'lank')
    if (i.isnumeric()):
        completed_frequency.append(i+' x Per Day') 
</code></pre>
","0","","0","22","0","0","4","60021446","60021504","<p>My code is the following:</p>

<pre><code>manipulate_list = data['Incorrect Frequency Cap1'].astype(str).tolist()
manipulate_list = ['Blank' if x == '' else x for x in manipulate_list]

first_numerical = []
for i in manipulate_list:
    first_numerical.append(i[0])

completed_frequency = []
for i in first_numerical:
    if i == 'N':
        completed_frequency.append(i+ 'o Cap Per Day')
    if i == 'B':
        completed_frequency.append(i+'lank')
    else:
        completed_frequency.append(i+' x Per Day') 
</code></pre>

<p>When I check ""first_numerical"" with the following - <code>first_numerical[5]</code> - I get '5'. </p>

<p>Why am I getting the following when I check ""completed_frequency""?</p>

<p><code>completed_frequency[5]</code> = 'N x Per Day'</p>
"
"60021504","<p>IIUC, your list kind of gets overwritten as you missed <code>elif</code> do this</p>

<pre><code>  for i in first_numerical:
        if i == 'N':
            completed_frequency.append(i+ 'o Cap Per Day')
        elif i == 'B':
            completed_frequency.append(i+'lank')
        else:
            completed_frequency.append(i+' x Per Day')
</code></pre>

<p>Lets have an example to clear the air</p>

<pre><code>n=['1','1','1']
b=[]
for i in n:
    if i == '1':
        b.append(i)
    if i=='2':
        b.append(2)
    else:
        b.append('none')
</code></pre>

<p>Output</p>

<pre><code>['1', 'none', '1', 'none', '1', 'none']
</code></pre>

<p><strong>Correct way</strong></p>

<pre><code>n=['1','1','1']
b=[]
for i in n:
    if i == '1':
        b.append(i)
    elif i=='2':
        b.append(2)
    else:
        b.append('none')
</code></pre>

<p>Output</p>

<pre><code>['1', '1', '1']
</code></pre>

<p>Not overwritten but gets appended with extra values</p>
","0","2020-02-01 22:16:48","3","2271","358","52","360","60021446","60021504","<p>My code is the following:</p>

<pre><code>manipulate_list = data['Incorrect Frequency Cap1'].astype(str).tolist()
manipulate_list = ['Blank' if x == '' else x for x in manipulate_list]

first_numerical = []
for i in manipulate_list:
    first_numerical.append(i[0])

completed_frequency = []
for i in first_numerical:
    if i == 'N':
        completed_frequency.append(i+ 'o Cap Per Day')
    if i == 'B':
        completed_frequency.append(i+'lank')
    else:
        completed_frequency.append(i+' x Per Day') 
</code></pre>

<p>When I check ""first_numerical"" with the following - <code>first_numerical[5]</code> - I get '5'. </p>

<p>Why am I getting the following when I check ""completed_frequency""?</p>

<p><code>completed_frequency[5]</code> = 'N x Per Day'</p>
"
"60021895","<p>Azure Blob Storage it's a good thing to store your image with metadata. </p>

<p>Microsoft provides an example how set and retrive image with metadata using Azure SDK (in c#): <a href=""https://docs.microsoft.com/en-us/azure/storage/blobs/storage-blob-container-properties-metadata"" rel=""nofollow noreferrer"">https://docs.microsoft.com/en-us/azure/storage/blobs/storage-blob-container-properties-metadata</a></p>

<p>The best storage for this, is Azure Data Lake gen 2: <a href=""https://docs.microsoft.com/en-us/azure/storage/blobs/data-lake-storage-introduction"" rel=""nofollow noreferrer"">https://docs.microsoft.com/en-us/azure/storage/blobs/data-lake-storage-introduction</a>
New storage generation wich use Blob Storage (low price)</p>

<p>In python you can configure environment follow the step in next link:</p>

<p><a href=""https://docs.microsoft.com/en-us/azure/storage/blobs/storage-quickstart-blobs-python#code-examples"" rel=""nofollow noreferrer"">https://docs.microsoft.com/en-us/azure/storage/blobs/storage-quickstart-blobs-python#code-examples</a></p>
","0","","2","44","0","0","0","60021457","60021895","<p>I am developing a python web application hosted on Azure that requires access to a set of images and associated metadata. I have read that the best option for storing images in Azure is using Blob Storage, but I am a little confused about how to then access the images from my app. Ideally, I'd like something that would allow my app quick access to a specific image as well as its metadata. Thanks in advance!</p>
"
"60021603","<p>You can call the <a href=""https://docs.python.org/3/library/datetime.html#datetime.datetime.time"" rel=""nofollow noreferrer""><strong><code>.time()</code></strong> method [python-doc]</a> to retrieve the time object:</p>

<pre><code>&gt;&gt;&gt; from datetime import datetime
&gt;&gt;&gt; datetime(1958, 3, 25, 12, 34).time()
datetime.time(12, 34)
</code></pre>
","0","","1","312807","16628","2518","41861","60021568","60021603","<p>I saved the datetime in my model and now </p>

<p>I have this ---> Feb. 1, 2020, 10:11 p.m.</p>

<p>How can I reach this? --->  10:11 p.m</p>
"
"60022979","<p>Yes, if the main code is in C++ and the bindings are well fleshed out, then option 1 is the easiest to work with, as in that case the bound C++ objects are as natural to use in Python as native Python classes. It makes life easier because you get full control over object identity and whether or not to copy.</p>

<p>For 3, I'm finding pybind11 to be too aggressive with copying when using callbacks (as seems to be your use case), e.g. with numpy arrays it's perfectly possible to work with the buffer on the C++ side if it is verified to be contiguous. Sure, copying will safeguard against memory problems, but there's too little control given over copying v.s. non-copying (numpy has the same problem tbs).</p>

<p>The reason why 3 exists is mostly because it improves usability and provides nice syntax. For example, if we have a function with this signature:</p>

<pre><code>void func(const std::vector&lt;int&gt;&amp;)
</code></pre>

<p>then it is nice to be able to call it from the Python side as <code>func((1, 2, 3))</code> or even <code>func(range(3))</code>. It's convenient, easy to use, looks clean, etc. But at that point, there is no way out but to copy, since the memory layout of a <code>tuple</code> is so different from a <code>std::vector</code> (and the range does not even represent an in-memory container).</p>

<p>Note carefully however, that with the <code>func</code> example above, the caller could still decide to provide a bound <code>std::vector&lt;int&gt;</code> object, and thus pre-empt any copying. May not look as nice, but there is full control. This is useful, for example if the vector is a return value from some other function, or is modified in between calls:</p>

<pre><code>v = some_calc()   # with v a bound C++ vector
func(v)
v.append(4)       # add an element
func(v)
</code></pre>

<p>Contrast this to the case where a list of floats is returned after calculating some numbers, analog to (but not quite) your description:</p>

<pre><code>std::list&lt;float&gt; calc()
</code></pre>

<p>If you choose ""option 1"", then the bound function <code>calc</code> will return a bound C++ object of <code>std::list&lt;float&gt;</code>. If you choose ""option 3"", then the bound function <code>calc</code> will return a Python <code>list</code> with the contents of the C++ <code>std::list&lt;float&gt;</code> copied into it.</p>

<p>The problem that arises with ""option 3"" is that if the caller actually wanted a bound C++ object, then the values need to be copied back into a new list, so a total of 2 copies. OTOH, if you choose ""option 1"" and the caller wanted instead a Python <code>list</code>, then they are free to do the copy on the return value of <code>calc</code> if desired:</p>

<pre><code>res = calc()
list_res = list(res)
</code></pre>

<p>or even, if they want this all the time:</p>

<pre><code>def pycalc():
    return list(calc())
</code></pre>

<p>Now finally to your specific case where it is a Python callback, called from C++, that returns a list of floats. If you use ""option 1"", then the Python function is forced to create a C++ list to return, so for example (with type <code>cpplist</code> the name given to a bound type <code>std::list&lt;float&gt;</code>):</p>

<pre><code>def pycalc():
    return cpplist(range(3))
</code></pre>

<p>which a Python programmer would not find pretty. Instead, by choosing ""option 3"", checking the return type and doing a conversion if needed, this would be valid as well:</p>

<pre><code>def pycalc():
    return [x for x in range(3)]
</code></pre>

<p>Depending on the overall requirements and typical use cases then, ""option 3"" may be more appreciated by your users.</p>
","2","","1","2323","67","2","219","60021569","60022979","<p>I have a project where i am mixing cpp and python code.</p>

<p>For multiple reasons, the frontend needs to be in python and the backend in cpp.</p>

<p>now, i am looking for a solution as for how to pass my python object to cpp. one think to note is the fact that the backend needs to callback into python at some point for calculating some numbers where the python function will return a list of floats.</p>

<p>I have been looking at pybind type conversion options defined here:
<a href=""https://pybind11.readthedocs.io/en/stable/advanced/cast/index.html"" rel=""nofollow noreferrer"">https://pybind11.readthedocs.io/en/stable/advanced/cast/index.html</a></p>

<p>However, to me it seems like options 1 is kind of easy to use as i can see here:
<a href=""https://pybind11.readthedocs.io/en/stable/advanced/classes.html#overriding-virtual-functions-in-python"" rel=""nofollow noreferrer"">https://pybind11.readthedocs.io/en/stable/advanced/classes.html#overriding-virtual-functions-in-python</a></p>

<p>so i am wondering, why would someone choose number 3? how does it compare with option 1?</p>

<p>Many thanks</p>
"
"60021791","<p>There is a difference between a <code>float</code> and a <code>Decimal</code>. A <code>Decimal</code> encodes the data by storing the digits of a decimal number. You can however <em>not</em> perform <code>DecimalValidation</code> on a <code>float</code>, since due to rounding errors, it will add extra digits.</p>

<p>You thus can use a <a href=""https://docs.djangoproject.com/en/dev/ref/models/fields/#decimalfield"" rel=""nofollow noreferrer""><strong><code>DecimalField</code></strong> [Django-doc]</a> instead. Note that you thus need to pass <code>Decimal</code> objects in that case, <em>not</em> floats.</p>

<pre><code>class Course(models.Model):
    title = models.CharField(max_length = 200)
    author = models.ForeignKey(User,default=None, on_delete=models.SET_DEFAULT)
    description = models.TextField(max_length=1000, blank=True)
    tags = models.TextField(blank = True)
    duration = models.<b>DecimalField(max_digits=3,decimal_places=2,</b> validators=(MinValueValidator(0.1),MaxValueValidator(12), DecimalValidator(max_digits=3,decimal_places=2))<b>)</b>


    def __str__(self):
            return self.title</code></pre>

<p>You might want to take a look at the <a href=""https://docs.djangoproject.com/en/dev/ref/models/fields/#durationfield"" rel=""nofollow noreferrer""><strong><code>DurationField</code></strong> [Django-doc]</a> to store duration however, this will automatically use a <code>timedelta</code>, and store it as an integer for databases that do <em>not</em> support such types.</p>
","2","","1","312807","16628","2518","41861","60021577","60021791","<p>I have a Django model with a FloatField, which I later base a form on. For some reason I get ""'float' object has no attribute 'as_tuple'"", and unfortunately I have no idea why do I get this error or how to fix it.</p>

<p>models.py:</p>

<pre class=""lang-py prettyprint-override""><code>class Course(models.Model):
    title = models.CharField(max_length = 200)
    author = models.ForeignKey(User,default=None, on_delete=models.SET_DEFAULT)
    description = models.TextField(max_length=1000, blank=True)
    tags = models.TextField(blank = True)
    duration = models.FloatField(validators=(MinValueValidator(0.1),MaxValueValidator(12), DecimalValidator(max_digits=3,decimal_places=2)))


    def __str__(self):
            return self.title

</code></pre>

<p>forms.py:</p>

<pre class=""lang-py prettyprint-override""><code>class CourseForm(ModelForm):
    class Meta:
        model = Course
        fields = ('title', 'description', 'price', 'duration', 'tags')
</code></pre>

<p>views.py:</p>

<pre class=""lang-py prettyprint-override""><code>@login_required
def create_course(request):
    if request.method == ""POST"":
        form = CourseForm(request.POST)

        if form.is_valid():

            form.save()
            messages.info(request, f""Course created succesfully!"")

        else:
            messages.error(request, ""Something went wrong, please resubmit!"")


    form = CourseForm()
    return render(request, ""main/createcourse.html"", {""form"": form})
</code></pre>

<p>html:</p>

<pre class=""lang-html prettyprint-override""><code>{% extends 'main/header.html' %}
&lt;body&gt;

   {% block content%}
&lt;div class=""container""&gt;

    &lt;form method=""POST""&gt;
        {% csrf_token %}

        {{form.as_p}}

        &lt;br&gt;
        &lt;button class=""btn"" type=""submit""&gt;Create&lt;/button&gt;
    &lt;/form&gt;

    If you to modify an existing course, click &lt;a href=""/modify""&gt;&lt;strong&gt;here&lt;/strong&gt;&lt;/a&gt; instead.
&lt;/div&gt;
&lt;br&gt;&lt;br&gt;
    {% endblock %}



&lt;/body&gt;

</code></pre>
"
"63889173","<p>If you really need to use a <code>FloatField</code>, then you need to write your own validator:</p>
<pre><code>def validate_decimals(value):
    s = str(value)
    d = decimal.Decimal(s)
    if abs(d.as_tuple().exponent) &gt; 2:
        raise ValidationError(
            _('%(value)s has more than 2 decimals. Please enter 2 decimals only.'),
            params={'value': value},
        )
</code></pre>
<p>Then, you add <code>validators='validate_decimals'</code> when you declare the <code>FloatField</code>.</p>
<p>Note that a float value cannot directly be converted to decimal. It should first be converted to string and then to decimal. See also:</p>
<p><a href=""https://stackoverflow.com/questions/316238/python-float-to-decimal-conversion"">Python float to Decimal conversion</a></p>
","0","2020-09-14 17:37:54","2","21","0","0","3","60021577","60021791","<p>I have a Django model with a FloatField, which I later base a form on. For some reason I get ""'float' object has no attribute 'as_tuple'"", and unfortunately I have no idea why do I get this error or how to fix it.</p>

<p>models.py:</p>

<pre class=""lang-py prettyprint-override""><code>class Course(models.Model):
    title = models.CharField(max_length = 200)
    author = models.ForeignKey(User,default=None, on_delete=models.SET_DEFAULT)
    description = models.TextField(max_length=1000, blank=True)
    tags = models.TextField(blank = True)
    duration = models.FloatField(validators=(MinValueValidator(0.1),MaxValueValidator(12), DecimalValidator(max_digits=3,decimal_places=2)))


    def __str__(self):
            return self.title

</code></pre>

<p>forms.py:</p>

<pre class=""lang-py prettyprint-override""><code>class CourseForm(ModelForm):
    class Meta:
        model = Course
        fields = ('title', 'description', 'price', 'duration', 'tags')
</code></pre>

<p>views.py:</p>

<pre class=""lang-py prettyprint-override""><code>@login_required
def create_course(request):
    if request.method == ""POST"":
        form = CourseForm(request.POST)

        if form.is_valid():

            form.save()
            messages.info(request, f""Course created succesfully!"")

        else:
            messages.error(request, ""Something went wrong, please resubmit!"")


    form = CourseForm()
    return render(request, ""main/createcourse.html"", {""form"": form})
</code></pre>

<p>html:</p>

<pre class=""lang-html prettyprint-override""><code>{% extends 'main/header.html' %}
&lt;body&gt;

   {% block content%}
&lt;div class=""container""&gt;

    &lt;form method=""POST""&gt;
        {% csrf_token %}

        {{form.as_p}}

        &lt;br&gt;
        &lt;button class=""btn"" type=""submit""&gt;Create&lt;/button&gt;
    &lt;/form&gt;

    If you to modify an existing course, click &lt;a href=""/modify""&gt;&lt;strong&gt;here&lt;/strong&gt;&lt;/a&gt; instead.
&lt;/div&gt;
&lt;br&gt;&lt;br&gt;
    {% endblock %}



&lt;/body&gt;

</code></pre>
"
"60021696","<p>IIUC for your current example you can try this:</p>

<pre><code>DataFrame[['column2','column3']]=DataFrame[['column2','column3']].bfill()
</code></pre>

<p>Output:</p>

<pre><code> column1  column2   column3
0   0.0     0.0     0.0
1   NaN     0.0     0.0
2   NaN     2.0     0.0
3   1.0     2.0     5.0
4   NaN     2.0     5.0
5   NaN     4.0     5.0
6   2.0     4.0     10.0
7   NaN     4.0     10.0
8   NaN     6.0     10.0
9   3.0     6.0     15.0
10  NaN     6.0     15.0
11  NaN     8.0     15.0
12  4.0     8.0     20.0
13  NaN     8.0     20.0
14  NaN     NaN     20.0
</code></pre>

<p>then remove the <code>NaN</code> :</p>

<pre><code>DataFrame.dropna(inplace=True)
</code></pre>

<p>Outpt:</p>

<pre><code> column1  column2   column3
0   0.0     0.0     0.0
3   1.0     2.0     5.0
6   2.0     4.0     10.0
9   3.0     6.0     15.0
12  4.0     8.0     20.0
</code></pre>
","1","","1","2271","358","52","360","60021634","60021696","<p>So I want to add/append data to a specific pandas dataFrame column but without it causing NaN values in the remaining columns</p>

<p><strong>I.e.</strong></p>

<pre><code>DataFrame = pd.DataFrame(columns=[""column1"", ""column2"", ""column3""])
for i in range():
    DataFrame = DataFrame.append({""column1"":int(i)}, ignore_index=True)
    DataFrame = DataFrame.append({""column2"":float(i*2)}, ignore_index=True)
    DataFrame = DataFrame.append({""column3"":int(i*5)}, ignore_index=True)
print(DataFrame)

</code></pre>

<p><strong>This will return:</strong></p>

<pre><code>   column1  column2  column3
0      0.0      NaN      NaN
1      NaN      0.0      NaN
2      NaN      NaN      0.0
3      1.0      NaN      NaN
4      NaN      2.0      NaN
5      NaN      NaN      5.0
6      2.0      NaN      NaN
7      NaN      4.0      NaN
8      NaN      NaN     10.0
</code></pre>

<p><strong>What we want returned:</strong></p>

<pre><code>   column1  column2  column3
0      0.0      0.0      0.0
1      1.0      2.0      5.0
2      2.0      4.0     10.0
</code></pre>

<p>I know I can in this case use one .append for all the different columns. But I have some cases where the data to be appended will vary based on multiple conditions. Hence I'd like to know if it's possible to append to single columns in a dataframe without producing NaN values in the remaining columns. So that I can avoid writing hundreds of if else statements. </p>

<p>Or if someone has any good idea regarding how to 'collapse' the NaN values (removing the NaN values without removing the entire row so that if there is a NaN value at index 0 in column 3 and there is a integer 5 at index 1 in the same column the integer 5 gets moved up to index 0)</p>

<p>Happy to hear any ideas.</p>
"
"60021811","<p>You need to only subtract <code>m[i]</code> from the values in <code>n[i]</code>, but your code is subtracting <code>m[i]</code> from all elements of <code>n</code>, but then only returning the result from subtracting <code>m[2]</code> since you overwrite <code>newlist</code> in each pass through the <code>for</code> loop. Here's a list comprehension that does what you want:</p>

<pre><code>n = [[1,2,3], [2,3,4], [43,2,5]]
m = [4,5,6]

o = [[abs(v-m[i]) for v in n[i]] for i in range(len(m))]
print(o)
</code></pre>

<p>Output:</p>

<pre><code>[[3, 2, 1], [3, 2, 1], [37, 4, 1]]
</code></pre>
","0","2020-02-01 23:03:23","1","116404","1598","3075","10590","60021764","60021869","<p>I am trying to delete list from a list of lists. For instance:</p>

<pre><code>n = [[1,2,3], [2,3,4], [43,2,5]]
m = [4,5,6]
</code></pre>

<p>I want to subtract m[0], from all the values in n[0], then go to m[1], and subtract m[1] from all the values in n[1], etc....</p>

<p>Finally, I want to have something like this as my output</p>

<pre><code>Output = [[3,2,1], [3,2,1], [37,4,1]]
</code></pre>

<p>Here is my code:</p>

<pre><code>def diff(n,m):
    for i in range(0,3):
        newlist = [[abs(m[i]-value) for value in sublist]
                   for sublist in n]
    return newlist
n = [[1,2,3], [2,3,4], [43,2,5]]
m = [4,5,6]

diff(n,m)

Output = [[3,2,1], [3,2,1], [37,4,1]]
</code></pre>
"
"60021869","<p>Just a pythonic list comprehension (with <code>zip</code> instead of indexes)...</p>

<pre><code>[[abs(b-x) for x in a] for a, b in zip(n, m)]
</code></pre>
","3","","2","5574","625","2339","1000","60021764","60021869","<p>I am trying to delete list from a list of lists. For instance:</p>

<pre><code>n = [[1,2,3], [2,3,4], [43,2,5]]
m = [4,5,6]
</code></pre>

<p>I want to subtract m[0], from all the values in n[0], then go to m[1], and subtract m[1] from all the values in n[1], etc....</p>

<p>Finally, I want to have something like this as my output</p>

<pre><code>Output = [[3,2,1], [3,2,1], [37,4,1]]
</code></pre>

<p>Here is my code:</p>

<pre><code>def diff(n,m):
    for i in range(0,3):
        newlist = [[abs(m[i]-value) for value in sublist]
                   for sublist in n]
    return newlist
n = [[1,2,3], [2,3,4], [43,2,5]]
m = [4,5,6]

diff(n,m)

Output = [[3,2,1], [3,2,1], [37,4,1]]
</code></pre>
"
"60022145","<p>In your views:</p>

<pre><code>if request.method == ""POST"":
    ...
else:
    mini_form = MinitaskForm(
        minitask=minitask,
        data={
            ""reason"": minitask.reason,
            ""selected_choice"": minitask.selected_choice,
        },
    )
</code></pre>

<p>According to the <a href=""https://docs.djangoproject.com/en/dev/ref/forms/api/#bound-and-unbound-forms"" rel=""nofollow noreferrer"">docs</a>:</p>

<blockquote>
  <p>A Form instance is either bound to a set of data, or unbound.</p>
</blockquote>

<p>Most of the times, a form gets its data from the user through a <a href=""https://docs.djangoproject.com/en/dev/ref/request-response/#django.http.HttpRequest.POST"" rel=""nofollow noreferrer"">POST</a> request. (bound form)</p>

<p>The <a href=""https://docs.djangoproject.com/en/dev/ref/request-response/#django.http.HttpRequest.GET"" rel=""nofollow noreferrer"">GET</a> request provides the user with the form in order to fill it with data. (unbound form)</p>

<p>Therefore, through a GET request, you need to provide the user with an unbound form.</p>

<p>In your code, you declare that if the request is not POST (a GET request is not POST), then return a bound form populated with data you programmatically provide. </p>

<p>This does not make sense.</p>

<p>Chances are that if you insert a <a href=""https://docs.python.org/3/library/functions.html#breakpoint"" rel=""nofollow noreferrer""><code>breakpoint()</code></a> after <code>else</code>, render the page with <code>./manage.py runserver</code> and type in the prompt provided in the console:</p>

<p><code>minitask.reason == None</code> the result will be <code>True</code>.</p>

<p>The above, mean that you bound your form with data that contain an empty reason which is not allowed.</p>

<p>If you want to provide initial data in your <a href=""https://docs.djangoproject.com/en/dev/ref/forms/api/#attributes-of-boundfield"" rel=""nofollow noreferrer"">unbound form</a>, you can do it using <a href=""https://docs.djangoproject.com/en/dev/ref/forms/api/#django.forms.Form.initial"" rel=""nofollow noreferrer""><code>initial</code></a>:</p>

<pre><code>mini_form = MinitaskForm(
    minitask=minitask,
    initial={
        ""reason"": minitask.reason,
        ""selected_choice"": minitask.selected_choice,
    },
)
</code></pre>
","2","2020-02-02 00:14:07","1","6085","3180","0","557","60021784","60022145","<p>I have a custom bootstrap form which is displayed in the Dashboard. The problem is, that when the user goes to the dashboard, he sees validation errors right away, even though he did not submit the form yet (the text field should be required). </p>

<p>I do not understand why this is happening, any help is appreciated! :)
Picture of the problem (I do not want the red ""The field is required"" message to display now, only after submitting):</p>

<p><a href=""https://i.stack.imgur.com/y6gMB.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/y6gMB.png"" alt=""enter image description here""></a></p>

<p>Form:</p>

<pre><code>class MinitaskForm(forms.ModelForm):
    class Meta:
        model = Minitask
        fields = ()


    def __init__(
        self,
        data=None,
        files=None,
        auto_id=""id_%s"",
        prefix=None,
        initial=None,
        error_class=ErrorList,
        label_suffix=None,
        empty_permitted=False,
        instance=None,
        use_required_attribute=None,
        minitask=None,
    ):
        super().__init__(
            data,
            files,
            auto_id,
            prefix,
            initial,
            error_class,
            label_suffix,
            empty_permitted,
            instance,
            use_required_attribute,
        )

        assert minitask is not None

        self.fields[""selected_choice""] = forms.CharField(
            widget=forms.RadioSelect(
                choices=[(val, val) for val in minitask.choices]
            ),
            required=False,
            label=""Which of these emotions best describes your day?"",
        )

        self.fields[""reason""] = forms.CharField(label=""Why?"")
</code></pre>

<p>Views:</p>

<pre><code>@login_required(login_url=""login"")
def dashboard(request):
    task = request.user.current_weekly_task()
    user_id = request.user.id
    solutions = Solution.objects.filter(user_id=user_id)
    minitask = request.user.current_minitask()
    minitasks = request.user.minitask_set.filter(selected_choice__isnull=False)

    if request.method == ""POST"":

        if ""minitask"" in request.POST:
            form = MinitaskForm(request.POST, minitask=minitask)
            if ""selected_choice"" not in request.POST:
                form.add_error(""selected_choice"", ""Can't be blank"")
                messages.error(request, ""You must pick your today's emotion"")
            if form.is_valid():
                minitask.reason = request.POST[""reason""]
                minitask.selected_choice = request.POST[""selected_choice""]
                minitask.user = request.user
                minitask.save()
                messages.success(request, ""Your daily status has been updated."")

        return redirect(""dashboard"")
    else:
        mini_form = MinitaskForm(
            minitask=minitask,
            data={
                ""reason"": minitask.reason,
                ""selected_choice"": minitask.selected_choice,
            },
        )

    return render(
        request,
        ""app/dashboard.html"",
        {
            ""solutions"": solutions,
            ""task"": task,
            ""mini_form"": mini_form,
            ""minitask"": minitask,
            ""minitasks"": minitasks,
            ""user"": request.user,
        },
    )
</code></pre>

<p>Template:</p>

<pre><code>&lt;form method=""POST"" class=""post-form""&gt;
  {% csrf_token %}
  {% bootstrap_form mini_form %}
  &lt;button 
    type=""Submit"" 
    id=""minitask-button"" 
    class=""save btn btn-pink"" 
    name=""minitask""
  &gt;Save minitask&lt;/button&gt;
&lt;/form&gt;
</code></pre>
"
"60021917","<p>Windows, Mac OS and UNIXes code new lines with differents chars.</p>

<ul>
<li>Windows uses <code>\r\n</code></li>
<li>Mac OS uses <code>\r</code></li>
<li>UNIXes use <code>\n</code></li>
</ul>

<p>if you want your program to be cross-platform, you should use <a href=""https://docs.python.org/3.7/library/os.html?highlight=linesep#os.linesep"" rel=""nofollow noreferrer""><code>os.linesep</code></a> instead of an OS-specific linebreak</p>

<hr>

<p>answering the comment:</p>

<p>Indeed on Windows, <code>\r</code> just return at the start of the line while <code>\n</code> actually starts a new line (see <a href=""https://softwareengineering.stackexchange.com/questions/29075/difference-between-n-and-r-n"">this StackExchange anwser</a> for a nice explanation).</p>

<p>I assume that, on windows, it allows you to simply write on the same line until the program exits.</p>

<p>Sadly it could work at least with some terminals on UNIXes but not necessarily on every terminals...</p>

<p>As a work around, you could probably use the <code>\b</code> character which deletes the last caracter of the line, like the <code>[backspace]</code> key.</p>
","4","2020-02-02 00:20:42","1","4899","456","27","210","60021860","60021917","<p>I'm pretty new to python and linux and I'm running into a problem... </p>

<p>So I'm trying to run the following code 
<em>(It is supposed to inform the person in front of the terminal, that the program is still running and then delete that line after 1 second)</em>:</p>

<pre><code>import sys

while True:
   # do something

   sys.stdout.write(""Still going..."")
   time.sleep(1)
   sys.stdout.write(""\r"")
   sys.stdout.flush()
</code></pre>

<p>This works perfectly fine on windows on python 3.8, but when i run it on my linux vps with python 3.6.9 via the ""python3"" command it doesn't flush the ""\r"", so the ""Still going..."" line only gets deleted and immediately reprinted the next time it reaches sys.stdout.write(""Still going..."").</p>

<p>If anyone has an idea what's going on here - please tell me
Any help is appreciated!</p>
"
"60022300","<p><strong>If you <code>truncate</code> a file<sup>1</sup> while another process has it open in <code>w</code> mode, that process will continue to write to the same offsets, making the file sparse. Low offsets will thus be read as <code>0</code>s.</strong></p>

<p>As per <a href=""https://unix.stackexchange.com/questions/346062/concurrent-writing-to-a-log-file-from-many-processes"">x11 - Concurrent writing to a log file from many processes - Unix &amp; Linux Stack Exchange</a> and <a href=""https://stackoverflow.com/questions/19667739/can-two-unix-processes-simultaneous-write-to-different-positions-in-a-single-file"">Can two Unix processes simultaneous write to different positions in a single file?</a>, each process that has a file open has its own offset in it, and a <code>ftruncate()</code> doesn't change that.</p>

<p><strong>If you want the other process to react to truncation, it needs to have it open in <code>a</code> mode.</strong></p>

<hr>

<p>Your approach has principal bugs, too. E.g. it's not atomic: you may (=will, eventually) truncate the file after the producer has added data but before you have read it so it would get lost.</p>

<p>Consider using dedicated data buffering utilities instead like <code>buffer</code> or <code>pv</code> as per <a href=""https://stackoverflow.com/questions/8554568/add-a-big-buffer-to-a-pipe-between-two-commands"">Add a big buffer to a pipe between two commands</a>.</p>

<hr>

<p><sup>1</sup><sub>Which is superfluous because <code>open(mode='w')</code> already does that. Either <code>truncate</code> or reopen, no need to do both.</sub></p>
","1","2020-02-02 00:31:22","2","28324","2387","1411","4522","60021864","60022300","<p>How do I truncate a csv log file that is being used as std out pipe destination from another process without generating a <code>_csv.Error: line contains NULL byte</code> error?</p>

<p>I have one process running <code>rtlamr &gt; log/readings.txt</code> that is piping radio signal data to <code>readings.txt</code>. I don't think it matters what is piping to the file--any long-running pipe process will do.</p>

<p>I have a file watcher using <code>watchdog</code> (Python file watcher) on that file, which triggers a function when the file is changed. The function read the files and updates a database.</p>

<p>Then I try to truncate <code>readings.txt</code> so that it doesn't grow infinitely (or back it up).</p>

<pre><code>file = open(dir_path+'/log/readings.txt', ""w"")
file.truncate()
file.close()
</code></pre>

<p>This corrupts <code>readings.txt</code> and generates the error (the start of the file contains garbage characters). </p>

<p>I tried moving the file instead of truncating it, in the hopes that <code>rtlamr</code> will recreate a fresh file, but that only has the effect of stopping the pipe. </p>

<p>EDIT
I noticed that the charset changes from <code>us-ascii</code> to <code>binary</code> but attempting to   truncate the file  with <code>file = open(dir_path+'/log/readings.log', ""w"",encoding=""us-ascii"")</code> does not do anything.</p>
"
"60022076","<p>This is an answer to a similar quesion which might help you.</p>

<p>Use the datetime library.</p>

<p>Loop through subset of days in august of that year.</p>

<p>Check if if it is thursday.</p>

<p><a href=""https://stackoverflow.com/questions/18424467/python-third-friday-of-a-month"">Python: third Friday of a month</a></p>

<p>Here is a solution based on one of the answers in that thread.  It is a generalized solution so you should be able to pick a month, a day of the week and the number in the month you want and get that date.</p>

<p>Note: Week days are 0 indexed starting at Monday.  So Sunday's index is 6 and monday's index is 0.  So when you feed the day_of_week into this function make sure you choose numbers between 0 and 6.</p>

<p>I have defaulted it to choose the 3rd Sunday of the month given the year.</p>

<pre><code>import datetime as dt

def get_year_day(year,month=8,day_of_week=6,num_in_month=3):
    ## set up possible ranges
    range_1 = 7*(num_in_month-1)+1
    range_2 = 7*num_in_month+1
    ## loop through possible range in the year and the month
    for i in range(range_1,range_2):
        date = dt.datetime(year=year,month=month, day=i)
        ## if we have our weekday we can break
        if date.weekday()==day_of_week:
            break
    return date

for i in range(2015,2021):

    print(i,get_year_day(i))

2015 2015-08-16 00:00:00
2016 2016-08-21 00:00:00
2017 2017-08-20 00:00:00
2018 2018-08-19 00:00:00
2019 2019-08-18 00:00:00
2020 2020-08-16 00:00:00

</code></pre>
","4","2020-02-02 13:47:38","0","566","12","2","32","60021927","60022076","<p>My pandas dataframe ""MSYs"" has a ""start_yr"" variable built from a datetime column ""Start Date"" showing the year of someone's start date (note that month and day of ""Start Date"" also vary).</p>

<p><code>start_yr = pd.DatetimeIndex(MSYs['Start Date']).year</code></p>

<p>I want to use start_yr to help me return a datetime date in another column ""Grant Start"" showing the third Sunday in August of that variable year.  I am stumped.</p>
"
"60022164","<p>Although QPainter is used to paint a widget it will not work for this case since it paints the ""MainWindow"" that is below its children as the QLabels. There are at least 2 possible solutions:</p>

<ul>
<li><p>Create a custom QLabel and detect the click and paint the circle,</p></li>
<li><p>Create a QLabel that shows a QPixmap that has the circle and move it based on the mouse information.</p></li>
</ul>

<p>In this case I will implement the second method:</p>

<pre class=""lang-py prettyprint-override""><code>import sys, cv2
from PyQt5.QtWidgets import QMainWindow, QApplication, QLabel
from PyQt5.QtGui import QImage, QPixmap, QPainter, QPen, QFont
from PyQt5.QtCore import QTimer, Qt


class MainWindow(QMainWindow):
    def __init__(self):
        super().__init__()
        self.initUI()

    def initUI(self):
        self.statusBar().showMessage(""Ready"")
        self.setGeometry(50, 50, 800, 600)
        self.setWindowTitle(""Statusbar"")
        self.vidWindow = QLabel(self)
        self.vidWindow.setGeometry(20, 20, 640, 480)
        self.maskWindow = QLabel(self)
        self.maskWindow.setGeometry(20, 20, 640, 480)
        self.maskWindow.setStyleSheet(""background-color: rgba(0,0,0,0%)"")
        font = QFont()
        font.setPointSize(18)
        font.setBold(True)
        font.setWeight(75)
        self.maskWindow.setFont(font)
        self.maskWindow.setText(""Message is on the mask Qlabel object"")
        self.msgLabel = QLabel(self)
        self.msgLabel.setGeometry(675, 300, 100, 20)

        self.marker_label = QLabel(self)

        pixmap = QPixmap(100, 100)
        pixmap.fill(Qt.transparent)

        painter = QPainter(pixmap)
        painter.setPen(QPen(Qt.green, 4, Qt.SolidLine))
        painter.drawEllipse(pixmap.rect().adjusted(4, 4, -4, -4))
        painter.end()

        self.marker_label.setPixmap(pixmap)
        self.marker_label.adjustSize()
        self.marker_label.hide()
        self.marker_label.raise_()

        self.cap = cv2.VideoCapture(0)
        self.timer = QTimer()
        self.frame_rate = 5
        self.show()
        self.start()

    def nextFrameSlot(self):
        ret, frame = self.cap.read()
        if ret == True:
            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            img = QImage(frame, frame.shape[1], frame.shape[0], QImage.Format_RGB888)
            img = img.scaled(640, 480, Qt.KeepAspectRatio)
            pix = QPixmap.fromImage(img)
            self.vidWindow.setPixmap(pix)

    def mousePressEvent(self, event):
        self.msgLabel.setText(""Mouse Clicked!"")
        if self.vidWindow.rect().contains(event.pos()):
            self.marker_label.move(event.pos() - self.marker_label.rect().center())
            self.marker_label.show()
        super().mousePressEvent(event)

    def start(self):
        rate = int(1000.0 / self.frame_rate)
        self.timer.setTimerType(Qt.PreciseTimer)
        self.timer.timeout.connect(self.nextFrameSlot)
        self.timer.start(rate)

    def closeEvent(self, event):
        if self.cap.isOpened():
            self.cap.release()
        super().closeEvent(event)


if __name__ == ""__main__"":
    app = QApplication(sys.argv)
    ex = MainWindow()
    sys.exit(app.exec_())
</code></pre>
","1","","3","184341","3940","32065","41961","60021937","60022164","<p>I want to draw a circle that displays over a video at the cursor location when pressing the mouse.  The video is playing in a QLabel object that is in a MainWindow.  I’m using OpenCV to read frames from the webcam at 10 fps.  I’m converting the frames to QPixmap and displaying them in the QLabel object (<code>self.vidWindow</code>).</p>

<p>In the code below, the circle is painted immediately when the MainWindow is launched (not what I want) and is then covered up by the video stream.  Text displays in the mask Qlabel object and a message is printed in the MainWindow when the mouse button is pressed.</p>

<p>Can I draw a circle in a QLabel object?  If so, should I use the mask QLabel object or is there a way to overlay directly over the video in the <code>self.vidWindow</code>?</p>

<p>In the minimalized version of the code, the video displays, but an error is triggered when I try to draw the ellipse.</p>

<pre><code>import sys, cv2
from PyQt5.QtWidgets import QMainWindow, QApplication, QLabel
from PyQt5.QtGui import QImage, QPixmap, QPainter, QPen, QFont
from PyQt5.QtCore import QTimer, Qt, QCoreApplication

class MainWindow(QMainWindow):

    def __init__(self):
        super().__init__()        
        self.initUI()        

    def initUI(self):                       
        self.statusBar().showMessage('Ready')        
        self.setGeometry(50, 50, 800, 600)
        self.setWindowTitle('Statusbar')
        self.vidWindow = QLabel(self)
        self.vidWindow.setGeometry(20, 20, 640, 480)
        self.maskWindow = QLabel(self)
        self.maskWindow.setGeometry(20, 20, 640, 480)
        self.maskWindow.setStyleSheet('background-color: rgba(0,0,0,0%)')
        font = QFont()
        font.setPointSize(18)
        font.setBold(True)
        font.setWeight(75)
        self.maskWindow.setFont(font)
        self.maskWindow.setText('Message is on the mask Qlabel object')
        self.msgLabel = QLabel(self)
        self.msgLabel.setGeometry(675, 300, 100, 20)
        self.cap = cv2.VideoCapture(0)
        self.pix = QImage()
        self.timer = QTimer()
        self.frame_rate = 5
        self.show()
        self.start()

    def nextFrameSlot(self):
        ret, frame = self.cap.read()
        if ret == True:
            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            img = QImage(frame,frame.shape[1], frame.shape[0], QImage.Format_RGB888)
            img = img.scaled(640, 480, Qt.KeepAspectRatio)
            self.pix = QPixmap.fromImage(img)
            self.vidWindow.setPixmap(self.pix)

    def mousePressEvent(self, QMouseEvent):        
        self.msgLabel.setText('Mouse Clicked!')

    def paintEvent(self, QMouseEvent):
        e = QMouseEvent
        painter = QPainter(self)
        painter.setPen(QPen(Qt.green,  4, Qt.SolidLine))
        painter.drawEllipse(e.x(), e.y(), 100)

    def start(self):
        rate = int(1000.0 / self.frame_rate)        
        self.timer.setTimerType(Qt.PreciseTimer)
        self.timer.timeout.connect(self.nextFrameSlot)
        self.timer.start(rate)

    def closeEvent(self, event):
        if self.cap.isOpened():
            self.cap.release()
            self.vidWindow.clear()        
        QCoreApplication.quit()

if __name__ == '__main__':    
    app = QApplication(sys.argv)
    ex = MainWindow()
sys.exit(app.exec_())
</code></pre>
"
"60034821","<p>That's a known PyCharm issue, please vote for the relevant ticket in the IDE's bug tracker <a href=""https://youtrack.jetbrains.com/issue/PY-39526"" rel=""nofollow noreferrer"">https://youtrack.jetbrains.com/issue/PY-39526</a></p>
","1","","3","4976","1118","77","415","60021944","60034821","<p><a href=""https://i.stack.imgur.com/jRXlj.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/jRXlj.png"" alt=""enter image description here""></a></p>

<p>So console is showing the correct precision for integers (no decimals), but SciView is not. </p>

<p>Is there a setting I can change? Because it is highly confusing when you're working with both integer columns and float columns.</p>
"
"60022005","<p>You can use a list comprehension :</p>

<pre><code>x = [item for item in x if item[1] != 6]
</code></pre>
","0","","1","904","133","2","157","60021978","60022005","<p>So if I were to have a list:</p>

<pre><code>x = [(1,3.),(2,4.),(5,6), (6,6.)]
</code></pre>

<p>how would I be able to remove the ones that have 6 as it's second(or first if in indexing terms) term? It would look like:</p>

<pre><code>x = [(1,3.),(2,4.)]
</code></pre>

<p>The code I have tried always gave me the Errors:</p>

<pre><code>TypeError: 'float' object is not subscriptable
</code></pre>

<p>or </p>

<pre><code>TypeError: 'int' object is not subscriptable
</code></pre>
"
"60022125","<p>Since the temperature can be between 25 and 40 and out of range we probably need to calculate the duration of different intervals, so I use <a href=""https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.groupby.html"" rel=""nofollow noreferrer""><code>DataFrame.groupby</code></a> here</p>

<pre><code>l=25
h = 40
measure_range = df['Temperature'].between(l,h)
df_range = df.loc[measure_range]
groups = (~measure_range).cumsum()
intervals_df = (pd.to_datetime(df_range['Time'].astype(str))
                  .groupby(groups)
                  .agg(['first','last'])
                  .reset_index(drop=True)
                  .assign(Total_time=lambda x: x.diff(axis =1).iloc[:,-1],
                          first = lambda x: x['first'].dt.time,
                          last = lambda x: x['last'].dt.time)
                  )
print(intervals_df)
      first      last Total_time
0  09:13:00  09:13:03   00:00:03
</code></pre>

<p>in this way a row is generated in the dataframe for each time interval in which the temperature is between <code>l</code> and <code>h</code> continuously.</p>
","0","2020-02-02 00:03:17","2","26109","745","224","1510","60022040","60022125","<p>I have dataset <code>df</code> as below:</p>

<pre><code>
Time    Temperature
17:29:33    18
8:23:04     18.5
8:23:04     19
9:12:57     19
9:12:57     20
9:12:58     20
9:12:58     21
9:12:59     21
9:12:59     23
9:13:00     23
9:13:00     25
9:13:01     25
9:13:01     27
9:13:02     27
9:13:02     28
9:13:03     28
</code></pre>

<p>which constantly records temperature data whenever there is a temperature change that is greater than 0.5°C.</p>

<p>I want to calculate the total time duration where the temperature is between 25°C-40°C <strong>(ie. if the spikes exceed 40°C, the corresponding time will not be taken into account)</strong>. How can I do this in Python? </p>

<p>Edited:
Below is a plot for better illustration of the dataset. 
<a href=""https://i.stack.imgur.com/yPu0p.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/yPu0p.png"" alt=""enter image description here""></a></p>

<p>Thanks.</p>
"
"60022452","<p>Make sure the time column is in the right format.</p>

<pre><code>df['time'] = pd.to_timedelta(df['time'],unit='s')
</code></pre>

<p>Get the time when temp reaches 40. (Tail gives you the most recent temp. You can use head() if required). Reset index to get the diff later.</p>

<pre><code>temp_40 = df[df['temp'] == 40]['time'].tail(1)
temp_40 = temp_40.reset_index(drop = True)
</code></pre>

<p>Similarly, get the time when the temp reached 25.</p>

<pre><code>temp_25 = df[df['temp'] == 25]['time'].tail(1)
temp_25 = temp_25.reset_index(drop = True)
</code></pre>

<p>Now get the diff</p>

<pre><code>temp_40 - temp_25
</code></pre>
","3","","1","31","13","0","5","60022040","60022125","<p>I have dataset <code>df</code> as below:</p>

<pre><code>
Time    Temperature
17:29:33    18
8:23:04     18.5
8:23:04     19
9:12:57     19
9:12:57     20
9:12:58     20
9:12:58     21
9:12:59     21
9:12:59     23
9:13:00     23
9:13:00     25
9:13:01     25
9:13:01     27
9:13:02     27
9:13:02     28
9:13:03     28
</code></pre>

<p>which constantly records temperature data whenever there is a temperature change that is greater than 0.5°C.</p>

<p>I want to calculate the total time duration where the temperature is between 25°C-40°C <strong>(ie. if the spikes exceed 40°C, the corresponding time will not be taken into account)</strong>. How can I do this in Python? </p>

<p>Edited:
Below is a plot for better illustration of the dataset. 
<a href=""https://i.stack.imgur.com/yPu0p.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/yPu0p.png"" alt=""enter image description here""></a></p>

<p>Thanks.</p>
"
"60022897","<p>Do it step by step , <code>numpy.ptp</code> is a way to calculate the max and min different from <code>numpy</code></p>

<pre><code>df.Time=pd.Timedelta(df.Time)

s = df.Temperature.between(25,40)
out = df[s].groupby((~s).cumsum()).Time.agg(['min', 'max', np.ptp])
                 min      max      ptp
Temperature                           
10          09:13:00 09:13:03 00:00:03
</code></pre>
","1","","2","252249","5881","962","22297","60022040","60022125","<p>I have dataset <code>df</code> as below:</p>

<pre><code>
Time    Temperature
17:29:33    18
8:23:04     18.5
8:23:04     19
9:12:57     19
9:12:57     20
9:12:58     20
9:12:58     21
9:12:59     21
9:12:59     23
9:13:00     23
9:13:00     25
9:13:01     25
9:13:01     27
9:13:02     27
9:13:02     28
9:13:03     28
</code></pre>

<p>which constantly records temperature data whenever there is a temperature change that is greater than 0.5°C.</p>

<p>I want to calculate the total time duration where the temperature is between 25°C-40°C <strong>(ie. if the spikes exceed 40°C, the corresponding time will not be taken into account)</strong>. How can I do this in Python? </p>

<p>Edited:
Below is a plot for better illustration of the dataset. 
<a href=""https://i.stack.imgur.com/yPu0p.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/yPu0p.png"" alt=""enter image description here""></a></p>

<p>Thanks.</p>
"
"60022202","<p>Try:</p>

<pre><code>df.groupby(['Gene name','Level'], as_index=False)['Cell type'].agg(', '.join)
</code></pre>

<p>Output:</p>

<pre><code>|    | Gene name   | Level        | Cell type                                                                                                       |
|---:|:------------|:-------------|:----------------------------------------------------------------------------------------------------------------|
|  0 | CD99        | High         | hematopoietic cells                                                                                             |
|  1 | CD99        | Low          | adipocytes                                                                                                      |
|  2 | CD99        | Medium       | glandular cells                                                                                                 |
|  3 | CD99        | Not detected | glandular cells     ,  lymphoid tissue     ,  adipocytes                                                        |
|  4 | ENPP4       | High         | glandular cells                                                                                                 |
|  5 | ENPP4       | Low          | adipocytes          ,  lymphoid tissue                                                                          |
|  6 | ENPP4       | Medium       | glandular cells     ,  hematopoietic cells                                                                      |
|  7 | M6PR        | High         | adipocytes          ,  glandular cells     ,  glandular cells     ,  lymphoid tissue     ,  hematopoietic cells |
</code></pre>

<p>Update added per comments below:</p>

<pre><code>(df.groupby(['Gene name','Level'], as_index=False)['Cell type']
   .agg(','.join).set_index(['Gene name','Level'])['Cell type']
   .unstack().reset_index())
</code></pre>

<p>Output:</p>

<pre><code>| Gene name   |  High                                                                                                           |  Low                                   |  Medium                                    |  Not detected                                            |
|:------------|:----------------------------------------------------------------------------------------------------------------|:---------------------------------------|:-------------------------------------------|:---------------------------------------------------------|
| CD99        | hematopoietic cells                                                                                             | adipocytes                             | glandular cells                            | glandular cells     ,  lymphoid tissue     ,  adipocytes |
| ENPP4       | glandular cells                                                                                                 | adipocytes          ,  lymphoid tissue | glandular cells     ,  hematopoietic cells | nan                                                      |
| M6PR        | adipocytes          ,  glandular cells     ,  glandular cells     ,  lymphoid tissue     ,  hematopoietic cells | nan                                    | nan                                        | nan                                                      |
</code></pre>
","8","2020-02-03 17:42:01","3","111735","6882","268","5246","60022107","60022202","<p>I have this dataframe(df), that looks like </p>

<pre><code>+-----------------+-----------+----------------+---------------------+--------------+-------------+
|      Gene       | Gene name |     Tissue     |      Cell type      |    Level     | Reliability |
+-----------------+-----------+----------------+---------------------+--------------+-------------+
| ENSG00000001561 | ENPP4     | adipose tissue | adipocytes          | Low          | Approved    |
| ENSG00000001561 | ENPP4     | adrenal gland  | glandular cells     | High         | Approved    |
| ENSG00000001561 | ENPP4     | appendix       | glandular cells     | Medium       | Approved    |
| ENSG00000001561 | ENPP4     | appendix       | lymphoid tissue     | Low          | Approved    |
| ENSG00000001561 | ENPP4     | bone marrow    | hematopoietic cells | Medium       | Approved    |
| ENSG00000002586 | CD99      | adipose tissue | adipocytes          | Low          | Supported   |
| ENSG00000002586 | CD99      | adrenal gland  | glandular cells     | Medium       | Supported   |
| ENSG00000002586 | CD99      | appendix       | glandular cells     | Not detected | Supported   |
| ENSG00000002586 | CD99      | appendix       | lymphoid tissue     | Not detected | Supported   |
| ENSG00000002586 | CD99      | bone marrow    | hematopoietic cells | High         | Supported   |
| ENSG00000002586 | CD99      | breast         | adipocytes          | Not detected | Supported   |
| ENSG00000003056 | M6PR      | adipose tissue | adipocytes          | High         | Approved    |
| ENSG00000003056 | M6PR      | adrenal gland  | glandular cells     | High         | Approved    |
| ENSG00000003056 | M6PR      | appendix       | glandular cells     | High         | Approved    |
| ENSG00000003056 | M6PR      | appendix       | lymphoid tissue     | High         | Approved    |
| ENSG00000003056 | M6PR      | bone marrow    | hematopoietic cells | High         | Approved    |
+-----------------+-----------+----------------+---------------------+--------------+-------------+
</code></pre>

<p>Expected output:</p>

<pre><code>
+-----------+--------+-------------------------------+
| Gene name | Level  |            Tissue             |
+-----------+--------+-------------------------------+
| ENPP4     | Low    | adipose tissue, appendix      |
| ENPP4     | High   | adrenal gland, bronchus       |
| ENPP4     | Medium | appendix, breast, bone marrow |
| CD99      | Low    | adipose tissue, appendix      |
| CD99      | High   | bone marrow                   |
| CD99      | Medium | adrenal gland                 |
| ...       | ...    | ...                           |
+-----------+--------+-------------------------------+
</code></pre>

<p>code used (took help from <a href=""https://stackoverflow.com/questions/48569166/multiple-if-else-conditions-in-pandas-dataframe-and-derive-multiple-columns/48569899"">multiple if else conditions in pandas dataframe and derive multiple columns</a>):</p>

<pre><code>def text_df(df):
    if (df[df['Level'].str.match('High')]):
        return (df.assign(Level='High') + df['Tissue'].astype(str))
    elif (df[df['Level'].str.match('Medium')]):
        return (df.assign(Level='Medium') + df['Tissue'].astype(str))
    elif (df[df['Level'].str.match('Low')]):
        return (df.assign(Level='Low') + df['Tissue'].astype(str))

df = df.apply(text_df, axis = 1)
</code></pre>

<p>Error: <code>KeyError: ('Level', 'occurred at index 172')</code> I can't understand what am I doing wrong. any suggestion?</p>
"
"60022212","<p>In your function, you're returning prime_factors.</p>

<p>But in your test, you're not using that return value.</p>

<p>Your prime_factor value in your test is never assigned, so it remains an empty list.</p>
","4","","2","640","117","5","68","60022139","60022212","<p>I need a little help guys, I'm doing a project for school and i'm running in to an issue with my code. Not sure where i'm going wrong. Here is a little bit about the project.</p>

<p>Requirements:
Write a function called generate_prime_factors in the module prime.py. This function will accept an integer as an argument, and return a list of integers.</p>

<p>Step 1:
Write a test that asserts that when generate_prime_factors is called with a data type that is not an integer (e.g. a string or float), a ValueError is raised. Write the appropriate code to solve this and then commit the changes.</p>

<p>Step 2:
Write a test that asserts that when generate_prime_factors is called with 1, an empty list is returned. Solve &amp; commit.</p>

<p>Step 3:
Write a test that asserts that when generate_prime_factors is called with 2, the list [2] is returned. Solve &amp; commit.</p>

<p>etc.....</p>

<p>this is my main prime.py:</p>

<pre><code>    """"""
    generate prime factors fuctions
    """"""
    if user_input == 1:
        return prime_factors
    if user_input == 2:
        return prime_factors
    if isinstance(user_input, str):
        raise ValueError
    return prime_factors
</code></pre>

<p>and here is my test python script:</p>

<pre><code>import pytest
from prime import generate_prime_factors # Imports the prime module (prime.py)

def test_not_integer():
    """"""
    A test that asserts that when `generate_prime_factors` is called with a
    data type that is not an integer (e.g. a string or float), a ValueError is
    raised.
    """"""
    prime_factors = []
    with pytest.raises(ValueError):
        generate_prime_factors('Hello World', prime_factors)

def test_generate_prime_factor_1():
    """"""
    A test that asserts that when `generate_prime_factors` is called with
    `1`, an empty list is returned.
    """"""
    prime_factors = []
    generate_prime_factors(1, prime_factors)
    assert prime_factors == []

def test_generate_prime_factor_2():
    """"""
    a test that asserts that when `generate_prime_factors` is called with
    `2`, the list `[2]` is returned.
    """"""
    prime_factors = []
    generate_prime_factors(2, prime_factors)
    assert prime_factors == [2]
</code></pre>

<p><a href=""https://i.stack.imgur.com/jAYjP.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/jAYjP.png"" alt=""enter image description here""></a></p>

<p>as you can see from the image. I keep getting pytest error, seems to be coming from the def test_generate_prime_factors_2(): method as you can see from the image two pass and 1 fail</p>
"
"60022169","<p>Filter out character '-'-containing lines from your read-in lines:</p>

<pre><code>filtered_lines = [x for x in content if '-' not in x]
</code></pre>
","0","","4","6047","467","19","531","60022157","60022273","<p>I am trying to figure out how to write a function that opens a file and reads it, however I need it to ignore any lines that contain the character '-' </p>

<p>This is what I have so far:</p>

<pre><code>def read_from_file(filename):
    with open('filename', 'r') as file:
        content = file.readlines()
</code></pre>

<p>Any help would be appreciated</p>
"
"60022210","<p>I'd filter out while reading the file, not collect the unwanted lines in the first place.</p>

<pre><code>def read_from_file(filename):
    with open(filename) as file:
        content = [line for line in file if '-' not in line]
</code></pre>

<p>Also note that the <code>'filename'</code> in your <code>open('filename', 'r')</code> is wrong and that the <code>'r'</code> is unnecessary, so I fixed/removed that.</p>
","0","2020-02-02 00:28:06","2","5574","625","2339","1000","60022157","60022273","<p>I am trying to figure out how to write a function that opens a file and reads it, however I need it to ignore any lines that contain the character '-' </p>

<p>This is what I have so far:</p>

<pre><code>def read_from_file(filename):
    with open('filename', 'r') as file:
        content = file.readlines()
</code></pre>

<p>Any help would be appreciated</p>
"
"60022273","<p>Gwang-Jin Kim and Heap Overflow answers are both 100% right, but, I always feel that using the tools that Python give you to be a plus one, so here is a solution using the built-in <a href=""https://docs.python.org/3/library/functions.html#filter"" rel=""nofollow noreferrer""><code>filter()</code></a> function:</p>

<pre class=""lang-py prettyprint-override""><code>list(filter(lambda line: ""-"" not in line, file.splitlines()))
</code></pre>

<hr>

<pre class=""lang-py prettyprint-override""><code>def read_from_file(filename):
    with open(filename, ""r"") as file:
        content = filter(lambda line: ""-"" not in line, file.readlines())

    return list(content)
</code></pre>

<hr>

<p>Here is a more verbose, yet more efficient solution:</p>

<pre><code>def read_from_file(filename):

    content = []
    with open(filename, ""r"") as file:
        for line in file:
            if ""-"" not in line:
                content.append(line)

    return content
</code></pre>
","4","2020-02-02 00:32:34","1","4588","211","39","464","60022157","60022273","<p>I am trying to figure out how to write a function that opens a file and reads it, however I need it to ignore any lines that contain the character '-' </p>

<p>This is what I have so far:</p>

<pre><code>def read_from_file(filename):
    with open('filename', 'r') as file:
        content = file.readlines()
</code></pre>

<p>Any help would be appreciated</p>
"