Id,Body,CommentCount,LastEditDate,Score,Reputation,UpVotes,DownVotes,Views,QId,QAcceptedAnswerId,QBody
"60473588","<blockquote>
  <p>[...] after dealing with all mobs in level 2 it won't load level 3. instead it restarts in level 2. I think my mistake is in the update section of the code, [...]</p>
</blockquote>

<p>Of course. See the following liens of code:</p>

<blockquote>
  <pre class=""lang-py prettyprint-override""><code>class Game:
   # [...]

   def update(self):
       # Game over?
       if len(self.mobs) == 0:
           self.new_2()
           if len(self.mobs) == 0:
               self.new_3()
</code></pre>
</blockquote>

<p><code>self.new_3()</code> will never be invoked. If <code>len(self.mobs) == 0</code> is fulfilled, the <code>self.new_2()</code> is executed and <code>self.mobs</code> is initialized.</p>

<p>Add the number of the level (<code>self.current_level</code>) to the class <code>Game</code>. Increment the  level in <code>update</code> and invoke either <code>new_2</code> or <code>new_3</code> dependent on <code>self.current_level</code>. e.g.:</p>

<pre class=""lang-py prettyprint-override""><code>class Game:
    def __init__(self):
        # [...]
        self.current_level = 1

    # [...]

    def update(self):
        # Game over?
        if len(self.mobs) == 0:
            self.current_level += 1
            if self.current_level == 2:
                self.new_2()
            else:
                self.new_3()
</code></pre>

<p>With this approach it is easy to add and load further levels.</p>
","3","","0","136140","16645","626","8521","60470790","60473588","<p>I'm working on a top down tile based game. i've already created 3 levels for the game but now i have no idea how to load the new levels within the game. The game starts in level 1 and after dealing with all the mobs it starts level 2, but after dealing with all mobs in level 2 it won't load level 3. instead it restarts in level 2. I think my mistake is in the update section of the code, but since i'm still very inexperienced it might be more than just ""one"" mistake within in that code. 
I'd be glad if anyone could help me</p>

<p>here's my main.py of the code:</p>

<pre><code>import pygame as pg
import sys
from os import path
from settings import *
from sprites import *
from tilemap import *

# HUD functions
def draw_player_health(surf, x, y, pct):
    if pct &lt; 0:
        pct = 0
    BAR_LENGTH = 100
    BAR_HEIGHT = 20
    fill = pct * BAR_LENGTH
    outline_rect = pg.Rect(x, y, BAR_LENGTH, BAR_HEIGHT)
    fill_rect = pg.Rect(x, y, fill, BAR_HEIGHT)
    if pct &gt; 0.6:
        col = GREEN
    elif pct &gt; 0.3:
        col = YELLOW
    else:
        col = RED
    pg.draw.rect(surf, col, fill_rect)
    pg.draw.rect(surf, BLACK, outline_rect, 2)

class Game:
    def __init__(self):
        pg.mixer.pre_init(44100, -16, 2, 2048)
        pg.init()
        self.screen = pg.display.set_mode((WIDTH, HEIGHT))
        pg.display.set_caption(TITLE)
        self.clock = pg.time.Clock()
        self.load_data()
        self.level = 0

    def draw_text(self, text, font_name, size, color, x, y, align=""nw""):
        font = pg.font.Font(font_name, size)
        text_surface = font.render(text, True, color)
        text_rect = text_surface.get_rect()
        if align == ""nw"":
            text_rect.topleft = (x, y)
        if align == ""ne"":
            text_rect.topright = (x, y)
        if align == ""sw"":
            text_rect.bottomleft = (x, y)
        if align == ""se"":
            text_rect.bottomright = (x, y)
        if align == ""n"":
            text_rect.midtop = (x, y)
        if align == ""s"":
            text_rect.midbottom = (x, y)
        if align == ""e"":
            text_rect.midright = (x, y)
        if align == ""w"":
            text_rect.midleft = (x, y)
        if align == ""center"":
            text_rect.center = (x, y)
        self.screen.blit(text_surface, text_rect)

    def load_data(self):
        game_folder = path.dirname(__file__)
        img_folder = path.join(game_folder, 'img')
        self.map_folder = path.join(game_folder, 'maps')
        sfx_folder = path.join(game_folder, ""sfx"")
        music_folder = path.join(game_folder, ""music"")
        self.title_font = path.join(img_folder, ""ZOMBIE.TTF"")
        self.hud_font = path.join(img_folder, ""Impacted2.0.ttf"")
        self.dim_screen = pg.Surface(self.screen.get_size()).convert_alpha()
        self.dim_screen.fill((0, 0, 0, 180))
        self.player_img = pg.image.load(path.join(img_folder, PLAYER_IMG)).convert_alpha()
        self.mob_img = pg.image.load(path.join(img_folder, MOB_IMG)).convert_alpha()
        self.wall_img = pg.image.load(path.join(img_folder, WALL_IMG)).convert_alpha()
        self.wall_img = pg.transform.scale(self.wall_img, (TILESIZE, TILESIZE))
        self.bullet_images = {}
        self.bullet_images[""lg""] = pg.image.load(path.join(img_folder, BULLET_IMG)).convert_alpha()
        self.bullet_images[""sm""] = pg.transform.scale(self.bullet_images[""lg""], (10, 10))
        self.splat = pg.image.load(path.join(img_folder, SPLAT)).convert_alpha()
        self.splat = pg.transform.scale(self.splat, (64, 64))
        self.gun_flashes = []
        for img in MUZZLE_FLASHES:
            self.gun_flashes.append(pg.image.load(path.join(img_folder, img)).convert_alpha())
        self.item_images = {}
        for item in ITEM_IMAGES:
            self.item_images[item] = pg.image.load(path.join(img_folder, ITEM_IMAGES[item])).convert_alpha()
        # lighting effect
        self.fog = pg.Surface((WIDTH, HEIGHT))
        self.fog.fill(NIGHT_COLOR)
        self.light_mask = pg.image.load(path.join(img_folder, LIGHT_MASK)).convert_alpha()
        self.light_mask = pg.transform.scale(self.light_mask, LIGHT_RADIUS)
        self.light_rect = self.light_mask.get_rect()
        # SOUND LOADING
        pg.mixer.music.load(path.join(music_folder, BG_MUSIC))
        self.effects_sounds = {}
        for type in EFFECTS_SOUNDS:
            self.effects_sounds[type] = pg.mixer.Sound(path.join(sfx_folder, EFFECTS_SOUNDS[type]))
        self.weapon_sounds = {}
        for weapon in WEAPON_SOUNDS:
            self.weapon_sounds[weapon] = []
            for sfx in WEAPON_SOUNDS[weapon]:
                s = pg.mixer.Sound(path.join(sfx_folder, sfx))
                s.set_volume(0.2)
                self.weapon_sounds[weapon].append(s)
        self.zombie_moan_sounds = []
        for sfx in ZOMBIE_MOAN_SOUNDS:
            s = pg.mixer.Sound(path.join(sfx_folder, sfx))
            s.set_volume(0.2)
            self.zombie_moan_sounds.append(s)
        self.player_hit_sounds = []
        for sfx in PLAYER_HIT_SOUNDS:
            self.player_hit_sounds.append(pg.mixer.Sound(path.join(sfx_folder, sfx)))
        self.zombie_hit_sounds = []
        for sfx in ZOMBIE_HIT_SOUNDS:
            self.zombie_hit_sounds.append(pg.mixer.Sound(path.join(sfx_folder, sfx)))



    def new(self):
        # initialize all variables and do all the setup for a new game
        self.all_sprites = pg.sprite.LayeredUpdates()
        self.walls = pg.sprite.Group()
        self.bullets = pg.sprite.Group()
        self.mobs = pg.sprite.Group()
        self.items = pg.sprite.Group()
        self.map = Tiled_Map(path.join(self.map_folder, 'level1.tmx'))
        self.map_image = self.map.make_map()
        self.map_rect = self.map_image.get_rect()
        # for row, tiles in enumerate(self.map.data):
        #   for col, tile in enumerate(tiles):
        #        if tile == '1':
        #            Wall(self, col, row)
        #        if tile == 'M':
        #            Mob(self, col, row)
        #        if tile == 'P':
        #            self.player = Player(self, col, row)
        for tile_object in self.map.tmxdata.objects:
            obj_center = vec(tile_object.x + tile_object.width / 2, tile_object.y + tile_object.height / 2)
            if tile_object.name == ""player"":
                self.player = Player(self, obj_center.x, obj_center.y)
            if tile_object.name == ""zombie"":
               Mob(self, obj_center.x, obj_center.y)
            if tile_object.name == ""wall"":
                Obstacle(self, tile_object.x, tile_object.y, tile_object.width, tile_object.height)
            if tile_object.name in [""health"", ""shotgun"", ""m_gun"", ""desert_eagle""]:
                Item(self, obj_center, tile_object.name)
        self.camera = Camera(self.map.width, self.map.height)
        self.draw_debug = False
        self.paused = False
        self.night = False
        self.effects_sounds[""level_start""].play()

    def new_2(self):
        # initialize all variables and do all the setup for a new game
        self.all_sprites = pg.sprite.LayeredUpdates()
        self.walls = pg.sprite.Group()
        self.bullets = pg.sprite.Group()
        self.mobs = pg.sprite.Group()
        self.items = pg.sprite.Group()
        self.map = Tiled_Map(path.join(self.map_folder, 'level2.tmx'))
        self.map_image = self.map.make_map()
        self.map_rect = self.map_image.get_rect()
        # for row, tiles in enumerate(self.map.data):
        #   for col, tile in enumerate(tiles):
        #        if tile == '1':
        #            Wall(self, col, row)
        #        if tile == 'M':
        #            Mob(self, col, row)
        #        if tile == 'P':
        #            self.player = Player(self, col, row)
        for tile_object in self.map.tmxdata.objects:
            obj_center = vec(tile_object.x + tile_object.width / 2, tile_object.y + tile_object.height / 2)
            if tile_object.name == ""player"":
                self.player = Player(self, obj_center.x, obj_center.y)
            if tile_object.name == ""zombie"":
               Mob(self, obj_center.x, obj_center.y)
            if tile_object.name == ""wall"":
                Obstacle(self, tile_object.x, tile_object.y, tile_object.width, tile_object.height)
            if tile_object.name in [""health"", ""shotgun"", ""m_gun"", ""desert_eagle""]:
                Item(self, obj_center, tile_object.name)
        self.camera = Camera(self.map.width, self.map.height)
        self.draw_debug = False
        self.paused = False
        self.night = False
        self.effects_sounds[""level_start""].play()

    def new_3(self):
        # initialize all variables and do all the setup for a new game
        self.all_sprites = pg.sprite.LayeredUpdates()
        self.walls = pg.sprite.Group()
        self.bullets = pg.sprite.Group()
        self.mobs = pg.sprite.Group()
        self.items = pg.sprite.Group()
        self.map = Tiled_Map(path.join(self.map_folder, 'level3.tmx'))
        self.map_image = self.map.make_map()
        self.map_rect = self.map_image.get_rect()
        # for row, tiles in enumerate(self.map.data):
        #   for col, tile in enumerate(tiles):
        #        if tile == '1':
        #            Wall(self, col, row)
        #        if tile == 'M':
        #            Mob(self, col, row)
        #        if tile == 'P':
        #            self.player = Player(self, col, row)
        for tile_object in self.map.tmxdata.objects:
            obj_center = vec(tile_object.x + tile_object.width / 2, tile_object.y + tile_object.height / 2)
            if tile_object.name == ""player"":
                self.player = Player(self, obj_center.x, obj_center.y)
            if tile_object.name == ""zombie"":
               Mob(self, obj_center.x, obj_center.y)
            if tile_object.name == ""wall"":
                Obstacle(self, tile_object.x, tile_object.y, tile_object.width, tile_object.height)
            if tile_object.name in [""health"", ""shotgun"", ""m_gun"", ""desert_eagle""]:
                Item(self, obj_center, tile_object.name)
        self.camera = Camera(self.map.width, self.map.height)
        self.draw_debug = False
        self.paused = False
        self.night = False
        self.effects_sounds[""level_start""].play()

    def run(self):
        # game loop - set self.playing = False to end the game
        self.playing = True
        pg.mixer.music.play(loops=-1)
        while self.playing:
            self.dt = self.clock.tick(FPS) / 1000.0  # fix for Python 2.x
            self.events()
            if not self.paused:
                self.update()
            self.draw()

    def quit(self):
        pg.quit()
        sys.exit()

    def update(self):
        # Game over?
        if len(self.mobs) == 0:
            self.new_2()
            if len(self.mobs) == 0:
                self.new_3()
        # update portion of the game loop
        self.all_sprites.update()
        self.camera.update(self.player)
        # player hits item
        hits = pg.sprite.spritecollide(self.player, self.items, False, collide_hit_rect)
        for hit in hits:
            if hit.type == ""health"" and self.player.health &lt; PLAYER_HEALTH:
                hit.kill()
                self.effects_sounds[""health_up""].play()
                self.player.add_health(HEALTH_PACK_AMOUNT)
            if hit.type == ""shotgun"":
                hit.kill()
                self.player.weapon = ""shotgun""
                self.effects_sounds[""gun_pickup""].play()
            if hit.type == ""m_gun"":
                hit.kill()
                self.player.weapon = ""m_gun""
                self.effects_sounds[""gun_pickup""].play()
            if hit.type == ""desert_eagle"":
                hit.kill()
                self.player.weapon = ""desert_eagle""
                self.effects_sounds[""gun_pickup""].play()

        # mobs hit player
        hits = pg.sprite.spritecollide(self.player, self.mobs, False, collide_hit_rect)
        for hit in hits:
            if random() &lt; 0.7:
                choice(self.player_hit_sounds).play()
            self.player.health -= MOB_DAMAGE
            hit.vel = vec(0, 0)
            if self.player.health &lt;= 0:
                self.playing = False
            if hits:
                self.player.hit()
                self.player.pos += vec(MOB_KNOCKBACK, 0).rotate(-hits[0].rot)
        # bullet hit mobs
        hits = pg.sprite.groupcollide(self.mobs, self.bullets, False, True)
        for mob in hits:
            # hit.health -= WEAPONS[self.player.weapon][""damage""] * len(hits[hit])
            for bullet in hits[mob]:
                mob.health -= bullet.damage
            mob.vel = vec(0, 0)

    def draw_grid(self):
        for x in range(0, WIDTH, TILESIZE):
            pg.draw.line(self.screen, LIGHTGREY, (x, 0), (x, HEIGHT))
        for y in range(0, HEIGHT, TILESIZE):
            pg.draw.line(self.screen, LIGHTGREY, (0, y), (WIDTH, y))

    def render_fog(self):
        # draw the light mask (gradient) onto the fog image
        self.fog.fill(NIGHT_COLOR)
        self.light_rect.center = self.camera.apply(self.player).center
        self.fog.blit(self.light_mask, self.light_rect)
        self.screen.blit(self.fog, (0, 0), special_flags=pg.BLEND_MULT)

    def draw(self):
        pg.display.set_caption(""{:.2f}"".format(self.clock.get_fps()))
        # self.screen.fill(BGCOLOR)
        self.screen.blit(self.map_image, self.camera.apply_rect(self.map_rect))
        # self.draw_grid()
        for sprite in self.all_sprites:
            if isinstance(sprite, Mob):
                sprite.draw_health()
            self.screen.blit(sprite.image, self.camera.apply(sprite))
            if self.draw_debug:
                pg.draw.rect(self.screen, CYAN, self.camera.apply_rect(sprite.rect), 1)
        if self.draw_debug:
            for wall in self.walls:
                pg.draw.rect(self.screen, CYAN, self.camera.apply_rect(wall.rect), 1)
        # pg.draw.rect(self.screen, WHITE, self.player.hit_rect, 2)
        if self.night:
            self.render_fog()
        # HUD functions
        draw_player_health(self.screen, 10, 10, self.player.health / PLAYER_HEALTH)
        self.draw_text(""Zombies: {}"".format(len(self.mobs)), self.hud_font,
                       30, WHITE, WIDTH - 10, 10, align=""ne"")
        if self.paused:
            self.screen.blit(self.dim_screen, (0, 0))
            self.draw_text(""PAUSED"", self.title_font, 105, RED, WIDTH / 2, HEIGHT / 2, align=""center"")
        pg.display.flip()

    def events(self):
        # catch all events here
        for event in pg.event.get():
            if event.type == pg.QUIT:
                self.quit()
            if event.type == pg.KEYDOWN:
                if event.key == pg.K_ESCAPE:
                    self.quit()
                if event.key == pg.K_h:
                    self.draw_debug = not self.draw_debug
                if event.key == pg.K_p:
                    self.paused = not self.paused
                if event.key == pg.K_n:
                    self.night = not self.night

    def show_start_screen(self):
        pass


    def show_go_screen(self):
        self.screen.fill(BLACK)
        self.draw_text(""GAME OVER"", self.title_font, 100,
                       RED, WIDTH / 2, HEIGHT / 2, align=""center"")
        self.draw_text(""Press a key to start"", self.title_font, 75, WHITE, WIDTH / 2, HEIGHT * 3 / 4, align=""center"")
        pg.display.flip()
        self.wait_for_key()

    def wait_for_key(self):
        pg.event.wait()
        waiting = True
        while waiting:
            self.clock.tick(FPS)
            for event in pg.event.get():
                if event.type == pg.QUIT:
                    waiting = False
                    self.quit()
                if event.type == pg.KEYUP:
                    waiting = False

# create the game object
g = Game()
g.show_start_screen()
while True:
    g.new()
    g.run()
    g.show_go_screen()

</code></pre>
"
"60470950","<p>You have to use <code>self.number</code> to have access to numbers in <code>update</code>. And you should use <code>self</code> instead of <code>number</code> in <code>def update(number)</code></p>

<p>Also to create new list you have to create empty list before <code>for</code>-loop and <code>append(newnum)</code> to this list. And later you can <code>return</code> this list to get it as  <code>b = ...</code></p>

<pre><code>class Fraction():

    def __init__(self):
        shape = int(input(""How many sides does the shape have? : ""))

        if shape &lt;= 0: #doesnt work with negatives?
            print(""Please make a valid choice (positive integers only)"")
            shape = int(input(""How many sides does the shape have? : ""))

        self.numbers = []
        for i in range(shape):
            n = random.randint(1, 100)
            self.numbers.append(n)
        print(""Your numbers are:"", self.numbers)

    def update(self):
        newlist = []

        long = len(self.numbers)
        for i in range(long-1): # it has to be long-1 because later `long-1+1`will give `long` 
            newnum = self.numbers[i] - self.numbers[i+1]
            newlist.append(newnum)

        return newlist

import random

def main():
    a = Fraction()
    b = a.update()
    print(b)
main()
</code></pre>

<hr>

<p><strong>BTW:</strong> it could be good to use <code>input()</code> outside class and run it as <code>Fraction(shape)</code> so it could run with values from <code>input()</code> or file or hardcoded varaible. It is helps to test code again and again with the same values.</p>
","2","","0","91473","3793","3687","13493","60470809","60470950","<p>I's adjusted it to add the self to the update but now I'm having trouble with my main where I'm testing stuff.</p>

<pre><code>from file import Fraction
import random
def main():
    a = Fraction()
    b = a.update()
main()
</code></pre>

<hr>

<p>I'm trying to make this for loop to work, its supposed to subtract the first number of a list by the second, second by the third etc and create a new list with those values. The <code>__init__</code> part works but then the update function is where I run into trouble.</p>

<pre><code>class Fraction():
    def __init__(self):
        shape = int(input(""How many sides does the shape have? : ""))
        if shape &lt;= 0: #doesnt work with negatives?
            print(""Please make a valid choice (positive integers only)"")
            shape = int(input(""How many sides does the shape have? : ""))
        numbers = 0
        print(""Your numbers are: "")
        numbers = []
        for i in range(0,shape):
            n = random.randint(1,100)
            numbers.append(n)
        print(numbers)

    def update(numbers):
        long=len(numbers)
        for i in range(long):
            newnum = numbers[i]-numbers[i+1]

        print(newnum)
</code></pre>
"
"60470978","<p>You can run a subprocess to source the results and print the <code>os.environ</code>  back to the current python process. For example:</p>

<pre><code>os.environ=ast.literal_eval(subprocess.check_output(
  'source credentials.txt &amp;&amp; python -c ""import os;print os.environ""', shell=True)
)
</code></pre>

<p>Answer inspired by <a href=""https://stackoverflow.com/a/7198338/651174"">this answer</a>.</p>
","0","2020-03-01 01:27:17","-1","95528","2897","13","6872","60470924","60471160","<p>I thought of using the following to run a normally-run-as-shell inside python:</p>

<pre><code>x = subprocess.call('source credentials.txt', shell=True)
print os.environ
</code></pre>

<p>However, it seems that the environment doesn't update in the rest of the script. Why not? And is there a way to get over this with using shell (and not python) to update my os vars?</p>
"
"60471160","<p>Take a look at this library:  <a href=""https://pypi.org/project/python-dotenv/"" rel=""nofollow noreferrer"">https://pypi.org/project/python-dotenv/</a> </p>

<p>I've used it before and it's simple and does the job.Instead of 'credentials.txt' you put the key-value pairs in '.env' file and load it during program start using a single 'load' call.</p>

<p>Here is somple code:</p>

<pre><code>import os
from pathlib import Path
from dotenv import load_dotenv, find_dotenv

# write some sample contents in the current dir
Path.cwd().joinpath("".env"").write_text(""USERNAME=My user name\nPASSWORD=MyCust0mS3cr3tPAsw00d"")

# loads from .env file in CWD
load_dotenv(find_dotenv())  

# here is the magic:
print(os.environ[""PASSWORD""])
</code></pre>
","1","2020-03-01 01:25:30","0","427","13","0","32","60470924","60471160","<p>I thought of using the following to run a normally-run-as-shell inside python:</p>

<pre><code>x = subprocess.call('source credentials.txt', shell=True)
print os.environ
</code></pre>

<p>However, it seems that the environment doesn't update in the rest of the script. Why not? And is there a way to get over this with using shell (and not python) to update my os vars?</p>
"
"60477028","<p>The correct answer turned out to be that the name (master) node of the cluster had firewall access to the MongoDB instance, but the other nodes in the cluster did not.  So apparently MongoDB queries are distributed on the cluster as well.  Once I added the slave nodes to the Security Group for the MongoDB server as allowed incoming connections, the cluster mode processing began working.</p>
","0","","0","23","48","0","10","60470949","60477028","<p>I have a PySpark script that reads in a collection from a MongoDB database.  When I run the script in standalone mode it works:</p>

<pre><code>  MONGO_URL = ""mongodb://USER:PASSWORD@HOST:27017/DB_NAME.COLLECTION""
  spark = SparkSession.builder \
            .appName('TestMongoLoad') \
            .config('spark.mongodb.input.uri', MONGO_URL) \
            .getOrCreate()

    df = spark.read.format(""com.mongodb.spark.sql.DefaultSource"").load()


spark-submit \
--master local[*] \
--packages org.mongodb.spark:mongo-spark-connector_2.11:2.4.1 \
load_from_mongo.py 

[SUCCESS]

</code></pre>

<p>When I run the script on the cluster, it fails:</p>

<pre><code>spark-submit \
--master yarn \
--deploy-mode client \
--driver-memory 4g \
--executor-memory 2g \
--executor-cores 3 \
--num-executors 10 \
--packages org.mongodb.spark:mongo-spark-connector_2.11:2.4.1 \
load_from_mongo.py
</code></pre>

<p>The script failes with the following errors:</p>

<pre><code>20/03/01 00:25:59 ERROR TaskSetManager: Task 0 in stage 0.0 failed 4 times; aborting job
Traceback (most recent call last):
  File ""/home/ubuntu/server/load_from_mongo.py"", line 117, in &lt;module&gt;
    main(args)
  File ""/home/ubuntu/server/load_from_mongo.py"", line 94, in main
    keyword_df = getKeywordCorpus(args.begin_dt, args.end_dt)
  File ""/home/ubuntu/server/load_from_mongo.py"", line 74, in getKeywordCorpus
    df = spark.read.format(""com.mongodb.spark.sql.DefaultSource"").load()
  File ""/home/ubuntu/server/spark-2.4.4-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/sql/readwriter.py"", line 172, in load
  File ""/home/ubuntu/server/spark-2.4.4-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py"", line 1257, in __call__
  File ""/home/ubuntu/server/spark-2.4.4-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/sql/utils.py"", line 63, in deco
  File ""/home/ubuntu/server/spark-2.4.4-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/protocol.py"", line 328, in get_return_value
py4j.protocol.Py4JJavaError: An error occurred while calling o45.load.
: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 0.0 failed 4 times, most recent failure: Lost task 0.3 in stage 0.0 (TID 3, ip-172-31-9-94.ec2.internal, executor 5): com.mongodb.MongoTimeoutException: Timed out after 30000 ms while waiting to connect. Client view of cluster state is {type=UNKNOWN, servers=[{address=52.91.254.92:27017, type=UNKNOWN, state=CONNECTING, exception={com.mongodb.MongoSocketOpenException: Exception opening socket}, caused by {java.net.SocketTimeoutException: connect timed out}}]
    at com.mongodb.internal.connection.BaseCluster.getDescription(BaseCluster.java:182)
    at com.mongodb.internal.connection.SingleServerCluster.getDescription(SingleServerCluster.java:41)
    at com.mongodb.client.internal.MongoClientDelegate.getConnectedClusterDescription(MongoClientDelegate.java:136)
    at com.mongodb.client.internal.MongoClientDelegate.createClientSession(MongoClientDelegate.java:94)
    at com.mongodb.client.internal.MongoClientDelegate$DelegateOperationExecutor.getClientSession(MongoClientDelegate.java:249)
    at com.mongodb.client.internal.MongoClientDelegate$DelegateOperationExecutor.execute(MongoClientDelegate.java:172)
    at com.mongodb.client.internal.MongoIterableImpl.execute(MongoIterableImpl.java:132)
    at com.mongodb.client.internal.MongoIterableImpl.iterator(MongoIterableImpl.java:86)
    at com.mongodb.spark.rdd.MongoRDD.getCursor(MongoRDD.scala:193)
    at com.mongodb.spark.rdd.MongoRDD.compute(MongoRDD.scala:161)
    at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
    at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
    at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
    at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
    at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
    at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
    at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
    at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
    at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
    at org.apache.spark.scheduler.Task.run(Task.scala:123)
    at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
    at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
    at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
    at java.lang.Thread.run(Thread.java:748)

Driver stacktrace:
    at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1889)
    at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1877)
    at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1876)
    at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
    at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
    at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1876)
    at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)
    at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)
    at scala.Option.foreach(Option.scala:257)
    at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:926)
    at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2110)
    at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2059)
    at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2048)
    at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
    at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:737)
    at org.apache.spark.SparkContext.runJob(SparkContext.scala:2061)
    at org.apache.spark.SparkContext.runJob(SparkContext.scala:2158)
    at org.apache.spark.rdd.RDD$$anonfun$fold$1.apply(RDD.scala:1098)
    at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
    at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
    at org.apache.spark.rdd.RDD.withScope(RDD.scala:363)
    at org.apache.spark.rdd.RDD.fold(RDD.scala:1092)
    at org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1.apply(RDD.scala:1161)
    at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
    at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
    at org.apache.spark.rdd.RDD.withScope(RDD.scala:363)
    at org.apache.spark.rdd.RDD.treeAggregate(RDD.scala:1137)
    at com.mongodb.spark.sql.MongoInferSchema$.apply(MongoInferSchema.scala:88)
    at com.mongodb.spark.sql.DefaultSource.constructRelation(DefaultSource.scala:97)
    at com.mongodb.spark.sql.DefaultSource.createRelation(DefaultSource.scala:50)
    at org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:318)
    at org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:223)
    at org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)
    at org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:167)
    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
    at java.lang.reflect.Method.invoke(Method.java:498)
    at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
    at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
    at py4j.Gateway.invoke(Gateway.java:282)
    at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
    at py4j.commands.CallCommand.execute(CallCommand.java:79)
    at py4j.GatewayConnection.run(GatewayConnection.java:238)
    at java.lang.Thread.run(Thread.java:748)
Caused by: com.mongodb.MongoTimeoutException: Timed out after 30000 ms while waiting to connect. Client view of cluster state is {type=UNKNOWN, servers=[{address=52.91.254.92:27017, type=UNKNOWN, state=CONNECTING, exception={com.mongodb.MongoSocketOpenException: Exception opening socket}, caused by {java.net.SocketTimeoutException: connect timed out}}]
    at com.mongodb.internal.connection.BaseCluster.getDescription(BaseCluster.java:182)
    at com.mongodb.internal.connection.SingleServerCluster.getDescription(SingleServerCluster.java:41)
    at com.mongodb.client.internal.MongoClientDelegate.getConnectedClusterDescription(MongoClientDelegate.java:136)
    at com.mongodb.client.internal.MongoClientDelegate.createClientSession(MongoClientDelegate.java:94)
    at com.mongodb.client.internal.MongoClientDelegate$DelegateOperationExecutor.getClientSession(MongoClientDelegate.java:249)
    at com.mongodb.client.internal.MongoClientDelegate$DelegateOperationExecutor.execute(MongoClientDelegate.java:172)
    at com.mongodb.client.internal.MongoIterableImpl.execute(MongoIterableImpl.java:132)
    at com.mongodb.client.internal.MongoIterableImpl.iterator(MongoIterableImpl.java:86)
    at com.mongodb.spark.rdd.MongoRDD.getCursor(MongoRDD.scala:193)
    at com.mongodb.spark.rdd.MongoRDD.compute(MongoRDD.scala:161)
    at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
    at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
    at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
    at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
    at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
    at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
    at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
    at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
    at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
    at org.apache.spark.scheduler.Task.run(Task.scala:123)
    at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
    at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
    at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
    ... 1 more
</code></pre>

<p>Would very much appreciate having some tips on how to track down why this is failing.</p>
"
"60473043","<p>You can use <code>panda.DataFrame.merge</code> to merge them.</p>

<p>If you just want to merge two lists:</p>

<pre class=""lang-py prettyprint-override""><code>def merge_probability(f3, f4):
    df0 = pd.DataFrame(f3[0], columns=f3[1] + [""probability0""])
    df1 = pd.DataFrame(f4[0], columns=f4[1] + [""probability1""])

    df = df0.merge(df1)

    df[""probability""] = df[""probability0""] * df[""probability1""]
    df = df.drop([""probability0"", ""probability1""], axis=1)
    return [df.values.tolist(), f4[1]]
</code></pre>

<p>Or if more lists need to be merged together:</p>

<pre><code>def merge_probabilitys(*fs):
    size = len(fs)
    dfs = [
        pd.DataFrame(fs[i][0], columns=fs[i][1] + [""probability"" + str(i)])
        for i in range(size)
    ]

    df_res = dfs[0]
    for df in dfs[1:]:
        df_res = df_res.merge(df)

    df_res[""probability""] = 1
    for i in range(size):
        df_res[""probability""] *= df_res[""probability"" + str(i)]

    df_res = df_res.drop([""probability"" + str(i) for i in range(size)], axis=1)
    return [df_res.values.tolist(), list(df_res.columns)[:-1]]
</code></pre>
","0","","1","331","9","0","13","60470963","60473043","<p>I have these two lists of lists, the last column is the probability of this happening</p>

<pre><code>#Pr(Fraud | Trav)
f3 = [[
    [True, True, 0.01],
    [False, True, 0.004],
    [True, False, 0.99],
    [False, False, 0.996]
], [""Trav"", ""Fraud""]]

f4 = [[
    [False, True, True, 0.1],
    [False, False, True, 0.01],
    [True, True, True, 0.9],
    [True, False, True, 0.9],
    [False, True, False, 0.9],
    [False, False, False, 0.99],
    [True, True, False, 0.1],
    [True, False, False, 0.1],
], [""Trav"", ""Fraud"", ""FP""]]
</code></pre>

<p>and I would like to join them together by Trav and Fraud to produce the following table:</p>

<pre><code>[[True,True,True,0.009]
[True,True,False,0.001]
[True,False,True,0.891]
[True,False,False,0.099]
[False,True,True,0.0004]
[False,True,False,0.0036]
[False,False,True,0.00996]
[False,False,False,0.98604]],
[""Trav"",""Fraud"",""FP""]]
</code></pre>

<p>Thanks in advance!!!</p>
"
"60471097","<p>In the first image, you don't have your virtual environment activated. Because you only have <code>python-nmap</code> installed in your virtual environment python, your system-wide python installation can't find it.</p>

<p>In the second image, you do have the virtual environment activated, which is why it says python-nmap is installed.</p>

<p>To activate your virtual environment on Windows, you need to execute <code>\path\to\your\venv\bin\activate.exe</code>. Then run your command and it should work.</p>

<p>Alternatively, you could just run <code>pip install python-nmap</code> to install it on your system level python installation.</p>
","0","","2","1337","2625","1","61","60470971","60471097","<p>I used <code>import nmap</code> module from python-nmap, and it works fine in Pycharm.</p>

<p>But when I try to run the same program on command prompt, it gives error:</p>

<blockquote>
  <p>ModuleNotFoundError: No module named 'nmap'</p>
</blockquote>

<p>pip is installed in the directory path <code>pycharmprojects\botnet\venv\lib\site-packages (0.6.1)</code>. This is the same path where my program is located.</p>

<p>Has anyone seen this error? </p>

<p>It doesn't work in <code>cmd</code> instead of Pycharm.
<img src=""https://i.stack.imgur.com/oF4Rm.png"" alt=""in cmd not working in pycharm everything works fine//""> </p>

<p>Pycharm terminal says it's installed in the path where it should be installed.
<img src=""https://i.stack.imgur.com/nc4HX.png"" alt=""//pycharm terminal says its installed in the path where it should be installed i guess..""></p>
"
"60471100","<p>Use <a href=""https://docs.scipy.org/doc/numpy/reference/generated/numpy.where.html"" rel=""nofollow noreferrer""><code>numpy.where</code></a> with <a href=""http://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.fillna.html"" rel=""nofollow noreferrer""><code>Series.fillna</code></a>:</p>

<pre><code>enr['gender'] = np.where(enr['home_work'] &gt; 9,  
                         enr['gender'].fillna('m'),
                         enr['gender'].fillna('f'))
</code></pre>

<p>Or filter separately by 2 masks:</p>

<pre><code>m = enr['gender'].isna()
enr.loc[m, 'gender'] = np.where(enr['home_work'] &gt; 9,  'm',  'f')[m]
</code></pre>

<hr>

<pre><code>print (enr)
   name_id enrollment_term  gpa_term  dog_owner    salary  home_work gender
0     1254     spring 2018      2.93          0   50657.0         34      m
1     1359     spring 2018       NaN          1   90658.0         42      f
2     1254       fall 2018      1.65          1       NaN         12      f
3     1296     spring 2018      4.00          1  104352.0          9      f
4     1353     spring 2018      3.95          1       NaN          8      f
5     2656       fall 2020      2.92          0  102043.0         27      m
</code></pre>

<p>EDIT:</p>

<pre><code>m = enr['gender'].isna() &amp; enr['home_work'].notna()
enr.loc[m, 'gender'] = np.where(enr['home_work'] &gt;= 0.5, 0, 1)[m]
print (enr)
   name_id enrollment_term  gpa_term  dog_owner    salary  home_work  gender
0     1254     spring 2018      2.93          0   50657.0        NaN     0.0
1     1359     spring 2018       NaN          1   90658.0        NaN     1.0
2     1254       fall 2018      1.65          1       NaN       0.70     1.0
3     1296     spring 2018      4.00          1  104352.0       0.30     1.0
4     1353     spring 2018      3.95          1       NaN       0.64     0.0
5     2656       fall 2020      2.92          0  102043.0       0.49     1.0
</code></pre>
","13","2020-03-01 14:26:03","3","615041","23439","1483","126104","60471025","60471100","<p>I have been working on this for a while and just can't seem to find the answer to what I need.  Suppose I have a dataframe as below.</p>

<p>What I would like to do is fill the last three rows of <code>df['gender']</code> based on the value in <code>df['home_work']</code> column, specifically if <code>home_work</code> > 9, then <code>m</code>, if not, then <code>f</code>.  Please keep in mind this is just a <strong>made up dataset</strong> and I don't mean to offend anyone, I promise!</p>

<pre class=""lang-rb prettyprint-override""><code>enr = pd.DataFrame({'name_id':[1254, 1359, 1254, 1296, 1353, 2656], 
                   'enrollment_term':['spring 2018', 'spring 2018', 'fall 2018', 'spring 2018', 'spring 2018', 'fall 2020'],
                   'gpa_term': [2.93, np.nan, 1.65, 4.00, 3.95, 2.92],
                   'dog_owner':[0,1,1,1, 1, 0],
                   'salary':[50657, 90658, np.nan, 104352, np.nan, 102043],
                   'home_work':[34, np.nan, 12, 9, 8, 27],
                   'gender':['m','f','f',np.nan, np.nan, np.nan]})

enr
</code></pre>

<p>Below is the code that I attempted but it presented the error down below:</p>

<pre class=""lang-rb prettyprint-override""><code>for i in df['gender'].isna():
    if df['home_work'][i] &gt; 9:
        df['gender'][i].fillna('m')
    else:
        df['gender'][i].fillna('f')
</code></pre>

<pre class=""lang-rb prettyprint-override""><code>KeyError: False
</code></pre>

<p>Any help would be <strong>greatly</strong> appreciated as I have been working on this for a while.  I have a dataset of 90K + that I want to adapt this work to and would like to create a function that streamlines this process but have hit a speedbump!</p>

<p>The issue I am running into is that <code>np.nan</code> defaults and fills in a value for <code>gender</code> if it doesn't meet the requirement.  Thoughts?</p>

<hr>

<h2># Edited</h2>

<p>Suppose I have the following df:</p>

<pre class=""lang-rb prettyprint-override""><code>enr = pd.DataFrame({'name_id':[1254, 1359, 1254, 1296, 1353, 2656], 
                   'enrollment_term':['spring 2018', 'spring 2018', 'fall 2018', 'spring 2018', 'spring 2018', 'fall 2020'],
                   'gpa_term': [2.93, np.nan, 1.65, 4.00, 3.95, 2.92],
                   'dog_owner':[0,1,1,1, 1, 0],
                   'salary':[50657, 90658, np.nan, 104352, np.nan, 102043],
                   'home_work':[np.nan, np.nan, 0.7, 0.3, 0.64, 0.49],
                   'gender':[0, 1, 1,np.nan, np.nan, np.nan]})
</code></pre>

<p><a href=""https://i.stack.imgur.com/MXy1r.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/MXy1r.png"" alt=""enter image description here""></a></p>

<p>I would like to impute <code>enr['gender']</code> based on <code>home_work</code>.  If <code>enr['home_work'] &gt;= 0.5</code>, then <code>enr['gender'] == 0</code>, else <strong>(as long as <code>enr['home_work'] != np.nan</code>)</strong>, <code>enr['gender'] == 1</code>.  </p>

<p>What I don't want is imputation of values in <code>enr[gender]</code> where their <code>enr['home_work']</code> is <code>np.nan</code>I have tried many different techniques but all seem to impute a 1.  Thoughts?</p>
"
"60471550","<p>Let us try <code>map</code> the value and <code>where</code> </p>

<pre><code>df.gender=df.gender.where(df.gender.notna(),df.home_work.gt(9).map({True:'m',False:'f'})) 


df
   name_id enrollment_term  gpa_term  dog_owner    salary  home_work gender
0     1254     spring 2018      2.93          0   50657.0       34.0      m
1     1359     spring 2018       NaN          1   90658.0        NaN      f
2     1254       fall 2018      1.65          1       NaN       12.0      f
3     1296     spring 2018      4.00          1  104352.0        9.0      f
4     1353     spring 2018      3.95          1       NaN        8.0      f
5     2656       fall 2020      2.92          0  102043.0       27.0      m
</code></pre>
","0","2020-03-01 02:53:30","3","252249","5881","962","22297","60471025","60471100","<p>I have been working on this for a while and just can't seem to find the answer to what I need.  Suppose I have a dataframe as below.</p>

<p>What I would like to do is fill the last three rows of <code>df['gender']</code> based on the value in <code>df['home_work']</code> column, specifically if <code>home_work</code> > 9, then <code>m</code>, if not, then <code>f</code>.  Please keep in mind this is just a <strong>made up dataset</strong> and I don't mean to offend anyone, I promise!</p>

<pre class=""lang-rb prettyprint-override""><code>enr = pd.DataFrame({'name_id':[1254, 1359, 1254, 1296, 1353, 2656], 
                   'enrollment_term':['spring 2018', 'spring 2018', 'fall 2018', 'spring 2018', 'spring 2018', 'fall 2020'],
                   'gpa_term': [2.93, np.nan, 1.65, 4.00, 3.95, 2.92],
                   'dog_owner':[0,1,1,1, 1, 0],
                   'salary':[50657, 90658, np.nan, 104352, np.nan, 102043],
                   'home_work':[34, np.nan, 12, 9, 8, 27],
                   'gender':['m','f','f',np.nan, np.nan, np.nan]})

enr
</code></pre>

<p>Below is the code that I attempted but it presented the error down below:</p>

<pre class=""lang-rb prettyprint-override""><code>for i in df['gender'].isna():
    if df['home_work'][i] &gt; 9:
        df['gender'][i].fillna('m')
    else:
        df['gender'][i].fillna('f')
</code></pre>

<pre class=""lang-rb prettyprint-override""><code>KeyError: False
</code></pre>

<p>Any help would be <strong>greatly</strong> appreciated as I have been working on this for a while.  I have a dataset of 90K + that I want to adapt this work to and would like to create a function that streamlines this process but have hit a speedbump!</p>

<p>The issue I am running into is that <code>np.nan</code> defaults and fills in a value for <code>gender</code> if it doesn't meet the requirement.  Thoughts?</p>

<hr>

<h2># Edited</h2>

<p>Suppose I have the following df:</p>

<pre class=""lang-rb prettyprint-override""><code>enr = pd.DataFrame({'name_id':[1254, 1359, 1254, 1296, 1353, 2656], 
                   'enrollment_term':['spring 2018', 'spring 2018', 'fall 2018', 'spring 2018', 'spring 2018', 'fall 2020'],
                   'gpa_term': [2.93, np.nan, 1.65, 4.00, 3.95, 2.92],
                   'dog_owner':[0,1,1,1, 1, 0],
                   'salary':[50657, 90658, np.nan, 104352, np.nan, 102043],
                   'home_work':[np.nan, np.nan, 0.7, 0.3, 0.64, 0.49],
                   'gender':[0, 1, 1,np.nan, np.nan, np.nan]})
</code></pre>

<p><a href=""https://i.stack.imgur.com/MXy1r.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/MXy1r.png"" alt=""enter image description here""></a></p>

<p>I would like to impute <code>enr['gender']</code> based on <code>home_work</code>.  If <code>enr['home_work'] &gt;= 0.5</code>, then <code>enr['gender'] == 0</code>, else <strong>(as long as <code>enr['home_work'] != np.nan</code>)</strong>, <code>enr['gender'] == 1</code>.  </p>

<p>What I don't want is imputation of values in <code>enr[gender]</code> where their <code>enr['home_work']</code> is <code>np.nan</code>I have tried many different techniques but all seem to impute a 1.  Thoughts?</p>
"
"60476029","<p>The response is in that format because you are explicitly wrapping it in a JSON object with a <code>body</code> property. Change <code>return {'body' : data}</code> to <code>return data</code>.</p>
","0","","2","137251","10558","9025","8564","60471046","60476029","<p>I am using the following Python function in AWs Lambda:</p>

<pre><code>import json
import boto3
from boto3.dynamodb.conditions import Key, Attr

#always start with the lambda_handler
def lambda_handler(event, context):

    # make the connection to dynamodb
    dynamodb = boto3.resource('dynamodb')

    # select the table
    table = dynamodb.Table(""test"")

    response = table.query(
    KeyConditionExpression=Key('coursename').eq('intro')
    )
    data = response['Items']
    return {'body' : data}
</code></pre>

<p>It outputs the following JSON - notice the ""body"" key? This is creating some issues when I try to use the response in my app because I have to reference the ""body"" as part of the response.</p>

<p><strong>JSON response from Lambda</strong></p>

<pre><code>{
    ""body"": [{
        ""coursename"": ""introto1"",
        ""course-lesson-name"": ""Welcome to One! ""
    }, {
        ""coursename"": ""introto2"",
        ""course-lesson-name"": ""What is One?""
    }, {
        ""coursename"": ""introto2"",
        ""course-lesson-name"": ""What Can We do with One?""
    }]
}
</code></pre>

<p>This is the JSON format I need my Python function to output. Can this be done in AWS Lambda?</p>

<p><strong>JSON format I need:</strong></p>

<pre><code>[{
    ""coursename"": ""introto1"",
    ""course-lesson-name"": ""Welcome to One! ""
}, {
    ""coursename"": ""introto2"",
    ""course-lesson-name"": ""What is One?""
}, {
    ""coursename"": ""introto2"",
    ""course-lesson-name"": ""What Can We do with One?""
}]
</code></pre>
"
"60471088","<p>Inside your for loop put in a line to <code>print(item)</code>
Youâ€™ll see it is the value in wrongMark, not the index. 
You probably want</p>

<pre><code>For index in range(len(wrongMark)):
</code></pre>
","0","2020-03-01 01:13:39","2","1323","92","59","106","60471060","60471088","<p>I am a student relatively new to coding, using Python at GCSE level and I am struggling to see where I am going wrong with this piece of code, used to correct different students marks by an adjustment factor. Why am I getting an error when both lists have the same number of items in them?</p>

<pre><code>wrongMark = [72,75,23,54,48]
adFactor = [1.25,1.1,1.8,1.3,0.9]
newMark = []
examTable = [[""Doc"",""Sarah"",""Jar-Jar"",""Jake"",""Ben""],
             wrongMark,
             adFactor
             ]
#print(examTable)

for item in wrongMark:
    results = item*adFactor[item]
    newMark.append(results)
print(newMark)

</code></pre>
"
"60471093","<p>The error is that you are using <code>for item in wrongMark</code>. In the first iteration, the loop will assign item with value 75 and the list <code>adFactor</code> doesn't have 75 items ;)</p>

<p>One way to solve this is just changing the loop to:</p>

<pre><code>for item in range(len(wrongMark)):
    results = wrongMark[item]*adFactor[item]
    newMark.append(results)
</code></pre>
","0","","0","125","730","0","16","60471060","60471088","<p>I am a student relatively new to coding, using Python at GCSE level and I am struggling to see where I am going wrong with this piece of code, used to correct different students marks by an adjustment factor. Why am I getting an error when both lists have the same number of items in them?</p>

<pre><code>wrongMark = [72,75,23,54,48]
adFactor = [1.25,1.1,1.8,1.3,0.9]
newMark = []
examTable = [[""Doc"",""Sarah"",""Jar-Jar"",""Jake"",""Ben""],
             wrongMark,
             adFactor
             ]
#print(examTable)

for item in wrongMark:
    results = item*adFactor[item]
    newMark.append(results)
print(newMark)

</code></pre>
"
"60471128","<p>The problem is at this row:</p>

<pre><code>   results = item*adFactor[item]
</code></pre>

<p>For the first iteration of the for loop, you are trying to access the 72th cell in the list adFactor.</p>

<p>That is why you get ""list index out of range""</p>
","0","","0","101","7","0","1","60471060","60471088","<p>I am a student relatively new to coding, using Python at GCSE level and I am struggling to see where I am going wrong with this piece of code, used to correct different students marks by an adjustment factor. Why am I getting an error when both lists have the same number of items in them?</p>

<pre><code>wrongMark = [72,75,23,54,48]
adFactor = [1.25,1.1,1.8,1.3,0.9]
newMark = []
examTable = [[""Doc"",""Sarah"",""Jar-Jar"",""Jake"",""Ben""],
             wrongMark,
             adFactor
             ]
#print(examTable)

for item in wrongMark:
    results = item*adFactor[item]
    newMark.append(results)
print(newMark)

</code></pre>
"
"60471141","<p>you need to use index while iterating. You are using value which is 72 for first iteration. That is why it out of range error. Use something like :        for idx in range(len(wrongMark)):
    results = wrongMark[idx]*adFactor[idx]
    newMark.append(results)</p>
","0","2020-03-01 01:28:04","0","386","10","2","32","60471060","60471088","<p>I am a student relatively new to coding, using Python at GCSE level and I am struggling to see where I am going wrong with this piece of code, used to correct different students marks by an adjustment factor. Why am I getting an error when both lists have the same number of items in them?</p>

<pre><code>wrongMark = [72,75,23,54,48]
adFactor = [1.25,1.1,1.8,1.3,0.9]
newMark = []
examTable = [[""Doc"",""Sarah"",""Jar-Jar"",""Jake"",""Ben""],
             wrongMark,
             adFactor
             ]
#print(examTable)

for item in wrongMark:
    results = item*adFactor[item]
    newMark.append(results)
print(newMark)

</code></pre>
"
"60471182","<p>The error is In the code: results = item*adFactor[item]
It is easier to note the error when you imagine the first iteration of your loop to be : result = 72 * adFactor[72]
You get an  out of index  error because the list adFactor doesnt have a  72nd term.</p>
","0","","0","23","5","0","8","60471060","60471088","<p>I am a student relatively new to coding, using Python at GCSE level and I am struggling to see where I am going wrong with this piece of code, used to correct different students marks by an adjustment factor. Why am I getting an error when both lists have the same number of items in them?</p>

<pre><code>wrongMark = [72,75,23,54,48]
adFactor = [1.25,1.1,1.8,1.3,0.9]
newMark = []
examTable = [[""Doc"",""Sarah"",""Jar-Jar"",""Jake"",""Ben""],
             wrongMark,
             adFactor
             ]
#print(examTable)

for item in wrongMark:
    results = item*adFactor[item]
    newMark.append(results)
print(newMark)

</code></pre>
"
"60472369","<p>In <code>BaggingClassifier</code> you can only use base estimators that support sample weights because it relies on <a href=""https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.BaggingClassifier.html#sklearn.ensemble.BaggingClassifier.score"" rel=""nofollow noreferrer"">score</a> method, which takes in <code>sample_weight</code>param.</p>

<p>You can list all the available classifiers like:</p>

<pre><code>import inspect 
from sklearn.utils.testing import all_estimators 
for name, clf in all_estimators(type_filter='classifier'): 
    if 'sample_weight' in inspect.getargspec(clf.fit)[0]: 
        print(name) 
</code></pre>
","0","2020-03-01 05:59:53","0","15516","968","609","1473","60471192","60472369","<p>I am new to Sklearn, and I am trying to combine KNN, Decision Tree,  SVM, and Gaussian NB for BaggingClassifier.</p>

<p>Part of my code looks like this:</p>

<pre><code>best_KNN = KNeighborsClassifier(n_neighbors=5, p=1)
best_KNN.fit(X_train, y_train)

majority_voting = VotingClassifier(estimators=[('KNN', best_KNN), ('DT', best_DT), ('SVM', best_SVM), ('gaussian', gaussian_NB)], voting='hard')
majority_voting.fit(X_train, y_train)

bagging = BaggingClassifier(base_estimator=majority_voting)
bagging.fit(X_train, y_train)
</code></pre>

<p>But this causes an error saying: </p>

<blockquote>
  <p>TypeError: Underlying estimator KNeighborsClassifier does not support sample weights.</p>
</blockquote>

<p>The ""bagging"" part worked fine if I remove KNN.
Does anyone have any idea to solve this issue? Thank you for your time.</p>
"
"60471488","<p>Python logged <code>str(stdout)</code>, but <code>stdout</code> is a byte stream so you got the whole <code>bytes</code> representation starting with <code>b'</code> and backslash escaped newlines. You need to decode it first. Using the default encoding on your system should work</p>

<pre><code>&gt;&gt;&gt; import logging
&gt;&gt;&gt; logging.basicConfig()
&gt;&gt;&gt; import subprocess as subp
&gt;&gt;&gt; cmd = subp.Popen([""ls""], stdout=subp.PIPE, stderr=subp.STDOUT)
&gt;&gt;&gt; stdout, stderr = cmd.communicate()
&gt;&gt;&gt; logging.warning(stdout)
</code></pre>

<p>WARNING:root:b'a.py\nb.py\nc.py\ne.py\nf.py\ng.py\nh.py\ni.py\nj.py\nl.py\n__pycache__\n'</p>

<pre><code>&gt;&gt;&gt; logging.warning(stdout.decode())
WARNING:root:a.py
b.py
c.py
e.py
f.py
g.py
h.py
i.py
j.py
l.py
__pycache__
</code></pre>
","0","2020-03-01 02:55:12","2","55035","2176","130","4224","60471200","60471488","<p>I am calling a system program from my script using <code>subprocess.Popen</code>, and capturing the <code>stdout</code> and <code>stderr</code> in a log file. However, all of the returned info is on a single line with <code>\n</code> and <code>\t</code> characters not interpreted. Is there a module to wrap those in my log file? </p>

<pre><code>import logging
import subprocess as sp

# build list for cmd
logging.info('Command to run: {}'.format(cmd_list))
cmd = sp.Popen(cmd_list, stdout=sp.PIPE, stderr=sp.STDOUT)
stdout, stderr = cmd.communicate()
logging.info(stdout)
# output is INFO:root:b""Welcome to MAGMA v1.07b (linux/s)\nUsing flags:\n\t--annotate...
</code></pre>
"
"60471326","<p>Is this what you're looking for?</p>

<pre><code>from random import shuffle

my_list = [1,2,3,4,5]
print (my_list)
shuffle (my_list)
print (my_list)
</code></pre>
","2","","1","1349","59","3","86","60471250","60471336","<p>I have a list with elements as following:</p>

<pre><code>L =[1, 2, 3, 4, 5]
</code></pre>

<p>I want to mirror and reorder as follows: </p>

<pre><code>L =[1,5,2,4,3]
</code></pre>

<p>Numbers and size of elements in the list may vary and change!</p>

<p>Having some other examples,</p>

<pre><code>K=[1, 2, 3]
</code></pre>

<p>Output may come out as: </p>

<pre><code>K=[1, 3, 2]
</code></pre>

<p>And</p>

<pre><code>D=[1,2,3,4]
</code></pre>

<p>Final results:</p>

<pre><code>D = [1,4,2,3]
</code></pre>

<p>I have tried to do it with slice, it doesn't work for me.</p>
"
"60471336","<p>You can do that by merging the list with its reverse:</p>

<pre><code>lst = [1,2,3,4,5]

b = [c for a,b in zip(lst,reversed(lst)) for c in (a,b)][:len(lst)]

print(b) # [1, 5, 2, 4, 3]
</code></pre>
","0","2020-03-04 14:34:53","2","24359","14","17","1310","60471250","60471336","<p>I have a list with elements as following:</p>

<pre><code>L =[1, 2, 3, 4, 5]
</code></pre>

<p>I want to mirror and reorder as follows: </p>

<pre><code>L =[1,5,2,4,3]
</code></pre>

<p>Numbers and size of elements in the list may vary and change!</p>

<p>Having some other examples,</p>

<pre><code>K=[1, 2, 3]
</code></pre>

<p>Output may come out as: </p>

<pre><code>K=[1, 3, 2]
</code></pre>

<p>And</p>

<pre><code>D=[1,2,3,4]
</code></pre>

<p>Final results:</p>

<pre><code>D = [1,4,2,3]
</code></pre>

<p>I have tried to do it with slice, it doesn't work for me.</p>
"
"60471370","<p>The following code gives you the expected output.</p>

<pre class=""lang-py prettyprint-override""><code>l = [1,2,3,4,5]

r = []
for i in range(len(l)):
    if i % 2 == 0:
        r.append(l[i // 2])
    else:
        r.append(l[-1 - i // 2])

print(r)  # prints [1, 5, 2, 4, 3]
</code></pre>
","1","","1","590","106","10","40","60471250","60471336","<p>I have a list with elements as following:</p>

<pre><code>L =[1, 2, 3, 4, 5]
</code></pre>

<p>I want to mirror and reorder as follows: </p>

<pre><code>L =[1,5,2,4,3]
</code></pre>

<p>Numbers and size of elements in the list may vary and change!</p>

<p>Having some other examples,</p>

<pre><code>K=[1, 2, 3]
</code></pre>

<p>Output may come out as: </p>

<pre><code>K=[1, 3, 2]
</code></pre>

<p>And</p>

<pre><code>D=[1,2,3,4]
</code></pre>

<p>Final results:</p>

<pre><code>D = [1,4,2,3]
</code></pre>

<p>I have tried to do it with slice, it doesn't work for me.</p>
"
"60471385","<p><a href=""https://docs.scipy.org/doc/numpy/reference/generated/numpy.loadtxt.html"" rel=""nofollow noreferrer""><code>np.loadtxt</code></a> has supported an <code>encoding</code> argument since version 1.14.0. It allows you to manually set the encoding. Something like UTF-16 comes to mind as a possibility when the first byte is 0xFF. However the actual determination of the encoding is best made by investigating the program that created your file.</p>
","2","2020-03-01 02:11:29","1","73982","12512","5089","14868","60471251","60471385","<p>I'm trying to import data from a text file using <code>numpy.loadtxt</code>. This is something I've done many times in the past without issue. However, after generating a new set of text files to import, something about the encoding must be different because I get an error when trying to run the following code: </p>

<pre><code>import numpy as np 

asdf = np.loadtxt('data/asdf.txt', skiprows=28, max_rows=720, usecols=range(1,722))
</code></pre>

<p>The error message I receive is: </p>

<pre><code>---------------------------------------------------------------------------
UnicodeDecodeError                        Traceback (most recent call last)
/Users/iangullett/Desktop/coadd/coadd.py in &lt;module&gt;()
     61 
     62 
---&gt; 63 test = np.loadtxt('data/asdf.txt')
     64 
     65 

/Users/iangullett/opt/anaconda2/lib/python2.7/site-packages/numpy/lib/npyio.pyc in loadtxt(fname, dtype, comments, delimiter, converters, skiprows, usecols, unpack, ndmin, encoding, max_rows)
   1091         try:
   1092             while not first_vals:
-&gt; 1093                 first_line = next(fh)
   1094                 first_vals = split_line(first_line)
   1095         except StopIteration:

/Users/iangullett/opt/anaconda2/lib/python2.7/codecs.pyc in decode(self, input, final)
    312         # decode input (taking the buffer into account)
    313         data = self.buffer + input
--&gt; 314         (result, consumed) = self._buffer_decode(data, self.errors, final)
    315         # keep undecoded input until the next call
    316         self.buffer = data[consumed:]

UnicodeDecodeError: 'utf8' codec can't decode byte 0xff in position 0: invalid start byte
</code></pre>

<p>And for reference, here is a bit of the beginning of the text file I'm trying to read (which is actually very large): </p>

<pre><code>Detector Viewer Listing

File : C:\file_path_hidden
Title: 
Date : 10/16/2019


Detector 6, NSCG Surface 1: 
Max polar angle: 90.00 deg, Total Hits = 224724030

Peak Intensity  : 3.957E+005 Watts/Steradian
Total Power     : 9.915E-001 Watts
Data Type       : Radiant Intensity
Maximum Angle   : 90.0000
Detector X      : 0.0000
Detector Y      : 0.0000
Detector Z      : 0.0000
Detector Tilt X : 0.0000
Detector Tilt Y : 180.0000
Detector Tilt Z : 0.0000
Units           : Watts/Steradian

Radial Pixels   : 721, increment 0.1250 degrees
Azimuthal Pixels: 720, increment 0.5000 degrees
Columns are radial angles, rows are azimuthal angles.

Power Values:
                 1           2           3           4           5           6           7           8           
</code></pre>

<p>Any help would be greatly appreciated. </p>
"
"60478140","<ol>
<li><p>When you use <code>create_task</code> with an <code>async def</code> function, call the function normally and then pass the result to <code>create_task</code>. </p>

<pre><code>await asyncio.create_task(start_tornado())
await asyncio.create_task(display_date())
</code></pre></li>
<li><p>You don't need to use <code>create_task</code> if you're going to <code>await</code> it immediately. Use <code>create_task</code> without <code>await</code> to start tasks in the background, like <code>display_date()</code>. <code>start_tornado</code> is not a background task in this sense because it doesn't have an infinite loop, it just starts a server that is put into the background by Tornado. So I'd write it like this:</p>

<pre><code>await start_tornado()
asyncio.create_task(display_date())
</code></pre></li>
<li><p>Since Tornado 5.0, the Tornado IOLoop and asyncio event loop are integrated by default, so you only need to start one, not both. So just remove the <code>IOLoop.start()</code> call in <code>start_tornado</code>. </p></li>
<li><p><code>start_tornado</code> isn't currently doing anything asynchronous, so it could just be a normal function. But it would also be a reasonable place to add asynchronous startup logic like establishing database connections, so you can keep it as a coroutine. </p></li>
</ol>

<p>Working version of the code with my edits: <a href=""https://repl.it/@bdarnell/FarawayAdmiredConversions"" rel=""nofollow noreferrer"">https://repl.it/@bdarnell/FarawayAdmiredConversions</a></p>
","2","","2","20673","55","11","2489","60471268","60478140","<p>I would like to run a Tornado server alongside an independent long-running task in <code>asyncio</code> in Python 3.7. I'm new to <code>asyncio</code>. I've read that you should only call <code>asyncio.run()</code> once, so I've brought both tasks together under the <code>main()</code> method so that I can pass a single argument to <code>asyncio.run()</code>. When I run this code, I get the error <code>TypeError: a coroutine was expected, got &lt;function start_tornado at 0x105c8e6a8&gt;</code>. I'd like to get the code to run without errors, but ultimately I want to know how to do this the right way. The code I've written below feels like an ugly hack.</p>

<pre><code>import asyncio
import datetime
import tornado.ioloop
import tornado.web


class MainHandler(tornado.web.RequestHandler):
    def get(self):
        self.write(""Hello, world"")

def make_app():
    return tornado.web.Application([
        (r""/"", MainHandler),
    ])

# Fake background task I got from here:
# https://docs.python.org/3/library/asyncio-task.html#sleeping
async def display_date():
    while True:
        print(datetime.datetime.now())
        await asyncio.sleep(1)

async def start_tornado():
    app = make_app()
    app.listen(8888)
    tornado.ioloop.IOLoop.current().start()

async def main():
    await asyncio.create_task(start_tornado)
    await asyncio.create_task(display_date)

asyncio.run(main())
</code></pre>
"
"60495807","<p>Tornado might already have everything you need.</p>

<ol>
<li>Instead of using <code>await asyncio.create_task</code> you can use <code>tornado.ioloop.IOLoop.current().add_callback</code></li>
<li>Instead of <code>await asyncio.sleep(1)</code> you can use <code>yield gen.sleep(1)</code></li>
</ol>

<p>So in the end the whole code from your example could look like this:</p>

<pre><code>import datetime
import tornado.ioloop
import tornado.web
import tornado.gen as gen


class MainHandler(tornado.web.RequestHandler):
    def get(self):
        self.write(""Hello, world"")


def make_app():
    return tornado.web.Application([
        (r""/"", MainHandler),
    ])


@gen.coroutine
def display_date():
    while True:
        print(datetime.datetime.now())
        yield gen.sleep(1)


def start_tornado():
    app = make_app()
    app.listen(8888)
    tornado.ioloop.IOLoop.current().add_callback(display_date)
    tornado.ioloop.IOLoop.current().start()


start_tornado()
</code></pre>
","0","","-1","1250","210","8","169","60471268","60478140","<p>I would like to run a Tornado server alongside an independent long-running task in <code>asyncio</code> in Python 3.7. I'm new to <code>asyncio</code>. I've read that you should only call <code>asyncio.run()</code> once, so I've brought both tasks together under the <code>main()</code> method so that I can pass a single argument to <code>asyncio.run()</code>. When I run this code, I get the error <code>TypeError: a coroutine was expected, got &lt;function start_tornado at 0x105c8e6a8&gt;</code>. I'd like to get the code to run without errors, but ultimately I want to know how to do this the right way. The code I've written below feels like an ugly hack.</p>

<pre><code>import asyncio
import datetime
import tornado.ioloop
import tornado.web


class MainHandler(tornado.web.RequestHandler):
    def get(self):
        self.write(""Hello, world"")

def make_app():
    return tornado.web.Application([
        (r""/"", MainHandler),
    ])

# Fake background task I got from here:
# https://docs.python.org/3/library/asyncio-task.html#sleeping
async def display_date():
    while True:
        print(datetime.datetime.now())
        await asyncio.sleep(1)

async def start_tornado():
    app = make_app()
    app.listen(8888)
    tornado.ioloop.IOLoop.current().start()

async def main():
    await asyncio.create_task(start_tornado)
    await asyncio.create_task(display_date)

asyncio.run(main())
</code></pre>
"
"60471360","<p>Because python 2 is no longer supported,
Pip2(invoked by either <code>pip</code> or <code>python -m pip</code>) is complaining that you should use python 3. The package manager for python 3 is called pip3(invoked by <code>pip3</code> or <code>python3 -m pip</code>).</p>

<p>Your pip3 is currently the latest version and you dont need to take any action to upgrade pip3.</p>

<p>If you want to use PIL in python then i recommend you <a href=""https://pillow.readthedocs.io/en/stable/installation.html"" rel=""nofollow noreferrer"">install pillow</a>. Pillow is the PIL of python 3.
You should be able to install pillow with <code>pip3 install Pillow</code>. Pillow supercedes PIL. (unless you specifically want to use PIL with python 2)</p>

<p>Perhaps you want to configure your terminal to alias pip to pip3 so you wont call pip2 by mistake.</p>
","0","2020-03-01 02:17:05","2","1024","81","14","64","60471280","60471360","<p>I wanted to download the PIL library to crop images on python, but I just can't download the module. Here's what appears on the terminal</p>

<pre><code>$ pip install PIL

    DEPRECATION: Python 2.7 reached the end of its life on January 1st, 2020. Please upgrade your Python as Python 2.7 is no longer maintained. A future version of pip will drop support for Python 2.7. More details about Python 2 support in pip, can be found at https://pip.pypa.io/en/latest/development/release-process/#python-2-support
    Defaulting to user installation because normal site-packages is not writeable
    ERROR: Could not find a version that satisfies the requirement PIL (from versions: none)
    ERROR: No matching distribution found for PIL
</code></pre>

<p>Then I tried this out. But another error shows up</p>

<pre><code>$ python3 -m pip install PIL
Could not find a version that satisfies the requirement PIL (from versions: )
No matching distribution found for PIL
You are using pip version 10.0.1, however version 20.0.2 is available.
You should consider upgrading via the 'pip install --upgrade pip' command.
</code></pre>

<p>So I tried to upgrade my pip. But then this shows up</p>

<pre><code>$ pip install --upgrade pip
Defaulting to user installation because normal site-packages is not writeable
Requirement already up-to-date: pip in /Library/Python/2.7/site-packages/pip-20.0.2-py2.7.egg (20.0.2)
</code></pre>

<p>When I check my pip version it shows this</p>

<pre><code>$ pip --version
pip 20.0.2 from /Library/Python/2.7/site-packages/pip-20.0.2-py2.7.egg/pip (python 2.7)
</code></pre>

<p>When I check my python version it shows this</p>

<pre><code>$ python --version
Python 2.7.10
$ python3 --version
Python 3.7.1
</code></pre>

<p>So I downloaded pip3 and then tried the command</p>

<pre><code>$ pip3 install PIL
WARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.
Please see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.
To avoid this problem you can invoke Python with '-m pip' instead of running pip directly.
Defaulting to user installation because normal site-packages is not writeable
ERROR: Could not find a version that satisfies the requirement PIL (from versions: none)
ERROR: No matching distribution found for PIL
</code></pre>

<p>I also tried what they said.</p>

<pre><code>$ python3 -m pip3 install PIL
/Library/Frameworks/Python.framework/Versions/3.7/bin/python3: No module named pip3
</code></pre>

<p>Here are some details about my pip and python</p>

<pre><code>$ which pip3
/Library/Frameworks/Python.framework/Versions/3.7/bin/pip3
$ which python3
/Library/Frameworks/Python.framework/Versions/3.7/bin/python3
</code></pre>

<p>How do I solve this once and for all?</p>
"
"60471415","<p>It actually catches it, but your 'except' block generates anoter one.</p>
","4","","2","427","13","0","32","60471366","60471415","<p>I am using Python 3.7 and I have a question about some code &amp; an error that just happened.</p>

<p>Basically my code reads like this:</p>

<pre><code>try:
    # Sometimes the &lt;span&gt; tag has a &lt;a&gt; tag as a child element...
    post_company = card.find(""span"", {""class"": ""company""}).find(""a"").decode_contents().replace(""\u2026"", ""..."")
except AttributeError:
    # ...And sometimes it doesn't.
    post_company = card.find(""span"", {""class"": ""company""}).decode_contents().replace(""\u2026"", ""..."")
</code></pre>

<p>But I still got this error message:</p>

<pre><code>Traceback (most recent call last):
  File ""C:/Users/Roland/dir1/2020/Indeed-Scraper/database/database.py"", line 163, in update_post_from_soup
    post_company = card.find(""span"", {""class"": ""company""}).find(""a"").decode_contents().replace(""\u2026"", ""..."")
AttributeError: 'NoneType' object has no attribute 'find'
</code></pre>

<p>Line 163 mentioned in the trace <em>is</em> the line in the try block. So it raised an AttributeError because there was no <code>&lt;a&gt;&lt;/a&gt;</code> tag within the <code>&lt;span&gt;</code>. I get that. But why didn't my <code>except</code> block catch this and execute the alternative line? Isn't <code>except AttributeError</code> handling precisely that error msg?</p>

<p>As <a href=""https://stackoverflow.com/questions/14460189/python-try-except-not-working"">this link</a> says: ""The except clause will only catch exceptions that are raised inside of their corresponding try block"". So yeah, it should've caught it, no?</p>
"
"60471574","<p>I haven't used BeatifulSoup before, but try using urlopen instead. This will store the webpage as a string, which you can use to find the email.</p>

<pre class=""lang-py prettyprint-override""><code>from urllib.request import urlopen

try:
    response = urlopen(""http://www.traiteurcheminfaisant.com"")
    html = response.read().decode(encoding = ""UTF8"", errors='ignore')
    print(html.find(""traiteurcheminfaisant@hotmail.com""))
except:
    print(""Cannot open webpage"")


</code></pre>
","0","","0","68","2","0","9","60471420","60471709","<p>So I am new to webscraping, I want to scrape all the text content of only the home page.</p>

<p>this is my code, but it now working correctly.</p>

<pre><code>from bs4 import BeautifulSoup
import requests


website_url = ""http://www.traiteurcheminfaisant.com/""
ra = requests.get(website_url)
soup = BeautifulSoup(ra.text, ""html.parser"")

full_text = soup.find_all()

print(full_text)
</code></pre>

<p>When I print ""full_text"" it give me a lot of html content but not all, when I  <code>ctrl + f "" traiteurcheminfaisant@hotmail.com""</code> the email adress that is on the home page (footer) 
is not found on full_text.</p>

<p>Thanks you for helping!</p>
"
"60471709","<p>A quick glance at the website that you're attempting to scrape from makes me suspect that not all content is loaded when sending a simple get request via the requests module. In other words, it seems likely that some components on the site, such as the footer you mentioned, are being loaded asynchronously with Javascript.</p>

<p>If that is the case, you'll probably want to use some sort of automation tool to navigate to the page, wait for it to load and then parse the fully loaded source code. For this, the most common tool would be Selenium. It can be a bit tricky to set up the first time since you'll also need to install a separate webdriver for whatever browser you'd like to use. That said, the last time I set this up it was pretty easy. Here's a rough example of what this might look like for you (once you've got Selenium properly set up):</p>

<pre><code>from bs4 import BeautifulSoup
from selenium import webdriver

import time

driver = webdriver.Firefox(executable_path='/your/path/to/geckodriver')
driver.get('http://www.traiteurcheminfaisant.com')
time.sleep(2)

source = driver.page_source
soup = BeautifulSoup(source, 'html.parser')

full_text = soup.find_all()

print(full_text)
</code></pre>
","0","","3","138","45","0","13","60471420","60471709","<p>So I am new to webscraping, I want to scrape all the text content of only the home page.</p>

<p>this is my code, but it now working correctly.</p>

<pre><code>from bs4 import BeautifulSoup
import requests


website_url = ""http://www.traiteurcheminfaisant.com/""
ra = requests.get(website_url)
soup = BeautifulSoup(ra.text, ""html.parser"")

full_text = soup.find_all()

print(full_text)
</code></pre>

<p>When I print ""full_text"" it give me a lot of html content but not all, when I  <code>ctrl + f "" traiteurcheminfaisant@hotmail.com""</code> the email adress that is on the home page (footer) 
is not found on full_text.</p>

<p>Thanks you for helping!</p>
"
"60513800","<p>Most likely, the key is not wrapped correctly. Can you please try the following commands to see that the decryption of the wrapped key generates the right output?</p>

<pre><code>cat wrapped_key.txt | base64 -d &gt; ciphertext.txt
</code></pre>

<pre><code>gcloud kms decrypt --location global --keyring &lt;key-ring-name&gt; --key &lt;key-name&gt; --plaintext-file unwrapped_secret.txt --ciphertext-file ciphertext.txt
</code></pre>

<pre><code>stat --printf=""%s\n"" unwrapped_secret.txt
</code></pre>

<p>Here are the steps to generate the KMS wrapped key for use with Google Cloud DLP API.</p>

<p><strong>Basic Terminology:</strong></p>

<p>DEK: Key to be wrapped.</p>

<p>KEK: Key with which DEK would be wrapped. This key does not leave Google Cloud KMS. </p>

<p>Go to your Google cloud console project > cryptographic keys and create a keyring and a KEK (if not already done so).</p>

<p><strong>Commands</strong></p>

<p>In order to execute the following commands, Google Cloud Shell might be the best option as it takes care of gcloud credential setup for you.</p>

<p>Step 1. Generate a 32 Byte random value. This would be your DEK.</p>

<pre><code>openssl rand 32 &gt; secret.txt
</code></pre>

<p>Step 2. Encrypt using Cloud KMS</p>

<pre><code>gcloud kms encrypt --location global --keyring &lt;key-ring-name&gt; --key \
&lt;key-name&gt; --plaintext-file secret.txt --ciphertext-file \
mysecret.txt.encrypted
</code></pre>

<p>Step 3: Convert to base64</p>

<pre><code>base64 mysecret.txt.encrypted
</code></pre>

<p>Step 4: Use this generated value in your request to Google Cloud DLP API.</p>

<p>Let me know if this doesn't help. If you could provide details on how you are wrapping the key, we could triage this further.</p>
","1","2020-03-03 18:57:26","5","66","0","0","6","60471428","60513800","<p>I am implementing the standard implementation of Google Cloud Platforms- Data Loss Prevention API in Python for De-Identifying text. This is from the example in <em><a href=""https://github.com/GoogleCloudPlatform/python-docs-samples/blob/master/dlp/deid.py"" rel=""nofollow noreferrer"">https://github.com/GoogleCloudPlatform/python-docs-samples/blob/master/dlp/deid.py</a></em> for the method <em>deidentify_with_fpe</em></p>

<p>When I run the code with the parameters I mentioned below I am getting the following error.</p>

<p>Can someone suggest how to fix the error? </p>

<pre><code>google.api_core.exceptions.InvalidArgument: 400 Received the following error message from Cloud KMS when unwrapping KmsWrappedCryptoKey ""projects/xxxx-xxx/locations/global/keyRings/dlp-key-ring-4/cryptoKeys/key9"": Decryption failed: the ciphertext is invalid.
</code></pre>

<p>the entire trace is </p>

<pre><code>Last login: Fri Feb 28 15:29:09 on ttys001
Restored session: Fri 28 Feb 2020 15:27:53 AEDT
xxxxs-MacBook-Pro:poc-bucket-flow-dlp xxxxxxxx$ python dlp3.py --verbosity=debug
Traceback (most recent call last):
  File ""/usr/local/lib/python3.7/site-packages/google/api_core/grpc_helpers.py"", line 57, in error_remapped_callable
    return callable_(*args, **kwargs)
  File ""/usr/local/lib/python3.7/site-packages/grpc/_channel.py"", line 826, in __call__
    return _end_unary_response_blocking(state, call, False, None)
  File ""/usr/local/lib/python3.7/site-packages/grpc/_channel.py"", line 729, in _end_unary_response_blocking
    raise _InactiveRpcError(state)
grpc._channel._InactiveRpcError: &lt;_InactiveRpcError of RPC that terminated with:
    status = StatusCode.INVALID_ARGUMENT
    details = ""Received the following error message from Cloud KMS when unwrapping KmsWrappedCryptoKey ""projects/xxxx-xxx/locations/global/keyRings/dlp-key-ring-4/cryptoKeys/key9"": Decryption failed: the ciphertext is invalid.""
    debug_error_string = ""{""created"":""@1582865236.411224000"",""description"":""Error received from peer ipv4:1xx.2xx.1xx.1xx:443"",""file"":""src/core/lib/surface/call.cc"",""file_line"":1056,""grpc_message"":""Received the following error message from Cloud KMS when unwrapping KmsWrappedCryptoKey ""projects/xxxx-xxx/locations/global/keyRings/dlp-key-ring-4/cryptoKeys/key9"": Decryption failed: the ciphertext is invalid."",""grpc_status"":3}""
&gt;

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File ""dlp3.py"", line 249, in &lt;module&gt;
    main()
  File ""dlp3.py"", line 246, in main
    test_deidentify_with_fpe()
  File ""dlp3.py"", line 240, in test_deidentify_with_fpe
    key_name=KEY_NAME,
  File ""dlp3.py"", line 101, in deidentify_with_fpe
    item=item,
  File ""/usr/local/lib/python3.7/site-packages/google/cloud/dlp_v2/gapic/dlp_service_client.py"", line 655, in deidentify_content
    request, retry=retry, timeout=timeout, metadata=metadata
  File ""/usr/local/lib/python3.7/site-packages/google/api_core/gapic_v1/method.py"", line 143, in __call__
    return wrapped_func(*args, **kwargs)
  File ""/usr/local/lib/python3.7/site-packages/google/api_core/retry.py"", line 286, in retry_wrapped_func
    on_error=on_error,
  File ""/usr/local/lib/python3.7/site-packages/google/api_core/retry.py"", line 184, in retry_target
    return target()
  File ""/usr/local/lib/python3.7/site-packages/google/api_core/timeout.py"", line 214, in func_with_timeout
    return func(*args, **kwargs)
  File ""/usr/local/lib/python3.7/site-packages/google/api_core/grpc_helpers.py"", line 59, in error_remapped_callable
    six.raise_from(exceptions.from_grpc_error(exc), exc)
  File ""&lt;string&gt;"", line 3, in raise_from
google.api_core.exceptions.InvalidArgument: 400 Received the following error message from Cloud KMS when unwrapping KmsWrappedCryptoKey ""projects/xxxx-xxx/locations/global/keyRings/dlp-key-ring-4/cryptoKeys/key9"": Decryption failed: the ciphertext is invalid.
xxxxs-MacBook-Pro:poc-bucket-flow-dlp xxxxxxxx$ python dlp3.py --verbosity=debug
Traceback (most recent call last):
  File ""/usr/local/lib/python3.7/site-packages/google/api_core/grpc_helpers.py"", line 57, in error_remapped_callable
    return callable_(*args, **kwargs)
  File ""/usr/local/lib/python3.7/site-packages/grpc/_channel.py"", line 826, in __call__
    return _end_unary_response_blocking(state, call, False, None)
  File ""/usr/local/lib/python3.7/site-packages/grpc/_channel.py"", line 729, in _end_unary_response_blocking
    raise _InactiveRpcError(state)
grpc._channel._InactiveRpcError: &lt;_InactiveRpcError of RPC that terminated with:
    status = StatusCode.INVALID_ARGUMENT
    details = ""Received the following error message from Cloud KMS when unwrapping KmsWrappedCryptoKey ""projects/xxxx-xxx/locations/global/keyRings/dlp-key-ring-4/cryptoKeys/key9"": Decryption failed: the ciphertext is invalid.""
    debug_error_string = ""{""created"":""@1583026339.185480000"",""description"":""Error received from peer ipv4:216.58.203.106:443"",""file"":""src/core/lib/surface/call.cc"",""file_line"":1056,""grpc_message"":""Received the following error message from Cloud KMS when unwrapping KmsWrappedCryptoKey ""projects/xxxx-xxx/locations/global/keyRings/dlp-key-ring-4/cryptoKeys/key9"": Decryption failed: the ciphertext is invalid."",""grpc_status"":3}""
&gt;

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File ""dlp3.py"", line 249, in &lt;module&gt;
    main()
  File ""dlp3.py"", line 246, in main
    test_deidentify_with_fpe()
  File ""dlp3.py"", line 240, in test_deidentify_with_fpe
    key_name=KEY_NAME,
  File ""dlp3.py"", line 101, in deidentify_with_fpe
    item=item,
  File ""/usr/local/lib/python3.7/site-packages/google/cloud/dlp_v2/gapic/dlp_service_client.py"", line 655, in deidentify_content
    request, retry=retry, timeout=timeout, metadata=metadata
  File ""/usr/local/lib/python3.7/site-packages/google/api_core/gapic_v1/method.py"", line 143, in __call__
    return wrapped_func(*args, **kwargs)
  File ""/usr/local/lib/python3.7/site-packages/google/api_core/retry.py"", line 286, in retry_wrapped_func
    on_error=on_error,
  File ""/usr/local/lib/python3.7/site-packages/google/api_core/retry.py"", line 184, in retry_target
    return target()
  File ""/usr/local/lib/python3.7/site-packages/google/api_core/timeout.py"", line 214, in func_with_timeout
    return func(*args, **kwargs)
  File ""/usr/local/lib/python3.7/site-packages/google/api_core/grpc_helpers.py"", line 59, in error_remapped_callable
    six.raise_from(exceptions.from_grpc_error(exc), exc)
  File ""&lt;string&gt;"", line 3, in raise_from
google.api_core.exceptions.InvalidArgument: 400 Received the following error message from Cloud KMS when unwrapping KmsWrappedCryptoKey ""projects/xxxx-xxx/locations/global/keyRings/dlp-key-ring-4/cryptoKeys/key9"": Decryption failed: the ciphertext is invalid.
</code></pre>

<p>I am passing the following parameters</p>

<ul>
<li>project=project_id</li>
<li>string=""My SSN is 372819127"" </li>
<li>info_types=[""US_SOCIAL_SECURITY_NUMBER""] </li>
<li>alphabet=""NUMERIC""</li>
<li>surrogate_type=None</li>
</ul>

<p>For key_name I passed the parameter in the format (THE project name here is masked)</p>

<pre><code> - key_name=(
    ""projects/xxxxxx/locations/global/keyRings/""
    ""dlp-key-ring-4/cryptoKeys/key9""
)
</code></pre>

<p>The wrapped text passed is in the following parameter, the key characters are masked</p>

<pre><code>- wrapped_key=(
    ""MIIxxxxxyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyy""
    ""D+Ixxxxxyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyy""
    ""MIIxxxxxyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyy""
    ""D+Ixxxxxyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyy""
    ""MIIxxxxxyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyy""
    ""MIIxxxxxyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyy""
    ""D+Ixxxxxyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyy""
    ""MIIxxxxxyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyy""
    ""yt1zhbQNhsLICCFMNDFJDBFHBDFVBSHDFNSSKSKSKDKLSDKLMBAAE=""
),
</code></pre>

<p>here is the code snippet</p>

<pre><code>    # [START dlp_deidentify_fpe]
def deidentify_with_fpe(
    project,
    string,
    info_types,
    alphabet=None,
    surrogate_type=None,
    key_name=None,
    wrapped_key=None,
):
    """"""Uses the Data Loss Prevention API to deidentify sensitive data in a
    string using Format Preserving Encryption (FPE).
    Args:
        project: The Google Cloud project id to use as a parent resource.
        item: The string to deidentify (will be treated as text).
        alphabet: The set of characters to replace sensitive ones with. For
            more information, see https://cloud.google.com/dlp/docs/reference/
            rest/v2beta2/organizations.deidentifyTemplates#ffxcommonnativealphabet
        surrogate_type: The name of the surrogate custom info type to use. Only
            necessary if you want to reverse the deidentification process. Can
            be essentially any arbitrary string, as long as it doesn't appear
            in your dataset otherwise.
        key_name: The name of the Cloud KMS key used to encrypt ('wrap') the
            AES-256 key. Example:
            key_name = 'projects/YOUR_GCLOUD_PROJECT/locations/YOUR_LOCATION/
            keyRings/YOUR_KEYRING_NAME/cryptoKeys/YOUR_KEY_NAME'
        wrapped_key: The encrypted ('wrapped') AES-256 key to use. This key
            should be encrypted using the Cloud KMS key specified by key_name.
    Returns:
        None; the response from the API is printed to the terminal.
    """"""
    # Import the client library
    import google.cloud.dlp

    # Instantiate a client
    dlp = google.cloud.dlp_v2.DlpServiceClient()

    # Convert the project id into a full resource id.
    parent = dlp.project_path(project)

    # The wrapped key is base64-encoded, but the library expects a binary
    # string, so decode it here.
    import base64

    wrapped_key = base64.b64decode(wrapped_key)


    # Construct FPE configuration dictionary
    crypto_replace_ffx_fpe_config = {
        ""crypto_key"": {
            ""kms_wrapped"": {
                ""wrapped_key"": wrapped_key,
                ""crypto_key_name"": key_name,
            }
        },
        ""common_alphabet"": alphabet,
    }

    # Add surrogate type
    if surrogate_type:
        crypto_replace_ffx_fpe_config[""surrogate_info_type""] = {
            ""name"": surrogate_type
        }

    # Construct inspect configuration dictionary
    inspect_config = {
        ""info_types"": [{""name"": info_type} for info_type in info_types]
    }

    # Construct deidentify configuration dictionary
    deidentify_config = {
        ""info_type_transformations"": {
            ""transformations"": [
                {
                    ""primitive_transformation"": {
                        ""crypto_replace_ffx_fpe_config"": crypto_replace_ffx_fpe_config
                    }
                }
            ]
        }
    }

    # Convert string to item
    item = {""value"": string}

    # Call the API
    response = dlp.deidentify_content(
        parent,
        inspect_config=inspect_config,
        deidentify_config=deidentify_config,
        item=item,
        #location_id=""us-east1"",
    )

    # Print results
    print(response.item.value)


# [END dlp_deidentify_fpe]
</code></pre>
"
"60482141","<p>In the CArchive step PyInstaller tries to bundle the Python DLLs. These names are set dependent on the version, and PyInstaller will return an empty string if it's an unsupported version of python. That is what is causing the error. Please use python 3.5-3.7</p>
","0","","3","2289","1152","280","424","60471485","60482141","<p>I've have seen many posts about this very same error code with many different answers and I still can't fix my problem. </p>

<p>The difference of mine from all the other posts is that I get the following:</p>

<pre><code>317 INFO: Building PKG because PKG-00.toc is non existent
318 INFO: Building PKG (CArchive) PKG-00.pkg
Traceback (most recent call last):
  File ""C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.8_3.8.752.0_x64__qbz5n2kfra8p0\lib\runpy.py"", line 193, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File ""C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.8_3.8.752.0_x64__qbz5n2kfra8p0\lib\runpy.py"", line 86, in _run_code
    exec(code, run_globals)
  File ""C:\Users\Christopher\Desktop\project\venv\Scripts\pyinstaller.exe\__main__.py"", line 7, in &lt;module&gt;
  File ""c:\users\christopher\desktop\project\venv\lib\site-packages\PyInstaller\__main__.py"", line 114, in run
    run_build(pyi_config, spec_file, **vars(args))
  File ""c:\users\christopher\desktop\project\venv\lib\site-packages\PyInstaller\__main__.py"", line 65, in run_build
    PyInstaller.building.build_main.main(pyi_config, spec_file, **kwargs)
  File ""c:\users\christopher\desktop\project\venv\lib\site-packages\PyInstaller\building\build_main.py"", line 729, in main
    build(specfile, kw.get('distpath'), kw.get('workpath'), kw.get('clean_build'))
  File ""c:\users\christopher\desktop\project\venv\lib\site-packages\PyInstaller\building\build_main.py"", line 676, in build
    exec(code, spec_namespace)
  File ""C:\Users\Christopher\Desktop\project\main.spec"", line 20, in &lt;module&gt;
    exe = EXE(pyz,
  File ""c:\users\christopher\desktop\project\venv\lib\site-packages\PyInstaller\building\api.py"", line 433, in __init__
    self.pkg = PKG(self.toc, cdict=kwargs.get('cdict', None),
  File ""c:\users\christopher\desktop\project\venv\lib\site-packages\PyInstaller\building\api.py"", line 199, in __init__
    self.__postinit__()
  File ""c:\users\christopher\desktop\project\venv\lib\site-packages\PyInstaller\building\datastruct.py"", line 160, in __postinit__
    self.assemble()
  File ""c:\users\christopher\desktop\project\venv\lib\site-packages\PyInstaller\building\api.py"", line 259, in assemble
    fnm = checkCache(fnm, strip=self.strip_binaries,
  File ""c:\users\christopher\desktop\project\venv\lib\site-packages\PyInstaller\building\utils.py"", line 213, in checkCache
    digest = cacheDigest(fnm, redirects)
  File ""c:\users\christopher\desktop\project\venv\lib\site-packages\PyInstaller\building\utils.py"", line 358, in cacheDigest
    with open(fnm, ""rb"") as f:
FileNotFoundError: [Errno 2] No such file or directory: ''
</code></pre>

<p>The file in question is '' (No file at all). I'm new to python and PyInstaller and I am really confused about this.</p>
"
"60471529","<p>We can try using a list comprehension along with <code>re.sub</code>:</p>

<pre><code>output = [re.sub(r'^&lt;a ', '&lt;a target=""_blank"" ', i) for i in list]
print(output)

['&lt;a target=""_blank"" href=""url_1""&gt;Title_1&lt;/a&gt;',
 '&lt;a target=""_blank"" href=""url_2""&gt;Title_2&lt;/a&gt;',
 '&lt;a target=""_blank"" href=""url_3""&gt;Title_3&lt;/a&gt;',
 '&lt;a target=""_blank"" href=""url_4""&gt;Title_4&lt;/a&gt;']
</code></pre>
","0","","1","379372","14513","4457","41845","60471506","60471529","<p>I have a list which each element is an urls with an <code>&lt;a&gt;</code> tag.
I need to add <code>target=""_blank""</code> after <code>&lt;a&gt;</code> and before <code>""href=""</code> for each element of the list</p>

<pre><code>list = [""&lt;a href=\""url_1\""&gt;Title_1&lt;/a&gt;"", 
    ""&lt;a href=\""url_2\""&gt;Title_2&lt;/a&gt;"", 
    ""&lt;a href=\""url_3\""&gt;Title_3&lt;/a&gt;"", 
    ""&lt;a href=\""url_4\""&gt;Title_4&lt;/a&gt;""]
</code></pre>
"
"60471568","<p>This is how to do it without regex. An alternative to @Tim Biegeleisen solution. Explanation in code comments:</p>

<pre><code>list = [""&lt;a href=\""url_1\""&gt;Title_1&lt;/a&gt;"",
    ""&lt;a href=\""url_2\""&gt;Title_2&lt;/a&gt;"",
    ""&lt;a href=\""url_3\""&gt;Title_3&lt;/a&gt;"",
    ""&lt;a href=\""url_4\""&gt;Title_4&lt;/a&gt;""]

new_list = []
# for each html string in the list
for html in list:
    # Create a new string concatenating the first 4 characters of html with  target=""_blank""  and the remainder of html string
    s = html[:3] + 'target=""_blank"" ' + html[3:]
    new_list.append(s)

print(new_list)
</code></pre>
","0","","0","1541","222","23","129","60471506","60471529","<p>I have a list which each element is an urls with an <code>&lt;a&gt;</code> tag.
I need to add <code>target=""_blank""</code> after <code>&lt;a&gt;</code> and before <code>""href=""</code> for each element of the list</p>

<pre><code>list = [""&lt;a href=\""url_1\""&gt;Title_1&lt;/a&gt;"", 
    ""&lt;a href=\""url_2\""&gt;Title_2&lt;/a&gt;"", 
    ""&lt;a href=\""url_3\""&gt;Title_3&lt;/a&gt;"", 
    ""&lt;a href=\""url_4\""&gt;Title_4&lt;/a&gt;""]
</code></pre>
"
"60476710","<p>Another option is to use the <a href=""https://book.pythontips.com/en/latest/map_filter.html#map"" rel=""nofollow noreferrer""><code>map</code></a> function to perform the <code>target</code> addition:</p>

<pre><code>inlist = [""&lt;a href=\""url_1\""&gt;Title_1&lt;/a&gt;"", 
    ""&lt;a href=\""url_2\""&gt;Title_2&lt;/a&gt;"", 
    ""&lt;a href=\""url_3\""&gt;Title_3&lt;/a&gt;"", 
    ""&lt;a href=\""url_4\""&gt;Title_4&lt;/a&gt;""]

newList = list(map(lambda elem: elem.replace('&lt;a', '&lt;a target=""blank""'), inlist))
print(newList)
</code></pre>

<p>Output:</p>

<pre><code>['&lt;a target=""blank"" href=""url_1""&gt;Title_1&lt;/a&gt;', '&lt;a target=""blank"" href=""url_2""&gt;Title_2&lt;/a&gt;', '&lt;a target=""blank"" href=""url_3""&gt;Title_3&lt;/a&gt;', '&lt;a target=""blank"" href=""url_4""&gt;Title_4&lt;/a&gt;']
</code></pre>

<p><strong>Note</strong>: Do not use <code>list</code> as variable name because it's a reserved Python keyword.</p>
","0","","0","6360","377","3","5416","60471506","60471529","<p>I have a list which each element is an urls with an <code>&lt;a&gt;</code> tag.
I need to add <code>target=""_blank""</code> after <code>&lt;a&gt;</code> and before <code>""href=""</code> for each element of the list</p>

<pre><code>list = [""&lt;a href=\""url_1\""&gt;Title_1&lt;/a&gt;"", 
    ""&lt;a href=\""url_2\""&gt;Title_2&lt;/a&gt;"", 
    ""&lt;a href=\""url_3\""&gt;Title_3&lt;/a&gt;"", 
    ""&lt;a href=\""url_4\""&gt;Title_4&lt;/a&gt;""]
</code></pre>
"
"60473364","<p>This is because the callback instance is recreated every time you run the script; it isn't saved with the model. As such, the first epoch will always begin from the default value which is either <code>np.Inf</code> or <code>-np.Inf</code> as per <a href=""https://github.com/keras-team/keras/blob/7a39b6c62d43c25472b2c2476bd2a8983ae4f682/keras/callbacks/callbacks.py#L683"" rel=""nofollow noreferrer"">this right here.</a></p>
","0","","2","1012","172","5","229","60471533","60473364","<p>I'm training a CNN model using keras.</p>

<p>After end of each epoch, I save the weights as checkpoints if the validation accuracy has improved.</p>

<pre><code>from keras.callbacks import ModelCheckpoint


checkpoint = ModelCheckpoint(checkpoint_path, monitor='val_accuracy', mode='max', 
save_best_only=True, verbose=1)

callbacks = [checkpoint]

#load checkpoints if existing
import os

num_of_epochs = 65
epochs_done = 0

if(os.path.exists(checkpoint_path)):
    model.load_weights(checkpoint_path)
    num_of_epochs = num_of_epochs - epochs_done
    print('checkpoints loaded')
</code></pre>

<p>When I restart training after stopping, this is how my first epoch output looks like.</p>

<pre><code>Epoch 1/65
425/425 [==============================] - 224s 526ms/step - loss: 2.1739 - accuracy: 0.2939 - val_loss: 2.1655 - val_accuracy: 0.2985

Epoch 00001: val_accuracy improved from -inf to 0.29846, saving model to checkpoints-finetuning.hdf5
</code></pre>

<p>I noticed this happening at at the first epoch every time I restart training. Why does it happen? Does my checkpoint file get overwritten by worse accurate weights each time I restart?</p>
"
"60471589","<p>Is very easy, in your example you can simply use the models.ForeingKey() method, this will work because that classroom can be linked to many students. But in the case where you have one model linked only to one other model you will use the models.OneToOne().</p>

<p>You will also have to enter the ""on_delete"" argument, this is telling django what to do with this attribute if the other model gets deleted from the database. The most common used is ""models.CASCADE"" which will delete the model as well but you can use others like (PROTECT, SET_NULL, SET_DEFAULT, etc)</p>

<p><a href=""https://docs.djangoproject.com/en/3.0/ref/models/fields/#module-django.db.models.fields.related"" rel=""nofollow noreferrer"">LINK</a> to official documentation just in case.</p>

<pre><code>class Student(models.Model):
    name = models.CharField(max_length=255)
    surname = models.CharField(max_length=255)
    age = models.IntegerField()
    classroom = models.ForeignKey(Item, on_delete=models.CASCADE)

    def __str__(self):
        return str(self.name) + "" - "" + str(self.surname)
</code></pre>
","2","2020-03-01 14:05:17","2","633","42","33","146","60471585","60471589","<p>Hello I have 2 models: </p>

<pre><code>class Classroom(models.Model):
    name = models.CharField(max_length=255)
    description = models.TextField()
    price = models.FloatField()

    def __str__(self):
        return self.name


class Student(models.Model):
    name = models.CharField(max_length=255)
    surname = models.CharField(max_length=255)
    age = models.IntegerField()
    classroom = &lt;---- How to link to classroom here

    def __str__(self):
        return str(self.name) + "" - "" + str(self.surname)
</code></pre>

<p>How do I create a link so I can store which classroom each student belongs to?
Many thanks!</p>
"
"60471714","<p><a href=""https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.filter.html"" rel=""nofollow noreferrer"">filter</a> out the columns to be merged; add ', ' and convert relevant columns from int to string. finally concat back to df.ID on the columns axis</p>

<pre><code>Merged_Dfs = (df.filter(like='Cat').astype(str)
             .add(', ')
             .add(df1.filter(like='Cat').astype(str)))

pd.concat([df.ID,
           Merged_Dfs
           ],axis=1)

    ID  Cat1    Cat2    Cat3
0   1   1, text 1, text 0, text
1   2   0, text 2, text 1, text
2   3   0, text 0, text 5, text
</code></pre>

<p>Alternatively, you can use pandas insert to hook back df.ID to Merged Dfs as the first column</p>

<pre><code>Merged_Dfs.insert(0,'ID',df.ID)

print(Merged_Dfs)
</code></pre>
","0","","2","13958","3315","15","1304","60471614","60471714","<p>I have two Data Frames with identical column names and identical IDs in the first column. In the first Data Frame I have int information and in the second - str.</p>

<p>Here's an example of what they look like:</p>

<pre><code>ID    Cat1    Cat2    Cat3  
1     1        1       0 
2     0        2       1 
3     0        0       5


ID    Cat1    Cat2    Cat3 
1     text    text    text 
2     text    text    text
3     text    text    text
</code></pre>

<p>I want to merge them into one DataFrame and combine information of two Data Frames into the same cells. So the result would look like this:</p>

<pre><code>ID    Cat1      Cat2         Cat3  
1    1, text   1, text     0, text 
2    0, text   2, text     1, text  
3    0, text   0, text     5, text
</code></pre>

<p>I tried use pandas.combine, but it didn't work properly.</p>

<p>Is it possible to solve this task?</p>
"
"60471759","<p>You can use <code>combine</code> to join the two dataframes using <code>pd.Series.str.cat</code> to join the elements of each dataframe:</p>

<pre><code>df1.set_index('ID').astype(str).combine(df2.set_index('ID'), lambda x,y: x.str.cat(y, sep=', '))
</code></pre>

<p>This requires setting the index as <code>ID</code> and having the numerics as strings.</p>

<p>Output:</p>

<pre><code>       Cat1     Cat2     Cat3
ID                           
1   1, text  1, text  0, text
2   0, text  2, text  1, text
3   0, text  0, text  5, text
</code></pre>
","0","","1","8332","312","225","547","60471614","60471714","<p>I have two Data Frames with identical column names and identical IDs in the first column. In the first Data Frame I have int information and in the second - str.</p>

<p>Here's an example of what they look like:</p>

<pre><code>ID    Cat1    Cat2    Cat3  
1     1        1       0 
2     0        2       1 
3     0        0       5


ID    Cat1    Cat2    Cat3 
1     text    text    text 
2     text    text    text
3     text    text    text
</code></pre>

<p>I want to merge them into one DataFrame and combine information of two Data Frames into the same cells. So the result would look like this:</p>

<pre><code>ID    Cat1      Cat2         Cat3  
1    1, text   1, text     0, text 
2    0, text   2, text     1, text  
3    0, text   0, text     5, text
</code></pre>

<p>I tried use pandas.combine, but it didn't work properly.</p>

<p>Is it possible to solve this task?</p>
"
"60471848","<p>You can use <code>pandas.DataFrame.conbine</code> to merge two data frames. However, you need to pass the correct function to attribute <code>func</code>. </p>

<hr>

<pre><code>merge = lambda x,y: [x,y]
df1.combine(df2, func = lambda s1,s2: s1.combine(s2, func = merge))
</code></pre>

<p>Note that the variable of this function is <code>pandas.Series</code>. Thus, <code>pandas.Series.combine</code> is called to get the correct result.</p>
","1","2020-03-01 22:34:33","1","46","0","0","2","60471614","60471714","<p>I have two Data Frames with identical column names and identical IDs in the first column. In the first Data Frame I have int information and in the second - str.</p>

<p>Here's an example of what they look like:</p>

<pre><code>ID    Cat1    Cat2    Cat3  
1     1        1       0 
2     0        2       1 
3     0        0       5


ID    Cat1    Cat2    Cat3 
1     text    text    text 
2     text    text    text
3     text    text    text
</code></pre>

<p>I want to merge them into one DataFrame and combine information of two Data Frames into the same cells. So the result would look like this:</p>

<pre><code>ID    Cat1      Cat2         Cat3  
1    1, text   1, text     0, text 
2    0, text   2, text     1, text  
3    0, text   0, text     5, text
</code></pre>

<p>I tried use pandas.combine, but it didn't work properly.</p>

<p>Is it possible to solve this task?</p>
"
"60471787","<p>My solution might be complicated, and I haven't worked with Django, nor REST api before. However, I was thinking along the lines of using Pathlib, and it loops through all of the apps, finding the location of the ViewSet. Then, using regex, finds the names of the ViewSets and writes them to a file with a list of all the things. Then, the routers.py reads the file, and loops through each ViewSet in the file.</p>
","0","","0","11","0","0","14","60471704","60471985","<p>Hello I've setup a Django project that includes a REST api, so far this is the project structure:</p>

<pre><code>django
â”‚
â”œâ”€â”€â”€apps
â”‚   â”œâ”€â”€â”€store
â”‚   |       admin.py
â”‚   |       apps.py
â”‚   |       models.py
â”‚   |       serializers.py
â”‚   |       tests.py
â”‚   |       urls.py
â”‚   |       views.py
â”‚   |       viewsets.py
â”‚   |       __init__.py
â”‚   â”œâ”€â”€â”€accounts 
â”‚           admin.py
â”‚           apps.py
â”‚           models.py
â”‚           serializers.py
â”‚           tests.py
â”‚           urls.py
â”‚           views.py
â”‚           viewsets.py
â”‚           __init__.py
â”œâ”€â”€â”€main
        asgi.py
        router.py
        settings.py
        urls.py
        wsgi.py
        __init__.py
</code></pre>

<p>Inside main/urls.py I have something like this (which is setting up the API url endpoint by including the routers.py):</p>

<pre><code>from django.contrib import admin
from django.urls import path, include
from .router import router

urlpatterns = [
    # Default urls
    path('admin/', admin.site.urls),
    path('api/', include(router.urls)),
    path('', include('apps.store.urls')),
]
</code></pre>

<p>Inside the main/routers.py I am registering all my viewsets for all the project:</p>

<pre><code>from rest_framework.routers import DefaultRouter
from apps.store.viewsets import ItemViewSet, PurchaseViewSet, ReceiptViewSet
from apps.accounts.viewsets import ProfileViewSet, TransactionViewSet

router = DefaultRouter()
router.register('items', ItemViewSet)
router.register('purchases', PurchaseViewSet)
router.register('receipts', ReceiptViewSet)
router.register('profiles', ProfileViewSet)
router.register('transactions', TransactionViewSet)
</code></pre>

<p>Everything works well but my issue is that in this routers.py I will have to register all the ViewSets for the whole project, I'm guessing this doesn't help with modularity and can make this file big and confusing.</p>

<p><strong>QUESTION:</strong> 
Is it possible to create one routers.py per app, and then somehow import and merge them in the main/routers.py or is there any other way of registering the viewsets for each app inside each respective app? Or is there some other recommended method?</p>

<p>I hope the question is clear, many thanks!</p>
"
"60471985","<p>I just found out that the best way is to import the router from the app and use the router.registry.extend method.</p>

<p>First in the routers.py I will name the router something unique to avoid name collisions when merging them</p>

<pre><code>router_store = DefaultRouter()
router_store.register('items', ItemViewSet)
router_store.register('purchases', PurchaseViewSet)
router_store.register('receipts', ReceiptViewSet)
</code></pre>

<p>Then the main routers.py, I will import all my routers, then create a new router and extend it using them routers.py:</p>

<pre><code>from store.routers import router_store
from accounts.routers import router_accounts

router = DefaultRouter()
router.registry.extend(router_store.registry)
router.registry.extend(router_accounts.registry)
</code></pre>
","0","2020-03-01 04:44:24","0","633","42","33","146","60471704","60471985","<p>Hello I've setup a Django project that includes a REST api, so far this is the project structure:</p>

<pre><code>django
â”‚
â”œâ”€â”€â”€apps
â”‚   â”œâ”€â”€â”€store
â”‚   |       admin.py
â”‚   |       apps.py
â”‚   |       models.py
â”‚   |       serializers.py
â”‚   |       tests.py
â”‚   |       urls.py
â”‚   |       views.py
â”‚   |       viewsets.py
â”‚   |       __init__.py
â”‚   â”œâ”€â”€â”€accounts 
â”‚           admin.py
â”‚           apps.py
â”‚           models.py
â”‚           serializers.py
â”‚           tests.py
â”‚           urls.py
â”‚           views.py
â”‚           viewsets.py
â”‚           __init__.py
â”œâ”€â”€â”€main
        asgi.py
        router.py
        settings.py
        urls.py
        wsgi.py
        __init__.py
</code></pre>

<p>Inside main/urls.py I have something like this (which is setting up the API url endpoint by including the routers.py):</p>

<pre><code>from django.contrib import admin
from django.urls import path, include
from .router import router

urlpatterns = [
    # Default urls
    path('admin/', admin.site.urls),
    path('api/', include(router.urls)),
    path('', include('apps.store.urls')),
]
</code></pre>

<p>Inside the main/routers.py I am registering all my viewsets for all the project:</p>

<pre><code>from rest_framework.routers import DefaultRouter
from apps.store.viewsets import ItemViewSet, PurchaseViewSet, ReceiptViewSet
from apps.accounts.viewsets import ProfileViewSet, TransactionViewSet

router = DefaultRouter()
router.register('items', ItemViewSet)
router.register('purchases', PurchaseViewSet)
router.register('receipts', ReceiptViewSet)
router.register('profiles', ProfileViewSet)
router.register('transactions', TransactionViewSet)
</code></pre>

<p>Everything works well but my issue is that in this routers.py I will have to register all the ViewSets for the whole project, I'm guessing this doesn't help with modularity and can make this file big and confusing.</p>

<p><strong>QUESTION:</strong> 
Is it possible to create one routers.py per app, and then somehow import and merge them in the main/routers.py or is there any other way of registering the viewsets for each app inside each respective app? Or is there some other recommended method?</p>

<p>I hope the question is clear, many thanks!</p>
"
"60471850","<p>Create your <code>Counter</code> as</p>

<pre><code>c = Counter(item['country']for item in item_data)
</code></pre>

<p>and itâ€™s now counted your countries up.</p>
","0","","1","18408","116","505","903","60471819","60471850","<p>I am looking to do the following within a generator that iterates through a ~5GB file:</p>

<pre><code>from collections import Counter
c=Counter()
lines_as_list = (line.strip().split('|') for line in open('file-00000-of-00001.csv'))
header = next(lines_as_list)
item_data = (dict(zip(header, data)) for data in lines_as_list)
totals_per_country = (c[item['country']]+=1 for item in item_data)
</code></pre>

<p>This of course fails due to trying to assign a value within the comprehension. What would be the suggested way to do this in a generator (without using a for loop or library such as pandas).</p>
"
"60471851","<p>One way would be to pass a generator of the countries to the <code>Counter</code>, as that takes an iterable. For example:</p>

<pre><code>&gt;&gt;&gt; countries = (item['country'] for item in item_data)
&gt;&gt;&gt; totals_per_country = Counter(countries) # not a generator, evaluates immediately
&gt;&gt;&gt; totals_per_country.most_common(5)
[('US', 299072), ('CA', 183927), ('GB', 150242), ('AU', 131295), ('DE', 100611)]
</code></pre>
","0","","0","95528","2897","13","6872","60471819","60471850","<p>I am looking to do the following within a generator that iterates through a ~5GB file:</p>

<pre><code>from collections import Counter
c=Counter()
lines_as_list = (line.strip().split('|') for line in open('file-00000-of-00001.csv'))
header = next(lines_as_list)
item_data = (dict(zip(header, data)) for data in lines_as_list)
totals_per_country = (c[item['country']]+=1 for item in item_data)
</code></pre>

<p>This of course fails due to trying to assign a value within the comprehension. What would be the suggested way to do this in a generator (without using a for loop or library such as pandas).</p>
"
"60471899","<p>Using the new Walrus operator in Python 3.8</p>

<pre class=""lang-py prettyprint-override""><code>(c[item['country']]:=c[item['country']]+1 for item in item_data)
</code></pre>

<p>This allows you to do assignments an expression, making it syntactically legal in places it otherwise is not, such as a comprehension</p>
","0","","0","1588","262","65","275","60471819","60471850","<p>I am looking to do the following within a generator that iterates through a ~5GB file:</p>

<pre><code>from collections import Counter
c=Counter()
lines_as_list = (line.strip().split('|') for line in open('file-00000-of-00001.csv'))
header = next(lines_as_list)
item_data = (dict(zip(header, data)) for data in lines_as_list)
totals_per_country = (c[item['country']]+=1 for item in item_data)
</code></pre>

<p>This of course fails due to trying to assign a value within the comprehension. What would be the suggested way to do this in a generator (without using a for loop or library such as pandas).</p>
"
"60471912","<p>You can use <code>extractall</code>: </p>

<pre><code>df2 = df.pop('Dimension').str.extractall('(\d+)')[0].unstack().astype(int) 
df2.columns = ['Amount', 'L', 'W', 'H']
</code></pre>

<p>Assuming you only have the one ""Dimension"" column, you are finished. Otherwise, concatenate this back to <code>df</code>: </p>

<pre><code>pd.concat([df, df2], axis=1)

   Index  Amount    L   W   H
0      0       1   43  32  34
1      1       1  120  80  74
2      2       2   26  26  32
3      3       1  120  80  81
</code></pre>
","0","","4","266035","10142","8528","64481","60471885","60471950","<p>I have a DataFrame that looks like this:</p>

<pre><code>|Index| Dimension |
|-----|-----------|
|0    |1@43X32X34 |
|1    |1@120X80X74|
|2    |2@26X26X32 |
|3    |1@120X80X81|
</code></pre>

<p>I want to extract the number from the Dimension column and split it into multiple column:</p>

<pre><code>|Index| Amount|Length|Width|Height|
|-----|-------|------|-----|------|
|0    |      1|    43|   32|    34|
|1    |      1|   120|   80|    74|
|2    |      2|    26|   26|    32|
|3    |      1|   120|   80|    81|
</code></pre>

<p>How to do that using the Pandas module in Python?
Thank you!</p>
"
"60471950","<p>You can use <a href=""https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.str.split.html"" rel=""nofollow noreferrer"">pandas str split</a> with expand=True, the delimiters are @ and X, so passing them in will ensure appropriate splits. You can then insert Index as the first column and rewrite the column names:</p>

<pre><code>M = df.Dimension.str.split('[@X]',expand=True)
M.insert(0,'Index',df.Index)
M.columns = ['Index','Amount','Length','Width','Height']


   Index    Amount  Length  Width   Height
0   0       1         43    32      34
1   1       1        120    80      74
2   2       2         26    26      32
3   3       1        120    80      81
</code></pre>
","0","","4","13958","3315","15","1304","60471885","60471950","<p>I have a DataFrame that looks like this:</p>

<pre><code>|Index| Dimension |
|-----|-----------|
|0    |1@43X32X34 |
|1    |1@120X80X74|
|2    |2@26X26X32 |
|3    |1@120X80X81|
</code></pre>

<p>I want to extract the number from the Dimension column and split it into multiple column:</p>

<pre><code>|Index| Amount|Length|Width|Height|
|-----|-------|------|-----|------|
|0    |      1|    43|   32|    34|
|1    |      1|   120|   80|    74|
|2    |      2|    26|   26|    32|
|3    |      1|   120|   80|    81|
</code></pre>

<p>How to do that using the Pandas module in Python?
Thank you!</p>
"
"60471974","<p>Information in your variables is stored during the execution of your script. It is not automatically carried across to <em>different</em> executions of your script. Each one is a blank slate. Even if it weren't, the first line of your program sets <code>list</code> to an empty dictionary.</p>

<p>At the moment, you're putting salt on your broccoli, eating it, then expecting the broccoli you eat tomorrow to <em>also</em> have salt on it.</p>

<p>You could serialise the dictionary to a file, that can be read back in on next execution, rather than starting with an empty dictionary each time.</p>
","3","","0","16086","826","623","2362","60471967","60471974","<p>I made a dictionary in IDE and made a function to take input from user and it takes the input but when I rerun that program and try to print the output It don`t show anything. 
Here is the code, help if anyone want to.</p>

<pre><code># Created dictionary.

list = {}

# Made a Function to save data.

def up():
    v = int(input(f""How many inputs you want to give : ""))

    for i in range(v):
        a = input(f""Give words you want to put : "")
        b = input(f""Assign : "")
        list.update({a:b})
    print(f""Saved"",{a:b})


value = input(f""What you want to do ? \nSee List or update it. \nIf you want to update type 'u' , If you want to see list type 's' "")


if value == ""s"":
    print(list)
elif value == ""u"":
    up()
</code></pre>
"
"60472247","<p>You will need recursion in order to support an undefined number of levels.</p>

<p>Assuming your levels always have 2 or 3 items in the lists at each level, the recursive function could look like this:</p>

<pre><code>a = ['foo', 'bar', ['can', 'haz']]

def f(a):
    k,v,b,*_ = a+[None]
    result = [{""key"":k,""val"":v}]
    if b: result.append(f(b))
    return result
</code></pre>

<p>output:</p>

<pre><code>print(f(a))

# [{'key': 'foo', 'val': 'bar'}, [{'key': 'can', 'val': 'haz'}]]


b = ['foo', 'bar', ['can', 'haz', ['boo','yah',['dino','dog']]]]
print(f(b))
[
  {'key': 'foo', 'val': 'bar'},
  [
     {'key': 'can', 'val': 'haz'},
     [
        {'key': 'boo', 'val': 'yah'},
        [
          {'key': 'dino', 'val': 'dog'}
        ]
     ]
  ]
]
</code></pre>
","3","2020-03-02 03:34:23","0","24359","14","17","1310","60471996","60500273","<pre><code>a = ['foo', 'bar', ['can', 'haz']]
</code></pre>

<p>Looking to apply a function to each pair of strings, replacing them, including those inside lists. E.g.,</p>

<pre><code>f = lambda k,v: {'key': k, 'val': v}
</code></pre>

<p>So that <code>f(a)</code> would become:</p>

<pre><code>[{'key': 'foo', 'val': 'bar'}, [{'key': 'can', 'val': 'haz'}]]
</code></pre>

<p>Above <code>a</code> is only 2 dimensions, but I would be interested in <em>k</em> dimensions. Started hacking something together with <a href=""https://boltons.readthedocs.io/en/latest/iterutils.html#boltons.iterutils.remap"" rel=""nofollow noreferrer""><code>boltons.iterutils.remap</code></a> before it became clear that replacing all non-list elements at each hierarchy level with a <code>dict</code> or other <code>f</code> is not the right use-case for itâ€¦</p>

<p>EDIT: Another example</p>

<pre><code># create some random variables, alternative: `locals().update({c: (round(â€¦`
a, b, c, d, e, f, g, h, i, j, k, l, m, n, o, p, q, r, s, t, u, v, w, x, y, z = tuple(
    (round(abs(random()) ** 10, 4)
     if randint(0, 1) % 2 == 0
     else randint(20, 50)
     if randint(0, 1) % 2 == 0
     else ('foo', 'bar', 'can', 'haz', 'bzr')[randint(0, 4)])
           for c in ascii_lowercase)

l1 = [a, b, c, d, e, f, g, [h, i, j, k],
      l, m, n, [o, p, q, r, [s, t, u, v, w, x, y, z], a, b], c, d, e]

g = lambda k,v: {'{}_key'.format(k): k, '{}_val'.format(k): v}
</code></pre>

<p>When there are pairs of adjacent to each other, it should apply the type constructor T to it, and join (I've got an <code>add_to</code> function supporting dicts, lists, and more) any previous directly adjacentâ€”with no list inbetwixtâ€”else the raw scalar should be concatenated onto the list at the same hierarchy it was at before. Here is the expected output of <code>g(l1)</code>, excluding evaluation of variables:</p>

<pre><code>[
    {'a_key': a, 'a_val': b,
     'c_key': c, 'c_val': d,
     'e_key': e, 'e_val': f},
    g,
    [
        {'h_key': h, 'h_val': i,
         'j_key': j, 'j_val': k}
    ],
    {'l_key': l, 'l_val': m},
    n,
    [
        {'o_key': o, 'o_val': p,
         'q_key': q, 'q_val': r},
        [
            {'s_key': s, 's_val': t,
             'u_key': u, 'u_val': v,
             'w_key': w, 'w_val': x,
             'y_key': y, 'y_val': z}
        ],
        {'a_key': a, 'a_val': b}
    ],
    {'c_key': c, 'c_val': d},
    e
]
</code></pre>
"
"60472555","<p>Assuming consecutive content of every each one of the lists is always either key-val pair or a list:</p>

<pre><code>a = ['foo', 'bar', ['can', 'haz']]

def f(a):
  itr = iter(a)
  return [f(a) if isinstance(x, list) else {'key': x, 'val': next(itr)} for x in itr]

# &gt;&gt;&gt; f(a)
# [{'key': 'foo', 'val': 'bar'}, [{'key': 'can', 'val': 'haz'}]]
</code></pre>

<hr>

<p><strong>Update:</strong></p>

<p>Ok, I must say this gave me a bit of a headache but since it's an interesting problem and great opportunity to learn something new, here it is.<br>A function that does <strong>exactly</strong><sup>1</sup> what you wanted and since you have some issues with recursive operations:</p>

<blockquote>
  <p>With your precise function and input I get <code>RecursionError: maximum recursion depth exceeded while calling a Python object</code></p>
</blockquote>

<p>It does it <strong>without recursion</strong>. I'm sure this is not the <em>ultimate</em> solution but it works:</p>

<pre><code>from functools import reduce
import operator

def traverse(lst):
  stack = [lst]
  res = [[]]

  substack = stack[0]
  subres = res[0]

  depth = 0

  while stack:
    if substack:
      if isinstance(substack[0], list):
        substack = substack[0]
        subres.append([])
        subres = subres[-1]
        depth += 1
      else:
        if len(substack) &gt; 1 and not isinstance(substack[1], list):
            subres.append({'key': substack.pop(0), 'val': substack.pop(0)})
        else:
          subres.append(substack.pop(0))
    else:
        substack = reduce(operator.getitem, [0] * depth, stack)
        subres = reduce(operator.getitem, [-1] * depth, res)
        depth -= 1
        substack.pop(0)

  return res[0]
</code></pre>

<p><a href=""http://pythontutor.com/live.html?fbclid=IwAR2jZeYE0C2kgQ72rMOXdLLKySXyHRn2PY-MUM8B6Ua67JcvXm5rlTybq9k#code=from%20random%20import%20random,%20randint%0Afrom%20string%20import%20ascii_lowercase%0Afrom%20functools%20import%20reduce%0Aimport%20operator%0A%0Aa,%20b,%20c,%20d,%20e,%20f,%20g,%20h,%20i,%20j,%20k,%20l,%20m,%20n,%20o,%20p,%20q,%20r,%20s,%20t,%20u,%20v,%20w,%20x,%20y,%20z%20%3D%20tuple%28%0A%20%20%20%20%28round%28abs%28random%28%29%29%20**%2010,%204%29%0A%20%20%20%20%20if%20randint%280,%201%29%20%25%202%20%3D%3D%200%0A%20%20%20%20%20else%20randint%2820,%2050%29%0A%20%20%20%20%20if%20randint%280,%201%29%20%25%202%20%3D%3D%200%0A%20%20%20%20%20else%20%28&#39;foo&#39;,%20&#39;bar&#39;,%20&#39;can&#39;,%20&#39;haz&#39;,%20&#39;bzr&#39;%29%5Brandint%280,%204%29%5D%29%0A%20%20%20%20%20%20%20%20%20%20%20for%20c%20in%20ascii_lowercase%29%0A%0Al1%20%3D%20%5Ba,%20b,%20c,%20d,%20e,%20f,%20g,%20%5Bh,%20i,%20j,%20k%5D,%0A%20%20%20%20%20%20l,%20m,%20n,%20%5Bo,%20p,%20q,%20r,%20%5Bs,%20t,%20u,%20v,%20w,%20x,%20y,%20z%5D,%20a,%20b%5D,%20c,%20d,%20e%5D%0A%20%20%20%20%20%20%0Adef%20traverse%28lst%29%3A%0A%20%20stack%20%3D%20%5Blst%5D%0A%20%20res%20%3D%20%5B%5B%5D%5D%0A%20%20%0A%20%20substack%20%3D%20stack%5B0%5D%0A%20%20subres%20%3D%20res%5B0%5D%0A%20%20%0A%20%20depth%20%3D%200%0A%0A%20%20while%20stack%3A%0A%20%20%20%20if%20substack%3A%0A%20%20%20%20%20%20if%20isinstance%28substack%5B0%5D,%20list%29%3A%0A%20%20%20%20%20%20%20%20substack%20%3D%20substack%5B0%5D%0A%20%20%20%20%20%20%20%20subres.append%28%5B%5D%29%0A%20%20%20%20%20%20%20%20subres%20%3D%20subres%5B-1%5D%0A%20%20%20%20%20%20%20%20depth%20%2B%3D%201%0A%20%20%20%20%20%20else%3A%0A%20%20%20%20%20%20%20%20if%20len%28substack%29%20%3E%201%20and%20not%20isinstance%28substack%5B1%5D,%20list%29%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20subres.append%28%7B&#39;key&#39;%3A%20substack.pop%280%29,%20&#39;val&#39;%3A%20substack.pop%280%29%7D%29%0A%20%20%20%20%20%20%20%20else%3A%0A%20%20%20%20%20%20%20%20%20%20subres.append%28substack.pop%280%29%29%0A%20%20%20%20else%3A%0A%20%20%20%20%20%20%20%20substack%20%3D%20reduce%28operator.getitem,%20%5B0%5D%20*%20depth,%20stack%29%0A%20%20%20%20%20%20%20%20subres%20%3D%20reduce%28operator.getitem,%20%5B-1%5D%20*%20depth,%20res%29%0A%20%20%20%20%20%20%20%20depth%20-%3D%201%0A%20%20%20%20%20%20%20%20substack.pop%280%29%0A%0A%20%20return%20res%5B0%5D%0A%0Aprint%28l1%29%20%20%0Aprint%28traverse%28l1%29%29&amp;cumulative=false&amp;curInstr=258&amp;heapPrimitives=nevernest&amp;mode=display&amp;origin=opt-live.js&amp;py=3&amp;rawInputLstJSON=%5B%5D&amp;textReferences=false"" rel=""nofollow noreferrer"">Live Demo</a></p>

<p><sub><em>1. I'm not exactly sure how you're supposed to know the exact pre-names for dict keys in your output example if you're passing just lists of list to the function so I'll leave it up to you.</em></sub></p>
","3","2020-03-04 02:30:27","0","387","77","3","26","60471996","60500273","<pre><code>a = ['foo', 'bar', ['can', 'haz']]
</code></pre>

<p>Looking to apply a function to each pair of strings, replacing them, including those inside lists. E.g.,</p>

<pre><code>f = lambda k,v: {'key': k, 'val': v}
</code></pre>

<p>So that <code>f(a)</code> would become:</p>

<pre><code>[{'key': 'foo', 'val': 'bar'}, [{'key': 'can', 'val': 'haz'}]]
</code></pre>

<p>Above <code>a</code> is only 2 dimensions, but I would be interested in <em>k</em> dimensions. Started hacking something together with <a href=""https://boltons.readthedocs.io/en/latest/iterutils.html#boltons.iterutils.remap"" rel=""nofollow noreferrer""><code>boltons.iterutils.remap</code></a> before it became clear that replacing all non-list elements at each hierarchy level with a <code>dict</code> or other <code>f</code> is not the right use-case for itâ€¦</p>

<p>EDIT: Another example</p>

<pre><code># create some random variables, alternative: `locals().update({c: (round(â€¦`
a, b, c, d, e, f, g, h, i, j, k, l, m, n, o, p, q, r, s, t, u, v, w, x, y, z = tuple(
    (round(abs(random()) ** 10, 4)
     if randint(0, 1) % 2 == 0
     else randint(20, 50)
     if randint(0, 1) % 2 == 0
     else ('foo', 'bar', 'can', 'haz', 'bzr')[randint(0, 4)])
           for c in ascii_lowercase)

l1 = [a, b, c, d, e, f, g, [h, i, j, k],
      l, m, n, [o, p, q, r, [s, t, u, v, w, x, y, z], a, b], c, d, e]

g = lambda k,v: {'{}_key'.format(k): k, '{}_val'.format(k): v}
</code></pre>

<p>When there are pairs of adjacent to each other, it should apply the type constructor T to it, and join (I've got an <code>add_to</code> function supporting dicts, lists, and more) any previous directly adjacentâ€”with no list inbetwixtâ€”else the raw scalar should be concatenated onto the list at the same hierarchy it was at before. Here is the expected output of <code>g(l1)</code>, excluding evaluation of variables:</p>

<pre><code>[
    {'a_key': a, 'a_val': b,
     'c_key': c, 'c_val': d,
     'e_key': e, 'e_val': f},
    g,
    [
        {'h_key': h, 'h_val': i,
         'j_key': j, 'j_val': k}
    ],
    {'l_key': l, 'l_val': m},
    n,
    [
        {'o_key': o, 'o_val': p,
         'q_key': q, 'q_val': r},
        [
            {'s_key': s, 's_val': t,
             'u_key': u, 'u_val': v,
             'w_key': w, 'w_val': x,
             'y_key': y, 'y_val': z}
        ],
        {'a_key': a, 'a_val': b}
    ],
    {'c_key': c, 'c_val': d},
    e
]
</code></pre>
"
"60500273","<p>There's a pile of mess down below but the core algorithm in <code>solution()</code> doesn't seem so bad.  I can't say I like the <code>sentinel</code> there but...  it made everything else tidy.</p>

<p><a href=""https://repl.it/@altendky/ChartreuseWeightyRoot-10"" rel=""nofollow noreferrer"">https://repl.it/@altendky/ChartreuseWeightyRoot-10</a></p>

<pre class=""lang-py prettyprint-override""><code>import functools
import itertools
import random
import string

import attr
import toolz


@attr.s(frozen=True)
class Example:
    source = attr.ib()
    target = attr.ib()
    group_handler = attr.ib()


def random_example():
    a, b, c, d, e, f, g, h, i, j, k, l, m, n, o, p, q, r, s, t, u, v, w, x, y, z = tuple(
        (round(abs(random.random()) ** 10, 4)
        if random.randint(0, 1) % 2 == 0
        else random.randint(20, 50)
        if random.randint(0, 1) % 2 == 0
        else ('foo', 'bar', 'can', 'haz', 'bzr')[random.randint(0, 4)])
            for c in string.ascii_lowercase)

    l1 = [a, b, c, d, e, f, g, [h, i, j, k],
        l, m, n, [o, p, q, r, [s, t, u, v, w, x, y, z], a, b], c, d, e]

    auauughhghhhh = [
        {f'{a}_key': a, f'{a}_val': b,
        f'{c}_key': c, f'{c}_val': d,
        f'{e}_key': e, f'{e}_val': f},
        g,
        [
            {f'{h}_key': h, f'{h}_val': i,
            f'{j}_key': j, f'{j}_val': k}
        ],
        {f'{l}_key': l, f'{l}_val': m},
        n,
        [
            {f'{o}_key': o, f'{o}_val': p,
            f'{q}_key': q, f'{q}_val': r},
            [
                {f'{s}_key': s, f'{s}_val': t,
                f'{u}_key': u, f'{u}_val': v,
                f'{w}_key': w, f'{w}_val': x,
                f'{y}_key': y, f'{y}_val': z}
            ],
            {f'{a}_key': a, f'{a}_val': b}
        ],
        {f'{c}_key': c, f'{c}_val': d},
        e
    ]

    g = lambda k,v: {'{}_key'.format(k): k, '{}_val'.format(k): v}

    return Example(
        source=l1,
        target=auauughhghhhh,
        group_handler=functools.partial(process_group, paired_sequence_handler=lambda s: build_dict_by_update(s, g)),
    )


def process_group(group, paired_sequence_handler):
    processed_group = []

    if len(group) == 0:
        return processed_group

    odd = (len(group) % 2) != 0
    raw_pairs = group[:-1] if odd else group
    pairs = toolz.partition_all(2, raw_pairs)
    result = paired_sequence_handler(pairs)

    processed_group.append(result)

    if odd:
        processed_group.append(group[-1])

    return processed_group


def build_dict_by_update(sequence, pair_handler):
    result = {}
    for pair in sequence:
        result.update(pair_handler(*pair))

    return result


examples = [
    Example(
        source=['foo', 'bar', ['can', 'haz']],
        target=[{'key': 'foo', 'val': 'bar'}, [{'key': 'can', 'val': 'haz'}]],
        group_handler=functools.partial(process_group, paired_sequence_handler=lambda s: build_dict_by_update(s, lambda k,v: {'key': k, 'val': v})),
    ),
    random_example(),
]


def solution(source, group_handler):
    built = []
    group = []

    sentinel = object()

    for value in itertools.chain(source, [sentinel]):
        if not isinstance(value, list) and value is not sentinel:
            group.append(value)
            continue

        built.extend(group_handler(group))
        group = []

        if value is sentinel:
            break

        result = solution(
            source=value,
            group_handler=group_handler,
        )
        built.append(result)

    return built



for example in examples:
    result = solution(
        source=example.source,
        group_handler=example.group_handler,
    )

    succeeded = result == example.target

    print('?', succeeded)

    if not succeeded:
        print('?  ', example.target)
        print('?  ', result)
</code></pre>
","0","","1","3745","220","7","271","60471996","60500273","<pre><code>a = ['foo', 'bar', ['can', 'haz']]
</code></pre>

<p>Looking to apply a function to each pair of strings, replacing them, including those inside lists. E.g.,</p>

<pre><code>f = lambda k,v: {'key': k, 'val': v}
</code></pre>

<p>So that <code>f(a)</code> would become:</p>

<pre><code>[{'key': 'foo', 'val': 'bar'}, [{'key': 'can', 'val': 'haz'}]]
</code></pre>

<p>Above <code>a</code> is only 2 dimensions, but I would be interested in <em>k</em> dimensions. Started hacking something together with <a href=""https://boltons.readthedocs.io/en/latest/iterutils.html#boltons.iterutils.remap"" rel=""nofollow noreferrer""><code>boltons.iterutils.remap</code></a> before it became clear that replacing all non-list elements at each hierarchy level with a <code>dict</code> or other <code>f</code> is not the right use-case for itâ€¦</p>

<p>EDIT: Another example</p>

<pre><code># create some random variables, alternative: `locals().update({c: (round(â€¦`
a, b, c, d, e, f, g, h, i, j, k, l, m, n, o, p, q, r, s, t, u, v, w, x, y, z = tuple(
    (round(abs(random()) ** 10, 4)
     if randint(0, 1) % 2 == 0
     else randint(20, 50)
     if randint(0, 1) % 2 == 0
     else ('foo', 'bar', 'can', 'haz', 'bzr')[randint(0, 4)])
           for c in ascii_lowercase)

l1 = [a, b, c, d, e, f, g, [h, i, j, k],
      l, m, n, [o, p, q, r, [s, t, u, v, w, x, y, z], a, b], c, d, e]

g = lambda k,v: {'{}_key'.format(k): k, '{}_val'.format(k): v}
</code></pre>

<p>When there are pairs of adjacent to each other, it should apply the type constructor T to it, and join (I've got an <code>add_to</code> function supporting dicts, lists, and more) any previous directly adjacentâ€”with no list inbetwixtâ€”else the raw scalar should be concatenated onto the list at the same hierarchy it was at before. Here is the expected output of <code>g(l1)</code>, excluding evaluation of variables:</p>

<pre><code>[
    {'a_key': a, 'a_val': b,
     'c_key': c, 'c_val': d,
     'e_key': e, 'e_val': f},
    g,
    [
        {'h_key': h, 'h_val': i,
         'j_key': j, 'j_val': k}
    ],
    {'l_key': l, 'l_val': m},
    n,
    [
        {'o_key': o, 'o_val': p,
         'q_key': q, 'q_val': r},
        [
            {'s_key': s, 's_val': t,
             'u_key': u, 'u_val': v,
             'w_key': w, 'w_val': x,
             'y_key': y, 'y_val': z}
        ],
        {'a_key': a, 'a_val': b}
    ],
    {'c_key': c, 'c_val': d},
    e
]
</code></pre>
"
"60472032","<p>Use <a href=""https://pandas.pydata.org/docs/user_guide/io.html#csv-text-files"" rel=""nofollow noreferrer"">Pandas</a> for better manipulation of data</p>

<pre><code>import pandas as pd
df = pd.read_csv(filename, sep=' ', header=None)
</code></pre>
","2","","0","7612","912","171","1052","60472015","60472280","<p>I am trying to convert a file listing into structured data. 
This is a standard file listing from windows as per below.</p>

<p>Currently im splitting this up using spaces. 
First replacing multiple spaces into a single space then splitting on space. But i feel like this can be better done (or assume it can be better done) with regex and matching/grouping? </p>

<p>My current code looks like this. </p>

<pre><code>def extract_columns_from_file_name(text, curr_dir, mappedProductNames):    

text = re.sub('\s+',' ',text)
space_location = text.find("" "")
date = text[0:space_location]
text = text[space_location+1:len(text)]

space_location = text.find("" "")
timeA = text[0:space_location]
text = text[space_location+1:len(text)]

space_location = text.find("" "")
timeB = text[0:space_location]
text = text[space_location+1:len(text)]

time = timeA + "" "" + timeB

space_location = text.find("" "")
size = text[0:space_location]
size = re.sub(',','',size)
text = text[space_location+1:len(text)]
</code></pre>

<p>The text i am converting looks like this.</p>

<pre><code>28/11/2019  05:26 PM     2,074,273,364 jdev_suite_122130_win64.exe
</code></pre>
"
"60472047","<p>You can simply use split that will split based on space and will return you a list with all the fields</p>

<pre><code>fields = text.split()
print (fields)
</code></pre>

<p>The output will be &amp; you can use it as you want</p>

<pre><code>['28/11/2019', '05:26', 'PM', '2,074,273,364', 'jdev_suite_122130_win64.exe']     
</code></pre>
","1","","1","802","15","1","31","60472015","60472280","<p>I am trying to convert a file listing into structured data. 
This is a standard file listing from windows as per below.</p>

<p>Currently im splitting this up using spaces. 
First replacing multiple spaces into a single space then splitting on space. But i feel like this can be better done (or assume it can be better done) with regex and matching/grouping? </p>

<p>My current code looks like this. </p>

<pre><code>def extract_columns_from_file_name(text, curr_dir, mappedProductNames):    

text = re.sub('\s+',' ',text)
space_location = text.find("" "")
date = text[0:space_location]
text = text[space_location+1:len(text)]

space_location = text.find("" "")
timeA = text[0:space_location]
text = text[space_location+1:len(text)]

space_location = text.find("" "")
timeB = text[0:space_location]
text = text[space_location+1:len(text)]

time = timeA + "" "" + timeB

space_location = text.find("" "")
size = text[0:space_location]
size = re.sub(',','',size)
text = text[space_location+1:len(text)]
</code></pre>

<p>The text i am converting looks like this.</p>

<pre><code>28/11/2019  05:26 PM     2,074,273,364 jdev_suite_122130_win64.exe
</code></pre>
"
"60472280","<p>You can do it by regex like this:</p>

<pre><code>import re

text = ""28/11/2019  05:26 PM     2,074,273,364 jdev_suite_122130_win64.exe""

m = re.match(r'(\d+/\d+/\d+) +(\d{2}:\d{2} (?:AM|PM)) +([0-9,]+) ([\w.]+)', text)
if m:
    print(m.groups())
</code></pre>

<p>Output:</p>

<pre><code>('28/11/2019', '05:26 PM', '2,074,273,364', 'jdev_suite_122130_win64.exe')
</code></pre>
","3","2020-03-01 05:57:16","1","5541","802","41","331","60472015","60472280","<p>I am trying to convert a file listing into structured data. 
This is a standard file listing from windows as per below.</p>

<p>Currently im splitting this up using spaces. 
First replacing multiple spaces into a single space then splitting on space. But i feel like this can be better done (or assume it can be better done) with regex and matching/grouping? </p>

<p>My current code looks like this. </p>

<pre><code>def extract_columns_from_file_name(text, curr_dir, mappedProductNames):    

text = re.sub('\s+',' ',text)
space_location = text.find("" "")
date = text[0:space_location]
text = text[space_location+1:len(text)]

space_location = text.find("" "")
timeA = text[0:space_location]
text = text[space_location+1:len(text)]

space_location = text.find("" "")
timeB = text[0:space_location]
text = text[space_location+1:len(text)]

time = timeA + "" "" + timeB

space_location = text.find("" "")
size = text[0:space_location]
size = re.sub(',','',size)
text = text[space_location+1:len(text)]
</code></pre>

<p>The text i am converting looks like this.</p>

<pre><code>28/11/2019  05:26 PM     2,074,273,364 jdev_suite_122130_win64.exe
</code></pre>
"
"60472126","<p>Look for week_number where holiday == 1. Then convert the remaining 0s to 1 by assigning Holiday to 1 for that particular week number. Last part is to remove duplicates based on subset = ['Week_number','Description']</p>

<pre><code>df['Qty'] = df.groupby(['Description','Week_number']).Qty.transform('sum')

cond = df.query('Holiday ==1').Week_number.unique()

df['Holiday'] = np.where(df.Week_number.isin(cond),1,df.Holiday)

df = df.drop_duplicates(['Week_number','Description'])

    Week_number Holiday Description  Qty
0       38          1       A        11
2       38          1       B         1
3       38          1       C         1
4       40          0       A         1
</code></pre>
","4","2020-03-01 07:38:13","1","13958","3315","15","1304","60472025","60472126","<pre><code>Week_number   Holiday Description  Qty
38              1        A          5
38              0        A          6
38              0        B          1
38              1        C          1
40              0        A          1
</code></pre>

<p>I want to find duplicates for same Week_number and Description. If we take example as above above Week_number 38 and Desciption A there are 2 records of it. Then I want to get sum of those 2 Qty so it will be 11. 
Finally merge those 2 records and display sum of the Qty and Holiday as 1.</p>

<pre><code>Week_number   Holiday Description  Qty
38              1        A          11
38              0        B          1
38              1        C          1
40              0        A          1
</code></pre>

<p>Again check the duplicates for Week_number 38 and there will be 3 records of it. And change Holiday to 1 of all the records which has same Week_number.</p>

<pre><code>Week_number   Holiday Description  Qty
38              1        A          11
38              1        B          1
38              1        C          1
40              0        A          1
</code></pre>

<p>Any comments how to do that?
Thanks</p>
"
"60472235","<p>The exact real number arithmetic product of 10 and 0.1000000000000000055511151231257827021181583404541015625, the IEEE 754 64-bit binary representation of 0.1, is 1.000000000000000055511151231257827021181583404541015625.</p>

<p>It is not exactly representable. It is bracketed by 1.0 and 1.0000000000000002220446049250313080847263336181640625</p>

<p>It is closer to 1.0, so that is the round-to-nearest result of the multiplication.</p>

<p>I calculated the numbers using a short Java program:</p>

<pre><code>import java.math.BigDecimal;

public strictfp class Test {
    public static void main(String[] args) {
        BigDecimal rawTenth = new BigDecimal(0.1);
        BigDecimal realProduct = rawTenth.multiply(BigDecimal.TEN);
        System.out.println(realProduct);
        System.out.println(new BigDecimal(Math.nextUp(1.0)));
    }
}
</code></pre>

<p>Output:</p>

<pre><code>1.0000000000000000555111512312578270211815834045410156250
1.0000000000000002220446049250313080847263336181640625
</code></pre>
","4","2020-03-01 16:11:29","4","24773","2187","18","5088","60472069","60472235","<p>I was working with floating point numbers recently and I realized a something I didn't expect about floating point numbers. Here is an example</p>

<pre class=""lang-py prettyprint-override""><code>a = 0.1
print(f""{a:0.20f}"")
#'0.10000000000000000555'
b = a * 10
print(f""{b:0.20f}"")
#'1.00000000000000000000'
</code></pre>

<p>I would expect the last print to output <code>1.00000000000000005551</code> (i.e., 1 followed by digits 1 through 21 of <code>0.1</code>). </p>

<p>What I am curious about is why the floating point error disappears when multiplying by 10. The normal rules of arithmetic suggests that the floating point error would be propagated, but that isn't actually happening. Why does this take place? Is there a way to avoid it? </p>
"
"60475395","<p>This answer shows how you can determine that converting 1/10 to floating-point and multiplying by 10 will produce exactly 1 using just a little arithmetic; there is no need to calculate large or precise numbers.</p>

<p>Your Python implementation uses the common IEEE-754 binary64 format. (Python is not strict about which floating-point format implementations should use.) In this format, numbers are represented, in effect, as a sign (+ or âˆ’) applied to some 53-bit integer multiplied by some power of two. Because 2<sup>âˆ’4</sup> â‰¤ 1/10 &lt; 2<sup>âˆ’3</sup>, the representable number nearest 1/10 is some integer M multiplied by 2<sup>âˆ’3âˆ’53</sup>. (The âˆ’53 scales the 53-bit integer to between Â½ and 1, and the âˆ’3 scales that to between 2<sup>âˆ’4</sup> and 2<sup>âˆ’3</sup>.) Letâ€™s call that representable number x.</p>

<p>Then we have x = Mâ€¢2<sup>âˆ’56</sup> = 1/10 + e, where e is some rounding error that occurs when we round 1/10 to the nearest representable value. Since we round to the nearest representable value, |e| â‰¤ Â½â€¢2<sup>âˆ’56</sup> = 2<sup>âˆ’57</sup>.</p>

<p>To find exactly what e is, multiply 1/10 by 2<sup>56</sup>. <a href=""https://www.wolframalpha.com/input/?i=2**56%2F10"" rel=""nofollow noreferrer"">WolframAlpha</a> tells us it is 7205759403792793+3/5. To get the nearest representable value, we should round up, so M = 7205759403792794 and e = 2/5 â€¢ 2<sup>âˆ’56</sup>. Although I used WolframAlpha to illustrate this, we do not need M, and we can find e by observing the pattern in powers of two modulo 10: 2<sup>1</sup>â†’2, 2<sup>2</sup>â†’4, 2<sup>3</sup>â†’8, 2<sup>4</sup>â†’6, 2<sup>5</sup>â†’2, 2<sup>6</sup>â†’4, and so the pattern repeats with a cycle of 4, and 56 modulo 4 is 0, so 2<sup>56</sup> modulo 10 has the same remainder as 2<sup>4</sup>, 6, so the fraction is 6/10 = 3/5. We know that should round to the nearest integer, 1, so e = 2/5 â€¢ 2<sup>âˆ’56</sup>.</p>

<p>So x = Mâ€¢2<sup>âˆ’56</sup> = 1/10 + 2/5â€¢2<sup>âˆ’56</sup>.</p>

<p>Now we can figure out the result of computing 10â€¢x with floating-point arithmetic. The result is as if we first compute 10â€¢x with real-number arithmetic and then round to the nearest representable value. In real-number arithmetic, 10â€¢x = 10â€¢(1/10 + 2/5â€¢2<sup>âˆ’56</sup>) = 1 + 10â€¢2/5â€¢2<sup>âˆ’56</sup> = 1 + 4â€¢2<sup>âˆ’56</sup> = 1 + 2<sup>âˆ’54</sup>. The two neighboring representable values are 1 and 1 + 2<sup>âˆ’52</sup>, and 1 + 2<sup>âˆ’54</sup> is closer to 1 than it is to 1 + 2<sup>âˆ’52</sup>. So the result is 1.</p>
","3","2020-03-01 17:25:21","2","138014","2844","4443","11797","60472069","60472235","<p>I was working with floating point numbers recently and I realized a something I didn't expect about floating point numbers. Here is an example</p>

<pre class=""lang-py prettyprint-override""><code>a = 0.1
print(f""{a:0.20f}"")
#'0.10000000000000000555'
b = a * 10
print(f""{b:0.20f}"")
#'1.00000000000000000000'
</code></pre>

<p>I would expect the last print to output <code>1.00000000000000005551</code> (i.e., 1 followed by digits 1 through 21 of <code>0.1</code>). </p>

<p>What I am curious about is why the floating point error disappears when multiplying by 10. The normal rules of arithmetic suggests that the floating point error would be propagated, but that isn't actually happening. Why does this take place? Is there a way to avoid it? </p>
"
"60478634","<p>Through experimentation and further research I discovered that the fastest method of checking the Levenshtein ratio is through the <code>python-Levenshtein</code> library itself. The function <code>Levenshtein.ratio()</code> is <em>significantly faster</em> (for one game the entire search takes only 0.05 seconds on average) compared to using any function in fuzzywuzzy or difflib, likely because of its simplicity and C implementation. I used this function in a for loop iterating over every name in the master list to get the best answer:</p>

<pre class=""lang-py prettyprint-override""><code>from Levenshtein import ratio

metric = 0
for master_name in master_names:
    new_metric = ratio(name, master_name)
    if (new_metric &gt; metric):
        metric = new_metric
</code></pre>

<p>In conclusion I say that the fastest method of searching for the highest percent Levenshtein distance between a string and a list of strings is to iterate over the list of strings, use <code>Levenshtein.ratio()</code> to get the ratio of each string compared with the first string, and then check for the highest value ratio on each iteration.</p>
","0","","2","156","22","1","11","60472100","60478634","<p>I'm writing a program that compares a smaller list of game titles to a master list of many games to see which games in the smaller list more closely match with the titles of the games in the master list than others. In order to do this, I've been checking the Levenshtein distance (in percent form) between each game in the smaller list and <em>every</em> game in the master list and taking the maximum of all of these values (the lower the maximum percentage, the more unique the game has to be) using both the <code>difflib</code> and the <code>fuzzywuzzy</code> modules. The problem that I'm having is that a typical search using either <code>process.extractOne()</code> or <code>difflib.get_close_matches()</code> takes about 5+ seconds per game (with 38000+ strings in the master list), and I have about 4500 games to search through (5 * 4500 is about 6 hours and 15 minutes, which I don't have time for).</p>

<p>In hopes of finding a better and faster method of searching through a list of strings, I'm asking here what the fastest method in python of searching for the highest percent Levenshtein distance between a string and a list of strings is. If there is no better way than by using the two functions above or writing some other looping code, then please say so.</p>

<p>The two functions I used in specific to search for the highest distance are these:</p>

<pre class=""lang-py prettyprint-override""><code>metric = process.extractOne(name, master_names)[1] / 100
metric = fuzz.ratio(name, difflib.get_close_matches(name, master_names, 1, 0)[0]) / 100
</code></pre>
"
"60472214","<p>You can't do:</p>

<pre><code>split.endswith('ay','ey','iy')
</code></pre>

<p>The <code>endswith</code> method only accepts a single string argument, optionally followed by <code>start</code> and <code>end</code> indices.  Instead, you can test each suffix individually, or you can avoid <code>endswith</code> and instead do:</p>

<pre><code>split[-2:] in ('ay', 'ey', 'iy')
</code></pre>

<p>which will do what you want.</p>

<p>Update:  You <em>can</em> have <code>endswith</code> check for multiple suffixes at once if you pass a <code>tuple</code> for the first argument.  So a better way to do this is:</p>

<pre><code>split.endswith(('ay','ey','iy'))
</code></pre>

<p>The extra parentheses create a <code>tuple</code> that's passed as the first (and only) argument to <code>endswith</code>.  This is closer to what you wanted to do in the first place.</p>
","0","2020-03-02 07:54:45","0","16811","333","672","2135","60472182","60472214","<p>I'm attempting to write a function that would pluralize all the words of a user's input. These are the criteria I want to worry about about:</p>

<ul>
<li>if the word ends in a 'y' preceded by a vowel (a,e,i,o,u), add 's';
e.g. monkey -> monkeys </li>
<li>if the word ends in 'y' not preceded by a
vowel, remove the 'y' and add 'ies', e.g. fly -> flies</li>
<li>if the word ends in 'o','ch', 's', 'sh', 'x', or 'z' then add 'es' otherwise,
just add 's'</li>
</ul>

<p>For example, if the user enters: 'monkey elephant potato porch fly button fish fox buzz', then the output should be 'monkeys elephants potatoes porches flies buttons fishes foxes buzzes'</p>

<p>Here's what I have so far:</p>

<pre><code>#Ask for user input
word = input(""What would you like to convert to plural?: "")

#Separate words in input into list
splitstring = word.split()
conversionlist = list(splitstring)
##list check
#print(conversionlist)


def plural(splitstring):
    #For every single word in string
    for split in conversionlist:
        #If vowel before y (endswith only takes 3 arguments)
        if split.endswith('ay','ey','iy') or split.endswith('oy','uy'):
            return split + 's'
        #If not a vowel before y
        if split.endswith('y') and not (split.endswith('ay','ey','iy') or split.endswith('oy','uy')):
            #Remove the y and append the appropriate ending
            return split[:-1] + 'ies'
        #o, ch, s, sh, x, or z endings
        if split.endswith('o') or split.endswith('ch') or split.endswith('s') or split.endswith('sh') or split.endswith('x') or split.endswith('z'):
            return split + 'es'
        #general case
        else:
            return split + 's'

plural(splitstring)

#Append all converted plurals into singular list and print output
totalplural = "" "".join(plural(splitstring))
print(totalplural)
</code></pre>

<p>Right now I'm getting a ""TypeError: slice indices must be integers or None or have an <strong>index</strong> method"" on line 25. Any thoughts on how I could modify the code to get it to do what I want it to do?</p>
"
"60472475","<h3>Firstly</h3>
<p>Your question is very ambiguous and I recommend reading this <a href=""https://stackoverflow.com/questions/20109391/how-to-make-good-reproducible-pandas-examples"">link</a> in @sammywemmy's comment. If I understand your problem correctly... we'll talk about this mask first:</p>
<pre><code>df.columns[      
    (df == 1)        # mask 
    .any(axis=0)     # mask
]
</code></pre>
<p>What's happening? Lets work our way outward starting from within <code>df.columns[**HERE**]</code> :</p>
<ol>
<li><code>(df == 1)</code> makes a boolean mask of the <code>df</code> with <code>True</code>/<code>False</code>(<code>1</code>/<code>0</code>)</li>
<li><code>.any()</code> as per the <a href=""https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.any.html"" rel=""nofollow noreferrer"">docs</a>:</li>
</ol>
<blockquote>
<p>&quot;Returns False unless there is at least one element within a series or along a Dataframe axis that is True or equivalent&quot;.</p>
</blockquote>
<p>This gives us a handy <code>Series</code> to mask the column names with.</p>
<p><strong>We will use this example to automate for your solution below</strong></p>
<hr />
<h3>Next:</h3>
<p>Automate to get an output of <code>(&lt;row index&gt; ,[&lt;col name&gt;, &lt;col name&gt;,..])</code> where there is <code>1</code> in the row values. Although this will be slower on large datasets, it should do the trick:</p>
<pre><code>import pandas as pd

data = {'foo':[0,0,0,0], 'bar':[0, 1, 0, 0], 'baz':[0,0,0,0], 'spam':[0,1,0,1]}
df = pd.DataFrame(data, index=['a','b','c','d'])

print(df)

   foo  bar  baz  spam
a    0    0    0     0
b    0    1    0     1
c    0    0    0     0
d    0    0    0     1
</code></pre>
<pre><code># group our df by index and creates a dict with lists of df's as values
df_dict = dict(
    list(
        df.groupby(df.index)
    )
)
</code></pre>
<p>Next step is a <code>for</code> loop that iterates the contents of each df in <code>df_dict</code>, checks them with the mask we created earlier, and prints the intended results:</p>
<pre><code>for k, v in df_dict.items():               # k: name of index, v: is a df
    check = v.columns[(v == 1).any()]
    if len(check) &gt; 0:
        print((k, check.to_list()))
</code></pre>
<pre><code>('b', ['bar', 'spam'])
('d', ['spam'])
</code></pre>
<h3>Side note:</h3>
<p>You see how I generated sample data that can be easily reproduced? In the future, please try to ask questions with posted sample data that can be reproduced. This way it helps you understand your problem better and it is easier for us to answer it for you.</p>
","1","2021-03-05 16:27:52","4","769","215","34","82","60472196","60472475","<p>I have a dataframe as below:
<a href=""https://i.stack.imgur.com/TgkOg.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/TgkOg.png"" alt=""enter image description here""></a></p>

<p>I want to get the name of the column if column of a particular row if it contains 1 in the that column.</p>

<p>e.g.</p>

<pre><code>For Row 1: Blanks,
For Row 2: Manufacturing,
For Row 3: Manufacturing,
For Row 4: Manufacturing,
For Row 5: Social, Finance, Analytics, Advertising,
</code></pre>

<p>Right now I am able to get the complete row only:</p>

<pre><code>primary_sectors = lambda primary_sector: sectors[
    sectors[""category_list""] == primary_sector
]
</code></pre>

<p>Please help me to get the name of the column in the above dataframe.</p>

<p>I tried this code:</p>

<pre><code>primary_sectors(""3D"").filter(items=[""0""])
</code></pre>

<p>It gives me output as <code>1</code> but I need output as <code>Manufacturing</code></p>
"
"60472541","<p>Use <a href=""http://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.dot.html"" rel=""nofollow noreferrer""><code>DataFrame.dot</code></a>:</p>

<pre><code>df1 = df.dot(df.columns)
</code></pre>

<p>If there is multiple <code>1</code> per row:</p>

<pre><code>df2 = df.dot(df.columns + ';').str.rstrip(';')
</code></pre>
","0","2020-03-01 07:18:58","3","615041","23439","1483","126104","60472196","60472475","<p>I have a dataframe as below:
<a href=""https://i.stack.imgur.com/TgkOg.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/TgkOg.png"" alt=""enter image description here""></a></p>

<p>I want to get the name of the column if column of a particular row if it contains 1 in the that column.</p>

<p>e.g.</p>

<pre><code>For Row 1: Blanks,
For Row 2: Manufacturing,
For Row 3: Manufacturing,
For Row 4: Manufacturing,
For Row 5: Social, Finance, Analytics, Advertising,
</code></pre>

<p>Right now I am able to get the complete row only:</p>

<pre><code>primary_sectors = lambda primary_sector: sectors[
    sectors[""category_list""] == primary_sector
]
</code></pre>

<p>Please help me to get the name of the column in the above dataframe.</p>

<p>I tried this code:</p>

<pre><code>primary_sectors(""3D"").filter(items=[""0""])
</code></pre>

<p>It gives me output as <code>1</code> but I need output as <code>Manufacturing</code></p>
"
"60472474","<p>You can do it with two <code>range</code> by iterating in 2 interval</p>

<pre><code>even_odd = [list(range(0, 19, 2)), list(range(1, 20, 2))]
# [[0, 2, 4, 6, 8, 10, 12, 14, 16, 18], [1, 3, 5, 7, 9, 11, 13, 15, 17, 19]]
</code></pre>
","2","","1","33900","639","3108","4197","60472333","60472474","<p>I am trying to print a list containing 2 lists at index 0 and 1. One list contains even numbers and the other one odd numbers.
Also, I want to do it with list comprehension and use only one list variable.</p>

<pre><code>even_odd = [[],[]]
even_odd = [even_odd[0].append(a) if a%2 == 0 else even_odd[1].append(a) for a in range(20)]
</code></pre>

<p><strong>Expected Output:</strong></p>

<pre><code>[[0, 2, 4, 6, 8, 10, 12, 14, 16, 18], [1, 3, 5, 7, 9, 11, 13, 15, 17, 19]]
</code></pre>

<p>Using list comprehension</p>
"
"60476610","<p>The code is trying to write text encoded as ISO-8859-1 to tables set to expect UTF-8.</p>

<p>There are two solutions:</p>

<ul>
<li><p>Set the <code>charset</code> argument on the connection to <code>latin1</code> (this is the same as ISO-8859-1) and let the connection handle re-encoding the bytes to UTF-8  </p>

<pre><code>db = MySQLdb.connect(host=cred.host, user=cred.user, password=cred.password, 
                     db=cred.db, port=cred.port, charset='latin1')
</code></pre></li>
<li><p>decode the encoded bytes to <code>str</code> and let the connection perform the encoding.</p>

<pre><code>report_as_dict = report.parsed.decode('ISO-8859-1')
</code></pre></li>
</ul>

<p>If the code is doing nothing apart from writing the bytes directly to the database then the first option is fine; if the bytes are undergoing further manipulations then decoding to <code>str</code> will keep things simple.  </p>
","2","","1","27066","4430","2273","3147","60472411","60476610","<p>I am parsing out a report form amazon, splits up lines into fields and then creates a mysql upload.   Data I believe is originally iso-8859-1.  Data uploads fine to mysql unless it has some special characters in it like an Ã„ or Â®.  If that happens I get an error like <code>pymysql.err.InternalError: (1366, ""Incorrect string value: '\\xAE Kids...' for column 'item-name' at row 74"")</code> &amp; <code>TypeError: can only concatenate str (not ""bytearray"") to str</code>.  I can hack around it by doing a replacing the bytes but I dont want to build a giant list plus I really want to store the proper values.  I tried changing my mysql character sets and collations but that didnt seem to fix.   I feel like the fix is a simple fix but i am already been trying things for a few hours.  </p>

<pre><code>report_as_dict = report.parsed
report_as_dict = report_as_dict.replace(b' \r\n', b'\r\n')  # remove black space at end

 multi_line_rebuild=list()
    for line in line_split[1:]:
        field_split = line.split(b'\t')
        logger.debug('Field Split : %s', field_split)
        field_split = [x.replace(b'\x92', b'') for x in field_split]  # removes single quotes
        field_split = [x.replace(b'\xA0', b'') for x in field_split]  # removes (
        field_split = [x.replace(b'\xAE', b'') for x in field_split]  # removes @
        field_split = [x.replace(b'\xCD', b'l') for x in field_split]  # replaces l with ' with l
        field_split = [x.replace(b'\xE4', b'a') for x in field_split]  # replaces a with two dots with a

        multi_line_rebuild.append(field_split)

 ....


 run_query_with_warnings(query_string, field_split=multi_line_rebuild)
</code></pre>

<p>Function</p>

<pre><code>def run_query_with_warnings(warn_type, query_string, **kargs):

db = MySQLdb.connect(host=cred.host, user=cred.user, password=cred.password, db=cred.db, port=cred.port)
cursor = db.cursor()
cursor.executemany(query_string, kargs['field_split'])
</code></pre>
"
"60496413","<p>The client is working with latin1 encoding (92, etc).  The table would like to have the utf8 encoding (E28099) for that ""right single quotation mark"".  You can achieve that by telling MySQL that the client is using latin1 in the connection parameters, and having the column be utf8 (or utf8mb4).</p>

<p>The former is something like</p>

<pre><code>db = MySQLdb.connect(host=DB_HOST, user=DB_USER, passwd=DB_PASS, db=DB_NAME,
              charset=""utf8"", use_unicode=True)
</code></pre>

<p>Also check whether or not you should change the beginning of your source to</p>

<pre><code># -*- coding: utf-8 -*-
</code></pre>

<p>But... I am worried.  Are you really using right quote, registered sign (AE), I-acute, and a-double-dot?  Or is this merely the beginning of some other mess?  Sometimes multiple bytes in a row are 'bad'.  To further analyze your situation, please get the hex for more than just one byte, and/or provide what characters you think the text <em>should</em> include.</p>
","0","","0","104249","1335","142","9251","60472411","60476610","<p>I am parsing out a report form amazon, splits up lines into fields and then creates a mysql upload.   Data I believe is originally iso-8859-1.  Data uploads fine to mysql unless it has some special characters in it like an Ã„ or Â®.  If that happens I get an error like <code>pymysql.err.InternalError: (1366, ""Incorrect string value: '\\xAE Kids...' for column 'item-name' at row 74"")</code> &amp; <code>TypeError: can only concatenate str (not ""bytearray"") to str</code>.  I can hack around it by doing a replacing the bytes but I dont want to build a giant list plus I really want to store the proper values.  I tried changing my mysql character sets and collations but that didnt seem to fix.   I feel like the fix is a simple fix but i am already been trying things for a few hours.  </p>

<pre><code>report_as_dict = report.parsed
report_as_dict = report_as_dict.replace(b' \r\n', b'\r\n')  # remove black space at end

 multi_line_rebuild=list()
    for line in line_split[1:]:
        field_split = line.split(b'\t')
        logger.debug('Field Split : %s', field_split)
        field_split = [x.replace(b'\x92', b'') for x in field_split]  # removes single quotes
        field_split = [x.replace(b'\xA0', b'') for x in field_split]  # removes (
        field_split = [x.replace(b'\xAE', b'') for x in field_split]  # removes @
        field_split = [x.replace(b'\xCD', b'l') for x in field_split]  # replaces l with ' with l
        field_split = [x.replace(b'\xE4', b'a') for x in field_split]  # replaces a with two dots with a

        multi_line_rebuild.append(field_split)

 ....


 run_query_with_warnings(query_string, field_split=multi_line_rebuild)
</code></pre>

<p>Function</p>

<pre><code>def run_query_with_warnings(warn_type, query_string, **kargs):

db = MySQLdb.connect(host=cred.host, user=cred.user, password=cred.password, db=cred.db, port=cred.port)
cursor = db.cursor()
cursor.executemany(query_string, kargs['field_split'])
</code></pre>
"
"60472766","<p>you could use ajax and bootstrap modal,
crate a general modal somewhere in your html page(I usually have it in my base.html so it will be included in all pages) then submit your from by using ajax then ajax will provide success or error function regarding the response will receive from server-side. put that message in the modal. an example is:</p>

<h1>somewhere inside base.html</h1>

<pre><code>    &lt;!-- Info General modal --&gt;
    &lt;div id=""general_modal"" class=""modal fade "" &gt;
      &lt;div class=""modal-dialog ""&gt;
        &lt;div class=""modal-content ""&gt;
          &lt;div class=""modal-header bg-info""&gt;
            &lt;h6 class=""modal-title""&gt;Info header&lt;/h6&gt;
            &lt;button type=""button"" class=""close"" data-dismiss=""modal""&gt;&amp;times;&lt;/button&gt;
          &lt;/div&gt;
          &lt;div class=""modal-body""&gt;
          &lt;!-- Empty will be field by Js --&gt;
          &lt;/div&gt;
        &lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
    &lt;!-- /info General modal --&gt;
</code></pre>

<h1>js and ajax function</h1>

<pre><code>$(""#your-form"").on('submit',function(e){
    e.preventDefault();
var ajax_link = this.getAttribute(""data-ajax-link"");
var target = this.getAttribute(""data-target"");
var title = this.getAttribute(""data-modal-title"");
var size = this.getAttribute(""data-modal-size"");
var bg = this.getAttribute(""data-modal-content-bg"");
// $(target+"" .modal-body"").load(ajax_link);
$.ajax({
    url:ajax_link,
    type:'POST',
    // data: $(""#your-form-feilds"").serialize(),

    success: function (response){
        $(target+"" .modal-body"").html(response);
    },
    /*
    error:function (response){
        new PNotify({
            title: 'oops',
            text:' Unable to load',
            type: 'error'
        });
    }
   */
});

$(target+"" .modal-content"").addClass(bg);
$(target+"" .modal-title"").html(title);
$(target+"" .modal-dialog"").removeClass().addClass(""modal-dialog"");
$(target+"" .modal-dialog"").addClass(size);
</code></pre>

<p>});</p>

<h1>html form</h1>

<pre><code>&lt;form action=""."" method=""post"" id=""your-form"" class=""btn btn-info  modal-ajax-load""
                        data-ajax-link=""url""
                        data-toggle=""modal""
                        data-modal-title=""tilte""
                        data-target=""#general_modal""&gt;
</code></pre>

<p>ofcurse you need to modify this answer to create the functions you need</p>
","0","2020-03-04 05:52:42","0","635","65","18","78","60472413","60472766","<p>I've been searching in google and SO about pop up message when user submit but that doesnt work when i apply it to my code, I just want that if the user update/insert data, a pop up modal message appears</p>

<p>I have this form in my html</p>

<pre><code>&lt;form method=""post"" id=""myform"" class=""myform"" style=""width: 100%"" enctype=""multipart/form-data""&gt;{% csrf_token %}
    &lt;table  id=""blacklistgrids"" border=""2px""&gt;
    &lt;tr&gt;
        {% for v in table.0 %}
            {% if forloop.first %}
                &lt;th id=""thupdate""&gt;{{v}}&lt;/th&gt;
            {% else %}
                &lt;th &gt;&lt;input type=""text"" name=""updatedate"" value=""{{ v }}""&gt;&lt;/th&gt;
            {% endif %}
        {% endfor %}
        &lt;th  hidden&gt;&lt;/th&gt;
        &lt;th data-id='headerss' id='headerave'&gt;Average&lt;/th&gt;
    &lt;/tr&gt;
    &lt;tbody&gt;
    {% for row in table|slice:""1:"" %}
        &lt;tr class=""tr2update""&gt;
            &lt;td&gt;&lt;input type=""text"" value=""{{row.0}}"" name=""students"" hidden&gt;{% for n in teacherStudents %}{{n.Students_Enrollment_Records.Student_Users}}{% endfor %}&lt;/td&gt;
             &lt;td class=""tdupdate"" hidden&gt;&lt;input type=""text"" hidden&gt;&lt;/td&gt;
            {% for teacher in students %}
            &lt;input type=""hidden""  name=""id""   value=""{{teacher.id}}""/&gt;
            &lt;td&gt;
                &lt;input type=""text""  data-form-field=""{{teacher.id}}"" name=""oldgrad"" class=""oldgrad""  value=""{{teacher.Grade|floatformat:'2'}}""/&gt;
            &lt;/td&gt;
            {% endfor %}
            {% for avg in average %}
            &lt;td data-id='row' id=""ans""&gt;&lt;input type='number' class='averages' step=""any"" name=""average"" value=""{{average.average_grade|floatformat:'2'}}"" readonly/&gt;&lt;/td&gt;
            {% endfor %}
        &lt;/tr&gt;
     {% endfor %}
    &lt;/tbody&gt;

&lt;/table&gt;
    &lt;div class=""buttons""&gt;
    &lt;input type=""submit"" value=""&amp;nearrow;&amp;nbsp;Update"" class=""save""   formaction=""/updategrades/""&gt;
    &lt;/div&gt;
        &lt;/form&gt;

&lt;script&gt;
if (typeof jqXhr.success != 'undefined') {
    $('#thanksModal').modal('show');
} else {
    $('#myform').html(jqXhr);
}
&lt;/script&gt;
</code></pre>

<p>and this is my views.py</p>

<pre><code>import json
def updategrades(request):
    /some logic/
   return HttpResponse(json.dumps({""success"":True}), content_type=""application/json"")
</code></pre>
"
"60472550","<p>You can append the user input to the same list every time. The while loop would accept input, if it's an empty string then break and print the list. Otherwise add the input to the list and print the value. The trickiest thing in your question is actually getting the ordinal number representation (1st, 2nd, 3rd, etc), which there is an answer to <a href=""https://stackoverflow.com/questions/9647202/ordinal-numbers-replacement"">here</a>.</p>

<pre><code>shoeCat = {1: 'Adidas', 2: 'Alexander McQueen', 3: 'Converse', 4: 'Fila', 5: 'Kids/Teens', 6: 'Menâ€™s Kicks', 7: 'New Balance', 8: 'Nike', 9: 'OFF-White', 10: 'Puma', 11: 'Select Brands', 12: 'Slides', 13: 'Under Armour', 14: 'Womenâ€™s Kicks'}
ordinal = lambda n: ""%d%s"" % (n, ""tsnrhtdd""[(n // 10 % 10 != 1) * (n % 10 &lt; 4) * n % 10::4])
i = 1
final = []
while True:
    mycat1 = input(f""Enter {ordinal(i)} category: "")
    if mycat1:
        final.append(shoeCat[int(mycat1)])
        print(final[-1:])
        i += 1
    else:
        print(' | '.join(final))
        break
</code></pre>
","0","","2","4481","30","42","339","60472446","60472569","<p>I am totally new to python. I am trying to do a dictionary concatenation from user input and print the result. I have searched the internet for all solutions, but no solutions. Please, help.</p>

<pre><code>shoeCat = {1: 'Adidas', 2: 'Alexander McQueen', 3: 'Converse', 4: 'Fila', 5: 'Kids/Teens', 6: 'Menâ€™s Kicks', 7: 'New Balance', 8: 'Nike', 9: 'OFF-White', 10: 'Puma', 11: 'Select Brands', 12: 'Slides', 13: 'Under Armour', 14: 'Womenâ€™s Kicks'}
mycat1 = input(""Enter 1st category: "")
cat1 = [shoeCat[int(x)] for x in mycat1.split()]
print(cat1)
mycat2 = input(""Enter 2nd Category: "")
cat2 = [shoeCat[int(x)] for x in mycat2.split()]
print(cat2)
final= cat1 + cat2
print(*final, sep = "" | "")
</code></pre>

<p>How do i make the code to ask for infinite multiple user inputs whith the whiile true if statement.</p>

<pre><code>while True:
print ('Enter Category: (Press enter to generate.)')
mycat1 = input("""")
if mycat1 == '':
    break
</code></pre>

<p>I want to achieve these:</p>

<pre><code>Enter 1st category: 1
['Adidas']
Enter 2nd Category: 2
['Alexander McQueen']
Enter 3rd Category: 6
['Menâ€™s Kicks']
Enter 4th Category: 11
['Select Brands']
Enter 2nd Category: 13
['Under Armour']
Adidas | Alexander McQueen | Menâ€™s Kicks | Select Brands | Under Armour
</code></pre>

<p>Please how do i make python3 get these result for me.</p>
"
"60472569","<p>Keep a list to store the values that you have printed:</p>

<pre><code>shoeCat = {1: 'Adidas', 2: 'Alexander McQueen', 3: 'Converse', 4: 'Fila', 5: 'Kids/Teens', 6: 'Menâ€™s Kicks', 7: 'New Balance', 8: 'Nike', 9: 'OFF-White', 10: 'Puma', 11: 'Select Brands', 12: 'Slides', 13: 'Under Armour', 14: 'Womenâ€™s Kicks'}
lst = []
while True:
    mycat1 = input(""Enter Category: (Press enter to generate.)"")
    if mycat1 == '':
        break
    lst.append(shoeCat[int(mycat1)])
    print(shoeCat[int(mycat1)])
print(*lst, sep="" | "")
</code></pre>

<p><code>lst</code> stores the values that you have printed out. You can then just plainly print out the list with the required separator.</p>

<p>Note that this assumes the user always enters a valid integer input that is in <code>shoeCat</code>. Additional checks need to be in place to make sure it handles edge cases.</p>
","0","","1","690","750","43","125","60472446","60472569","<p>I am totally new to python. I am trying to do a dictionary concatenation from user input and print the result. I have searched the internet for all solutions, but no solutions. Please, help.</p>

<pre><code>shoeCat = {1: 'Adidas', 2: 'Alexander McQueen', 3: 'Converse', 4: 'Fila', 5: 'Kids/Teens', 6: 'Menâ€™s Kicks', 7: 'New Balance', 8: 'Nike', 9: 'OFF-White', 10: 'Puma', 11: 'Select Brands', 12: 'Slides', 13: 'Under Armour', 14: 'Womenâ€™s Kicks'}
mycat1 = input(""Enter 1st category: "")
cat1 = [shoeCat[int(x)] for x in mycat1.split()]
print(cat1)
mycat2 = input(""Enter 2nd Category: "")
cat2 = [shoeCat[int(x)] for x in mycat2.split()]
print(cat2)
final= cat1 + cat2
print(*final, sep = "" | "")
</code></pre>

<p>How do i make the code to ask for infinite multiple user inputs whith the whiile true if statement.</p>

<pre><code>while True:
print ('Enter Category: (Press enter to generate.)')
mycat1 = input("""")
if mycat1 == '':
    break
</code></pre>

<p>I want to achieve these:</p>

<pre><code>Enter 1st category: 1
['Adidas']
Enter 2nd Category: 2
['Alexander McQueen']
Enter 3rd Category: 6
['Menâ€™s Kicks']
Enter 4th Category: 11
['Select Brands']
Enter 2nd Category: 13
['Under Armour']
Adidas | Alexander McQueen | Menâ€™s Kicks | Select Brands | Under Armour
</code></pre>

<p>Please how do i make python3 get these result for me.</p>
"
"60517680","<p>By passing the result of EnvInterpolation to another configparser, I'm able to get the required output. Sharing the results so that it could benefit others.</p>

<pre><code>import configparser
import os

class EnvInterpolation(configparser.BasicInterpolation):
    """"""Interpolation which expands environment variables in values.""""""

    def before_get(self, parser, section, option, value, defaults):
        return os.path.expandvars(value)

cfg = """"""
[Default]
key = world
my_path = ${PYSPARK_PYTHON}
path2 = /user/${Default:key} 
[Main]
path_main = Hello.${Default:key}
""""""

config = configparser.ConfigParser(interpolation=EnvInterpolation())
config.read_string(cfg)

config2 = configparser.ConfigParser(interpolation=configparser.ExtendedInterpolation())
config2.read_dict(config)

print(""====1====="")
print(config['Default']['my_path'])
print(config['Default']['path2'])
print(config['Main']['path_main'])

print(""====2====="")
print(config2['Default']['path2'])
print(config2['Default']['my_path'])
print(config2['Main']['path_main'])
</code></pre>

<p>Results:</p>

<pre><code>====1=====
C:\install\anaconda\Anaconda3\python.exe
/user/${Default:key}
Hello.${Default:key}
====2=====
/user/world
C:\install\anaconda\Anaconda3\python.exe
Hello.world
</code></pre>
","0","","1","7626","379","2","947","60472455","60517680","<p>Using the configparser library, I'm trying to have both interpolation as well as env variables resolving, but it is not happening.</p>

<pre><code>import os, configparser

class EnvInterpolation(configparser.BasicInterpolation):
    """"""Interpolation which expands environment variables in values.""""""

    def before_get(self, parser, section, option, value, defaults):
        return os.path.expandvars(value)

cfg = """"""
[Default]
key = world
my_path = ${PYTHONPATH}
path2 = /user/${Default:key} 
[Main]
path_main = Hello.${Default:key}
""""""

config = configparser.ConfigParser(interpolation=EnvInterpolation())
config.read_string(cfg)

print(config['Default']['my_path'])
print(config['Default']['path2'])
print(config['Main']['path_main']) 
</code></pre>

<p>I get the result as </p>

<pre><code>C:\install\spark\spark-2.4.0-bin-hadoop2.7\python
/user/${Default:key}
Hello.${Default:key}
</code></pre>

<p>whereas what I want is </p>

<pre><code>C:\install\spark\spark-2.4.0-bin-hadoop2.7\python
/user/world
Hello.world
</code></pre>

<p>If i use the ExtendedInterpolation directly, I get below error.</p>

<pre><code>InterpolationMissingOptionError: Bad value substitution: option 'my_path' in section 'Default' contains an interpolation key 'PYTHONPATH' which is not a valid option name. Raw value: '${PYTHONPATH}'
</code></pre>
"
"60472480","<p>Use <code>in</code> in <a href=""http://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.apply.html"" rel=""nofollow noreferrer""><code>Series.apply</code></a> with lambda function:</p>

<pre><code>df['Monday'] = df.DaysOfWeek.str.split("","").apply(lambda x: 'Monday' in x)
</code></pre>

<p>Or create <code>DataFrame</code> and test with <a href=""http://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.isin.html"" rel=""nofollow noreferrer""><code>DataFrame.isin</code></a> and <a href=""http://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.any.html"" rel=""nofollow noreferrer""><code>DataFrame.any</code></a>:</p>

<pre><code>df['Monday'] = df.DaysOfWeek.str.split("","", expand=True).eq('Monday').any(axis=1)

print(df)
   UniqueID                                         DaysOfWeek  \
0         1                                     Monday,Tuesday   
1         2  Wednesday,Thursday,Can work Monday if given ad...   
2         3                                             Friday   

                                            DaysList  Monday  
0                                  [Monday, Tuesday]    True  
1  [Wednesday, Thursday, Can work Monday if given...   False  
2                                           [Friday]   False  
</code></pre>

<p>If need matches also in substrings use generator with <code>any</code>:</p>

<pre><code>df['Monday'] = df.DaysOfWeek.str.split("","").apply(lambda x: any('Monday' in y for y in x))
</code></pre>

<p>Or add <a href=""http://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.str.contains.html"" rel=""nofollow noreferrer""><code>Series.str.contains</code></a>:</p>

<pre><code>df['Monday'] = df.DaysOfWeek.str.split("","", expand=True).apply(lambda x: x.str.contains('Monday')).any(axis=1)
print (df)
   UniqueID                                         DaysOfWeek  \
0         1                                     Monday,Tuesday   
1         2  Wednesday,Thursday,Can work Monday if given ad...   
2         3                                             Friday   

                                            DaysList  Monday  
0                                  [Monday, Tuesday]    True  
1  [Wednesday, Thursday, Can work Monday if given...    True  
2                                           [Friday]   False  
</code></pre>
","3","2020-03-01 06:14:08","0","615041","23439","1483","126104","60472463","60472480","<p>I've been given a set of poorly formatted data to clean up, there are several columns of data which contain multiple pieces of information which need to be split into multiple columns each.
One example is a column called DaysOfWeek which contains the days that a person can work, plus a free text field. I want to create 8 columns, 1 for each day of the week, and one for anything that isn't a day of the week (which may contain the name of a day of the week as shown in my example below).
I've imported the data into Pandas, and tried to use the ""in"" list function to scan for days of the week, but I'm getting false responses for everything. Here's code that replicates my problem:</p>

<pre><code>import pandas as pd

# First example - Testing it in regular code:
x = 'Monday,Tuesday'
dayslist = x.split("","") # redundant, just for testing/printing
Monday = 'Monday' in x.split("","")
print(dayslist, 'Result:',Monday)
# Gives True as a result

# Second example - Trying to do it in a dataframe.
df = pd.DataFrame({'UniqueID':[1,2,3],
                   'DaysOfWeek':['Monday,Tuesday', 'Wednesday,Thursday,Can work Monday if given advance notice', 'Friday']})
df['DaysList'] = df.DaysOfWeek.str.split("","") #redundant, just for testing/printing
df['Monday'] = 'Monday' in df.DaysOfWeek.str.split("","")
print(df)
# False for every record, should be true for first record.
</code></pre>

<p>I don't understand why the first example works in regular code, but the second cannot find Monday in the data frame.</p>
"
"60472603","<p>Add parameter <code>expand=True</code> for <code>DataFrame</code> and then add <code>[]</code> for new columns:</p>

<pre><code>df[['date','time']] = df.Time.str.split("":"", 1, expand=True)
print (df)
           IP                   Time                        URL  Staus  \
0  10.128.2.1  [29/Nov/2017:06:58:55     GET/login.php HTTP/1.1    200   
1  10.128.2.1  [29/Nov/2017:06:59:02  POST/process.php HTTP/1.1    302   

           date      time  
0  [29/Nov/2017  06:58:55  
1  [29/Nov/2017  06:59:02  
</code></pre>

<p>Or also add <a href=""http://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.str.strip.html"" rel=""nofollow noreferrer""><code>Series.str.strip</code></a> for remove trailing <code>[]</code>:</p>

<pre><code>df[['date','time']] = df.Time.str.strip('[]').str.split("":"", 1, expand=True)
print (df)
           IP                   Time                        URL  Staus  \
0  10.128.2.1  [29/Nov/2017:06:58:55     GET/login.php HTTP/1.1    200   
1  10.128.2.1  [29/Nov/2017:06:59:02  POST/process.php HTTP/1.1    302   

          date      time  
0  29/Nov/2017  06:58:55  
1  29/Nov/2017  06:59:02  
</code></pre>
","0","2020-03-01 06:41:29","1","615041","23439","1483","126104","60472483","60472603","<p>I have the following dataframe with 4 columns:</p>

<pre><code>    IP  Time    URL Staus
0   10.128.2.1  [29/Nov/2017:06:58:55   GET /login.php HTTP/1.1 200
1   10.128.2.1  [29/Nov/2017:06:59:02   POST /process.php HTTP/1.1  302
2   10.128.2.1  [29/Nov/2017:06:59:03   GET /home.php HTTP/1.1  200
3   10.131.2.1  [29/Nov/2017:06:59:04   GET /js/vendor/moment.min.js HTTP/1.1   200
4   10.130.2.1  [29/Nov/2017:06:59:06   GET /bootstrap-3.3.7/js/bootstrap.js HTTP/1.1   200
5   10.130.2.1  [29/Nov/2017:06:59:19   GET /profile.php?user=bala HTTP/1.1 200
</code></pre>

<p>I need to split the Time column into two new columns titled 'date' and 'time'. I need to split the current value under the Time column by the first occurrence of ':'. </p>

<p>I have tried the split function for the first instance of ':' as follows:</p>

<pre><code>df['date','time']=df.Time.str.split("":"", 1)
</code></pre>

<p>But this is what i end up getting:</p>

<pre><code>    IP  Time    URL Staus   (date, time)
0   10.128.2.1  [29/Nov/2017:06:58:55   GET /login.php HTTP/1.1 200 [[29/Nov/2017, 06:58:55]
1   10.128.2.1  [29/Nov/2017:06:59:02   POST /process.php HTTP/1.1  302 [[29/Nov/2017, 06:59:02]
2   10.128.2.1  [29/Nov/2017:06:59:03   GET /home.php HTTP/1.1  200 [[29/Nov/2017, 06:59:03]
3   10.131.2.1  [29/Nov/2017:06:59:04   GET /js/vendor/moment.min.js HTTP/1.1   200 [[29/Nov/2017, 06:59:04]
</code></pre>

<p>How do I properly split into two columns? What am I doing wrong? Help :(</p>
"
"60634520","<p>I have used phase unwrapping module in C++. For Python, I have seen that this module is available in cv2 namespace in Ubuntu 20.04 and Fedora 31. </p>

<p>Which distribution are you using?</p>
","3","","1","51","1","0","6","60472492","62402057","<p>I would like to use the OpenCV phase unwrapping functions presented <a href=""https://docs.opencv.org/master/df/d3a/group__phase__unwrapping.html"" rel=""nofollow noreferrer"">here</a> in Python, but I've been unable to find the function inside the <code>cv2</code> namespace (this <a href=""https://pypi.org/project/opencv-python/"" rel=""nofollow noreferrer"">module</a>). Has anyone else used this function outside of C++? I know there is an <code>unwrap</code> function in Numpy, but my goal is to use the OpenCV algorithm inside our production code in C# via the <a href=""https://github.com/shimat/opencvsharp"" rel=""nofollow noreferrer"">OpenCVSharp Nuget package</a>, so it would be preferable to use the same OpenCV function in Python and C# than to use the Numpy unwrap function and rewrite it in C#. Has anyone been able to successfully use the OpenCV phase unwrapping functions outside of C++?</p>
"
"62402057","<p>I discovered that if I <code>pip install opencv-contrib-python</code>, then I have the following functions available, which were not available before I installed opencv contrib</p>

<p><code>cv2.phase_unwrapping_HistogramPhaseUnwrapping()</code></p>

<p>and </p>

<p><code>cv2.phase_unwrapping_PhaseUnwrapping()</code></p>

<p>I believe these were the ones I was looking for, so the reason I couldn't find them before is that they were/are still contrib modules. Note that I'm using version 4.2.0 of OpenCV.</p>
","0","","1","193","125","0","13","60472492","62402057","<p>I would like to use the OpenCV phase unwrapping functions presented <a href=""https://docs.opencv.org/master/df/d3a/group__phase__unwrapping.html"" rel=""nofollow noreferrer"">here</a> in Python, but I've been unable to find the function inside the <code>cv2</code> namespace (this <a href=""https://pypi.org/project/opencv-python/"" rel=""nofollow noreferrer"">module</a>). Has anyone else used this function outside of C++? I know there is an <code>unwrap</code> function in Numpy, but my goal is to use the OpenCV algorithm inside our production code in C# via the <a href=""https://github.com/shimat/opencvsharp"" rel=""nofollow noreferrer"">OpenCVSharp Nuget package</a>, so it would be preferable to use the same OpenCV function in Python and C# than to use the Numpy unwrap function and rewrite it in C#. Has anyone been able to successfully use the OpenCV phase unwrapping functions outside of C++?</p>
"
"60472568","<p>You can use the zip function in python to do pair 2 lists.</p>

<pre><code>list_a=[1,2,3]
list_b=[4,5,6]
multiplied_ab=[]
for i,j in zip(list_a,list_b):
    multiplied_ab.append(i,j)
print(multiplied_ab)
</code></pre>

<p>Your result will be multiplication of the 2 lists like this:
[4,10,18]</p>

<p>You'll have to make sure that the length of the 2 lists match.</p>

<p>Then you can simply calculate the sum of the list by using the <code>sum()</code> function</p>
","1","","-1","123","11","0","27","60472526","60472673","<p>I have a formula (image attached) that I need to use. I have two lists, x and y. My issue is that I need to multiply these two lists in the formula for M. But it seems that I can not multiply lists in python. How can I code for M using two lists? Here is my current code </p>

<pre><code>m = (1/D)sum((([(xi-xbar) for xi in x]))*([(yi*1) for yi in y]))
print('m',m)
</code></pre>

<p>I get the error ""can't multiply sequence by non-int of type 'list'"" </p>

<p>How do I multiply two lists, thanks!</p>

<p><a href=""https://i.stack.imgur.com/9yZWT.jpg"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/9yZWT.jpg"" alt=""Formula""></a></p>
"
"60472673","<p>You want to do this.</p>

<p><code>m=sum((x<sub>i</sub>-mean(x))*y<sub>i</sub>)</code></p>

<p>You can try this.</p>

<pre><code>from statistics import mean
x=[1,2,3,4,5]
y=[6,7,8,9,10]

mean_x=mean(x)

m=(1/D)*sum((i-mean_x)*j for i,j in zip(x,y))
c=mean(y)-(m*mean_x)
</code></pre>
","5","","1","14733","1831","61","1931","60472526","60472673","<p>I have a formula (image attached) that I need to use. I have two lists, x and y. My issue is that I need to multiply these two lists in the formula for M. But it seems that I can not multiply lists in python. How can I code for M using two lists? Here is my current code </p>

<pre><code>m = (1/D)sum((([(xi-xbar) for xi in x]))*([(yi*1) for yi in y]))
print('m',m)
</code></pre>

<p>I get the error ""can't multiply sequence by non-int of type 'list'"" </p>

<p>How do I multiply two lists, thanks!</p>

<p><a href=""https://i.stack.imgur.com/9yZWT.jpg"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/9yZWT.jpg"" alt=""Formula""></a></p>
"
"60472759","<p>Is the image type float from 0.0 to 1.0? Is it one channel grayscale? You are assigning text color with 3 channels and 255 valued... Probably you're having trouble because of one of those.</p>
","0","","0","891","507","43","130","60472551","60472759","<p>The original image is </p>

<p><a href=""https://i.stack.imgur.com/OKc5O.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/OKc5O.png"" alt=""enter image description here""></a></p>

<pre><code>font                   = cv2.FONT_HERSHEY_SIMPLEX
bottomLeftCornerOfText = (10,150)
fontScale              = 1
fontColor              = (255,255,255)

cv2.putText(img=img,text='Hello World!', 
    org = bottomLeftCornerOfText,
    fontFace=font, 
    fontScale=fontScale,
    color=fontColor,
    lineType=cv2.LINE_AA,
    thickness=1)

</code></pre>

<p>After running the code above, I got image like this</p>

<p><a href=""https://i.stack.imgur.com/YwiNw.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/YwiNw.png"" alt=""enter image description here""></a></p>

<p>Only text showed and the background image disappeared. I also tried other colors like blue and green, they all worked fine, both image and text were kept. I wonder why white text doesn't work here and how can I fix it.</p>
"
"60472745","<p>You don't need them in the first place - as you wrote, you can just use instance variables:</p>
<pre><code>def __init__(self):
    self.the_answer = 42
</code></pre>
<p>But if you later change the implementation to use a function instead of a variable, you can change that to:</p>
<pre><code>def __init__(self):
    self._the_answer = None

@property
def the_answer(self):
    if self._the_answer is None:
         self._the answer = self.calculate_answer() 
    return self._the_answer
</code></pre>
<p>without changing the API. In this example, it is using lazy evaluation to make the calculation only on access, but there are a lot of other cases where this can be helpful:</p>
<ul>
<li>calculate the property value from several variables, so no single variable is needed</li>
<li>add constraints to the setter to only allow setting certain values</li>
<li>do not add a setter to have read-only attributes</li>
<li>invalidate the value on certain events and re-calculate them only in this case</li>
<li>overwrite the behavior of attributes in subclasses</li>
</ul>
","3","2021-03-02 19:23:37","4","7188","468","333","872","60472614","60472745","<p>Just want to undertstand property/getter/setter in python. Two questions on hand, could you please help to answer? Thanks.</p>

<ol>
<li><p>Go through several threads, basic knowledge is we can use the getter/setter to make some attributes private, then by using property, we can use these attributes like public. So why we need this? since original <code>__init__</code> is public</p></li>
<li><p>Several thread give us the example that we can add value constraint inside setter. My question is  why we not add constraint inside <code>__init__</code> directly just like code below? </p></li>
</ol>

<pre><code>class test1:
  def __init__(self, num):
     if type(num) == int:
         self.num = num
     else:
         raise TypeError('we need int')

</code></pre>
"
"60472770","<p><code>r</code> is actually an instance of class:<a href=""https://2.python-requests.org/en/master/api/#requests.Response"" rel=""nofollow noreferrer""><code>request.Response</code></a>. You can read documentation of <a href=""https://2.python-requests.org/en/master/api/#requests.get"" rel=""nofollow noreferrer""><code>requests.get</code></a> for more information.</p>
","0","","0","331","9","0","13","60472659","60472785","<pre><code>import requests

r = requests.get('https://www.theguardian.com/international')

print(r.status_code)
print(r.headers)
</code></pre>

<p>As far as I can understand, in this code I am assigning the result of the <code>requests.get('https://www.theguardian.com/international')</code> call to <code>r</code> which is the response to the HTTP request. But how can I use the <code>.status_code</code> and <code>.header</code> methods with <code>r</code>? <code>r</code> is not an instance of a class as far as I can tell. </p>
"
"60472785","<p>According to <a href=""https://2.python-requests.org/en/v1.1.0/user/quickstart/#make-a-request"" rel=""nofollow noreferrer"">Python Requests quickstart guide</a>   <code>requests.get(url)</code> simply returns a <code>Response</code> object, thus in your example, <code>r</code> is assigned to that object, which enables you to access its attributes such as <code>status_code</code>, <code>text</code>, etc.</p>
","0","","0","36","6","0","3","60472659","60472785","<pre><code>import requests

r = requests.get('https://www.theguardian.com/international')

print(r.status_code)
print(r.headers)
</code></pre>

<p>As far as I can understand, in this code I am assigning the result of the <code>requests.get('https://www.theguardian.com/international')</code> call to <code>r</code> which is the response to the HTTP request. But how can I use the <code>.status_code</code> and <code>.header</code> methods with <code>r</code>? <code>r</code> is not an instance of a class as far as I can tell. </p>
"
"60472677","<p>Apparently you should install pip separately in CentOS.
Try this <a href=""https://www.liquidweb.com/kb/how-to-install-pip-on-centos-7/"" rel=""nofollow noreferrer"">Link</a>.</p>
","0","","1","354","9","1","41","60472660","60472683","<p>I am using CentOS. It has Python 3.6 version installed.</p>

<p>From command line if I try to execute PIP, I get error: ""Command not found""</p>

<p>How to add Python folder to the environment path?</p>
"
"60472683","<p>Pip is not available in CentOS 7 core repositories. To install pip we need to enable the EPEL repository:</p>

<pre><code>sudo yum install epel-release
</code></pre>

<p>Once the EPEL repository is enabled we can install pip and all of its dependencies with the following command:</p>

<pre><code>sudo yum install python-pip
</code></pre>

<p>To verify that the pip is installed correctly run the following command which will print the pip version:</p>

<pre><code>pip --version
</code></pre>

<p>Enjoy! :)</p>
","4","","2","595","8","3","84","60472660","60472683","<p>I am using CentOS. It has Python 3.6 version installed.</p>

<p>From command line if I try to execute PIP, I get error: ""Command not found""</p>

<p>How to add Python folder to the environment path?</p>
"
"60480823","<p>I think this should do it:</p>

<pre><code>elms = []
for elem in soup.find_all('font'):
    if elem not in elms:
        elms.append(elem)
    else:
        target =elem.findParent().findParent()
        target.decompose()
print(soup.html)
</code></pre>

<p>This should get you your the desired output.</p>

<p>Edit:</p>

<p>To remove only for those paragraphs that have don't size 4 or 5, change the <code>else</code> block to</p>

<pre><code> else:
    if elem.attrs['size'] != ""4"" and elem.attrs['size'] !=""5"":
        target =elem.findParent().findParent()
        target.decompose()
</code></pre>
","4","2020-03-04 12:01:24","1","15499","2905","1040","1214","60472800","60480823","<p>IÂ´m trying to clean an html file that has repeated paragraphs within body. Below I show the input file and expected output.</p>

<p><strong>Input.html</strong>
<a href=""https://jsfiddle.net/97ptc0Lh/4/"" rel=""nofollow noreferrer"">https://jsfiddle.net/97ptc0Lh/4/</a></p>

<p><strong>Output.html</strong>
<a href=""https://jsfiddle.net/97ptc0Lh/1/"" rel=""nofollow noreferrer"">https://jsfiddle.net/97ptc0Lh/1/</a></p>

<p>I've been trying with the following code using BeautifulSoup but I donÂ´t know why is not working, since the resultant list <code>CleanHtml</code> contains the repeated elements (paragraphs) that IÂ´d like to remove.</p>

<pre><code>from bs4 import BeautifulSoup

fp = open(""Input.html"", ""rb"")
soup = BeautifulSoup(fp, ""html5lib"")

Uniques = set()
CleanHtml = []

for element in soup.html:
    if element not in Uniques:
        Uniques.add(element)
        CleanHtml.append(element)   

print (CleanHtml)
</code></pre>

<p>May someone help me to reach this goal please.  </p>
"
"60472886","<p>If you use Pandas, you may refer to this question <a href=""https://stackoverflow.com/questions/16476924/how-to-iterate-over-rows-in-a-dataframe-in-pandas"">How to iterate over rows in a DataFrame in Pandas?</a></p>

<p>the index is where the row is, probably the row slice you referred to? and the row is obviously the row. You can select the data field in the row you're interested in.</p>

<p>for 'Edit' data field, when you loop through the dataset, you may write something like:</p>

<pre><code>for index, row in df.iterrows():
    if row['Edit'] == 'False'
        print(index) #where the row is
</code></pre>
","0","2020-03-01 09:08:05","0","1","0","0","3","60472837","60473864","<p><strong>Objective</strong></p>

<p>I have a large dataset, df, where I have a Length, Date and Edit Column. My goal is to iterate through a large dataset and find the index, start and end times for a given condition.</p>

<p><strong><em>Working backwards</em></strong>, I need to get the index or <strong><em>row number</em></strong> <strong><em>where Edit is False</em></strong> *with the condition that the <strong><em>previous</em></strong> <strong><em>Edit is True</em></strong>.This will output an 'End' and the value that is in the Length column.</p>

<p>The <strong><em>Start is generated by going backwards from the 'End' index</em></strong> <em>(Edit is False</em>) and when you come across the next <em>(Edit is False)</em>  <strong>+ 1</strong></p>

<pre><code> Length        Date                               Edit

  20            1/2/2020 1:00:00 AM               False
  21            1/2/2020 1:00:01 AM               True
  81            1/2/2020 1:00:02 AM               True
  81            1/2/2020 1:00:03 AM               True
  90            1/2/2020 1:00:04 AM               False
  20            1/2/2020 1:00:05 AM               True
  90            1/2/2020 1:00:06 AM               True
  81            1/2/2020 1:00:10 AM               True
  90            1/2/2020 1:00:15 AM               False        
  20            1/2/2020 1:00:25 AM               True
</code></pre>

<p><strong>This is my desired output:</strong></p>

<pre><code>Start                   End                   Duration   RowNum      Length 

1/2/2020 1:00:05 AM     1/2/2020 1:00:15 AM   10         8              90
1/2/2020 1:00:01 AM     1/2/2020 1:00:04 AM   3          4              90
</code></pre>

<p><strong><em>Starting backwards</em></strong>, we see that the first End time is at, 1/2/2020 1:00:15 AM, because Edit is False, and its previous Edit value is True. The length is 90, and the RowNumber is 8. The Start would go backwards from 1/2/2020 1:00:15 AM until we come to <em>another Edit is False line plus 1</em> , so it would be: 1/2/2020 1:00:05 AM</p>

<p><strong>dput</strong></p>

<pre><code>structure(list(Length = c(20L, 21L, 81L, 81L, 90L, 20L, 90L, 
81L, 90L, 20L), Date = structure(1:10, .Label = c(""1/2/2020 1:00:00 AM"", 
""1/2/2020 1:00:01 AM"", ""1/2/2020 1:00:02 AM"", ""1/2/2020 1:00:03 AM"", 
""1/2/2020 1:00:04 AM"", ""1/2/2020 1:00:05 AM"", ""1/2/2020 1:00:06 AM"", 
""1/2/2020 1:00:10 AM"", ""1/2/2020 1:00:15 AM"", ""1/2/2020 1:00:25 AM""
 ), class = ""factor""), Edit = c(FALSE, TRUE, TRUE, TRUE, FALSE, 
TRUE, TRUE, TRUE, FALSE, TRUE)), class = ""data.frame"", row.names = c(NA, 
-10L))
</code></pre>

<p><strong>This is what I have tried</strong></p>

<pre><code> library(dplyr)
 library(readr)

 for (i in 1:nrow(df) {


if (df[i] == Edit == ""False"") {
print(df[rows]) 
}
    else if (df[i] &lt; condition) {
print(df[rows])

}
    }

   mutate(Date = as.POSIXct(Date, format = '%m/%d/%Y %H:%M:%OS')) %&gt;%
   mutate(RowNum = cumsum(!cond)) %&gt;%
   group_by(Length) %&gt;%
   summarize(Start = min(Date),
        End = max(Date),
        Duration = End - Start) %&gt;%
</code></pre>

<p>I have a start, I am just unsure of how to put this together. Any help or suggestions are appreciated.</p>
"
"60472968","<p>Using <code>dplyr</code> : </p>

<pre><code>library(dplyr)

df %&gt;%
  mutate(Date = lubridate::mdy_hms(Date),
         gr = lag(cumsum(!Edit), default = TRUE)) %&gt;%
  slice(-c(1, n())) %&gt;%
  group_by(gr) %&gt;%
  summarise(Start = min(Date),
            End = max(Date),
            Duration = as.integer(End - Start), 
            RowNum = n(), 
            Length = Length[n()]) %&gt;%
  mutate(RowNum = cumsum(RowNum)) %&gt;%
  slice(n():1) %&gt;%
  select(-gr)

#  Start               End                 Duration RowNum Length
#  &lt;dttm&gt;              &lt;dttm&gt;                 &lt;int&gt;  &lt;int&gt;  &lt;int&gt;
#1 2020-01-02 01:00:05 2020-01-02 01:00:15       10      8     90
#2 2020-01-02 01:00:01 2020-01-02 01:00:04        3      4     90
</code></pre>
","15","","0","269285","5403","4754","49182","60472837","60473864","<p><strong>Objective</strong></p>

<p>I have a large dataset, df, where I have a Length, Date and Edit Column. My goal is to iterate through a large dataset and find the index, start and end times for a given condition.</p>

<p><strong><em>Working backwards</em></strong>, I need to get the index or <strong><em>row number</em></strong> <strong><em>where Edit is False</em></strong> *with the condition that the <strong><em>previous</em></strong> <strong><em>Edit is True</em></strong>.This will output an 'End' and the value that is in the Length column.</p>

<p>The <strong><em>Start is generated by going backwards from the 'End' index</em></strong> <em>(Edit is False</em>) and when you come across the next <em>(Edit is False)</em>  <strong>+ 1</strong></p>

<pre><code> Length        Date                               Edit

  20            1/2/2020 1:00:00 AM               False
  21            1/2/2020 1:00:01 AM               True
  81            1/2/2020 1:00:02 AM               True
  81            1/2/2020 1:00:03 AM               True
  90            1/2/2020 1:00:04 AM               False
  20            1/2/2020 1:00:05 AM               True
  90            1/2/2020 1:00:06 AM               True
  81            1/2/2020 1:00:10 AM               True
  90            1/2/2020 1:00:15 AM               False        
  20            1/2/2020 1:00:25 AM               True
</code></pre>

<p><strong>This is my desired output:</strong></p>

<pre><code>Start                   End                   Duration   RowNum      Length 

1/2/2020 1:00:05 AM     1/2/2020 1:00:15 AM   10         8              90
1/2/2020 1:00:01 AM     1/2/2020 1:00:04 AM   3          4              90
</code></pre>

<p><strong><em>Starting backwards</em></strong>, we see that the first End time is at, 1/2/2020 1:00:15 AM, because Edit is False, and its previous Edit value is True. The length is 90, and the RowNumber is 8. The Start would go backwards from 1/2/2020 1:00:15 AM until we come to <em>another Edit is False line plus 1</em> , so it would be: 1/2/2020 1:00:05 AM</p>

<p><strong>dput</strong></p>

<pre><code>structure(list(Length = c(20L, 21L, 81L, 81L, 90L, 20L, 90L, 
81L, 90L, 20L), Date = structure(1:10, .Label = c(""1/2/2020 1:00:00 AM"", 
""1/2/2020 1:00:01 AM"", ""1/2/2020 1:00:02 AM"", ""1/2/2020 1:00:03 AM"", 
""1/2/2020 1:00:04 AM"", ""1/2/2020 1:00:05 AM"", ""1/2/2020 1:00:06 AM"", 
""1/2/2020 1:00:10 AM"", ""1/2/2020 1:00:15 AM"", ""1/2/2020 1:00:25 AM""
 ), class = ""factor""), Edit = c(FALSE, TRUE, TRUE, TRUE, FALSE, 
TRUE, TRUE, TRUE, FALSE, TRUE)), class = ""data.frame"", row.names = c(NA, 
-10L))
</code></pre>

<p><strong>This is what I have tried</strong></p>

<pre><code> library(dplyr)
 library(readr)

 for (i in 1:nrow(df) {


if (df[i] == Edit == ""False"") {
print(df[rows]) 
}
    else if (df[i] &lt; condition) {
print(df[rows])

}
    }

   mutate(Date = as.POSIXct(Date, format = '%m/%d/%Y %H:%M:%OS')) %&gt;%
   mutate(RowNum = cumsum(!cond)) %&gt;%
   group_by(Length) %&gt;%
   summarize(Start = min(Date),
        End = max(Date),
        Duration = End - Start) %&gt;%
</code></pre>

<p>I have a start, I am just unsure of how to put this together. Any help or suggestions are appreciated.</p>
"
"60473864","<p>True + False should give 1 (True ==1, False == 0).  Basically, one end should be True + False, the other end should be False + True. So you have a window. <br>
Next step is to get rid of the nulls
Then look for values in going_forward equal to 1.
<br></p>

<pre><code>df['grouping_forward'] = df.Edit.add(df.Edit.shift(1))
df['grouping_backward'] = df.Edit.add(df.Edit.shift(-1))


(df.dropna()
 .query('grouping_forward==1')
 .assign(Row = lambda x: np.where(x.Edit.eq(0),
                                  x.index,
                                  np.nan),
        Start = lambda x: np.where(x.Edit.eq(1), 
                                   x.Date,
                                   np.datetime64('NaT')),
        End = lambda x: np.where(x.Edit.eq(0),
                                 x.Date,
                                 np.datetime64('NaT'))
    )
 .ffill()
 .query('Edit == 0')
 .drop(['grouping_forward','grouping_backward','Date','Edit'],axis=1)
 .assign(Duration = lambda x: x.End.sub(x.Start).dt.seconds)
  )

    Length  Row     Start                End             Duration
4   90      4.0 2020-01-02 01:00:01 2020-01-02 01:00:04     3
8   90      8.0 2020-01-02 01:00:05 2020-01-02 01:00:15     10
</code></pre>
","19","","2","13958","3315","15","1304","60472837","60473864","<p><strong>Objective</strong></p>

<p>I have a large dataset, df, where I have a Length, Date and Edit Column. My goal is to iterate through a large dataset and find the index, start and end times for a given condition.</p>

<p><strong><em>Working backwards</em></strong>, I need to get the index or <strong><em>row number</em></strong> <strong><em>where Edit is False</em></strong> *with the condition that the <strong><em>previous</em></strong> <strong><em>Edit is True</em></strong>.This will output an 'End' and the value that is in the Length column.</p>

<p>The <strong><em>Start is generated by going backwards from the 'End' index</em></strong> <em>(Edit is False</em>) and when you come across the next <em>(Edit is False)</em>  <strong>+ 1</strong></p>

<pre><code> Length        Date                               Edit

  20            1/2/2020 1:00:00 AM               False
  21            1/2/2020 1:00:01 AM               True
  81            1/2/2020 1:00:02 AM               True
  81            1/2/2020 1:00:03 AM               True
  90            1/2/2020 1:00:04 AM               False
  20            1/2/2020 1:00:05 AM               True
  90            1/2/2020 1:00:06 AM               True
  81            1/2/2020 1:00:10 AM               True
  90            1/2/2020 1:00:15 AM               False        
  20            1/2/2020 1:00:25 AM               True
</code></pre>

<p><strong>This is my desired output:</strong></p>

<pre><code>Start                   End                   Duration   RowNum      Length 

1/2/2020 1:00:05 AM     1/2/2020 1:00:15 AM   10         8              90
1/2/2020 1:00:01 AM     1/2/2020 1:00:04 AM   3          4              90
</code></pre>

<p><strong><em>Starting backwards</em></strong>, we see that the first End time is at, 1/2/2020 1:00:15 AM, because Edit is False, and its previous Edit value is True. The length is 90, and the RowNumber is 8. The Start would go backwards from 1/2/2020 1:00:15 AM until we come to <em>another Edit is False line plus 1</em> , so it would be: 1/2/2020 1:00:05 AM</p>

<p><strong>dput</strong></p>

<pre><code>structure(list(Length = c(20L, 21L, 81L, 81L, 90L, 20L, 90L, 
81L, 90L, 20L), Date = structure(1:10, .Label = c(""1/2/2020 1:00:00 AM"", 
""1/2/2020 1:00:01 AM"", ""1/2/2020 1:00:02 AM"", ""1/2/2020 1:00:03 AM"", 
""1/2/2020 1:00:04 AM"", ""1/2/2020 1:00:05 AM"", ""1/2/2020 1:00:06 AM"", 
""1/2/2020 1:00:10 AM"", ""1/2/2020 1:00:15 AM"", ""1/2/2020 1:00:25 AM""
 ), class = ""factor""), Edit = c(FALSE, TRUE, TRUE, TRUE, FALSE, 
TRUE, TRUE, TRUE, FALSE, TRUE)), class = ""data.frame"", row.names = c(NA, 
-10L))
</code></pre>

<p><strong>This is what I have tried</strong></p>

<pre><code> library(dplyr)
 library(readr)

 for (i in 1:nrow(df) {


if (df[i] == Edit == ""False"") {
print(df[rows]) 
}
    else if (df[i] &lt; condition) {
print(df[rows])

}
    }

   mutate(Date = as.POSIXct(Date, format = '%m/%d/%Y %H:%M:%OS')) %&gt;%
   mutate(RowNum = cumsum(!cond)) %&gt;%
   group_by(Length) %&gt;%
   summarize(Start = min(Date),
        End = max(Date),
        Duration = End - Start) %&gt;%
</code></pre>

<p>I have a start, I am just unsure of how to put this together. Any help or suggestions are appreciated.</p>
"
"60472909","<p>If the length of the string <code>x</code> is 1 (you can also just ask if the length is greater than 1 for the while loop), the code skips straight to returning <code>r</code>. However, it may not know what <code>r</code> refers to because it only gets assigned inside the while loop.</p>
","0","","1","87","3","0","16","60472873","60472960","<pre><code>def digital_root(n):
    x = str(n)
    while len(x)!=0 and len(x)!=1:
        r = 0
        for i in range(len(x)):
            r= r + int(x[i])
        x = str(r)
    return r
</code></pre>

<p>A digital root is the recursive sum of all the digits in a number. Given n, take the sum of the digits of n. If that value has more than one digit, continue reducing in this way until a single-digit number is produced. This is only applicable to the natural numbers.</p>

<p>My code:</p>

<p>Is this code efficient? I get the following error:</p>

<pre><code>Traceback (most recent call last):
  File ""main.py"", line 8, in &lt;module&gt;
    test.assert_equals( digital_root(0), 0 )
  File ""/home/codewarrior/solution.py"", line 8, in digital_root
    return r
UnboundLocalError: local variable 'r' referenced before assignment
</code></pre>
"
"60472944","<p>I would approach this with recursion</p>

<pre><code>def root_sum(n):
    x = sum(int(i) for i in str(n))
    if x &gt; 9:
       return root_sum(x)
    return x
</code></pre>

<p>that is the easiest solution imho</p>
","1","2020-03-01 07:34:05","1","92651","4411","1247","10760","60472873","60472960","<pre><code>def digital_root(n):
    x = str(n)
    while len(x)!=0 and len(x)!=1:
        r = 0
        for i in range(len(x)):
            r= r + int(x[i])
        x = str(r)
    return r
</code></pre>

<p>A digital root is the recursive sum of all the digits in a number. Given n, take the sum of the digits of n. If that value has more than one digit, continue reducing in this way until a single-digit number is produced. This is only applicable to the natural numbers.</p>

<p>My code:</p>

<p>Is this code efficient? I get the following error:</p>

<pre><code>Traceback (most recent call last):
  File ""main.py"", line 8, in &lt;module&gt;
    test.assert_equals( digital_root(0), 0 )
  File ""/home/codewarrior/solution.py"", line 8, in digital_root
    return r
UnboundLocalError: local variable 'r' referenced before assignment
</code></pre>
"
"60472960","<p>It looks like r is out of scope when you reach the return statement. It only applies locally within the while statement, which ends before the return statement.</p>

<p>It's good that you only have one return statement and that it is at the broadest scope for the function, and at the end. So, try declaring r outside of the while loop, in the same scope as the return statement. That scope includes everything inside the while loop as well.</p>

<pre><code>def digital_root(n):
    x = str(n)
    r = 0
    while len(x) &gt; 1:
        r = 0
        for i in range(len(x)):
            r = r + int(x[i])
        x = str(r)
    return r
</code></pre>
","2","2020-03-01 08:30:14","3","169","112","3","50","60472873","60472960","<pre><code>def digital_root(n):
    x = str(n)
    while len(x)!=0 and len(x)!=1:
        r = 0
        for i in range(len(x)):
            r= r + int(x[i])
        x = str(r)
    return r
</code></pre>

<p>A digital root is the recursive sum of all the digits in a number. Given n, take the sum of the digits of n. If that value has more than one digit, continue reducing in this way until a single-digit number is produced. This is only applicable to the natural numbers.</p>

<p>My code:</p>

<p>Is this code efficient? I get the following error:</p>

<pre><code>Traceback (most recent call last):
  File ""main.py"", line 8, in &lt;module&gt;
    test.assert_equals( digital_root(0), 0 )
  File ""/home/codewarrior/solution.py"", line 8, in digital_root
    return r
UnboundLocalError: local variable 'r' referenced before assignment
</code></pre>
"
"60473142","<p>The function <code>calculateDate</code> doesn't have a return statement and hence <code>result</code> variable in function <code>calculate</code> (in routes.py) is always <strong>None</strong>.</p>

<p>Modify <code>calculateDate</code> in calc_ttv.py to return your calculated result:</p>

<pre class=""lang-py prettyprint-override""><code>return cttvcl.calculateTime()
</code></pre>
","4","","1","368","10","4","32","60472898","60473142","<p>Thanks for your attention!</p>

<p>I have problem with executing .py script with the flask.
When Im making all things in one 'def' in the call I can return values with dict right into flask and then HTML page. But when Im using more than one 'def's in my srcipt - I have 'None' outside. Sorry for my bad English :)</p>

<p>routes.py</p>

<pre><code>import calc_ttv as ct

...

@app.route('/calculate', methods=['GET', 'POST'])
@login_required
def calculate():
    undertitle = 'online web app'
    date_var = request.form['datepicker-input-line']
    if date_var == '':
        flash('Use calendar first!')
        return render_template('calculate_interface.html', undertitle=undertitle)
    time_var = request.form['timepicker-input-line']
    gender_var = request.form['gender-input-line']
    suntime_var = request.form['timepicker-sunrise-input-line']
    naksh_var = request.form['nakshatra-input-line']
    fday = date_var[0:2]
    fmonth = date_var[3:5]
    fyear = date_var[6:10]
    fhour = time_var[0:2]
    fminute = time_var[3:5]
    if gender_var == 'Male':
        fgender = 1
    else:
        fgender = 2
    fnakshatra = naksh_var
    fsunhour = suntime_var[0:2]
    fsunminute = suntime_var[3:5]
    result = ct.ctmainclass.calculateDate(fday, fmonth, fyear, fhour, fminute, fgender, fnakshatra,
                                          fsunhour, fsunminute)
    flash(result)
    return render_template('calculate_interface.html', undertitle=undertitle, date_var=date_var, 
                            time_var=time_var, gender_var=gender_var, suntime_var=suntime_var,
                            naksh_var=naksh_var, result=result)
</code></pre>

<p>calc_ttv.py</p>

<pre><code>class ctmainclass(object):

    def calculateDate(fday, fmonth, fyear, fhour, fminute, fgender, fnakshatra, fsunhour, fsunminute):

        global val1
        global val2
        global val3
        global val4
        global val5
        global val6
        global val7
        global val8

        val1 = int(fday)
        val2 = int(fmonth)
        val3 = int(fyear)
        val4 = int(fhour)
        val5 = int(fgender)
        val6 = str(fnakshatra)
        val7 = int(fsunhour)
        val8 = int(fsunminute)

        cttvcl = ctmainclass()

        cttvcl.calculateTime()

    def calculateTime(self):

        global val1
        global val2
        global val3
        global val4
        global val5
        global val6
        global val7
        global val8

        output_text_1 = str('fday: ' + str(val1))
        output_text_2 = str('fmonth: ' + str(val2))
        output_text_3 = str('fyear: ' + str(val3))
        output_text_4 = str('Some text')
        output_text_5 = int(279/63)

        return {'output_var1': output_text_1, 'output_var2': output_text_2,'output_var3': output_text_3,
                'output_var4': output_text_4,
                'output_var5': output_text_5}
</code></pre>

<p>calculate_interface.html</p>

<pre><code>{% extends ""base.html"" %}

{% block content %}
&lt;div class=""container""&gt;
    {% with messages = get_flashed_messages() %}
    {% if messages %}
    &lt;ul class=flashes&gt;
    {% for message in messages %}
    &lt;li&gt;&lt;span style='color: red;'&gt;{{ message }}&lt;/span&gt;&lt;/li&gt;
    {% endfor %}
    &lt;/ul&gt;
    {% endif %}
    {% endwith %}
    &lt;h1&gt;MY APP WEB EDITION&lt;/h1&gt;
    {% if undertitle %}
    &lt;div class=""obj-margin-bottom-for-undertitle-var3""&gt;
    &lt;span class=""obj-undertitle-span""&gt;{{ undertitle }}&lt;/span&gt;
    &lt;/div&gt;
    {% endif %}
    &lt;div class='col-lg-3 text-center'&gt;
        &lt;form action=""/calculate"" method=""POST""&gt;
            &lt;input name='datepicker-input-line' id='datepicker-input-line' type='text'
                         class='datepicker-here obj-picker-line-input form-control'/&gt;
            &lt;input name='timepicker-input-line' class=""time obj-picker-line-input form-control""
                         type=""text"" value=""07:30"" /&gt;
            &lt;select name='gender-input-line' class=""obj-picker-line-input form-control""
                          id=""gender-input-line""&gt;
              &lt;option&gt;Male&lt;/option&gt;
              &lt;option&gt;Female&lt;/option&gt;
            &lt;/select&gt;
            &lt;input name='timepicker-sunrise-input-line' class=""time obj-picker-line-input form-control""
                         type=""text"" value=""06:45"" /&gt;
            &lt;select name='nakshatra-input-line' class=""obj-picker-line-input form-control""
                          id=""nakshatra-input-line""&gt;
              &lt;option&gt;Ashvini&lt;/option&gt;
              &lt;option&gt;Bharni&lt;/option&gt;
              &lt;option&gt;Krittika&lt;/option&gt;
              &lt;option&gt;Rohini&lt;/option&gt;
              &lt;option&gt;Mrigashira&lt;/option&gt;
            &lt;/select&gt;
            &lt;button type=""submit"" class=""btn btn-primary btn-block obj-btn-for-calculate""&gt;
             Make some calculations&lt;/button&gt;
        &lt;/form&gt;
    &lt;/div&gt;
    &lt;div class='col-lg-9 text-center'&gt;
        {% if date_var %}
        &lt;div class=""obj-undertitle-span""&gt;{{ date_var }}&lt;/div&gt;
        &lt;div class=""obj-undertitle-span""&gt;{{ time_var }}&lt;/div&gt;
        &lt;div class=""obj-undertitle-span""&gt;{{ gender_var }}&lt;/div&gt;
        &lt;div class=""obj-undertitle-span""&gt;{{ suntime_var }}&lt;/div&gt;
        &lt;div class=""obj-undertitle-span""&gt;{{ naksh_var }}&lt;/div&gt;
        {% endif %}
        &lt;div class=""obj-undertitle-span""&gt;
        {% if result %}
            {% for obj in result.keys() %}
                {{ result[obj] }}
            {% endfor %}
        {% endif %}
        &lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;
{% endblock %}
</code></pre>

<p>And this is what I've got after all:</p>

<p><a href=""https://i.stack.imgur.com/uhciq.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/uhciq.png"" alt=""And this is what I&#39;ve got after all:""></a></p>
"
"60473009","<p>Following the <a href=""https://woocommerce.github.io/woocommerce-rest-api-docs/?python#list-all-products"" rel=""nofollow noreferrer"">docs</a>, I see that you can pass a <strong>page</strong> parameter also.</p>

<p>That makes it pretty straightforward to iterate all pages:</p>

<pre><code>page = 0
While True:
  products = wcapi.get('products', params={'per_page': 100, 'stock_status': 'instock', 'tag': '1111', 'page': page}).json()
  # retrieve ids from **products**
  if len(products) == 0: # no more products
    break
  page = page + 1
</code></pre>

<p>Edit: Bear in mind that this is going to process <strong>per page</strong> (in this case 100) products per loop.</p>
","0","","0","106","2","0","9","60472917","60473009","<p>What I need is to get all product <code>IDs</code> that are <code>'instock'</code> using python.
It looks like this:</p>

<pre><code>wcapi.get('products', params={""per_page"": 100, 'stock_status': 'instock', 'tag': '1111'}).json()
</code></pre>

<p>This code works, but have <code>max limit 100 per_page</code>, I don't understand how can I acquire rest of them (about 2k items in stock) and moreover this request returns all info about products, but I need only <code>IDs</code>.</p>
"
"60478438","<p>There can be several approaches for solving this problem
You can fetch all products in a single call or in multiple calls according to your use-case </p>

<p>for example, you want to fetch 2k records in a single call</p>

<pre><code>products = wcapi.get('products', params={'per_page': 2000, 'stock_status': 'instock', 'tag': '1111', 'page': page}).json()
</code></pre>

<p>But the above approach is not good enough as the number of products may vary from time to time, therefore limiting products to be fetched is not a good solution for the long run.</p>

<p>Hence the better solution is to fetch the product details by multiple calls </p>

<pre><code>page = 1 #The first page number to loop is page 1 
products = []
while True:
    prods = wcapi.get('products', params={'per_page': 100, 'stock_status': 'instock', 'tag': '1111', 'page': page}).json()
    page += 1
    if not prods:
        break
    products.append(prods)
</code></pre>

<p>After fetching all the product list you can fetch the product_ids like</p>

<pre><code>product_ids = [product['id'] for product in products]
</code></pre>
","1","2020-05-18 02:28:09","-1","1","0","0","3","60472917","60473009","<p>What I need is to get all product <code>IDs</code> that are <code>'instock'</code> using python.
It looks like this:</p>

<pre><code>wcapi.get('products', params={""per_page"": 100, 'stock_status': 'instock', 'tag': '1111'}).json()
</code></pre>

<p>This code works, but have <code>max limit 100 per_page</code>, I don't understand how can I acquire rest of them (about 2k items in stock) and moreover this request returns all info about products, but I need only <code>IDs</code>.</p>
"
"60473074","<p>You can put the credentials in a <code>dict</code> and check if the user name exists and matches the password</p>

<pre><code>credentials = {'zaphod': 'helloworld42',
           'mozzie': 'mozzietheaussie'}

user_name = input('Hello, what is your username?\n')
password = input(f'Hello {user_name}, what is your password?\n')

pas = credentials.get(user_name) # returns None if the user name doesn't exists
if not pas:
    print('Wrong Username')
elif pas != password:
    print('Wrong Password')
else:
    print(f'Hello {user_name}, welcome home')
</code></pre>

<p>The <code>print(""Are you gonna trick me pal xd"")</code> seems to be unnecessary, however you can add it by modifying the <code>elif</code></p>

<pre><code>elif pas != password:
    if password in credentials.values():
        print('Are you gonna trick me pal xd')
    else:
        print('Wrong Password')
</code></pre>
","0","2020-03-01 08:09:53","0","33900","639","3108","4197","60472959","60473074","<p>I'm a new coder. And this is my first login system code with python. How can i simplify my code without losing any functions like wrong username and wrong password etc.?</p>

<pre><code>username = ""zaphod""
password = ""helloworld42""
username2 = ""mozzie""
password2 = ""mozzietheaussie""
userUsername = input(""Hello, What is your username? \n"")
UserPassword = input(print(""Hello"", userUsername, ""What is your password? ""))
if userUsername == username:
    if password == UserPassword:
        print(""Hello"", userUsername, ""Welcome home"")
if userUsername == username:
    if UserPassword != password:
        print(""Wrong Password"")
if userUsername == username2:
    if UserPassword != password2:
        print(""Wrong Password"")
if UserPassword == password:
    if userUsername != username:
        print(""Wrong Username"")
if UserPassword == password2:
    if userUsername != username2:
        print(""Wrong Username"")
if userUsername == username2:
    if UserPassword == password2:
        print(""Hello"", userUsername,""Welcome Home"")
if userUsername == username:
    if UserPassword == password2:
        print(""Are you gonna trick me pal xd"")
if userUsername == username2:
    if UserPassword == password:
        print(""Are you gonna trick me pal xd"")
if userUsername != username:
    if userUsername != username2:
        if UserPassword != password:
            if UserPassword != password2:
                print(""Wrong credidentals"")
</code></pre>
"
"60473083","<p>according to @khelwood comment, the word 'async' is one of the reserved words.go to your .py document and change all of 'async' to something else.</p>
","0","","0","305","178","4","74","60472986","60473083","<p><a href=""https://i.stack.imgur.com/SyIth.png"" rel=""nofollow noreferrer"">Error in Cmd Prompt</a></p>

<pre><code>    Traceback (most recent call last):
  File ""Training.py"", line 2, in &lt;module&gt;
    import tensorflow as tf
  File ""C:\Users\Admin\AppData\Local\Programs\Python\Python37-32\lib\site-packages\tensorflow\__init__.py"", line 24, in &lt;module&gt;
    from tensorflow.python import pywrap_tensorflow  # pylint: disable=unused-import
  File ""C:\Users\Admin\AppData\Local\Programs\Python\Python37-32\lib\site-packages\tensorflow\python\__init__.py"", line 49, in &lt;module&gt;
    from tensorflow.python import pywrap_tensorflow
  File ""C:\Users\Admin\AppData\Local\Programs\Python\Python37-32\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 58, in &lt;module&gt;
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\Users\Admin\AppData\Local\Programs\Python\Python37-32\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 114
    def TFE_ContextOptionsSetAsync(arg1, async):
                                             ^
SyntaxError: invalid syntax
&gt;&gt;&gt;
</code></pre>

<p>Why is there a random invalid syntax error at async that prevents my code from running?</p>

<p>Edit: Training.py Code:
<a href=""https://pastebin.com/6uwgNuG3"" rel=""nofollow noreferrer"">https://pastebin.com/6uwgNuG3</a></p>
"
"60487073","<p>What you can do is to mask the data with the where function: </p>

<pre><code>ds = ds.where(np.logical_and(ds.latitude &gt; lat_bounds_min, ds.latitude &lt; lat_bounds_max))
ds = ds.where(np.logical_and(ds.longitude &gt; lon_bounds_min, ds.longitude &lt; lon_bounds_max))
</code></pre>

<p>To get only germany you need shapefiles to check whether a coordinates is in the german polygon or not. But this is not very clear if you need such a solution. </p>
","0","","1","1126","76","8","145","60473025","60487073","<p>I would like to create weather maps from models. For this purpose the German Weather Service provides its forecast data in GRIB2 format.</p>

<p>With xarray I read the grib-file like this:</p>

<pre><code>ds = od('path/to/grib', backend_kwargs={'filter_by_keys': {'typeOfLevel': 'heightAboveGround', 'level': 2}})
</code></pre>

<p>After that I want to plot this data:</p>

<pre><code>fig = plt.figure(figsize=(10,10))
ax = plt.axes(projection=ccrs.Robinson())
ax.coastlines(resolution='10m')
ax.gridlines()

states_provinces = cfeature.NaturalEarthFeature(
    category='cultural',
    name='admin_0_boundary_lines_land',
    scale='10m',
    facecolor='none')
provinces_provinces = cfeature.NaturalEarthFeature(
    category='cultural',
    name='admin_1_states_provinces_lines',
    scale='10m',
    facecolor='none')


ax.add_feature(cfeature.COASTLINE)
ax.add_feature(states_provinces, edgecolor='gray', zorder=1)
ax.add_feature(provinces_provinces, edgecolor='gray', zorder=1)

plot = ds.t2m.plot(cmap=plt.cm.coolwarm, transform=ccrs.PlateCarree())
</code></pre>

<p>But those GRIB files are for whole Europe. I only want to plot for example the Data for Germany with its map in background? So how can I restrict the coordinates (latitude, longitude), so that the plotted map will only show for example Germany?</p>
"
"60473088","<p>Use list comprehension:</p>

<pre><code>df = pd.concat([df] * 10000, ignore_index=True)

In [123]: %timeit [[*x, (x[1], x[2])] for x in df.values.tolist()]
27.8 ms Â± 404 Âµs per loop (mean Â± std. dev. of 7 runs, 10 loops each)

In [124]: %timeit [x + [(x[1], x[2])] for x in df.values.tolist()]
26.6 ms Â± 441 Âµs per loop (mean Â± std. dev. of 7 runs, 10 loops each)

In [125]: %timeit (test_get_value(df))
41.2 s Â± 1.97 s per loop (mean Â± std. dev. of 7 runs, 1 loop each)
</code></pre>
","0","2020-03-01 08:12:53","1","615041","23439","1483","126104","60473032","60473088","<p>I have a pandas dataframe <code>df</code> from which I need to create a list <code>Row_list</code>.</p>

<pre><code>import pandas as pd

df = pd.DataFrame([[1, 572548.283, 166424.411, -11.849, -11.512], 
                   [2, 572558.153, 166442.134, -11.768, -11.983],
                   [3, 572124.999, 166423.478, -11.861, -11.512],
                   [4, 572534.264, 166414.417, -11.123, -11.993]], 
                   columns=['PointNo','easting', 'northing', 't_20080729','t_20090808'])
</code></pre>

<p>I am able to create the list in the required format with the code below, but my dataframe has up to 8 million rows and the list creation is very slow. </p>

<pre><code>def test_get_value_iterrows(df):
    Row_list =[]
    for index, rows in df.iterrows():
        entirerow = df.values[index,].tolist()
        entirerow.append((df.iloc[index,1],df.iloc[index,2]))
        Row_list.append(entirerow)
Row_list
%timeit test_get_value_iterrows(df)

436 Âµs Â± 6.16 Âµs per loop (mean Â± std. dev. of 7 runs, 1000 loops each)
</code></pre>

<p>Not using df.iterrows() and df.iloc() is a little bit faster, </p>

<pre><code>def test_get_value(df):
    Row_list =[]
    for i in df.index:
        entirerow = df.values[i,].tolist()
        entirerow.append((df.iloc[i,1],df.iloc[i,2]))
        Row_list.append(entirerow)
Row_list
%timeit test_get_value(df)

270 Âµs Â± 14.1 Âµs per loop (mean Â± std. dev. of 7 runs, 1000 loops each)
</code></pre>

<p>I am wondering if there is a faster solution to this?</p>
"
"60473160","<p>This behavior of <code>_</code> is only available in REPL. <code>_</code> holds the output of that the last expression evaluated to. It should be noted, if the previous expression produced a TRACEBACK, <code>_</code> will hold the last valid output. You could also chain <code>_</code> upto three times (in IPython), to go fetch the 3rd last output:</p>

<pre><code>&gt;&gt;&gt; 5
5
&gt;&gt;&gt; 6
6
&gt;&gt;&gt; 7
7
&gt;&gt;&gt; ___
5
&gt;&gt;&gt; __
7
&gt;&gt;&gt; _
7
</code></pre>

<p>If you use it in actual scripts, you can treat it <code>_</code> as a variable name (not recommended, if you plan to use the variable), for example:</p>

<pre><code>_ = 10
print(_)

# will print 10
</code></pre>

<p>But the behavior you get at <code>REPL</code> can't be emulated in an actual script.</p>
","0","","3","12268","1175","288","837","60473102","60473160","<p>in <a href=""https://stackoverflow.com/questions/200020/get-last-result-in-interactive-python-shell"">this post</a>  it is explained, how to use the result of a previous code execution by using 
<code>_</code>, e.g. </p>

<pre><code>&gt;&gt;&gt; 5+5
10
&gt;&gt;&gt; _
10
&gt;&gt;&gt; _ + 5
15
&gt;&gt;&gt; _
15
</code></pre>

<p>The question is inspired by languages like Mathematica, where you can easily call the result of the last line. </p>

<p>I notices, that this example does not work when you execute it all at ones, e.g. </p>

<pre><code>5+5
_+5
</code></pre>

<p>Is there a corresponing way to calculate without defining new variables each time? </p>

<hr>

<p>Edit: 
The role of <code>_</code> has been understood. The question is, wether there is (can be/ can't be)  a corresponding statement that reads the result of the last line within the same execution. </p>
"
"60473179","<p>From a quick glance at it. <code>#gold = int(100)</code> is commented out on line 1.
This causes a issue because it doesn't know what gold is. it isn't defined. remove the # before it.</p>
","0","2020-03-01 08:19:04","2","48","10","0","8","60473147","60473179","<p>I got this sample rpg text adventure game online and im trying to understand the codes so that i can use it as a reference to develop my own text adventure game in the future. However, i am currently facing the error ""gold is not defined at line 121 and i suspect is cause by indentation error. Although this is the error im facing so far, i believed that are more mistakes in the codes which i am glad for anyone to point it out.Thanks!</p>

<pre><code># gold = int(100)
inventory = [""sword"", ""armor"", ""potion""]

print(""Welcome hero"")
name = input(""What is your name: "")
print(""Hello"", name,)
# role playing program
#
# spend 30 points on strenght, health, wisdom, dexterity 
# player can spend and take points from any attribute

classic = {""Warrior"",
         ""Archer"",
         ""Mage"",
         ""Healer""}
print(""Choose your race from"", classic,)
classicChoice = input(""What class do you choose: "")
print(""You are now a"", classicChoice,)


# library contains attribute and points
attributes = {""strenght"": int(""0""),
             ""health"": ""0"",
             ""wisdom"": ""0"",
             ""dexterity"": ""0""}

pool = int(30)
choice = None
print(""The Making of a Hero !!!"")
print(attributes)
print(""\nYou have"", pool, ""points to spend."")

while choice != ""0"":
    # list of choices
    print(
    """"""
    Options: 

    0 - End
    1 - Add points to an attribute
    2 - remove points from an attribute
    3 - Show attributes
    """"""
    )
    choice = input(""Choose option: "")
    if choice == ""0"":
        print(""\nYour hero stats are:"")
        print(attributes)
    elif choice == ""1"":
        print(""\nADD POINTS TO AN ATTRIBUTE"")
        print(""You have"", pool, ""points to spend."")
        print(
        """"""
        Choose an attribute:
           strenght
           health
           wisdom
           dexterity
        """"""
        )
        at_choice = input(""Your choice: "")
        if at_choice.lower() in attributes:
            points = int(input(""How many points do you want to assign: ""))
            if points &lt;= pool:
                pool -= points
                result = int(attributes[at_choice]) + points
                attributes[at_choice] = result
                print(""\nPoints have been added."")
            else:
                print(""\nYou do not have that many points to spend"")
        else:
            print(""\nThat attribute does not exist."")
    elif choice == ""2"":
        print(""\nREMOVE POINTS FROM AN ATTRIBUTE"")
        print(""You have"", pool, ""points to spend."")
        print(
        """"""
        Choose an attribute:
           strenght
           health
           wisdom
           dexterity
        """"""
        )
        at_choice = input(""Your choice: "")
        if at_choice.lower() in attributes:
            points = int(input(""How many points do you want to remove: ""))
            if points &lt;= int(attributes[at_choice]):
                pool += points
                result = int(attributes[at_choice]) - points
                attributes[at_choice] = result
                print(""\nPoints have been removed."")
            else:
                print(""\nThere are not that many points in that attribute"")
        else:
            print(""\nThat attribute does not exist."")

    elif choice == ""3"":
        print(""\n"", attributes)
        print(""Pool: "", pool)
    else:
        print(choice, ""is not a valid option."")





While True:
print(""Here is your inventory: "", inventory)
print(""What do you wish to do?"")
print(""please input shop, tavern, forest."")
choice = input(""Go to the shop, go to the tavern, go to the forest: "")

crossbow = int(50)
spell = int(35)
potion = int(35)


if choice == ""shop"":
    print(""Welcome to the shop!"")
    print(""You have"", gold,""gold"")
    buy = input(""What would you like to buy? A crossbow, a spell or a potion: "")

    if buy == ""crossbow"":
        print(""this costs 50 gold"")
        answer = input(""Do you want it: "")
        if answer == ""yes"":
            print(""Thank you for coming!"")
            inventory.append(""crossbow"")
            gold = gold - crossbow
            print(""Your inventory is now:"")
            print(inventory)
            print(""Your gold store now is: "", gold)
        if answer == ""no"":
            print(""Thank you for coming!"")

    if buy == ""spell"":
        print(""this costs 35 gold"")
        answear2 = input(""Do you want it: "")
        if answear2 == ""yes"":
            print(""Thank you for coming!"")
            inventory.append(""spell"")
            gold = gold - spell
            print(""Your inventory is now:"")
            print(inventory)
        if answear2 == ""no"":
            print(""Thank you for coming!"")


    if buy == ""potion"":
        print(""this costs 35 gold"")
        answear3 = input(""Do you want it: "")
        if answear3 == ""yes"":
            print(""Thank you for coming!"")
            inventory.append(""spell"")
            gold = gold - potion
            print(""Your inventory is now:"")
            print(inventory)
        if answear3 == ""no"":
            print(""Thank you for coming!"")


choice = input(""Go to the shop, go to the tavern, go to the forest: "")
while choice != ""shop"" or ""tavern"" or ""forest"":
    print(""Not acepted"")
    print(""What do you wish to do?"")
    print(""please input shop, tavern, forest."")
    choice = input(""Go to the shop, go to the tavern, go to the forest: "")

if choice == ""teavern"":
    print(""You enter the tavern and see a couple of drunken warriors singing, a landlord behind the bar and a dodgy figure sitting at the back of the tavern."")
    tavernChoice = input(""Would you like to talk to the 'drunken warriors', to the 'inn keeper', approach the 'dodgy figure' or 'exit'"")

    if tavernChoice == ""drunken warriors"":
        print(""You approach the warriors to greet them."")
        print(""They notice you as you get close and become weary of your presence."")
        print(""As you arrive at their table one of the warriors throughs a mug of ale at you."")
    if dexterity &gt;= 5:
        print(""You quickly dodge the mug and leave the warriors alone"")
    else:
        print(""You are caught off guard and take the mug to the face compleatly soaking you."")
        print(""The dodgy figure leaves the tavern"")
</code></pre>
"
"60473224","<h1>Reason</h1>

<p>You are overwriting to <code>failure_details_dict[test]</code> for every each loop.</p>

<hr>

<h1>Solution</h1>

<p>You should set list to it only once.
<br>You have several options to do it.</p>

<ul>
<li>Non-pythonic way(<strong>NOT RECOMMENDED</strong>)</li>
</ul>

<pre class=""lang-py prettyprint-override""><code>if test not in failure_details_dict:
    failure_details_dict[test] = []
</code></pre>

<ul>
<li>Replace assignment to <code>dict.setdefault</code> call. This way doesn't affect other interactions with <code>failure_details_dict</code></li>
</ul>

<pre class=""lang-py prettyprint-override""><code>failure_details_dict.setdefault(test, [])  # instead of failure_details_dict[test] = []
</code></pre>

<ul>
<li>Use <code>collections.defaultdict</code> instead of <code>dict</code>. This way will <strong>AFFECT</strong> other interactions with <code>failure_detilas_dict</code>.</li>
</ul>

<pre class=""lang-py prettyprint-override""><code>from collections import defaultdict

failure_details_dict = defaultdict(list)  # instead of {}
</code></pre>

<hr>

<h1>Example</h1>

<p>And I have refactored your code:</p>

<pre class=""lang-py prettyprint-override""><code>all_failures = [
    'test1/path/to/test1/log/failure_reason1',
    'test1/path/to/test1/log/failure_reason2',
    'test2/path/to/test2/log/failure_reason1',
    'test2/path/to/test2/log/failure_reason2',
    'test3/path/to/test3/log/failure_reason1',
    'test4/path/to/test4/log/failure_reason1',
]

failure_details_dict = {}

for failure in all_failures:
    key, *paths, reason = failure.split('/')
    failure_details_dict.setdefault(key, []).append({
        'path': f""/{'/'.join(paths)}/"",
        'reason': reason,
    })

for key, value in failure_details_dict.items():
    print(key)
    print(value)
    print()
</code></pre>

<hr>

<h1>Conclusion</h1>

<ul>
<li>If you want a simple change, use <code>dict.setdefault</code> method.</li>
<li>If you have multiple accesses to <code>failure_details_dict</code> and you want default value for each access, use <code>collection.defaultdict</code> class.</li>
</ul>

<hr>

<h1>Extra</h1>

<blockquote>
  <p>How can we modify the code so that 'path' key is copied only once and only multiple dictionaries with 'reason' key is created? In general, what would be the best way to store the data in JSON format?</p>
</blockquote>

<p>You can reformat your JSON like:</p>

<pre><code>{
  ""test1"": {
    ""path"": ""/path/to/test1/log/"",
    ""reason"": [
      ""failure_reason1"",
      ""failure_reason2""
    ]
  },
  ""test2"": {
    ""path"": ""/path/to/test2/log/"",
    ""reason"": [
      ""failure_reason1"",
      ""failure_reason2""
    ]
  },
  ""test3"": {
    ""path"": ""/path/to/test3/log/"",
    ""reason"": [
      ""failure_reason1""
    ]
  },
  ""test4"": {
    ""path"": ""/path/to/test4/log/"",
    ""reason"": [
      ""reason1""
    ]
  }
}
</code></pre>

<p>From code:</p>

<pre class=""lang-py prettyprint-override""><code>all_failures = [
    'test1/path/to/test1/log/failure_reason1',
    'test1/path/to/test1/log/failure_reason2',
    'test2/path/to/test2/log/failure_reason1',
    'test2/path/to/test2/log/failure_reason2',
    'test3/path/to/test3/log/failure_reason1',
    'test4/path/to/test4/log/failure_reason1',
]

failure_details_dict = {}

for failure in all_failures:
    key, *paths, reason = failure.split('/')
    failure_details_dict.setdefault(key, {
        'path': f""/{'/'.join(paths)}/"",
        'reason': [],
    })['reason'].append(reason)

for key, value in failure_details_dict.items():
    print(key)
    print(value)
    print()
</code></pre>
","1","2020-03-02 08:30:42","4","2217","279","150","156","60473163","60473224","<p>I have a list of test-failures as shown below -</p>

<pre><code>all_failures = [
            'test1/path/to/test1/log/failure_reason1',
            'test1/path/to/test1/log/failure_reason2',
            'test2/path/to/test2/log/failure_reason1',
            'test2/path/to/test2/log/failure_reason2',
            'test3/path/to/test3/log/failure_reason1',
            'test4/path/to/test4/log/failure_reason1',
        ]
</code></pre>

<p>I am trying to construct a JSON like object by parsing each failure in the list. So far, i have tried to write the following code -</p>

<pre><code>for failure in all_failures:
    data = failure.split('/',1)
    test = data[0]
    failure_details_dict[test] = []

    data = '/' + data[1]
    data = data.rsplit('/', 1)

    test_details_dict['path'] = data[0] + '/'
    test_details_dict['reason'] = data[1]

    failure_details_dict[test].append(test_details_dict)

    test_details_dict = {}  

for key,value in failure_details_dict.items():
    print(key)
    print(value)
    print()
</code></pre>

<p>The output i am getting is -</p>

<pre><code>test4
[{'reason': 'failure_reason1', 'path': '/path/to/test4/log/'}]

test3
[{'reason': 'failure_reason1', 'path': '/path/to/test3/log/'}]

test1
[{'reason': 'failure_reason2', 'path': '/path/to/test1/log/'}]

test2
[{'reason': 'failure_reason2', 'path': '/path/to/test2/log/'}]
</code></pre>

<p>whereas, the <strong>expected output</strong> is -</p>

<pre><code>{
    ""test1"": [
                {
                    ""path"": ""/path/to/test1/log/"",
                    ""reason"": ""failure_reason1"" 
                },
                {
                    ""path"": ""/path/to/test1/log/"",
                    ""reason"": ""failure_reason2""     
                }

            ],
    ""test2"": [
                {
                    ""path"": ""/path/to/test2/log/"",
                    ""reason"": ""failure_reason1"" 
                },
                {
                    ""path"": ""/path/to/test2/log/"",
                    ""reason"": ""failure_reason2""     
                }
            ],
    ""test3"": [
                {
                    ""path"": ""/path/to/test3/log/"",
                    ""reason"": ""failure_reason1"" 
                },
            ],
    ""test4"": [
                {
                    ""path"": ""/path/to/test4/log/"",
                    ""reason"": ""reason1"" 
                },
            ]
}
</code></pre>

<p>As we can see, I have not been able to add the <strong>second</strong> <em>path</em> and <em>reason for failure</em> to the same key. Example - test1 and test2 have two reasons for failure. </p>

<p>Can someone please help to understand what i am missing? Thank you!</p>
"
"60473261","<p>You can use <strong>regular expressions</strong> to extract the information from your failure log file names. This can be simply achieved in the following way:</p>

<pre><code>import re
import json

all_failures = [
            'test1/path/to/test1/log/failure_reason1',
            'test1/path/to/test1/log/failure_reason2',
            'test2/path/to/test2/log/failure_reason1',
            'test2/path/to/test2/log/failure_reason2',
            'test3/path/to/test3/log/failure_reason1',
            'test4/path/to/test4/log/failure_reason1',
        ]


info = dict()
for failure in all_failures:
    match = re.search(r""^(.*?)(/.*/)(.*)$"", failure)

    details = dict()
    details[""path""] = match.group(2)
    details[""reason""] = match.group(3)

    if match.group(1) in info:
        info[match.group(1)].append(details)
    else:
        info[match.group(1)] = []
        info[match.group(1)].append(details)

print(json.dumps(info, indent=4))
</code></pre>

<p><strong>OUTPUT:</strong></p>

<pre><code>{
    ""test1"": [
        {
            ""path"": ""/path/to/test1/log/"",
            ""reason"": ""failure_reason1""
        },
        {
            ""path"": ""/path/to/test1/log/"",
            ""reason"": ""failure_reason2""
        }
    ],
    ""test2"": [
        {
            ""path"": ""/path/to/test2/log/"",
            ""reason"": ""failure_reason1""
        },
        {
            ""path"": ""/path/to/test2/log/"",
            ""reason"": ""failure_reason2""
        }
    ],
    ""test3"": [
        {
            ""path"": ""/path/to/test3/log/"",
            ""reason"": ""failure_reason1""
        }
    ],
    ""test4"": [
        {
            ""path"": ""/path/to/test4/log/"",
            ""reason"": ""failure_reason1""
        }
    ]
}
</code></pre>
","2","","1","31794","2954","64","2384","60473163","60473224","<p>I have a list of test-failures as shown below -</p>

<pre><code>all_failures = [
            'test1/path/to/test1/log/failure_reason1',
            'test1/path/to/test1/log/failure_reason2',
            'test2/path/to/test2/log/failure_reason1',
            'test2/path/to/test2/log/failure_reason2',
            'test3/path/to/test3/log/failure_reason1',
            'test4/path/to/test4/log/failure_reason1',
        ]
</code></pre>

<p>I am trying to construct a JSON like object by parsing each failure in the list. So far, i have tried to write the following code -</p>

<pre><code>for failure in all_failures:
    data = failure.split('/',1)
    test = data[0]
    failure_details_dict[test] = []

    data = '/' + data[1]
    data = data.rsplit('/', 1)

    test_details_dict['path'] = data[0] + '/'
    test_details_dict['reason'] = data[1]

    failure_details_dict[test].append(test_details_dict)

    test_details_dict = {}  

for key,value in failure_details_dict.items():
    print(key)
    print(value)
    print()
</code></pre>

<p>The output i am getting is -</p>

<pre><code>test4
[{'reason': 'failure_reason1', 'path': '/path/to/test4/log/'}]

test3
[{'reason': 'failure_reason1', 'path': '/path/to/test3/log/'}]

test1
[{'reason': 'failure_reason2', 'path': '/path/to/test1/log/'}]

test2
[{'reason': 'failure_reason2', 'path': '/path/to/test2/log/'}]
</code></pre>

<p>whereas, the <strong>expected output</strong> is -</p>

<pre><code>{
    ""test1"": [
                {
                    ""path"": ""/path/to/test1/log/"",
                    ""reason"": ""failure_reason1"" 
                },
                {
                    ""path"": ""/path/to/test1/log/"",
                    ""reason"": ""failure_reason2""     
                }

            ],
    ""test2"": [
                {
                    ""path"": ""/path/to/test2/log/"",
                    ""reason"": ""failure_reason1"" 
                },
                {
                    ""path"": ""/path/to/test2/log/"",
                    ""reason"": ""failure_reason2""     
                }
            ],
    ""test3"": [
                {
                    ""path"": ""/path/to/test3/log/"",
                    ""reason"": ""failure_reason1"" 
                },
            ],
    ""test4"": [
                {
                    ""path"": ""/path/to/test4/log/"",
                    ""reason"": ""reason1"" 
                },
            ]
}
</code></pre>

<p>As we can see, I have not been able to add the <strong>second</strong> <em>path</em> and <em>reason for failure</em> to the same key. Example - test1 and test2 have two reasons for failure. </p>

<p>Can someone please help to understand what i am missing? Thank you!</p>
"
"60485767","<p>Try:</p>

<pre><code>  body = {
  ""size"": 0,
  ""aggs"": {
    ""sold"": {
      ""terms"": {
        ""field"": ""product.sold.keyword"",
        ""size"": 40000
      },
      ""aggs"": {
        ""bought"": {
          ""terms"": {
            ""field"": ""product.bought.keyword"",
            ""size"": 40000
          }
        }
      }
    }
  }
}
</code></pre>
","2","","1","2677","27","50","452","60473218","60485767","<p>I want to get the list of unique values from a field, and at the same time, count how many times each of those unique values have appeared in two different fields.</p>

<p>Let's say I have a product that can be both <em>bought</em> and <em>sold</em>. I want to query: Unique values that have appeared in the field <em>sold</em>, AND, count how many times each value has appeared in both <code>sold</code>, and <code>bought</code> fields. </p>

<p>The closest I came so far is <code>terms</code> aggregation I get to have both values, but in two different buckets:</p>

<pre><code>{
  ""aggs"": {
    ""sold"": {
      ""terms"":{
        ""field"": ""productname.sold.keyword"",
        ""size"": 1000
      }
    },
    ""bought"": {
      ""terms"":{
        ""field"": ""product.bought.keyword"",
        ""size"": 1000
      }
    }
  }
}
</code></pre>

<p>But it gives me the result in two seperate buckets. My ideal output is like this:</p>

<pre><code>  ""aggregations"": {
    ""product_stat"": {
      ""key"": ""&lt;product&gt;""
      ""sold"": ""&lt;#&gt;""
      ""bought"": ""&lt;#&gt;""
    }
  }
</code></pre>

<p>How should I form my query to achieve so? I want to get unique values of sold, and count how many times that value has appeared in sold and bought fields. </p>
"
"60473353","<p>When you specify a list by range, the first boundary is included and the second boundary is not.  So here you are including <code>{}-01-01</code> and not including <code>{}-12-31</code>.  But you are including the midnight value.  </p>

<p>So, you need to include the last day of the year, but omit the ""celebratory"" New Year Hour:</p>

<pre><code>&gt;&gt;&gt; year = 2018
&gt;&gt;&gt; times = list(pd.date_range('{}-01-01'.format(year), '{}-01-01'.format(year+1), freq='H'))
&gt;&gt;&gt; times = times[:-1]
&gt;&gt;&gt; len(times)
8760
</code></pre>

<p>You need to include the New Year's Day, <code>{}-01-01</code>, so that you get New Year's Eve, <code>{}-12-31</code>.  But then you get the midnight hour since that's what starts the day.  Hence the need to eliminate the last entry in the list: <code>times = times[:-1]</code>, so that you're ending at 11:00pm on 12-31.</p>
","0","2020-03-01 19:50:37","0","724","360","26","91","60473262","60473353","<p>I am using python <a href=""https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.date_range.html"" rel=""nofollow noreferrer"">pandas date range</a> package to create a list of hourly timestamps for a calendar year. I code to do this, it looks like : 
<code>
year = 2018
times = list(pd.date_range('{}-01-01'.format(year), '{}-12-31'.format(year), freq='H'))</code></p>

<p>I expect the length of <code>times</code> to be 8760 (the number of hours in a year). But when I view the length of the <code>times</code> vector, it is only 8737. Why????</p>
"
"60486170","<p>The problem is likely to come from the way you have written you csv file. I would bet a coin that when read as text (with a simple text editor like notepad, notepad++, or vi) is actually contains:</p>

<pre><code>1228280254256623616,â€¦,b'RT @MinisteroDifesa: #14febbraio Il Ministro...'
1228257366841405441,â€¦,b'\xe2\x80\x9cNon t\xe2\x80\x99ama chi amor ti...'
...
</code></pre>

<p>or:</p>

<pre><code>1228280254256623616,â€¦,""b'RT @MinisteroDifesa: #14febbraio Il Ministro...'""
1228257366841405441,â€¦,""b'\xe2\x80\x9cNon t\xe2\x80\x99ama chi amor ti...'""
...
</code></pre>

<p>Pandas read_csv then correctly reads <em>the text representation of a byte string</em>.</p>

<p>The correct fix would be to write true UTF-8 encoded strings, but as I do not know the code, I cannot propose a fix.</p>

<p>A possible workaround is to use <code>ast.literal_eval</code> to convert the text representation into a byte string and decode it:</p>

<pre><code>df['text'] = df['text'].apply(lambda x: ast.literal_eval(x).decode('utf8'))
</code></pre>

<p>It should give:</p>

<pre><code>                    id ... text
0  1228280254256623616 ... RT @MinisteroDifesa: #14febbraio Il Ministro...
1  1228257366841405441 ... â€œNon tâ€™ama chi amor ti...
...
</code></pre>
","1","","1","119467","1546","546","7383","60473284","60486170","<p>I have used tweepy to store the text of tweets in a csv file using Python csv.writer(), but I had to encode the text in utf-8 before storing, otherwise tweepy throws a weird error.</p>

<p>import pandas as pd</p>

<p>data = pd.read_csv('C:\Users\Lenovo\Desktop\_Carabinieri_10_tweets.csv', delimiter="","", encoding=""utf-8"")</p>

<p>data.head()</p>

<p>print(data.head())</p>

<p>Now, the text data is stored like this:</p>

<p>OUTPUT</p>

<p>id â€¦ text</p>

<p>0 1228280254256623616 â€¦ b'RT @MinisteroDifesa: #14febbraio Il Ministroâ€¦</p>

<p>1 1228257366841405441 â€¦ b'\xe2\x80\x9cNon t\xe2\x80\x99ama chi amor tiâ€¦</p>

<p>2 1228235394954620928 â€¦ b'Eseguite dai #Carabinieri del Nucleo Investiâ€¦</p>

<p>3 1228219588589965316 â€¦ b'Il pianeta brucia\nConosci il black carbon?...</p>

<p>4 1228020579485261824 â€¦ b'RT @Coninews: Emozioni tricolore \xe2\x9c\xaâ€¦</p>

<p>Although I used ""utf-8"" to read the file into a DataFrame with the code shown below, the characters look very different in the output. the output looks like bytes. The language is italian.</p>

<p>I tried to decode this using this code (there is more data in other columns, text is in second column). But, it doesn't decode the text. I cannot use .decode('utf-8') as the csv reader reads data as strings i.e. type(row[2]) is 'str' and I can't seem to convert it into bytes, the data gets encoded once more!</p>

<p>How can I decode the text data?</p>

<p>I would be very happy if you can help with this, thank you in advance.</p>
"
"60473609","<p>Your submodule should just be:</p>

<pre><code>import logging

logger = logging.getLogger(__name__)

logger.info(""This is an info message from submodule, should be recorded in main.log!"")
logger.debug(""This is a debug message from submodule, also should be recorded in main.log!!"")
</code></pre>

<p>Then your main module should be:</p>

<pre><code># main.py importing a submodule
import logging

logger = logging.getLogger(__name__)

# log to console
c_handler = logging.StreamHandler()

console_format = logging.Formatter(""[%(levelname)s] %(message)s"")
c_handler.setFormatter(console_format)
c_handler.setLevel(logging.INFO)

logging.getLogger().addHandler(c_handler)

# log to file from main
logfile = ""./logging/main.log""

f_handler = logging.FileHandler(filename=logfile)

f_format = logging.Formatter(""%(asctime)s: %(name)-18s [%(levelname)-8s] %(message)s"")
f_handler.setFormatter(f_format)
f_handler.setLevel(logging.DEBUG)

logging.getLogger().addHandler(f_handler)
logging.getLogger().setLevel(logging.DEBUG)

import submodule

logger.error(""This is an error!!! Logged to console"")
logger.debug(""This is a debug error. Not logged to console, but should log to file"")
</code></pre>

<p>Edit: The handlers have to be added before the code in the submodule runs. To effect this the <code>import submodule</code> was moved after the code that sets up the handlers. </p>

<p>Normally modules shouldn't have any top level logging calls so all the imports can be done at the top and then callables that use logging are called indirectly by the code in the <code>if __name__==""__main__"":</code> after it sets up logging.</p>
","3","2020-03-01 10:08:09","1","66828","4060","31","4293","60473336","60473609","<p>I would like to have:</p>

<ul>
<li>a <em>main.log</em> file with all logs above DEBUG level to be captured from main and imported modules</li>
<li>the console should show only ERROR level logs from main and its imported submodules. 

<ul>
<li>Note: I may have <em>no control on the error handling logs</em> of the imported submodules.</li>
</ul></li>
</ul>

<p>Here is the <em>main.py</em> code for this:</p>

<pre><code># main.py importing a submodule
import logging

import submodule

logger = logging.getLogger(__name__)
logger.setLevel(logging.DEBUG)

# log to console
c_handler = logging.StreamHandler()

console_format = logging.Formatter(""[%(levelname)s] %(message)s"")
c_handler.setFormatter(console_format)
c_handler.setLevel = logging.INFO

logger.addHandler(c_handler)

logger.error(""This is an error!!! Logged to console"")

# log to file from main
logfile = ""./logging/main.log""

f_handler = logging.FileHandler(filename=logfile)

f_format = logging.Formatter(""%(asctime)s: %(name)-18s [%(levelname)-8s] %(message)s"")
f_handler.setFormatter(f_format)
f_handler.setLevel = logging.DEBUG

logger.addHandler(f_handler)

logger.debug(""This is a debug error. Not logged to console, but should log to file"")
</code></pre>

<p>... and the <em>submodule.py</em> code ...</p>

<pre><code># submodule.py
import logging

logger = logging.getLogger(__name__)
logger.setLevel(logging.INFO)

formatter = logging.Formatter('%(levelname)s:%(name)s:%(message)s')

# log to console
c_handler = logging.StreamHandler()
c_handler.setFormatter(formatter)
logger.addHandler(c_handler)

logger.info(""This is an info message from submodule, should be recorded in main.log!"")
logger.debug(""This is a debug message from submodule, also should be recorded in main.log!!"")
</code></pre>

<p>When I run <em>main.py</em>:</p>

<ul>
<li><code>[ERROR] This is an error!!! Logged to console</code> shows up correctly in the console</li>
<li>But...

<ul>
<li>Console also shows...

<ul>
<li><code>INFO:submodule:This is an info message from submodule, should be recorded in main.log!</code> </li>
<li><code>[DEBUG] This is a debug error. Not logged to console, but should log to file</code></li>
</ul></li>
<li>The <code>main.log file</code> only shows <code>yy-mm-dd hh:mm:ss: __main__           [DEBUG   ] This is a debug error. Not logged to console, but should log to file</code> only. It does not show logs from the submodule.py</li>
</ul></li>
</ul>

<p>Appreciate knowing:</p>

<ul>
<li>Where am I going wrong?</li>
<li>What would be the code correction needed?</li>
</ul>

<p><strong>EDIT:</strong> Based on @Dan D. suggestion changed <em>submodule.py</em> as follows:</p>

<pre><code># submodule.py
import logging

logger = logging.getLogger(__name__)

def logsomething():
    logger.info(""This is an info message from submodule, should be recorded in main.log!"")
    logger.debug(""This is a debug message from submodule, also should be recorded in main.log!!"")
</code></pre>

<p>... and the program logs to console and file appropriately.</p>

<p>Q. If I want to change to message format for the <em>submodule.py</em> only, can this be done through <em>main.py</em>?</p>
"
"60536984","<p>This answer is scoped to the question's title and content: Providing getters and setters for frequency and channel of a packet.</p>

<p>For this solution, use the <a href=""https://wiki.wireshark.org/SampleCaptures?action=AttachFile&amp;do=get&amp;target=wpa-Induction.pcap"" rel=""nofollow noreferrer"">wpa-Induction.pcap</a> file in Wireshark's <a href=""https://wiki.wireshark.org/SampleCaptures"" rel=""nofollow noreferrer"">Sample Captures</a>.</p>

<h2>Poking around</h2>

<p>It's useful to poke around one packet to see what fields Scapy has access to in the Scapy interpreter.</p>

<pre class=""lang-py prettyprint-override""><code>&gt;&gt;&gt; pkts = rdpcap('wpa-Induction.pcap')
&gt;&gt;&gt; pkts[0].summary()
""RadioTap / Dot11FCS / Dot11Beacon / Dot11Elt / Dot11EltRates / Dot11Elt / Dot11Elt / Dot11Elt / Dot11Elt / Dot11EltRSN / Dot11Elt / Dot11EltVendorSpecific / Dot11EltMicrosoftWPA / SSID=''""
&gt;&gt;&gt; pkts[0].show()
###[ RadioTap dummy ]###
  version= 0
  pad= 0
  len= 24
  present= Flags+Rate+Channel+Lock_Quality+Antenna+dB_AntSignal+RXFlags
  Flags= FCS
  Rate= 2
  Channel= 2412
  ChannelFlags= CCK+2GHz
  Antenna= 84
  notdecoded= '\x00\x00+\x00\x00\x9fa\xc9\\'

... &lt;output truncated&gt; ...
</code></pre>

<p>While 2412 is a frequency and <strong>NOT a channel</strong>, this is the data we want. RadioTap is the layer per <code>pkts[0].summary()</code>. Putting it together, </p>

<pre class=""lang-py prettyprint-override""><code>&gt;&gt;&gt; frequency = pkts[0][RadioTap].Channel
&gt;&gt;&gt; print(frequency)
2412
</code></pre>

<p>Scapy <a href=""https://github.com/secdev/scapy/issues/1979"" rel=""nofollow noreferrer"">does not provide access</a> to the channel, but it's trivial to convert frequency to channel.</p>

<h2>Putting it Together</h2>

<h3>Getting the Frequency</h3>

<p>Given a file and packet number, we can now get the channel and frequency for a packet.</p>

<pre class=""lang-py prettyprint-override""><code>from scapy.all import RadioTap, rdpcap

def getChannel(frequency):
    base = 2407              # 2.4Ghz
    if frequency//1000 == 5: 
        base = 5000          # 5Ghz
    # 2.4 and 5Ghz channels increment by 5
    return (frequency-base)//5

def getFrequency(file, packet_number):
  pkts = rdpcap(file)
  # Scapy mixes up Channel/Frequency here
  frequency = pkts[packet_number][RadioTap].Channel
  return frequency

freq = getFrequency('wpa-Induction.pcap', 0)
chan = getChannel(freq)
print(""Channel: {0} \nFrequency: {1}"".format(freq, chan))
</code></pre>

<h3>Setting the Frequency</h3>

<p>Let's say we wanted to change the frequency to 5300 and save it. This would only require iterating over the packet list, change the frequency for every packet, and saving the result. In the scapy interpreter:</p>

<pre class=""lang-py prettyprint-override""><code>&gt;&gt;&gt; for i in range(len(pkts)):
...     pkts[i][RadioTap].Channel = 5300
&gt;&gt;&gt; wrpcap('temp.pcap', pkts)
&gt;&gt;&gt; pkts2 = rdpcap('temp.pcap')
&gt;&gt;&gt; pkts[0].Channel
5300
</code></pre>
","1","2020-03-06 23:17:23","2","2441","250","104","360","60473359","60609951","<p>I have been  trying to capture WIFI packets with Linux and see the frequency/channel at which packet was captured. I tried Wireshark and there was no luck and no <a href=""https://networkengineering.stackexchange.com/questions/65389/wireshark-not-showing-frequency-channel"">help</a>. Though using a <a href=""https://wiki.wireshark.org/SampleCaptures"" rel=""noreferrer"">sample packets</a> from Wireshark, I can see the frequency/channel.</p>

<p>So now I'm experimenting with Scapy. I wanted to figure out the frequency/channel of a sniffed packet, but still no luck. Is there a way to do this with Scapy.</p>

<p>P.S.
If there is a better tool than Scapy, or Python, I appreciate comments</p>
"
"60609951","<p>I <a href=""https://wifinigel.blogspot.com/2013/11/what-are-radiotap-headers.html"" rel=""noreferrer"">found out</a> that RadioTab headers are not part of any Dot11 protocol but are merely added by the network interface. And the reason I got the RadioTab headers on sample packets from <a href=""https://wiki.wireshark.org/SampleCaptures"" rel=""noreferrer"">Wireshark.org</a> and not from my live wireshark capture is because some network adapters do not add RadioTap while others do and the network adapter of my laptop does not add RadioTab headers. I checked this with a new external WiFi adapter and it did add the RadioTap headers.</p>

<blockquote>
  <p>If the adapter does not inject the additional information as it captures frames, then no radiotap headers will be added.</p>
</blockquote>

<p>So to my main question, how to get/set frequency of a packet.
I expected Scapy to have this option but it doesn't, and it shouldn't. The reason is that the frequency depends on what is set on the network adapter. So what I did was to set the frequency/channel of my WiFi adapter to a different one. My external WiFi adapter can work in various channels so I changed each and confirmed with the RadioTap header. There are a simple <a href=""https://unix.stackexchange.com/questions/77965/force-a-specific-frequency-from-my-wireless-card"">linux commands/tools</a> that helped me check the supported channels of my WiFi interface, and switch to a particular channel.</p>

<blockquote>
  <p>To capture/send packets at a certain frequency or channel, you need to change the working channel of your interface and set the sniffer/sender interface in scapy to that interface.</p>
</blockquote>

<p>EDIT - Other problems I faced and solutions:</p>

<p>If you are on linux, and you want to change the working channel of your interface you need to disable network-manager for that interface and to do this
First
Add the following snippet to <code>/etc/network/interfaces</code></p>

<pre><code>auto $iface
iface $iface inet dhcp
wpa-conf /etc/wpa_supplicant/wpa_supplicant.conf
</code></pre>

<p>replace <code>$iface</code> with your interface name. This will let you control the interface by yourself. And then add the following lines to <code>/etc/wpa_supplicant/wpa_supplicant.conf</code></p>

<pre><code>ctrl_interface=/var/run/wpa_supplicant

network={
    ssid=""Your_AP_SSID""
    psk=""Your_Passphrase""
    freq_list=2412 2437 2462
}
</code></pre>

<p>Note that <code>2412 2437 2462</code> are the frequencies (channel 1, 6, 11 in this case) for your interface to choose from. You can edit them to desired frequency. <a href=""https://askubuntu.com/questions/1058622/how-to-force-to-linux-to-connect-only-5ghz-channel"">Source</a>. But first you have to check that your interface supports these frequencies. To check that</p>

<pre><code>iwlist channel
</code></pre>

<p>Finally after everything is done. </p>

<pre><code>sendp(Ether()/IP(dst=""1.2.3.4"",ttl=(1,4)), iface=""wlp3s0"")
</code></pre>

<p>This will send you packets at the frequency that <code>wlp3s0</code> is set.</p>
","1","2020-03-11 06:13:51","6","1586","123","24","259","60473359","60609951","<p>I have been  trying to capture WIFI packets with Linux and see the frequency/channel at which packet was captured. I tried Wireshark and there was no luck and no <a href=""https://networkengineering.stackexchange.com/questions/65389/wireshark-not-showing-frequency-channel"">help</a>. Though using a <a href=""https://wiki.wireshark.org/SampleCaptures"" rel=""noreferrer"">sample packets</a> from Wireshark, I can see the frequency/channel.</p>

<p>So now I'm experimenting with Scapy. I wanted to figure out the frequency/channel of a sniffed packet, but still no luck. Is there a way to do this with Scapy.</p>

<p>P.S.
If there is a better tool than Scapy, or Python, I appreciate comments</p>
"
"60473738","<p>IIUC you have an equal amount of columns for each category, and you want to compress this into numeric columns which are shape agnostic. If so this will work:</p>

<pre><code>dfs = []
for var in ['S', 'D', 'C']:
        # filter  columns with a regex
        res = df[df.iloc[:, 2:].filter(regex= var + '\d{1,2}').columns].dropna()
        # rename coumns with just numbers to enable concatenation
        res.columns = range(3)
        dfs.append(res)

df = pd.concat([df.iloc[:, :2], pd.concat(dfs)], 1)
print(df)
</code></pre>

<p>Output:</p>

<pre><code>   SC0  Shape        0      1       2
2   1   Circle      1.0     1.0     1.0
3   13  Square      2.0     1.0     2.0
4   13  Diamond     2.0     1.0     2.0
5   16  Diamond     2.0     2.0     2.0
6   16  Square      2.0     2.0     2.0
</code></pre>
","0","","1","6477","2042","245","830","60473458","60473749","<p>I have the following data frame structure:</p>

<pre><code>    SC0 Shape   S1  S2  S3  C1  C2  C3  D1  D2  D3
2   1   Circle  NaN NaN NaN 1   1   1   NaN NaN NaN
3   13  Square  2   1   2   NaN NaN NaN NaN NaN NaN
4   13  Diamond NaN NaN NaN NaN NaN NaN 2   1   2
5   16  Diamond NaN NaN NaN NaN NaN NaN 2   2   2
6   16  Square  2   2   2   NaN NaN NaN NaN NaN NaN
</code></pre>

<p>How can I combine S1,S2,S3 with C1,C2,C3,D1,D2,D3 so S1,C1 and D1 are on the same column, S2,C2 and D2...(all the way to S16,C16 and D16)?</p>

<p>When Shape = Circle the populated columns are C1-C16, when Shape = Square its S1-S16 and for Shape = Diamond its D1-D16.</p>

<p>I don't mind creating a new set of columns or copy two of them to to an existing set, as long as I have all the #1 scores in the same column, #2 same column etc.</p>

<p>Thank you!</p>
"
"60473749","<p>Try:</p>

<pre class=""lang-py prettyprint-override""><code>n=3
cols_prefixes=[""C"", ""S"", ""D""]
for i in range(n):
    cols=[f""{l}{i+1}"" for l in cols_prefixes]
    df[f""res{i+1}""]=df[cols].bfill(axis=1).iloc[:,0]
    df=df.drop(columns=cols)
</code></pre>

<p>Outputs:</p>

<pre class=""lang-py prettyprint-override""><code>   SC0    Shape  res1  res2  res3
2    1   Circle   1.0   1.0   1.0
3   13   Square   2.0   1.0   2.0
4   13  Diamond   2.0   1.0   2.0
5   16  Diamond   2.0   2.0   2.0
6   16   Square   2.0   2.0   2.0
</code></pre>
","0","","1","11365","152","50","745","60473458","60473749","<p>I have the following data frame structure:</p>

<pre><code>    SC0 Shape   S1  S2  S3  C1  C2  C3  D1  D2  D3
2   1   Circle  NaN NaN NaN 1   1   1   NaN NaN NaN
3   13  Square  2   1   2   NaN NaN NaN NaN NaN NaN
4   13  Diamond NaN NaN NaN NaN NaN NaN 2   1   2
5   16  Diamond NaN NaN NaN NaN NaN NaN 2   2   2
6   16  Square  2   2   2   NaN NaN NaN NaN NaN NaN
</code></pre>

<p>How can I combine S1,S2,S3 with C1,C2,C3,D1,D2,D3 so S1,C1 and D1 are on the same column, S2,C2 and D2...(all the way to S16,C16 and D16)?</p>

<p>When Shape = Circle the populated columns are C1-C16, when Shape = Square its S1-S16 and for Shape = Diamond its D1-D16.</p>

<p>I don't mind creating a new set of columns or copy two of them to to an existing set, as long as I have all the #1 scores in the same column, #2 same column etc.</p>

<p>Thank you!</p>
"
"60473602","<pre><code>for sertag in soup.findAll('span', {'class': 'font-weight-medium text-jet'})[1]:
    print(sertag, sertag.next_element.strip())
</code></pre>
","3","2020-03-01 09:23:06","0","8986","62","313","1419","60473480","60473602","<p>I need a little help with my code. I am learning Python and beautiful soup in order to scrap some data from the Dell website. </p>

<p>I need to get the service tag, warranty and service code from a particular server but I am not understanding how to navigate the HTML tree. </p>

<p>This is my code so far. </p>

<pre><code>from selenium import webdriver
from selenium.webdriver.firefox.options import Options
from bs4 import BeautifulSoup
import time

options = Options()
options.add_argument('--headless')
driver = webdriver.Firefox(options=options, executable_path=r'/Users/peterfranca/Downloads/geckodriver')
driver.get(""https://www.dell.com/support/home/ca/en/cadhs1/product-support/servicetag/0-NE9lVXI4NlpmbjFtRHJBbTF0dDhoQT090/overview"")

time.sleep(1)
soup = BeautifulSoup(driver.page_source, 'html.parser')

for model in soup.findAll('h1', {'class':'mb-3 mb-lg-1 text-center text-lg-left position-relative word-break'}):
    print(model.text)

for tag in soup.findAll('p', {'class':'service-tag mb-0'}):
    print(tag.text)

for warranty in soup.findAll('p', {'id':'warrantyExpiringLabel'}):
    print(warranty.text)

for sertag in soup.findAll('p', {'class':'font-weight-medium text-jet'}):
    print(sertag.text)

driver.quit()
</code></pre>

<p>The last ""for"" is where I can't figure out how to get the correct data. </p>

<pre><code>for sertag in soup.findAll('p', {'class':'font-weight-medium text-jet'}):
    print(sertag.text)
</code></pre>

<p>Basically, I would like to run the above block of code and get the below output. </p>

<pre><code>Express Service Code: 14270045690
</code></pre>

<p>Can anyone help me with this? 
Can anyone also explain to me how to navigate in the right way in the HTML tree?</p>
"
"60473539","<p>Definitely store your results in a variable, and then save the whole thing into a file afterwards. Saving during the loop is ""messy"" and less efficient because of I/O calls constantly. </p>

<p>Note that this is not true if you are dealing with millions of entries, in which case you'd have to spare memory a bit and write to file in ""batches"". But it doesn't feel like this should be a problem in your case.</p>
","0","","0","938","98","29","140","60473489","60473539","<p>I'm trying to solve the simple pendulum in python. My goal is to save my results into a file in order to make a plot afterwards. Should I put my the code that saves the data in the loop or define a new function ?</p>

<p>NB: I'm a beginner.</p>

<p>Thank you.</p>

<pre><code>import numpy as np

g = 9.8
L = 3

THETA_0 = np.pi / 4
THETA_DOT_0 = 0

def get_theta_double_dot(theta):
    return - (g / L) * np.sin(theta)

def theta(t):
    theta = THETA_0
    theta_dot = THETA_DOT_0

    dela_t = 0.01
    for tps in np.arange(0, t, delta_t):
        theta_double_dot = get_theta_double_dot(theta)
        theta = theta + (theta_dot * delta_t)
        theta_dot = theta_dot + (theta_double_dot * delta_t)
    return theta
</code></pre>
"
"60473658","<p>Checking which statemets are triggered:</p>

<pre><code>import numpy as np

def scalar_function(x, y):
    """""" A function that returns x*y if x&lt;y and x/y otherwise
    """"""
    if x &lt; y :
        print('if x: ',x)
        print('if y: ',y)
        out = x * y 
        print('if out', out)
    else:
        print('else x: ',x)
        print('else y: ',y)
        out = x/y
        print('else out', out)

    return out

def vector_function(x, y):
    """"""
    Make it possible to accept vectors as input
    """"""
    v_scalar_function = np.vectorize(scalar_function)
    return v_scalar_function(x, y)


vector_function(np.array([3,4]), np.array([4,3]))

if x:  3
if y:  4
if out 12
if x:  3
if y:  4
if out 12
else x:  4
else y:  3
else out 1.3333333333333333 # &lt;-- seems that the value is calculated correctly, but the wrong dtype is returned
</code></pre>

<p>So, you can rewrite the scalar function:</p>

<pre><code>def scalar_function(x, y):
    """""" A function that returns x*y if x&lt;y and x/y otherwise
    """"""
    if x &lt; y :
        out = x * y 
    else:
        out = x/y
    return float(out)


vector_function(np.array([3,4]), np.array([4,3]))
array([12.        ,  1.33333333])
</code></pre>
","0","","2","6026","765","678","483","60473567","60473737","<p>I'm obtaining a strange result when I vectorise a function with numpy. </p>

<pre><code>import numpy as np
def scalar_function(x, y):
    """""" A function that returns x*y if x&lt;y and x/y otherwise
    """"""
    if x &lt; y :
        out = x * y 
    else:
        out = x/y 
    return out

def vector_function(x, y):
    """"""
    Make it possible to accept vectors as input
    """"""
    v_scalar_function = np.vectorize(scalar_function)
    return v_scalar_function(x, y)
</code></pre>

<p>we do have </p>

<pre><code>scalar_function(4,3)
# 1.3333333333333333
</code></pre>

<p>Why is the vectorized version giving this strange output? </p>

<pre><code>vector_function(np.array([3,4]), np.array([4,3]))
[12  1]
</code></pre>

<p>While this call to the vectorized version works fine:</p>

<pre><code>vector_function(np.array([4,4]), np.array([4,3]))
[1.         1.33333333]
</code></pre>

<p>Reading <a href=""https://docs.scipy.org/doc/numpy/reference/generated/numpy.divide.html"" rel=""nofollow noreferrer"">numpy.divide</a>:</p>

<blockquote>
  <p>Notes
  The floor division operator // was added in Python 2.2 making // and / equivalent operators. The default floor division operation of / can be replaced by true division with from <code>__future__</code> import division.
  In Python 3.0, // is the floor division operator and / the true division operator. The true_divide(x1, x2) function is equivalent to true division in Python.</p>
</blockquote>

<p>Makes me think this might be a remaining issue related to python2? 
But I'm using python 3!</p>
"
"60473737","<p>The docs for <a href=""https://docs.scipy.org/doc/numpy/reference/generated/numpy.vectorize.html"" rel=""nofollow noreferrer""><code>numpy.vectorize</code></a> state:</p>

<blockquote>
  <p>The output type is determined by evaluating the first element of the
  input, unless it is specified</p>
</blockquote>

<p>Since you did not specify a return data type, and the first example is integer multiplication, the first array is also of integer type and rounds the values. Conversely, when the first operation is division, the datatype is automatically upcasted to float. You can fix your code by specifying a dtype in <code>vector_function</code> (which doesn't necessarily have to be as big as 64-bit for this problem):</p>

<pre><code>def vector_function(x, y):
    """"""
    Make it possible to accept vectors as input
    """"""
    v_scalar_function = np.vectorize(scalar_function, otypes=[np.float64])
    return v_scalar_function(x, y)
</code></pre>

<p>Separately, you should also make note from that very same documentation that <code>numpy.vectorize</code> is a convenience function and basically just wraps a Python <code>for</code> loop so is not vectorized in the sense that it provides any real performance gains.</p>

<p>For a binary choice like this, a better overall approach would be:</p>

<pre><code>def vectorized_scalar_function(arr_1, arr_2):
    return np.where(arr_1 &lt; arr_2, arr_1 * arr_2, arr_1 / arr_2)

print(vectorized_scalar_function(np.array([4,4]), np.array([4,3])))
print(vectorized_scalar_function(np.array([3,4]), np.array([4,3])))
</code></pre>

<p>The above should be orders of magnitude faster and (possibly coincidentally rather than a hard-and-fast rule to rely on) doesn't suffer the type casting issue for the result.</p>
","2","2020-03-01 20:17:16","3","10837","1326","3819","7193","60473567","60473737","<p>I'm obtaining a strange result when I vectorise a function with numpy. </p>

<pre><code>import numpy as np
def scalar_function(x, y):
    """""" A function that returns x*y if x&lt;y and x/y otherwise
    """"""
    if x &lt; y :
        out = x * y 
    else:
        out = x/y 
    return out

def vector_function(x, y):
    """"""
    Make it possible to accept vectors as input
    """"""
    v_scalar_function = np.vectorize(scalar_function)
    return v_scalar_function(x, y)
</code></pre>

<p>we do have </p>

<pre><code>scalar_function(4,3)
# 1.3333333333333333
</code></pre>

<p>Why is the vectorized version giving this strange output? </p>

<pre><code>vector_function(np.array([3,4]), np.array([4,3]))
[12  1]
</code></pre>

<p>While this call to the vectorized version works fine:</p>

<pre><code>vector_function(np.array([4,4]), np.array([4,3]))
[1.         1.33333333]
</code></pre>

<p>Reading <a href=""https://docs.scipy.org/doc/numpy/reference/generated/numpy.divide.html"" rel=""nofollow noreferrer"">numpy.divide</a>:</p>

<blockquote>
  <p>Notes
  The floor division operator // was added in Python 2.2 making // and / equivalent operators. The default floor division operation of / can be replaced by true division with from <code>__future__</code> import division.
  In Python 3.0, // is the floor division operator and / the true division operator. The true_divide(x1, x2) function is equivalent to true division in Python.</p>
</blockquote>

<p>Makes me think this might be a remaining issue related to python2? 
But I'm using python 3!</p>
"
"60473624","<pre class=""lang-py prettyprint-override""><code>&gt;&gt;&gt; [[str(element) + '.jpg' for element in sublist] for sublist in a]
[['0.jpg', '1.jpg', '5.jpg'], ['3.jpg', '4.jpg', '6.jpg', '7.jpg'], ['2.jpg']]
</code></pre>
","1","","0","2466","181","38","203","60473592","60473624","<p>For example:</p>

<p>I have a list and need to add "".jpg"" to all elements in a list in python.</p>

<p>Input: </p>

<pre><code>a = [[0, 1, 5], [3, 4, 6, 7], [2]]
</code></pre>

<p>output:</p>

<pre><code>[[0.jpg, 1.jpg, 5.jpg], [3.jpg, 4.jpg, 6.jpg, 7.jpg], [2.jpg]]
</code></pre>

<p>hope someone here could help. I'm open to any ideas, recommendation and suggestion, thank you.</p>
"
"60473670","<p>Use <code>requests</code> module to get the data as dictionary, from there you can get the values by the key</p>

<pre><code>import requests

data = requests.get('http://110.93.230.117:1403/api/order/5e439b7052fcf2189ccb5207').json()
print(data)

""""""
{'date': '2020-02-12T06:30:08.106Z',
 '_id': '5e439b7052fcf2189ccb5207',
 'fitoName': 'Chinasor 01 - Bu Yang Huan Wu Wan',
 'fitoCode': 'Chinasor 01',
 'providerName': 'Soria - Chinasor',
 'providerCode': 'Chinasor 01',
 'valueItem': '01',
 'Email': 'helder@gmail.com',
 '__v': 0}
""""""
</code></pre>
","4","","2","33900","639","3108","4197","60473611","60473670","<p>I have a scenario where I will open my website and than I have to call the Rest API where in that API I will be needing some data, like user name,password and some URLs. The purpose of calling API is that I dont know the credentials as well as the URLS which is going to get check and every time these data will get change therefore I will just call an API.
Below is my Selenium Python </p>

<pre><code>from selenium import webdriver
from selenium import webdriver
from selenium.webdriver.common.keys import Keys
# declare variable to store the URL to be visited
base_url=""https://www.fitotouch.com/qitouch""

driver = webdriver.Chrome('E:/Chrome driver/chromedriver.exe')
driver.maximize_window()
#function of our 'driver' object.
driver.implicitly_wait(10) #10 is in seconds
driver.get(base_url)
driver.implicitly_wait(10)
driver.find_element_by_name('password').send_keys(""*****"")
driver.implicitly_wait(10)
driver.find_element_by_class_name('arrow-icon').click()
</code></pre>

<p>After above click command I have to call API and Login from the data given in the API.</p>

<p>My API is :
<a href=""http://110.93.230.117:1403/api/order/5e439b7052fcf2189ccb5207"" rel=""nofollow noreferrer"">http://110.93.230.117:1403/api/order/5e439b7052fcf2189ccb5207</a></p>

<p>If I can get solution in Java than also it is Fine. </p>

<p><a href=""https://i.stack.imgur.com/hpHfr.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/hpHfr.png"" alt=""enter image description here""></a></p>
"
"60473680","<p>Regarding the code:</p>

<pre><code>for row in csv_reader:
    if row[0] == idNum:
        print(""matching barcode found"")
        return True
    else:
        print(""barcode not on file. Adding..."")
        return False
</code></pre>

<p>This <code>for</code> loop does indeed process every row if you let it, but you are <em>not</em> letting it because both your true and false parts of the <code>if</code> statement return after reading the first row, effectively ignoring all the others.</p>

<hr>

<p>What you probably need is this scheme: if you don't find it in the first row, don't immediately return false - you need to check all the <em>other</em> rows and return false only if it's in <em>none</em> of them.</p>

<p>In other words, something like this:</p>

<pre><code># Check ALL rows.

for row in csv_reader:
    # If found in THIS row, notify success.

    if row[0] == idNum:
        print(""matching barcode found"")
        return True

# If found in NO rows, notify failure.

print(""barcode not on file. Adding..."")
return False
</code></pre>
","0","","3","765968","4508","1542","87167","60473651","60473680","<p>I want to read the 1st column of each row of a CSV file in order to try and find a value. Currently I have this:</p>

<pre><code>def checkForCable(idNum):
    with open(""test.txt"") as csv_file:
        csv_reader = csv.reader(csv_file, delimiter=',')
        for row in csv_reader:
            if row[0] == idNum:
                print(""matching barcode found"")
                return True
            else:
                print(""barcode not on file. Adding..."")
                return False
</code></pre>

<p>But this seems to only check the first column of the first row and then stop, rather than checking all of the first columns of the n rows in the CSV file. For instance if row[0] in column 0 is not equal to the number it's searching for, then it won't proceed to check row[0] in column 1 etc. and I'm not sure why.</p>
"
"60473759","<p>You can use Pandas. Pandas is very excellent in dealing with csv files. </p>

<pre><code>import Pandas as pd

file = pd.read_csv('csv_file')
df = pd.DataFrame(file)

# Check if Dataframe is empty using empty attribute
if df['Columnname'].empty == True:
    print('Barcode is empty')
else:
    print('Barcode is not empty')
</code></pre>
","3","","0","111","26","0","18","60473651","60473680","<p>I want to read the 1st column of each row of a CSV file in order to try and find a value. Currently I have this:</p>

<pre><code>def checkForCable(idNum):
    with open(""test.txt"") as csv_file:
        csv_reader = csv.reader(csv_file, delimiter=',')
        for row in csv_reader:
            if row[0] == idNum:
                print(""matching barcode found"")
                return True
            else:
                print(""barcode not on file. Adding..."")
                return False
</code></pre>

<p>But this seems to only check the first column of the first row and then stop, rather than checking all of the first columns of the n rows in the CSV file. For instance if row[0] in column 0 is not equal to the number it's searching for, then it won't proceed to check row[0] in column 1 etc. and I'm not sure why.</p>
"
"60482890","<p>I decided to just rerun the scripts and compare the outputs. Seems it's not promising -- I lost a lot of rows.</p>
","3","","0","1400","265","2","240","60473704","60482890","<p>I mistakenly had two scripts running at the same time that wrote a pandas dataframe in chunks to the same CSV file. Since the CSV file was supposed to be appended, the script itself doesn't block writing to the CSV file if it already exists. I didn't catch it until it was too late.</p>

<p>Kinda like this:</p>

<p><strong>script1.py</strong></p>

<pre><code>for i, chunk in enumerate(datachunks):
       do something
       result_df.to_csv('csvfile.csv') (in write mode for the 1st chunk, append mode for the next chunks)
</code></pre>

<p><strong>script2.py</strong></p>

<pre><code>for i, chunk in enumerate(datachunks2):
       do something
       result_df.to_csv('csvfile.csv') (in write mode for the 1st chunk, append mode for the next chunks)
       # should have been csvfile2.csv
</code></pre>

<p>Each script takes around 12 hours to execute due to the sheer volume of data that has to be processed, and I think it's faster to separate the CSV file into two so that I get the outputs that <em>each</em> script should have given. This should work -- unless I have unintended duplicates in the file, or even lines that didn't write.</p>

<p>Both scripts finished without any errors, if that's relevant.</p>

<p>Any chance of duplicates/missing data in this <code>csvfile.csv</code>?</p>
"
"60474315","<p>It really depends on exactly what you did. Without more information I'm going to assume that you have a text widget somewhere and that you want to disable tab from indenting there.  </p>

<p>Example:</p>

<pre><code>from tkinter import Tk, Text

def no_tab(event):
    return 'break'

root = Tk()
text_widget = Text()
text_widget.pack()
text_widget.bind('&lt;Tab&gt;', no_tab)
root.mainloop()
</code></pre>

<p>In this example we bind the <code>&lt;Tab&gt;</code> key to the function <code>no_tab</code>. So everytime tab is pressed within the text widget the <code>no_tab</code> function is called. The <code>no_tab</code> function returns the magic string <code>'break'</code> which means that the action of the key won't be preformed and thus disabling the indentation that the tab key would have created otherwise.</p>
","0","","1","2054","688","4","136","60473777","60474315","<p>I've recently made a text editor with tkinter for python.
I need a way to disable tab from being able to be used normally, so it doesn't indent.
Does anyone have any idea as to how I would achieve this?
Thank you for your time.</p>
"
"60473910","<p>Please check your code it's wrong.
You want somthing like this?</p>

<pre><code>class Parent:
    def __init__(self, var1, var2):
        self.var1 = var1
        self.var2 = var2
        print(var2)

    #more methods that to some stuff

class Child(Parent):
    a = 1 #a and b are class attributes
    b = 2

    def __init__(self, var1 = 1, var2 = 2, var3 = None):
        super().__init__(var1 = 1, var2 = 2) 
        self.var3 = var3

child_obj = Child(var3 = 3)
</code></pre>
","7","2020-03-01 10:23:44","0","924","0","5","55","60473871","60473910","<p>I am writing an OOP program in Python 3 with inheritance and am running into the title error when I try to initialize the child class like so:</p>

<pre><code>class Parent:
    def __init__(self, var1, var2):
        self.var1 = var1
        self.var2 = var2

    #more methods that to some stuff

class Child(Parent):
    a = 1 #a and b are class attributes
    b = 2

    def __init__(self, var1 = 1, var2 = 2, var3 = None):
        super().__init__(self, var1 = 1, var2 = 2) #error shows up for this line
        self.var3 = var3

child_obj = Child(var3 = 3)
</code></pre>

<p>When I create a <code>Child</code> object I get an error saying: <code>TypeError: __init__() got multiple values for argument 'var1'</code>. Anyone know what could be wrong here? Thanks in advance.</p>
"
"60474517","<p>The <a href=""https://docs.python.org/3/library/concurrent.futures.html"" rel=""nofollow noreferrer""><code>concurrent.futures</code></a> module provides a more high-level API for using threads or processes for individual operations.</p>

<pre><code>from concurrent.futures import ThreadPoolExecutor

executor = ThreadPoolExecutor()
executor.submit(np.savez_compressed, '/tmp/values.a', dict(a=a))
</code></pre>

<p>If you don't want the entire Executor API, you can define your own helper to run a function in a thread.</p>

<pre><code>def threaded(call, *args, **kwargs):
    """"""Execute ``call(*args, **kwargs)`` in a thread""""""
    thread = threading.Thread(target=call, args=args, kwargs=kwargs)
    thread.start()
    return thread

threaded(np.savez_compressed, '/tmp/values.a', dict(a=a))
</code></pre>
","0","2020-03-01 11:26:37","4","25421","1898","3232","3219","60473911","60474517","<p>I would like to call a function in a thread. Calling it with 
the conventional API looks like:</p>

<pre><code>from threading import Thread
import numpy as np
a = np.random.rand(int(1e8),1)

Thread(target=np.savez_compressed, args=('/tmp/values.a', dict(a=a))).start()
</code></pre>

<p>I was wondering if there is a pythonic was of making this threaded call with a cleaner API, without defining a  function which is specific for <code>np.savez_compressed</code>. </p>

<p>E.g. something in the style of (pseudo-code):</p>

<pre><code>@make_threaded
np.savez_compressed('/tmp/values.a', dict(a=a))
</code></pre>

<p>Unfortunately decorators can only be applied to function definitions, so the pseudo-code above is not legal.</p>

<p><strong>EDIT</strong>: I am not looking specifically for a decorator API. Rather, a cleaner way to make a function call threaded</p>
"
"60488483","<p>OP here:</p>

<p>Another solution I found was by using decorators with the decorators ""classic"" API:</p>

<pre><code>from threading import Thread

call_threaded(np.savez_compressed)('/tmp/values.a', dict(a=a))

# https://stackoverflow.com/a/19846691/2476373
def call_threaded(fn):        
    def wrapper(*args, **kwargs):
        thread = Thread(target=fn, args=args, kwargs=kwargs)
        thread.start()
        return thread
    return wrapper
</code></pre>
","0","","0","4585","243","8","331","60473911","60474517","<p>I would like to call a function in a thread. Calling it with 
the conventional API looks like:</p>

<pre><code>from threading import Thread
import numpy as np
a = np.random.rand(int(1e8),1)

Thread(target=np.savez_compressed, args=('/tmp/values.a', dict(a=a))).start()
</code></pre>

<p>I was wondering if there is a pythonic was of making this threaded call with a cleaner API, without defining a  function which is specific for <code>np.savez_compressed</code>. </p>

<p>E.g. something in the style of (pseudo-code):</p>

<pre><code>@make_threaded
np.savez_compressed('/tmp/values.a', dict(a=a))
</code></pre>

<p>Unfortunately decorators can only be applied to function definitions, so the pseudo-code above is not legal.</p>

<p><strong>EDIT</strong>: I am not looking specifically for a decorator API. Rather, a cleaner way to make a function call threaded</p>
"
"60476210","<p>No, as of Vega-Lite v4.4 there is no way to make interactions/selections work on mobile. The bug that tracks adding this feature is here: <a href=""https://github.com/vega/vega-lite/issues/4661"" rel=""nofollow noreferrer"">https://github.com/vega/vega-lite/issues/4661</a></p>
","0","","3","51859","797","15","8125","60473973","60476210","<p>The Altair example gallery contains <a href=""https://github.com/altair-viz/altair/blob/master/altair/examples/interval_selection.py"" rel=""nofollow noreferrer"">a nice example</a> of how to use interval selections to create two plots where one allows you to define the scale of the other.</p>

<pre><code>import altair as alt
from vega_datasets import data

source = data.sp500.url

brush = alt.selection(type='interval', encodings=['x'])

base = alt.Chart(source).mark_area().encode(
    x = 'date:T',
    y = 'price:Q'
).properties(
    width=600,
    height=200
)

upper = base.encode(
    alt.X('date:T', scale=alt.Scale(domain=brush))
)

lower = base.properties(
    height=60
).add_selection(brush)

upper &amp; lower
</code></pre>

<p><a href=""https://i.stack.imgur.com/k7nRJ.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/k7nRJ.png"" alt=""enter image description here""></a></p>

<p>If I embed the resulting specification on a page using vega-embed, I get something that works well on desktop browsers but seems to do little if anything on mobile browsers, where dragging along the graph does not create a selection. I can remove a predefined selection by clicking on it in mobile browsers, but that doesn't achieve much. My question therefore becomes:</p>

<blockquote>
  <p>Is there any way to create Vega-Lite specifications, preferably in Altair, with interval selections that are intuitive to use on (any of the prevalent) mobile browsers, ideally by allowing users to create selections by dragging along the graph?</p>
</blockquote>
"
"60474050","<p>This should work.  You need to have the print statement outside the function definition, and also the assignment of <code>x</code>.  </p>

<pre><code>    def factorial(x):
      total = 1
      while x&gt;0:
        total *= x
        x -= 1
      return total

    n = input(""type here: "")
    print factorial(n)
</code></pre>
","1","2020-03-01 10:50:24","0","27066","4430","2273","3147","60473975","60474050","<pre><code>def factorial(x = input(""type here: "")):
  total = 1
  while x&gt;0:
    total *= x
    x -= 1
  return total
  print factorial(x)
</code></pre>

<p><strong>What I am trying is find factorial of a number, but my code does not respond to print command. After input of a number and pressing enter nothing happen. What is wrong here?</strong></p>
"
"60475631","<p>you adopted a recursive method to find a fictoral. Your code is erroneous following code will work.</p>

<p>def factorial(x):</p>

<pre><code>  total =1
  while x&gt;0:
        total =total * factorial (x-1)

  return total
</code></pre>

<p>n = input(""type here: "")</p>

<p>print factorial(n)</p>
","0","","-1","63","10","0","37","60473975","60474050","<pre><code>def factorial(x = input(""type here: "")):
  total = 1
  while x&gt;0:
    total *= x
    x -= 1
  return total
  print factorial(x)
</code></pre>

<p><strong>What I am trying is find factorial of a number, but my code does not respond to print command. After input of a number and pressing enter nothing happen. What is wrong here?</strong></p>
"
"60476271","<p>The fact that the tooltips stop working is probably a bug, and it would be worth filing a <a href=""https://github.com/vega/vega-lite/issues/new?labels=Bug+%3Abug%3A&amp;template=Bug_report.md"" rel=""noreferrer"">Vega-Lite bug report</a></p>

<p>It appears you can work around this by adding a second empty selection to the upper chart:</p>

<pre><code>upper = base.add_selection(alt.selection_single())
</code></pre>

<p>You can view the interactive result <a href=""https://vega.github.io/editor/#/url/vega-lite/N4KABGBEDGD2B2AzAlgc0gLjMSA3ZApgO6bYwIAuy8ArrDQM4DqyAJhQBakAsADLwBooceFVr0GACQJoOFUgGZ+AX2UDwUXCOgBDeVgDaGiKAhmoAWx0AnANalINgjsjrzESAXhxW1dFlN3DwpYWAAbKgAHUhwKAE9IggcARxodUWQKPWRcJKFIFAIw1gdI62RoJLVjd0gADxjIeMSHCgILSNhrHTDXKELih1Y9KrcgqDjG5qSsSFT0qiyqXL6CwkHZsoqqmohqoMgOGVQ5UgAmfjHzSAYigmgqBEbbsPuQ634FKYSZqAY-V6QVRXMyQIhsTikABs-Bq+zMgWuVjsDicLhBHi8Pj8MV2oJC4Si3xas3mGSWOTy-XWJU25UqQIxoIaASaP1a7U63V6+QGtKgwzajLxHkmrOmKTS5OyK15NNK9J2QXh1yOsn0YBhTJudweyCerJeby6-DOxN+kGobWsuB6qyxsF88FQDFIBnqkAAusC8WCIVwsDDeHCNJ6xpBBS5WTRrL1ZnIKJEGBgAPQp3KoHQAOlQmQ4NAARln9emCJmALSR24UBgpyMphiRACs-Cz0AYuGFHgAJAxoEcrA4E0nU6XMzm84Xi7AG-32joxzpy2FMgR09ws7ws2cswArBhPEDKIA"" rel=""noreferrer"">here</a>.</p>
","2","","5","51859","797","15","8125","60474039","60476271","<p>The Altair example gallery contains <a href=""https://github.com/altair-viz/altair/blob/master/altair/examples/interval_selection.py"" rel=""nofollow noreferrer"">a nice example</a> of how to use interval selections to create two plots where one allows you to define the scale of the other. I have been trying to add tooltips to both parts of the stacked chart by defining the tooltips as part of the base:</p>

<pre><code>import altair as alt
from vega_datasets import data

source = data.sp500.url

brush = alt.selection(type='interval', encodings=['x'])

base = alt.Chart(source).mark_area().encode(
    x = 'date:T',
    y = 'price:Q',
    tooltip = 'price:Q'
).properties(
    width=600,
    height=200
)

upper = base

lower = base.properties(
    height=60
).add_selection(brush)

upper &amp; lower
</code></pre>

<p>Doing so, the tooltips work as expected on <code>lower</code> but not at all on <code>upper</code>.</p>

<p><a href=""https://i.stack.imgur.com/8CM71.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/8CM71.png"" alt=""enter image description here""></a></p>

<p>If, however, I remove the <code>.add_selection(brush)</code> from <code>lower</code>, the tooltips also work on <code>upper</code> (which was unchanged), but that of course defeats the purpose of the example. I can also make the tooltips work on <code>upper</code> by marking it as interactive, but again, that ruins what's nice about the example. Changing the definition of <code>upper</code> to <code>upper = base.encode(tooltip='price:Q')</code> does nothing.</p>

<blockquote>
  <p>How would I define the tooltip target in a way that makes tooltips show up on both <code>upper</code> and <code>lower</code>?</p>
</blockquote>
"
"60474361","<p>The best way to approach is first saving the file and then reading it to get the text. As a convention, you set a <code>UPLOAD_FOLDER</code> variable with the path to save. Then, in flask use the following to save the file:</p>

<pre class=""lang-py prettyprint-override""><code>
file_path = os.path.join(app.config['UPLOAD_FOLDER'], secure_filename(f.filename))
f = request.files['file']
f.save(file_path)
# This would save the file. Now to read simply use the normal way to read files in Python

with open(file_path, 'r') as f:
    file_content = f.read()
# Rest of the processing logic
</code></pre>

<p>Note that the path is relative to your current working directory, which is usually the root of your project. Also, please be careful when storing and reading files from untrusted users.</p>

<p>A better place to store these files would be somewhere other than your project root. You could have a data directory somewhere through which you could configure Nginx (or any other front proxy) to serve the uploaded files</p>
","3","","3","716","195","11","134","60474093","60474361","<p>I have from and in the form the user can upload files.
I'm using flask, and what im trying to do is to get the data from the text file that the user choose to upload.</p>

<p>There is any way to read the data inside the text file?
I have tried to open the file <code>file = open()</code>, but then i realized that i dont have the path.
Its diffrent then reading file on your local machine.</p>

<pre><code>@app.route('/admin',methods=['GET','POST'])
def admin_panel():
    if request.method == 'GET':
        return render_template('adminpanel.html')

    if request.method == 'POST':
        email = request.form['email']
        file_data = request.files['file']
        file_name = secure_filename(file_data.filename)
        file_data.save(os.path.join(""system"",""files"",""text"",file_name))
        with open(""system/files/text/file_name"") as f:
            file_content = f.read()
            print(file_content)
        file = File(file_data)
        file.read_file_dif()
</code></pre>

<p>Well of course this code does not working. But thats the idea.
Anyone have any idea how i can read a text file from an input file tag?</p>

<p><strong>HTML TAG</strong></p>

<pre><code>      &lt;label for=""myfile""&gt;Select a file:&lt;/label&gt;
      &lt;input type=""file"" id=""myfile"" name=""file""&gt;
</code></pre>
"
"60475361","<p>This is my solution to my problem</p>

<pre><code>from werkzeug.utils import secure_filename
import os

class File():
def __init__(self,file):
    self.file = file

def read_file(self):
    file_name = secure_filename(self.file.filename)
    self.file.save(os.path.join(""app"", ""static"", file_name))
    with open(f""app/static/{file_name}"") as f:
        email_list = f.read().splitlines()
    return email_list
</code></pre>
","0","","0","453","65","0","144","60474093","60474361","<p>I have from and in the form the user can upload files.
I'm using flask, and what im trying to do is to get the data from the text file that the user choose to upload.</p>

<p>There is any way to read the data inside the text file?
I have tried to open the file <code>file = open()</code>, but then i realized that i dont have the path.
Its diffrent then reading file on your local machine.</p>

<pre><code>@app.route('/admin',methods=['GET','POST'])
def admin_panel():
    if request.method == 'GET':
        return render_template('adminpanel.html')

    if request.method == 'POST':
        email = request.form['email']
        file_data = request.files['file']
        file_name = secure_filename(file_data.filename)
        file_data.save(os.path.join(""system"",""files"",""text"",file_name))
        with open(""system/files/text/file_name"") as f:
            file_content = f.read()
            print(file_content)
        file = File(file_data)
        file.read_file_dif()
</code></pre>

<p>Well of course this code does not working. But thats the idea.
Anyone have any idea how i can read a text file from an input file tag?</p>

<p><strong>HTML TAG</strong></p>

<pre><code>      &lt;label for=""myfile""&gt;Select a file:&lt;/label&gt;
      &lt;input type=""file"" id=""myfile"" name=""file""&gt;
</code></pre>
"
"60474331","<p>There is an <code>files</code> parameter for <a href=""https://requests.readthedocs.io/en/master/user/quickstart/#post-a-multipart-encoded-file"" rel=""nofollow noreferrer"">requests.post</a> you can use it to send files like this:</p>

<pre class=""lang-py prettyprint-override""><code>import requests

url = ""http://localhost:8000/post_text_file""
fin = open('Hello World.txt', 'rb')
files = {'file': fin}
try:
    r = requests.post(url, files=files)
finally:
    fin.close()
</code></pre>

<p>And usually the file sent with your request is accessible with <code>request.files</code> as a dictionary of files uploaded.</p>
","0","","3","680","178","6","67","60474097","60474331","<p>I can't write a function, that can get a .txt file through POST-request.</p>

<p>I have a .txt file that contains phrase: Hello World!</p>

<p>server side:</p>

<pre class=""lang-py prettyprint-override""><code>from fastapi import FastAPI, File
from starlette.requests import Request
import io

app = FastAPI()
@app.post(""/post_text_file"")
def text_function(request: Request,
            file: bytes = File(...)):
    text = open(io.BytesIO(file), ""r"").read()
    return text  # Hello World!
</code></pre>

<p>client side:</p>

<pre class=""lang-py prettyprint-override""><code>import requests

url = 'http://localhost:8000/post_text_file'
r = requests.post(url,data=open('Hello World.txt'))
</code></pre>

<p>after run command uvicorn main:app and run a code in a client side I get next answer:</p>

<p>On the client side: {'detail': 'There was an error parsing the body'}</p>

<p>On the server side: ""POST /post_text_file HTTP/1.1"" 400 Bad Request</p>
"
"62996203","<p>This can happen if you don't have <em>python-multipart</em> installed. So be sure you have done:</p>
<pre><code>pip install python-multipart
</code></pre>
","0","","0","1","0","0","0","60474097","60474331","<p>I can't write a function, that can get a .txt file through POST-request.</p>

<p>I have a .txt file that contains phrase: Hello World!</p>

<p>server side:</p>

<pre class=""lang-py prettyprint-override""><code>from fastapi import FastAPI, File
from starlette.requests import Request
import io

app = FastAPI()
@app.post(""/post_text_file"")
def text_function(request: Request,
            file: bytes = File(...)):
    text = open(io.BytesIO(file), ""r"").read()
    return text  # Hello World!
</code></pre>

<p>client side:</p>

<pre class=""lang-py prettyprint-override""><code>import requests

url = 'http://localhost:8000/post_text_file'
r = requests.post(url,data=open('Hello World.txt'))
</code></pre>

<p>after run command uvicorn main:app and run a code in a client side I get next answer:</p>

<p>On the client side: {'detail': 'There was an error parsing the body'}</p>

<p>On the server side: ""POST /post_text_file HTTP/1.1"" 400 Bad Request</p>
"
"60474234","<p>You need to declare <code>total_transaction</code> as a property:</p>

<pre><code>class Transaction(models.Model):
    item = models.ForeignKey(Item,on_delete=models.PROTECT)
    coupon = models.ForeignKey(Coupon,on_delete=models.PROTECT)

    @property
    def total_transaction(self):
        return self.item.price * self.coupon.percentage // 100
</code></pre>

<p>Note: Properties do not get saved to DB</p>
","0","","1","680","178","6","67","60474103","60474234","<p>Let's say I have these as a code</p>

<pre><code>class Transaction(models.Model):
    item = models.ForeignKey(Item,on_delete=models.PROTECT)
    total_transaction = get_price()
    coupon = models.ForeignKey(Coupon,on_delete=models.PROTECT)

    def get_price(self):
        return self.item.price * self.coupon.percentage // 100
</code></pre>

<p>I want to use the coupon's percentage and item's price to put in total_transaction, but i don't seem to be able to pass in the function as it says ""self"" is required?
How do I work around this?</p>
"
"60474208","<p>First idea is use <a href=""http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#boolean-indexing"" rel=""nofollow noreferrer""><code>boolean indexing</code></a>:</p>

<pre><code>s = df.isnull().sum()
res = list(s[s &gt; 0].items())
print (res)
[('B', 1), ('D', 3)]
</code></pre>

<p>Or filter using <a href=""https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#selection-by-callable"" rel=""nofollow noreferrer""><code>callable</code></a>:</p>

<pre><code>res = list(df.isnull().sum()[lambda x: x &gt; 0].items())
</code></pre>

<p>Or filter in list comprehension:</p>

<pre><code>res = [(k, v) for k, v in df.isnull().sum().items() if v &gt; 0]
</code></pre>
","0","2020-03-01 10:42:55","2","615041","23439","1483","126104","60474172","60474208","<p>Hi I have a code which prints column names along with null values in columns:</p>

<pre><code>A    B     C    D
1    1     4    NAN
2    2     5     NAN
3    NAN   6     NAN
</code></pre>

<p><strong>My Code</strong></p>

<pre><code>[IN]res = list(df.isnull().sum().items())
[IN]print(res)
</code></pre>

<p><strong>Current Output</strong></p>

<pre><code>[('A', 0), ('B', 1), ('C', 0), ('D', 3)]
</code></pre>

<p><strong>Expected output:</strong></p>

<pre><code>[('B', 1), ('D', 3)]
</code></pre>

<p>So basically I wish to remove columns where there are 0 null values and <strong>return only columns with at least 1 null value.</strong></p>
"
"60474454","<p>Ok, figured it out. Just putting this out there just incase anyone has the same issue. If your project has a requirements.txt file (if it doesn't make one)  and add (If you want to use django-countries)</p>

<pre><code>django-countries==5.3.3 
</code></pre>

<p>To it, you can also use the latest version but I chose to use version 5.3.3 in this case. After that run the command</p>

<pre><code>pip install -r requirements.txt
</code></pre>
","0","2020-03-01 16:47:02","1","15","1","0","7","60474286","60474454","<p>So I'm trying to run my development server using the command ""python manage.py runserver"" 
But whenever I try to run it, it gives me this error;</p>

<pre><code>Watching for file changes with StatReloader
Exception in thread Thread-1:
Traceback (most recent call last):
  File ""C:\Users\Kasutaja\AppData\Local\Programs\Python\Python36-32\lib\threading.py"", line 916, in _bootstrap_inner
    self.run()
  File ""C:\Users\Kasutaja\AppData\Local\Programs\Python\Python36-32\lib\threading.py"", line 864, in run
    self._target(*self._args, **self._kwargs)
  File ""C:\Users\Kasutaja\AppData\Local\Programs\Python\Python36-32\lib\site-packages\django\utils\autoreload.py"", line 54, in wrapper
    fn(*args, **kwargs)
  File ""C:\Users\Kasutaja\AppData\Local\Programs\Python\Python36-32\lib\site-packages\django\core\management\commands\runserver.py"", line 109, in inner_run
    autoreload.raise_last_exception()
  File ""C:\Users\Kasutaja\AppData\Local\Programs\Python\Python36-32\lib\site-packages\django\utils\autoreload.py"", line 77, in raise_last_exception
    raise _exception[0](_exception[1]).with_traceback(_exception[2])
  File ""C:\Users\Kasutaja\AppData\Local\Programs\Python\Python36-32\lib\site-packages\django\utils\autoreload.py"", line 54, in wrapper
    fn(*args, **kwargs)
  File ""C:\Users\Kasutaja\AppData\Local\Programs\Python\Python36-32\lib\site-packages\django\__init__.py"", line 24, in setup
    apps.populate(settings.INSTALLED_APPS)
  File ""C:\Users\Kasutaja\AppData\Local\Programs\Python\Python36-32\lib\site-packages\django\apps\registry.py"", line 91, in populate
    app_config = AppConfig.create(entry)
  File ""C:\Users\Kasutaja\AppData\Local\Programs\Python\Python36-32\lib\site-packages\django\apps\config.py"", line 90, in create
    module = import_module(entry)
  File ""C:\Users\Kasutaja\AppData\Local\Programs\Python\Python36-32\lib\importlib\__init__.py"", line 125, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File ""&lt;frozen importlib._bootstrap&gt;"", line 978, in _gcd_import
  File ""&lt;frozen importlib._bootstrap&gt;"", line 961, in _find_and_load
  File ""&lt;frozen importlib._bootstrap&gt;"", line 948, in _find_and_load_unlocked
ModuleNotFoundError: No module named 'django_countries'

Traceback (most recent call last):
  File ""C:\Users\Kasutaja\AppData\Local\Programs\Python\Python36-32\lib\site-packages\django\apps\registry.py"", line 155, in get_app_config
    return self.app_configs[app_label]
KeyError: 'admin'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""manage.py"", line 15, in &lt;module&gt;
    execute_from_command_line(sys.argv)
  File ""C:\Users\Kasutaja\AppData\Local\Programs\Python\Python36-32\lib\site-packages\django\core\management\__init__.py"", line 381, in execute_from_command_line
    utility.execute()
  File ""C:\Users\Kasutaja\AppData\Local\Programs\Python\Python36-32\lib\site-packages\django\core\management\__init__.py"", line 375, in execute
    self.fetch_command(subcommand).run_from_argv(self.argv)
  File ""C:\Users\Kasutaja\AppData\Local\Programs\Python\Python36-32\lib\site-packages\django\core\management\base.py"", line 323, in run_from_argv
    self.execute(*args, **cmd_options)
  File ""C:\Users\Kasutaja\AppData\Local\Programs\Python\Python36-32\lib\site-packages\django\core\management\commands\runserver.py"", line 60, in execute
    super().execute(*args, **options)
  File ""C:\Users\Kasutaja\AppData\Local\Programs\Python\Python36-32\lib\site-packages\django\core\management\base.py"", line 364, in execute
    output = self.handle(*args, **options)
  File ""C:\Users\Kasutaja\AppData\Local\Programs\Python\Python36-32\lib\site-packages\django\core\management\commands\runserver.py"", line 95, in handle
    self.run(**options)
  File ""C:\Users\Kasutaja\AppData\Local\Programs\Python\Python36-32\lib\site-packages\django\core\management\commands\runserver.py"", line 102, in run
    autoreload.run_with_reloader(self.inner_run, **options)
  File ""C:\Users\Kasutaja\AppData\Local\Programs\Python\Python36-32\lib\site-packages\django\utils\autoreload.py"", line 579, in run_with_reloader
    start_django(reloader, main_func, *args, **kwargs)
  File ""C:\Users\Kasutaja\AppData\Local\Programs\Python\Python36-32\lib\site-packages\django\utils\autoreload.py"", line 564, in start_django
    reloader.run(django_main_thread)
  File ""C:\Users\Kasutaja\AppData\Local\Programs\Python\Python36-32\lib\site-packages\django\utils\autoreload.py"", line 272, in run
    get_resolver().urlconf_module
  File ""C:\Users\Kasutaja\AppData\Local\Programs\Python\Python36-32\lib\site-packages\django\utils\functional.py"", line 80, in __get__
    res = instance.__dict__[self.name] = self.func(instance)
  File ""C:\Users\Kasutaja\AppData\Local\Programs\Python\Python36-32\lib\site-packages\django\urls\resolvers.py"", line 564, in urlconf_module
    return import_module(self.urlconf_name)
  File ""C:\Users\Kasutaja\AppData\Local\Programs\Python\Python36-32\lib\importlib\__init__.py"", line 125, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File ""&lt;frozen importlib._bootstrap&gt;"", line 978, in _gcd_import
  File ""&lt;frozen importlib._bootstrap&gt;"", line 961, in _find_and_load
  File ""&lt;frozen importlib._bootstrap&gt;"", line 950, in _find_and_load_unlocked
  File ""&lt;frozen importlib._bootstrap&gt;"", line 655, in _load_unlocked
  File ""&lt;frozen importlib._bootstrap_external&gt;"", line 678, in exec_module
  File ""&lt;frozen importlib._bootstrap&gt;"", line 205, in _call_with_frames_removed
  File ""F:\Users\Kasutaja\Documents\Veebipood v4\django-ecommerce\djecommerce\urls.py"", 
line 6, in &lt;module&gt;
    path('admin/', admin.site.urls),
  File ""C:\Users\Kasutaja\AppData\Local\Programs\Python\Python36-32\lib\site-packages\django\utils\functional.py"", line 256, in inner
    self._setup()
  File ""C:\Users\Kasutaja\AppData\Local\Programs\Python\Python36-32\lib\site-packages\django\contrib\admin\sites.py"", line 529, in _setup
    AdminSiteClass = import_string(apps.get_app_config('admin').default_site)
  File ""C:\Users\Kasutaja\AppData\Local\Programs\Python\Python36-32\lib\site-packages\django\apps\registry.py"", line 162, in get_app_config
    raise LookupError(message)
LookupError: No installed app with label 'admin'.
</code></pre>

<p>I have tried searching for solutions to this problem but nothing seems to be working. There seems to also be a weird issue with django-countries. Whenever I try installing it, it says;</p>

<pre><code>    Collecting django-countries
      Using cached django-countries-6.0.tar.gz (617 kB)
      WARNING: Generating metadata for package django-countries produced metadata for project name unknown. Fix your #egg=django-countries fragments.
    Requirement already satisfied (use --upgrade to upgrade): unknown from https://files.pythonhosted.org/packages/6d/7a/4046a82f6f0c7d00ad24b3a4fc30d10c562949bb6cd40ef7f3051ed7e2bc/django-countries-6.0.tar.gz#sha256=cca351f304d18187b6200e1aae381c2902045c33aea5f4da58fd74685b7cd4fc in c:\users\kasutaja\appdata\local\programs\python\python36-32\lib\site-packages

The weird thing with this is, that whenever I try to run ""python manage.py makemigrations"", it says;
Traceback (most recent call last):
  File ""manage.py"", line 15, in &lt;module&gt;
    execute_from_command_line(sys.argv)
  File ""C:\Users\Kasutaja\AppData\Local\Programs\Python\Python36-32\lib\site-packages\django\core\management\__init__.py"", line 381, in execute_from_command_line
    utility.execute()
  File ""C:\Users\Kasutaja\AppData\Local\Programs\Python\Python36-32\lib\site-packages\django\core\management\__init__.py"", line 357, in execute
    django.setup()
  File ""C:\Users\Kasutaja\AppData\Local\Programs\Python\Python36-32\lib\site-packages\django\__init__.py"", line 24, in setup
    apps.populate(settings.INSTALLED_APPS)
  File ""C:\Users\Kasutaja\AppData\Local\Programs\Python\Python36-32\lib\site-packages\django\apps\registry.py"", line 91, in populate
    app_config = AppConfig.create(entry)
  File ""C:\Users\Kasutaja\AppData\Local\Programs\Python\Python36-32\lib\site-packages\django\apps\config.py"", line 90, in create
    module = import_module(entry)
  File ""C:\Users\Kasutaja\AppData\Local\Programs\Python\Python36-32\lib\importlib\__init__.py"", line 125, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File ""&lt;frozen importlib._bootstrap&gt;"", line 978, in _gcd_import
  File ""&lt;frozen importlib._bootstrap&gt;"", line 961, in _find_and_load
  File ""&lt;frozen importlib._bootstrap&gt;"", line 948, in _find_and_load_unlocked
ModuleNotFoundError: No module named 'django_countries'
</code></pre>

<p>Does anyone know how to fix this?
Thanks in advance,
Nimetu.</p>
"
"60474405","<p>The position (<em>dest</em>) argument to <a href=""https://www.pygame.org/docs/ref/surface.html#pygame.Surface.blit"" rel=""nofollow noreferrer""><code>pygame.Surface.blit()</code></a> is ought to be a tuple of 2 integral numbers.<br />
In your case <code>self.pos[0]</code> and/or <code>self.pos[1]</code> seems to be a floating point number.</p>
<p>You can get rid of the warning by rounding the floating point coordinates to integral coordinates (<a href=""https://docs.python.org/3/library/functions.html#round"" rel=""nofollow noreferrer""><code>round</code></a>):</p>
<pre class=""lang-py prettyprint-override""><code>D.blit(self.player, (round(self.pos[0]), round(self.pos[1])))
</code></pre>
<p>For the sake of completeness it has to be mentioned that the argument can also be a rectangle. A tuple with the 4 components (left, top, width, height).</p>
<hr />
<p>Furthermore you have create a Surface with an integral length and you have to rotate the surface after it is (re)created:</p>
<pre class=""lang-py prettyprint-override""><code>class String:
    # [...]
   
    def draw(self):

        # compute INTEGRAL length        
        length = math.hypot(self.dx, self.dy)
        length = max(1, int(length))

        # create surface
        self.string = pygame.Surface((1, length)).convert_alpha()
        self.string.fill((0, 255, 0))

        # roatet surface
        angle = pygame.transform.rotate(self.string, player.orbital_angle)

        # blit rotated surface
        D.blit(angle, (round(self.pos[0]), round(self.pos[1])))
</code></pre>
","0","2020-10-16 05:55:09","1","136140","16645","626","8521","60474292","60474405","<p>The following is the <code>String</code> class. Using the draw function from this class in my main loop immediately closes the game without any errors and as long i dont include it, the game runs fine. It does give me the following warning.</p>

<pre><code>Warning (from warnings module):
  File ""C:\Users\rahul\OneDrive\Documents\A level python codes\shootingGame.py"", line 44
    D.blit(self.player, (self.pos[0], self.pos[1]))
DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
</code></pre>

<hr>

<pre><code>import math, sys, os, pygame
from pygame.locals import *

pygame.init()

win = pygame.display
D = win.set_mode((1200, 600))

class String:
    def __init__(self, x, y):
        self.pos = [x, y]
        self.dx = 0
        self.dy = 0
        self.string = pygame.Surface((1, 1)).convert_alpha()
        self.string.fill((0, 255, 0))

    def draw(self):
        angle = pygame.transform.rotate(self.string, (player.orbital_angle))
        length = math.hypot(self.dx, self.dy)
        self.string = pygame.Surface((3, length))
        D.blit(angle, (self.pos[0], self.pos[1]))

string = String(600, 300)
While True:
    string.draw()
</code></pre>

<p>I initially had everything in <code>draw</code> function in differnet functions but it got a bit messy while debugging.Specifically, it is the last two lines in <code>draw()</code> that's causing the window to crash i.e</p>

<pre><code>self.string = pygame.Surface((3, length))
D.blit(angle, (self.pos[0], self.pos[1]))
</code></pre>
"
"60484343","<p>You can try with <code>compile = False</code> parameter in your load_model call. This will remove any metadata related to optimizers and loss function and since you have a reinitialize function and if you don't need to train it from where you stopped last time, that won't be a problem I guess. </p>

<p>As you said it works with compile = False, I think the problem might be in your custom functions for loss/optimizer etc, I can't pin point what exactly is the problem, you can try tf. instead of tf.keras.backend. if you want.</p>
","0","","3","673","263","8","121","60474308","60484343","<p>While trying to loading my trained Keras model for further inference with</p>

<pre><code>self.model = tf.keras.models.load_model(filepath=weight_url, custom_objects={
                'dice_coef': dice_coef,
                'iou_coef': iou_coef,
                'bce_dice_coef': bce_dice_coef,
            })
</code></pre>

<p>I get the following error. Those three functions are the same I used to train my model, the weight URL is correct. The error message doesn't tell me anything.</p>

<pre><code>file ""/home/long/Desktop/bachelor-thesis/unet/pipeline.py"", line 344, in &lt;module&gt;
    binary.inference_blood_cell_unet()
  File ""/home/long/Desktop/bachelor-thesis/unet/pipeline.py"", line 305, in inference_blood_cell_unet
    self.blood_cell_unet = UNet(weight_url=self.blood_cell_final_name, class_weights=self.blut_koerperchen_classweights, num_classes=2)
  File ""/home/long/Desktop/bachelor-thesis/unet/model.py"", line 39, in __init__
    'bce_dice_coef': bce_dice_coef,
  File ""/home/long/Desktop/bachelor-thesis/venv/lib/python3.7/site-packages/tensorflow_core/python/keras/saving/save.py"", line 146, in load_model
    return hdf5_format.load_model_from_hdf5(filepath, custom_objects, compile)
  File ""/home/long/Desktop/bachelor-thesis/venv/lib/python3.7/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py"", line 193, in load_model_from_hdf5
    model._make_train_function()
  File ""/home/long/Desktop/bachelor-thesis/venv/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py"", line 2116, in _make_train_function
    params=self._collected_trainable_weights, loss=self.total_loss)
  File ""/home/long/Desktop/bachelor-thesis/venv/lib/python3.7/site-packages/tensorflow_core/python/keras/optimizer_v2/optimizer_v2.py"", line 500, in get_updates
    grads = self.get_gradients(loss, params)
  File ""/home/long/Desktop/bachelor-thesis/venv/lib/python3.7/site-packages/tensorflow_core/python/keras/optimizer_v2/optimizer_v2.py"", line 391, in get_gradients
    grads = gradients.gradients(loss, params)
  File ""/home/long/Desktop/bachelor-thesis/venv/lib/python3.7/site-packages/tensorflow_core/python/ops/gradients_impl.py"", line 158, in gradients
    unconnected_gradients)
  File ""/home/long/Desktop/bachelor-thesis/venv/lib/python3.7/site-packages/tensorflow_core/python/ops/gradients_util.py"", line 550, in _GradientsHelper
    gradient_uid)
  File ""/home/long/Desktop/bachelor-thesis/venv/lib/python3.7/site-packages/tensorflow_core/python/ops/gradients_util.py"", line 166, in _DefaultGradYs
    with _maybe_colocate_with(y.op, gradient_uid, colocate_gradients_with_ops):
AttributeError: 'NoneType' object has no attribute 'op'
</code></pre>

<p>Following is my code how the model is built:</p>

<pre><code>import tensorflow as tf
from tensorflow.keras.callbacks import ModelCheckpoint
from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, LeakyReLU, Dropout, MaxPooling2D, Conv2DTranspose
from tensorflow.keras.layers import concatenate
from tensorflow.keras.optimizers import Adam

from unet.metrics import dice_coef, iou_coef, cce_dice_coef, weighted_loss, bce_dice_coef

fil_coef = 4

class UNet(UNetBase, DataHandlingBase):
    def __init__(self,
                 class_weights,
                 weight_url=None,
                 width=256,
                 height=256,
                 channel=3,
                 learning_rate=0.0005,
                 num_classes=2,
                 alpha=0.01,
                 dropout_rate=0.25):
        super().__init__(weight_url, width, height, channel, learning_rate, num_classes, alpha, dropout_rate)
        self.class_weights = class_weights

        if self.num_classes &gt; 2:
            self.loss_function = weighted_loss(cce_dice_coef, weights_list=self.class_weights)
        elif self.num_classes == 2:
            self.loss_function = bce_dice_coef
        else:
            raise Exception(""Invalid num class: "", self.num_classes)

        if weight_url:
            self.model = tf.keras.models.load_model(filepath=weight_url, custom_objects={
                'dice_coef': dice_coef,
                'iou_coef': iou_coef,
                'bce_dice_coef': bce_dice_coef,
                'loss_function': self.loss_function
            })
        else:
            model_input = Input((self.height, self.width, self.channel))
            c1 = Conv2D(filters=16 * fil_coef, kernel_size=(3, 3), padding='same')(model_input)
            c1 = BatchNormalization()(c1)
            c1 = LeakyReLU(self.alpha)(c1)
            c1 = Dropout(self.dropout_rate)(c1)
            c1 = Conv2D(filters=16 * fil_coef, kernel_size=(3, 3), padding='same')(c1)

            ...

            c9 = BatchNormalization()(c9)
            c9 = LeakyReLU(self.alpha)(c9)
            c9 = Dropout(self.dropout_rate)(c9)

            if self.num_classes == 2:
                output = Conv2D(1, kernel_size=(1, 1), activation='sigmoid')(c9)
            else:
                output = Conv2D(self.num_classes, kernel_size=(1, 1), activation='softmax')(c9)
            self.model = tf.keras.Model(inputs=[model_input], outputs=[output])

            self.reinitialize()

    def reinitialize(self):
        if self.num_classes &gt; 2:
            self.model.compile(optimizer=Adam(lr=self.learning_rate),
                               loss=self.loss_function,
                               metrics=[dice_coef, iou_coef])
        else:
            self.model.compile(optimizer=Adam(lr=self.learning_rate),
                               loss=self.loss_function,
                               metrics=[dice_coef, iou_coef],
                               class_weight=self.class_weights)

    def fit(self, X, Y, x=None, y=None,
            batch_size=params[""batch_size""],
            epochs=params[""epochs""],
            validation_split=params[""validation_split""],
            checkpoint_path=""temp/models/model-{epoch:02d}-{val_loss:.2f}.h5"",
            patience=params[""patience""],
            min_delta=params[""min_delta""]):
        checkpoint = ModelCheckpoint(checkpoint_path,
                                     verbose=0,
                                     save_best_only=False,
                                     monitor='val_loss',
                                     mode='auto')
        if x is None and y is None:
            history = self.model.fit(X, Y,
                                     validation_split=validation_split,
                                     batch_size=batch_size,
                                     epochs=epochs,
                                     shuffle=True,
                                     callbacks=[checkpoint])
            return history
        elif x is not None and y is not None:
            history = self.model.fit(X, Y,
                                     verbose=0,
                                     steps_per_epoch=X.shape[0] // batch_size,
                                     validation_data=[x, y],
                                     validation_steps=x.shape[0] // batch_size,
                                     batch_size=batch_size,
                                     epochs=epochs,
                                     shuffle=True)
            return history

    def save_weights(self, url):
        self.model.save(url)

    def predict(self, X):
        return self.model.predict(X)

    def summary(self):
        log.info(f""Learning rate {self.learning_rate} Alpha {self.alpha} Dropout Rate {self.dropout_rate}"")
        self.model.summary()
</code></pre>

<p>And here are how my loss functions coded:</p>

<pre><code>import tensorflow as tf
import tensorflow.keras.backend as K


def weighted_loss(original_loss_function, weights_list):
    """"""
    Author: https://stackoverflow.com/questions/51793737/custom-loss-function-for-u-net-in-keras-using-class-weights-class-weight-not
    """"""

    def loss_function(true, pred):
        axis = -1  # if channels last
        # axis=  1 #if channels first

        # argmax returns the index of the element with the greatest value
        # done in the class axis, it returns the class index
        class_selectors = tf.cast(K.argmax(true, axis=axis), tf.int32)
        # if your loss is sparse, use only true as classSelectors

        # considering weights are ordered by class, for each class
        # true(1) if the class index is equal to the weight index
        class_selectors = [K.equal(i, class_selectors) for i in range(len(weights_list))]

        # casting boolean to float for calculations
        # each tensor in the list contains 1 where ground true class is equal to its index
        # if you sum all these, you will get a tensor full of ones.
        class_selectors = [K.cast(x, K.floatx()) for x in class_selectors]

        # for each of the selections above, multiply their respective weight
        weights = [sel * w for sel, w in zip(class_selectors, weights_list)]

        # sums all the selections
        # result is a tensor with the respective weight for each element in predictions
        weight_multiplier = weights[0]
        for i in range(1, len(weights)):
            weight_multiplier = weight_multiplier + weights[i]

        # make sure your originalLossFunc only collapses the class axis
        # you need the other axes intact to multiply the weights tensor
        loss = original_loss_function(true, pred)
        loss = loss * weight_multiplier
        return loss

    return loss_function


@tf.function
def cce_iou_coef(y_true, y_pred, smooth=1, cat_weight=1, iou_weight=1):
    return cat_weight * K.categorical_crossentropy(y_true, y_pred) + iou_weight * log_iou_coef(y_true, y_pred, smooth)


@tf.function
def cce_dice_coef(y_true, y_pred, smooth=1, cat_weight=1, dice_weight=1):
    return cat_weight * K.categorical_crossentropy(y_true, y_pred) + dice_weight * log_dice_coef(y_true, y_pred, smooth)


@tf.function
def bce_iou_coef(y_true, y_pred, smooth=1, cat_weight=1, iou_weight=1):
    return cat_weight * K.binary_crossentropy(y_true, y_pred) + iou_weight * log_iou_coef(y_true, y_pred, smooth)


@tf.function
def bce_dice_coef(y_true, y_pred, smooth=1, cat_weight=1, dice_weight=1):
    return cat_weight * K.binary_crossentropy(y_true, y_pred) + dice_weight * log_dice_coef(y_true, y_pred, smooth)


@tf.function
def log_iou_coef(y_true, y_pred, smooth=1):
    return - K.log(iou_coef(y_true, y_pred, smooth))


@tf.function
def log_dice_coef(y_true, y_pred, smooth=1):
    return -K.log(dice_coef(y_true, y_pred, smooth))


@tf.function
def iou_coef(y_true, y_pred, smooth=1):
    intersection = K.sum(K.abs(y_true * y_pred), axis=-1)
    union = K.sum(y_true, axis=-1) + K.sum(y_pred, axis=-1) - intersection
    iou = K.mean((intersection + smooth) / (union + smooth), axis=0)
    return iou


@tf.function
def dice_coef(y_true, y_pred, smooth=1):
    intersection = K.sum(y_true * y_pred, axis=-1)
    union = K.sum(y_true, axis=-1) + K.sum(y_pred, axis=-1)
    dice = K.mean((2. * intersection + smooth) / (union + smooth), axis=0)
    return dice
</code></pre>

<p>The error happens after I trained a binary model, saved it and loads it again for inference. As you can see the loss functions imported for inference are the same for the training phase. So I don't really understand why I get the error. And I don't understand what the error means, either.</p>
"
"60474604","<p><strong>Instead of using <code>subprocess.call</code> you should use <code>subprocess.run</code> function it waits for the process to finish and returns the <code>CompletedProcess</code></strong></p>

<p><strong>Note:</strong></p>

<h2><code>subprocess.run(args)</code></h2>

<blockquote>
  <p>Run the command described by args. Wait for command to complete, then
  return a <code>CompletedProcess</code> instance.</p>
</blockquote>

<p>You can refer more at <a href=""https://docs.python.org/3/library/subprocess.html#subprocess.run"" rel=""nofollow noreferrer"">Python docs</a></p>
","2","","2","31794","2954","64","2384","60474344","60474604","<p>I am calling 5 scripts through subprocess function but I want to make sure that it processes it in the same order as in the script to ensure dependencies. Is there a quick way of combining these 5 subprocess functions in a sequential way?</p>

<pre><code># CONNECT DATABASE
import seaborn as sns
import pandas as pd
from platform import python_version
import sys
import os
import subprocess
from sqlalchemy import create_engine
import sqlite3
# connection to database
db = sqlite3.connect('gencodb.db')
# cursor
cursor = db.cursor()

# ENTER THE DATA WEEKS
run_date = '29/02/2020'
this_wk = '29FEB20'
last_wk = '22FEB20'
prev_wk = '15FEB20'

subprocess.call(""python 01_DataCleaning_Transactions.py"".split() +
                [run_date, this_wk, last_wk, prev_wk], shell=True)

subprocess.call(""python 02_DataCleaning_Views.py"".split() +
                [run_date, this_wk, last_wk, prev_wk], shell=True)

subprocess.call(""python 03_DataCleaning_SP.py"".split() +
                [run_date, this_wk, last_wk, prev_wk], shell=True)

subprocess.call(""python 04_DataCleaning_Inventory.py"".split() +
                [run_date, this_wk, last_wk, prev_wk], shell=True)

subprocess.call(""python 05_DataCleaning_QAs.py"".split() +
                [run_date, this_wk, last_wk, prev_wk], shell=True)
</code></pre>
"
"60474625","<p>Always use W (unicode) versions unless you really don't want to for some reason (some more recent APIs don't even have A versions). 
This is documented here: <a href=""https://docs.microsoft.com/en-us/windows/win32/intl/conventions-for-function-prototypes"" rel=""nofollow noreferrer"">Conventions for Function Prototypes</a>. I quote:</p>

<blockquote>
  <p>New Windows applications should use Unicode to avoid the
  inconsistencies of varied code pages and for ease of localization.
  They should be written with generic functions, and should define
  UNICODE to compile the functions into Unicode functions. In the few
  places where an application must work with 8-bit character data, it
  can make explicit use of the functions for Windows code pages.</p>
</blockquote>
","2","","2","115910","827","209","10342","60474347","60474625","<p>I'm writing a program in Python and in one of my functions is a call to the <strong>GetWindowText</strong> function to get the title text of the current window. I don't know too much about the Windows API just yet, but I do understand that the 'A' variant of functions is ANSI and the 'W' variants is Wide per MSDN.</p>

<p>My question is, do I always want to utilize 'W' nowadays, i.e. <strong>GetWindowTextW</strong>, and why exactly if so? I've done some research but I can't seem to fully understand what's wrong with using 'A'. Is it just legacy now and programmers have naturally moved onto 'W', or is it bad practice because it causes issues with your code down the line?</p>
"
"60474863","<p>Seems like your app executes this code each time</p>
<pre><code>if(name[0].files.length === 1){
        console.log(&quot;File name: &quot;, name[0].files[0].name)
        var temp = name[0].files[0].name;
        eel.getFileName(temp,moduleSelection); // passing file to python function getFileName
    }
</code></pre>
<h3>1. Index selection</h3>
<p>Is there a reason you're selecting the first index from <code>name[0]</code> each time? Maybe just checking for <code>name.files.length</code> would work?</p>
<h3>2. If/else algorithm</h3>
<p>If you structure your code a bit better, it might surprisingly work better. Try using the Javascript <a href=""https://developer.mozilla.org/nl/docs/Web/JavaScript/Reference/Global_Objects/Array/forEach"" rel=""nofollow noreferrer"">Array.forEach()</a> method instead of your loop. It would look something like this</p>
<pre><code>function showname(moduleSelection) {
    console.log(&quot;i am here&quot;);
    var files = document.getElementsByClassName('selectButton');
    
    var fileList = [];
    if (files.length &gt; 0) {
        files.forEach(file =&gt; {
            console.log(&quot;File name: &quot;, file.files[0].name);
            fileList.push(file.files[0].name);
        })
        eel.getFileName(fileList, moduleSelection);
    }
    return;
}
</code></pre>
<p>I hope this will <em>maybe</em> <strong><em>hopefully</em></strong> help!</p>
<p>EDIT:</p>
<p>If u want to remove previous files <strong>after</strong> calling the files, you will have to mark the currently selected files at <code>document.getElementsByClassName('selectButton')</code> as <strong>already called</strong>.</p>
<p>You can do this in various way, an example would be to change the <strong>class name</strong> from <code>selectButton</code> to <code>selectButtonDone</code> after the file name was pushed into the <code>fileList[]</code> array.</p>
<p>You can do this particularly by executing <code>file.className = 'selectButtonDone';</code> at the end of the <code>files.forEach()</code> function.</p>
","4","2020-06-20 09:12:55","1","108","1","0","10","60474544","60474863","<p>I am using Eel package of python that help me to integrate Html/CSS/js with python
so I am dynamically generating Html tags via JS based on input in a python file
basically it's a chatbot and UI of that chatbot is created by Html/js </p>

<p>main.js that creates tags dynamically</p>

<pre><code>eel.expose(selectPDF);
function selectPDF(moduleSelection){ // moduleSelection is coming from python
    console.log(""select pdf called"")
    var DemoDom = document.createElement(""input"");
    DemoDom.setAttribute('type','file'); //creating tag for input file
    DemoDom.setAttribute('name','myfile');
    DemoDom.id = ""agenttext"";
    DemoDom.setAttribute('class','selectButton');
    DemoDom.setAttribute('multiple','multiple');
    DemoDom.setAttribute('onchange','showname(""'+moduleSelection+'"")')
    chatBox.appendChild(DemoDom);

}
eel.expose(showname); //this is eel package syntax
function showname(moduleSelection){
    console.log(""i am here"")
    var name = document.getElementsByClassName('selectButton');
    var fileList = [];
    // if only one file is selected do this
    if(name[0].files.length === 1){
        console.log(""File name: "", name[0].files[0].name)
        var temp = name[0].files[0].name;
        eel.getFileName(temp,moduleSelection); // passing file to python function getFileName
    }
    else{
        for (var i = 0; i &lt; name[0].files.length; i++) {
            console.log(""File name for loop: "", name[0].files[i].name)
           fileList.push(name[0].files[i].name); // push all file to list 
        }
        eel.getFileName(fileList,moduleSelection); // passing filelist to python function getFileName
    }
    return
}
</code></pre>

<p>Now when I call selectPDF() first time it creates input tag and call onchange method all working fine</p>

<p>but now When I call it the second time js again create input tag and call onchange method and it takes the previous file and not the new one that I want to select</p>

<p>see the image</p>

<p><a href=""https://i.stack.imgur.com/j4hGx.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/j4hGx.png"" alt=""Ignore red errors""></a></p>

<p><strong>JUST SEE THE FILE NAME: image.png</strong></p>

<p><strong>ignore all other red errors</strong></p>

<p>as you can see in the image when I call ""image to text"" first time it works fine creates DOM and proceed further but when the second time I call ""image to text"" it creates DOM but select the previous file image.png instead of Sample.pdf</p>

<p>You can see the console file name
it should select Sample.pdf instead of image.png when calling the second time</p>
"
"60474620","<p>From the <a href=""https://docs.python.org/3/library/stdtypes.html#dict.fromkeys"" rel=""nofollow noreferrer"">documentation</a>:</p>

<blockquote>
  <p><code>fromkeys()</code> is a class method that returns a new dictionary. <em>value</em> defaults to <code>None</code>. All of the values refer to just a single instance, so it generally doesnâ€™t make sense for <em>value</em> to be a mutable object such as an empty list. To get distinct values, use a dict comprehension instead.</p>
</blockquote>

<p>So, both the keys point to the same dictionary that you are trying to change.</p>

<p>You can use this instead:</p>

<pre><code>comp = {key: {'dep': '', 'sal': ''} for key in ('emp1', 'emp2')}
</code></pre>
","0","2020-03-01 11:37:16","0","6639","1993","1059","1424","60474564","60474620","<p>I'm trying to make a dictionary in python that has a key and a dictionary as a value like that</p>

<pre><code>a = ('emp1','emp2')
b = ({'dep':'', 'sal':''})
comp = dict.fromkeys(a,b)
print(comp)
comp['emp1']['dep'] = 'IT'
comp['emp1']['sal'] = '300$'
print(comp)
</code></pre>

<p>and the output is like that</p>

<pre><code>{'emp1': {'dep': '', 'sal': ''}, 'emp2': {'dep': '', 'sal': ''}}
{'emp1': {'dep': 'IT', 'sal': '300$'}, 'emp2': {'dep': 'IT', 'sal': '300$'}}
</code></pre>

<p>why all the values are changing if I'm trying to chang the <strong><em>value</em></strong> only for <strong><em><code>""emp1""</code></em></strong>
can any one help ???</p>
"
"60474800","<p>That is because the comp['emp1] and comp['emp2] actually refer to the same object.<br>
You can verify it by id() function which returns the unique identifier of the python object </p>

<pre class=""lang-py prettyprint-override""><code>a = ('emp1', 'emp2')
b = ({'dep': '', 'sal': ''})
comp = dict.fromkeys(a, b)
print(id(comp[""emp1""]))
print(id(comp[""emp2""]))
print(comp)
comp['emp1']['dep'] = 'IT'
comp['emp1']['sal'] = '300$'
print(comp)
</code></pre>

<p>it returns </p>

<pre><code>4467496912
4467496912
{'emp1': {'dep': '', 'sal': ''}, 'emp2': {'dep': '', 'sal': ''}}
{'emp1': {'dep': 'IT', 'sal': '300$'}, 'emp2': {'dep': 'IT', 'sal': '300$'}}
</code></pre>

<p>If u have to use fromkeys, The solution is </p>

<pre><code>from copy import deepcopy
a = ('emp1', 'emp2')
b = ({'dep': '', 'sal': ''})
comp = dict.fromkeys(a, b)
comp = {key: deepcopy(b) for key in comp}
print(id(comp[""emp1""]))
print(id(comp[""emp2""]))
print(comp)
comp['emp1']['dep'] = 'IT'
comp['emp1']['sal'] = '300$'
print(comp)
</code></pre>

<p>the output will be what u want</p>

<pre><code>4300371360
4301322592
{'emp1': {'dep': '', 'sal': ''}, 'emp2': {'dep': '', 'sal': ''}}
{'emp1': {'dep': 'IT', 'sal': '300$'}, 'emp2': {'dep': '', 'sal': ''}}
</code></pre>
","0","","1","66","19","0","2","60474564","60474620","<p>I'm trying to make a dictionary in python that has a key and a dictionary as a value like that</p>

<pre><code>a = ('emp1','emp2')
b = ({'dep':'', 'sal':''})
comp = dict.fromkeys(a,b)
print(comp)
comp['emp1']['dep'] = 'IT'
comp['emp1']['sal'] = '300$'
print(comp)
</code></pre>

<p>and the output is like that</p>

<pre><code>{'emp1': {'dep': '', 'sal': ''}, 'emp2': {'dep': '', 'sal': ''}}
{'emp1': {'dep': 'IT', 'sal': '300$'}, 'emp2': {'dep': 'IT', 'sal': '300$'}}
</code></pre>

<p>why all the values are changing if I'm trying to chang the <strong><em>value</em></strong> only for <strong><em><code>""emp1""</code></em></strong>
can any one help ???</p>
"
"60474687","<p>You have definied ""dexterity"" as part of ""attributes"" so you need to refer to is as attributes['dexterity'].</p>
","4","","1","71","4","0","43","60474576","60475230","<p>Im trying to produce a very simple adventure text game and i tried to produce a minimal reproducible example in this case(my code may appear to be slightly long but i cant delete anymore or else it becomes difficult to understand). </p>

<p>The problem with my codes right now is that it wont  proceed to go to the forest when the user is prompt to choose a choice = input(""Go to the shop, go to the tavern, go to the forest: ""). </p>

<p>And the other problem is that the user must enter tavern 2 times in order to proceed and after that it will show the error ""dexterity not defined"" at the line if dexterity >= 5: even though i have earlier listed it as part of the dictionary list...</p>

<pre><code>gold = int(100)
crossbow = int(50)
spell = int(35)
potion = int(35)
inventory = [""sword"", ""armor"", ""potion""]

print(""Welcome hero"")
name = input(""What is your name: "")
print(""Hello"", name,)
# role playing program
#
# spend 30 points on strenght, health, wisdom, dexterity 
# player can spend and take points from any attribute

# library contains attribute and points
attributes = {""strength"": int(""0""),
             ""health"": ""0"",
             ""wisdom"": ""0"",
             ""dexterity"": ""0""}

pool = int(30)
choice = None
print(""The Making of a Hero !!!"")
print(attributes)
print(""\nYou have"", pool, ""points to spend."")

while choice != ""0"":
    # list of choices
    print(
    """"""
    Options: 

    0 - End
    1 - Add points to an attribute
    2 - remove points from an attribute
    3 - Show attributes
    """"""
    )
    choice = input(""Choose option: "")
    if choice == ""0"":
        print(""\nYour hero stats are:"")
        print(attributes)
    elif choice == ""1"":
        print(""\nADD POINTS TO AN ATTRIBUTE"")
        print(""You have"", pool, ""points to spend."")



    choice = input(""Go to the shop, go to the tavern, go to the forest: "")
    while choice != ""shop"" or ""tavern"" or ""forest"":
        print(""Not accepted"")
        print(""What do you wish to do?"")
        print(""please input shop, tavern, forest."")
        choice = input(""Go to the shop, go to the tavern, go to the forest: "")

        if choice == ""tavern"":
            print(""You enter the tavern and see a couple of drunken warriors singing, a landlord behind the bar and a dodgy figure sitting at the back of the tavern."")
            tavernChoice = input(""Would you like to talk to the 'drunken warriors', to the 'inn keeper', approach the 'dodgy figure' or 'exit'"")

            if tavernChoice == ""drunken warriors"":
                print(""You approach the warriors to greet them."")
                print(""They notice you as you get close and become weary of your presence."")
                print(""As you arrive at their table one of the warriors throughs a mug of ale at you."")
            if dexterity &gt;= 5:
                print(""You quickly dodge the mug and leave the warriors alone"")
            else:
                print(""You are caught off guard and take the mug to the face compleatly soaking you."")
                print(""The dodgy figure leaves the tavern"")
</code></pre>
"
"60475230","<p>Your first problem is the input validation line:</p>

<pre><code>while choice != ""shop"" or ""tavern"" or ""forest"":
</code></pre>

<p>The expression is evaluated as:</p>

<pre><code>while (choice != ""shop"") or (""tavern"") or (""forest""):
</code></pre>

<p>So the condition will always be true because a non-empty string is truthy. You could write something like:</p>

<pre><code>while choice not in (""shop"", ""tavern"", ""forest""):
</code></pre>

<hr>

<p>Your second problem is that you keep all your code inside the input validation. You have a <code>while</code> loop to keep asking the user for input until a valid response is entered, which is good. But you need to remember that once a valid input was entered, the loop will terminate (because now <code>choice</code> is actually in <code>(""shop"", ""tavern"", ""forest"")</code>). So your code should be something like:</p>

<pre class=""lang-py prettyprint-override""><code>    choice = input(""Go to the shop, go to the tavern, go to the forest: "")
    while choice not in(""shop"", ""tavern"",""forest""):
        print(""Not accepted"")
        print(""What do you wish to do?"")
        print(""please input shop, tavern, forest."")
        choice = input(""Go to the shop, go to the tavern, go to the forest: "")

    if choice == ""tavern"":
        ....
</code></pre>

<hr>

<p>Regarding the <code>'dexterity'</code> error. It is not a variable, but a key in your dict so change to:</p>

<pre><code>if attributes['dexterity'] &gt;= 5:
</code></pre>
","0","2020-03-01 12:57:36","1","11641","812","4462","4469","60474576","60475230","<p>Im trying to produce a very simple adventure text game and i tried to produce a minimal reproducible example in this case(my code may appear to be slightly long but i cant delete anymore or else it becomes difficult to understand). </p>

<p>The problem with my codes right now is that it wont  proceed to go to the forest when the user is prompt to choose a choice = input(""Go to the shop, go to the tavern, go to the forest: ""). </p>

<p>And the other problem is that the user must enter tavern 2 times in order to proceed and after that it will show the error ""dexterity not defined"" at the line if dexterity >= 5: even though i have earlier listed it as part of the dictionary list...</p>

<pre><code>gold = int(100)
crossbow = int(50)
spell = int(35)
potion = int(35)
inventory = [""sword"", ""armor"", ""potion""]

print(""Welcome hero"")
name = input(""What is your name: "")
print(""Hello"", name,)
# role playing program
#
# spend 30 points on strenght, health, wisdom, dexterity 
# player can spend and take points from any attribute

# library contains attribute and points
attributes = {""strength"": int(""0""),
             ""health"": ""0"",
             ""wisdom"": ""0"",
             ""dexterity"": ""0""}

pool = int(30)
choice = None
print(""The Making of a Hero !!!"")
print(attributes)
print(""\nYou have"", pool, ""points to spend."")

while choice != ""0"":
    # list of choices
    print(
    """"""
    Options: 

    0 - End
    1 - Add points to an attribute
    2 - remove points from an attribute
    3 - Show attributes
    """"""
    )
    choice = input(""Choose option: "")
    if choice == ""0"":
        print(""\nYour hero stats are:"")
        print(attributes)
    elif choice == ""1"":
        print(""\nADD POINTS TO AN ATTRIBUTE"")
        print(""You have"", pool, ""points to spend."")



    choice = input(""Go to the shop, go to the tavern, go to the forest: "")
    while choice != ""shop"" or ""tavern"" or ""forest"":
        print(""Not accepted"")
        print(""What do you wish to do?"")
        print(""please input shop, tavern, forest."")
        choice = input(""Go to the shop, go to the tavern, go to the forest: "")

        if choice == ""tavern"":
            print(""You enter the tavern and see a couple of drunken warriors singing, a landlord behind the bar and a dodgy figure sitting at the back of the tavern."")
            tavernChoice = input(""Would you like to talk to the 'drunken warriors', to the 'inn keeper', approach the 'dodgy figure' or 'exit'"")

            if tavernChoice == ""drunken warriors"":
                print(""You approach the warriors to greet them."")
                print(""They notice you as you get close and become weary of your presence."")
                print(""As you arrive at their table one of the warriors throughs a mug of ale at you."")
            if dexterity &gt;= 5:
                print(""You quickly dodge the mug and leave the warriors alone"")
            else:
                print(""You are caught off guard and take the mug to the face compleatly soaking you."")
                print(""The dodgy figure leaves the tavern"")
</code></pre>
"
"60474688","<p>You can create a list with your selection indices and use it to join what you want:</p>

<pre><code>list = [""0A"",""00"",""0C"",""20"",""10"",""AC""]
sel = [1,2]
print ("""".join(map(str, [list[i] for i in sel])))
</code></pre>
","0","","0","16","0","0","1","60474606","60474688","<p>How to join so that I get the result: e.g: 000C</p>

<p>How to join only selected items from the list? in this case list[1] and list[2]</p>

<pre><code>list = [0A,00,0C,20,10,AC]
print ("""".join(map(str, list)))
&gt;&gt;&gt; 123456

</code></pre>
"
"60512492","<p>You may want to add <code>resizeMode=""contain""</code> at Image component - <a href=""https://github.com/GetStream/react-native-activity-feed/blob/master/src/components/Activity.js#L223"" rel=""nofollow noreferrer"">https://github.com/GetStream/react-native-activity-feed/blob/master/src/components/Activity.js#L223</a>.</p>

<p>But to add this prop, you will have to provide your own <code>Content</code> component to <code>Activity</code> component. So I suggest something like following (check the comments in code):</p>

<pre><code>&lt;StreamApp
    apiKey={apiKey}
    appId={appId}
    token={this.state.token}
&gt;
    &lt;FlatFeed
        notify
        feedGroup=""timeline""
        options={{
          limit: 10,
        }}
        notify
        navigation={this.props.navigation}
        Activity={(props) =&gt; (
            &lt;TouchableOpacity
                onPress={() =&gt; this._onPressActivity(props.activity)}
            &gt;
                &lt;Activity
                    {...props}
                    Footer={
                        &lt;View style={{ flexDirection: 'row', alignItems: 'center' }}&gt;
                        &lt;LikeButton reactionKind=""heart"" {...props} /&gt;
                        &lt;/View&gt;
                    }

                    // This is mostly copied from source of default `Content` component
                    // https://github.com/GetStream/react-native-activity-feed/blob/master/src/components/Activity.js#L193
                    Content={() =&gt; {
                        const width =
                        props.imageWidth != null
                            ? props.imageWidth
                            : Dimensions.get('window').width;
                        const { object, image, attachments } = props.activity;
                        let { text } = props.activity;
                        const { Card } = props;
                        if (text === undefined) {
                        if (typeof object === 'string') {
                            text = object;
                        } else {
                            text = '';
                        }
                        }
                        text = text.trim();

                        return (
                        &lt;View&gt;
                            {Boolean(text) &amp;&amp; (
                            &lt;View style={{
                                paddingBottom: 15,
                                paddingLeft: 15,
                                paddingRight: 15,
                            }}&gt;
                                &lt;Text&gt;{this.renderText(text, props.activity)}&lt;/Text&gt;
                            &lt;/View&gt;
                            )}

                            {Boolean(image) &amp;&amp; (
                                &lt;Image
                                    style={{ width, height: width }}
                                    source={{ uri: image }}
                                    // Either `contain` or `stretch`, depending on your requirement
                                    resizeMode=""contain""
                                /&gt;
                            )}

                            {attachments &amp;&amp;
                                attachments.images &amp;&amp;
                                attachments.images.length &gt; 0 &amp;&amp; (
                                    &lt;Image
                                        style={{ width, height: width }}
                                        source={{ uri: attachments.images[0] }}
                                        // Either `contain` or `stretch`, depending on your requirement
                                        resizeMode=""contain""
                                    /&gt;
                            )}
                            {attachments &amp;&amp;
                                attachments.og &amp;&amp;
                                Object.keys(attachments.og).length &gt; 0 &amp;&amp;
                                &lt;Card
                                    title={attachments.og.title}
                                    description={attachments.og.description}
                                    image={
                                        attachments.og.images &amp;&amp; attachments.og.images.length &gt; 0
                                            ? attachments.og.images[0].image
                                            : null
                                    }
                                    url={attachments.og.url}
                                    og={attachments.og} /&gt;
                            }
                        &lt;/View&gt;
                        );                        
                    }}
                /&gt;
            &lt;/TouchableOpacity&gt;
        )}
    /&gt;
&lt;/StreamApp&gt;
</code></pre>
","1","","0","329","18","1","40","60474634","60512492","<p>I am working on a react native app that is using the FlatFeed component but the images when displayed in the feed are being cropped. How do I stop the image from being cropped?</p>

<p>I am posting activities with an image to the feed server side in Python using the following code:</p>

<pre><code>client = stream.connect(STREAM_API_KEY, STREAM_KEY_SECRET)
user_feed = client.feed('timeline', user_id)
user_feed.add_activity({'actor': client.users.create_reference(user_id),'verb': 'post', 'object': message, 'image': front_image_url})
</code></pre>

<p>This is the react native code for the FlatFeed:</p>

<pre><code>&lt;StreamApp
            apiKey={apiKey}
            appId={appId}
            token={this.state.token}
          &gt;
            &lt;FlatFeed
              notify
              feedGroup=""timeline""
              options={{
                limit: 10,
              }}
              notify
              navigation={this.props.navigation}
              Activity={(props) =&gt; (
                &lt;TouchableOpacity
                  onPress={() =&gt; this._onPressActivity(props.activity)}
                &gt;
                  &lt;Activity
                    {...props}

                    Footer={
                      &lt;View style={{ flexDirection: 'row', alignItems: 'center' }}&gt;
                        &lt;LikeButton reactionKind=""heart"" {...props} /&gt;
                      &lt;/View&gt;
                    }
                  /&gt;
                &lt;/TouchableOpacity&gt;
              )}
            /&gt;
          &lt;/StreamApp&gt;
</code></pre>

<p>The actual image and what it looks like in the feed are here: 
<a href=""https://i.stack.imgur.com/qKnCu.jpg"" rel=""nofollow noreferrer"">This is how the FlatFeed displays the image</a></p>

<p><a href=""https://i.stack.imgur.com/95emY.jpg"" rel=""nofollow noreferrer"">This is an example image that the feed is pulling in from a public S3 bucket</a></p>

<p><strong>How do I stop the image from being cropped?</strong></p>

<p>Any help much appreciated, thanks.</p>
"
"60474754","<p>You can add <code>header=0</code> parameter for first row of data to columns names, <code>thousands=' '</code> for remove spaces in <a href=""http://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_html.html"" rel=""nofollow noreferrer""><code>read_html</code></a> in first step.</p>

<p>Then remove first column by indexing with <a href=""http://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.iloc.html"" rel=""nofollow noreferrer""><code>DataFrame.iloc</code></a>, set new columns names and change values in <code>Text</code> column by <a href=""http://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.replace.html"" rel=""nofollow noreferrer""><code>Series.replace</code></a>:</p>

<pre><code>url = 'http://www.livepriceofgold.com/pakistan-gold-price.html'
df = pd.read_html(url, header=0, thousands=' ')[3].iloc[:, 1:]
df.columns= ['Text','Rates']

df['Text'] = df['Text'].replace('Gold Rate per ', '', regex=True)
print (df)
          Text       Rates
0  Gram in PKR     7889.65
1    Oz in PKR   245368.02
2    KG in PKR  7889646.96
3  Tola in PKR    92023.26
</code></pre>
","0","2020-03-01 11:53:29","1","615041","23439","1483","126104","60474729","60474754","<p>I am using Pandas for receiving live gold prices, I just want to clean the output so it can look good and readable. <strong>Please help me with this</strong>.</p>

<p>My code:</p>

<pre><code>import pandas as pd
d = pd.read_html('http://www.livepriceofgold.com/pakistan-gold-price.html')
type(d)
a=len(d)
i=1
df = d[3]
finalString=df.to_string()
print(finalString) 
</code></pre>

<p>and The output is:</p>

<pre><code>     0                                 1             2
0 NaN  Gold Rate in PKR Pakistani rupee          Rate
1 NaN         Gold Rate per Gram in PKR      7 889.65
2 NaN           Gold Rate per Oz in PKR    245 368.02
3 NaN           Gold Rate per KG in PKR  7 889 646.96
4 NaN         Gold Rate per Tola in PKR     92 023.26
</code></pre>

<p>I want this type of output:</p>

<pre><code>Gram in PKR:      7 889.65
Oz in PKR  :      245 368.02
KG in PKR  :      7 889 646.96
Tola in PKR:     92 023.26
</code></pre>

<p>Or just Extract the Rates in variables</p>
"
"60475129","<p><strong>so far, I have used this to remove every thing and then split these strings and extract the values i need using split function</strong> </p>

<pre><code> fs=fs.replace(""Gold Rate per Gram in PKR"","""")
    fs=fs.replace(""Gold Rate per Oz in PKR"","""")
    fs=fs.replace(""Gold Rate per KG in PKR"","""")
    fs=fs.replace(""Gold Rate per Tola in PKR"","""")
    fs=fs.replace(""Gold Rate in PKR Pakistani rupee"","""")
    fs=fs.replace(""Rate"","""")
    fs=fs.replace(""0 NaN"","""")
    fs=fs.replace(""1 NaN"","""")
    fs=fs.replace(""2 NaN"","""")
    fs=fs.replace(""3 NaN"","""")
    fs=fs.replace(""4 NaN"","""")
    #print(fs.split())
    single= fs.split()
</code></pre>
","0","","-1","33","13","0","10","60474729","60474754","<p>I am using Pandas for receiving live gold prices, I just want to clean the output so it can look good and readable. <strong>Please help me with this</strong>.</p>

<p>My code:</p>

<pre><code>import pandas as pd
d = pd.read_html('http://www.livepriceofgold.com/pakistan-gold-price.html')
type(d)
a=len(d)
i=1
df = d[3]
finalString=df.to_string()
print(finalString) 
</code></pre>

<p>and The output is:</p>

<pre><code>     0                                 1             2
0 NaN  Gold Rate in PKR Pakistani rupee          Rate
1 NaN         Gold Rate per Gram in PKR      7 889.65
2 NaN           Gold Rate per Oz in PKR    245 368.02
3 NaN           Gold Rate per KG in PKR  7 889 646.96
4 NaN         Gold Rate per Tola in PKR     92 023.26
</code></pre>

<p>I want this type of output:</p>

<pre><code>Gram in PKR:      7 889.65
Oz in PKR  :      245 368.02
KG in PKR  :      7 889 646.96
Tola in PKR:     92 023.26
</code></pre>

<p>Or just Extract the Rates in variables</p>
"
"60478221","<pre><code>Match = df.loc[df['ID'].isin(L),'Num']
</code></pre>
","0","","0","3485","585","60","202","60474772","60478221","<p>I have a list, ""L"" and a DataFrame, ""df"" and I wish to extract a certain column value only where the L and a certain df column match.</p>

<pre><code>L = [299]
Match = []

df:
['ID']    ['Num']
299       1
300       3
....      ....
</code></pre>

<p>I wish to see 1 when I print Match:</p>

<pre><code>print(Match):

1
</code></pre>
"
"60474803","<p>They both have the same <em>values</em>, but they are two different lists.</p>

<p><code>table2D[:]</code> creates a copy of <code>table2D</code> and <code>[0]</code> takes the first index of that copy, so</p>

<pre><code>table2D[:][0]
</code></pre>

<p>is index 0 in a copy of <code>table2D</code>.</p>

<p><code>table2D[0]</code> takes the first index of <code>table2D</code> and <code>[:]</code> creates a copy of that list, so</p>

<pre><code>table2D[0][:]
</code></pre>

<p>is a copy of index 0 in <code>table2D</code>.</p>
","0","2020-03-01 12:07:39","0","33900","639","3108","4197","60474785","60474803","<p>Why does <code>tab2D[:][0]</code> and <code>tab2D[0][:]</code> gives this same result?</p>

<pre><code>if __name__ == ""__main__"":
    table2D = [
        [1, 2, 3],
        [4, 5, 6],
        [7, 8, 9]
    ]

    print(table2D[:][0]) #[1,2,3]
    print(table2D[0][:]) #[1,2,3]
</code></pre>
"
"60474879","<p>Actually, it's not <strong>exactly</strong> same.<br>
They looks like having same values.<br>
But they have different references.</p>

<pre class=""lang-py prettyprint-override""><code>table2D = [
    [1, 2, 3],
    [4, 5, 6],
    [7, 8, 9]
]

a = table2D[0][:]
b = table2D[:][0]

a[0] = 0
print(table2D[0])  # [1, 2, 3]
b[0] = 0
print(table2D[0])  # [0, 2, 3]
</code></pre>
","0","","0","2217","279","150","156","60474785","60474803","<p>Why does <code>tab2D[:][0]</code> and <code>tab2D[0][:]</code> gives this same result?</p>

<pre><code>if __name__ == ""__main__"":
    table2D = [
        [1, 2, 3],
        [4, 5, 6],
        [7, 8, 9]
    ]

    print(table2D[:][0]) #[1,2,3]
    print(table2D[0][:]) #[1,2,3]
</code></pre>
"
"60474933","<p>Your JSON data gets converted into a dictionary when using the <code>json.loads()</code> method, where the <em>keys</em> are 1, 2, 3 etc, and the <em>values</em> are dictionaries as well (e.g.: <code>{""home"":""001"",""street"":""Wolrd1"",""cap"":0}</code>).
The only modification you need is to use the <code>.values()</code> method in the for loop:</p>

<pre><code>import json
jsonData = '{""1"":{""home"":""001"",""street"":""Wolrd1"",""cap"":0},""2"":{""home"":""002"",""street"":""Wolrd2"",""cap"":0},""3"":{....}}'
jsonToPython = json.loads(jsonData)

jsonToPython = json.loads(jsonData)

for x in jsonToPython.values():
    print x
</code></pre>
","0","","0","71","14","0","6","60474851","60474933","<p>Please how print this line:</p>

<pre><code>{""1"":{""home"":""001"",""street"":""Wolrd1"",""cap"":0},""2"":{""home"":""002"",""street"":""Wolrd2"",""cap"":0},""3"":{....}}
</code></pre>

<p>in this format:</p>

<pre><code>{""home"":""001"",""street"":""Wolrd1"",""cap"":0}
{""home"":""002"",""street"":""Wolrd2"",""cap"":0}
{....}}
</code></pre>

<p>with this code:</p>

<pre><code>import json
jsonData = '{""1"":{""home"":""001"",""street"":""Wolrd1"",""cap"":0},""2"":{""home"":""002"",""street"":""Wolrd2"",""cap"":0},""3"":{....}}'
jsonToPython = json.loads(jsonData)

for x in jsonToPython:
    print x
</code></pre>

<p>print is:
1
2
3</p>
"
"60476810","<p>The reason is that this part of <code>feasibleMove</code> has errors:</p>

<pre><code>row = coordinate[0] // 3
col = coordinate[1] // 3

for i in range(x * 3, x * 3 + 3):
    for j in range(y * 3, y * 3 + 3):
        if board[row][col] == number and (i, j) != coordinate:
            return False
</code></pre>

<p>The iteration should be based on <code>row</code> and <code>col</code>, not on <code>x</code> and <code>y</code>. And when you read out the value from <code>board</code>, you should use <code>i</code> and <code>j</code> as indexes. Right now, you are 9 times looking at the very same cell on your board.</p>

<pre><code>row = (x // 3) * 3
col = (y // 3) * 3

for i in range(row, row + 3):
    for j in range(col, col + 3):
        if board[i][j] == number and (i, j) != coordinate:
            return False
</code></pre>

<p>However, your algorithm is too slow to solve the puzzle in a reasonable time. You should improve your algorithm, with the following:</p>

<ul>
<li>Don't look for blank cells in real time. Instead, collect them into a queue, and pop them from there (and put them back when backtracking)</li>
<li>Instead of checking whether a value is valid for a cell, stay one step ahead, and keep track of which values are still valid (in a <code>set</code>), for each cell. Initialise this at the very start of the algorithm.</li>
<li>When placing a value update the sets of impacted cells</li>
</ul>

<p>These last two points may seem to give no gain as it just shifts the work of scanning rows, columns and boxes to another moment in the algorithm, but the benefit comes here:</p>

<ul>
<li>In order to keep your recursion tree narrow, give priority to cells that have the fewest possible values left, ideally only one. You can use python's <code>heapq</code> for this, and it should be applied to the queue that I mentioned in the first point.</li>
</ul>

<p>I leave the implementation for you, as it was not your question. There are lots of working examples on the net anyway.</p>
","2","","0","204854","1897","2832","18633","60474867","60476810","<p>Hi I am trying to use backtracking to solve a <a href=""https://en.wikipedia.org/wiki/Sudoku"" rel=""nofollow noreferrer"">Sudoku Puzzle</a>.</p>

<pre><code>board = [[0, 0, 0, 7, 0, 0, 0, 0, 0],
         [1, 0, 0, 0, 0, 0, 0, 0, 0],
         [0, 0, 0, 4, 3, 0, 2, 0, 0],
         [0, 0, 0, 0, 0, 0, 0, 0, 6],
         [0, 0, 0, 5, 0, 9, 0, 0, 0],
         [0, 0, 0, 0, 0, 0, 4, 1, 8],
         [0, 0, 0, 0, 8, 1, 0, 0, 0],
         [0, 0, 2, 0, 0, 0, 0, 5, 0],
         [0, 4, 0, 0, 0, 0, 3, 0, 0]]

def findBlank(board):
    for i in range(9):
        for j in range(9):
            if board[i][j] == 0:
                return (i,j)
    return False

def feasibleMove(board, coordinate, number):
    x, y = coordinate
    #check row
    for i in range(9):
        if board[x][i] == number and y != i:
            return False
    #check column
    for i in range(9):
        if board[i][y] == number and x != i:
            return False
    #check box
    row = coordinate[0] // 3
    col = coordinate[1] // 3

    for i in range(x * 3, x * 3 + 3):
        for j in range(y * 3, y * 3 + 3):
            if board[row][col] == number and (i, j) != coordinate:
                return False

    return True

def solver(board):
    blankCell = findBlank(board)
    if not blankCell:
        return True
    else:
        row, col = blankCell

    for i in range(1, 10):
        if feasibleMove(board, (row, col), i):
            board[row][col] = i

            if solver(board):
                return True

            board[row][col] = 0

    return False

</code></pre>

<p>I have written one function to return a blank value if one exists, here 0 indicates a blank. Another function to test if placing a number into a specific position in a board is valid (based on Sudoku rules), and another one that implements backtracking to actually solve the puzzle.</p>

<p>With the board provided when I run the algorithm I get:</p>

<pre><code>[[2, 1, 3, 7, 4, 5, 6, 8, 9],
 [1, 3, 4, 2, 5, 6, 8, 9, 7],
 [5, 6, 9, 4, 3, 8, 2, 7, 1],
 [7, 5, 8, 1, 2, 4, 9, 3, 6],
 [4, 8, 7, 5, 6, 9, 1, 2, 3],
 [3, 2, 5, 6, 9, 7, 4, 1, 8],
 [9, 7, 6, 3, 8, 1, 5, 4, 2],
 [6, 9, 2, 8, 1, 3, 7, 5, 4],
 [8, 4, 1, 9, 7, 2, 3, 6, 5]]
</code></pre>

<p>It seems to work on a column by column and row by row basis. However the <code>3x3</code> squares are not correct.</p>

<p>For example taking the top left square</p>

<pre><code>[[2, 1, 3],
 [1, 3, 4],
 [5, 6, 9]]
</code></pre>

<p>This has duplicated entries for example <code>3</code> and also does not contain each number <code>1-9</code> precisely once.</p>

<p>Based on my <code>feasibleMove</code> method this should not be allowed!</p>

<p>Clearly I have made a mistake but I cannot see where...</p>

<p>Any ideas? </p>
"
"60474942","<p><code>choice[1]</code> is doing <code>1[1]</code> which doesn't make sense. I think you want <code>li[choice][1]</code>. i.e.</p>

<pre><code>if li[choice][1] == ""t"":
</code></pre>
","1","","1","2489","54","19","236","60474925","60474942","<p>Here is the code where I try to take the ""t"" char from the ""two"" string from the li list and compare it to a single ""t"" char:</p>

<pre><code>li=[""one"",""two"",""three""];

choice=1;

if li[choice[1]]==""t"":
    print(""valid"");

else:
    print(""unvalid"");
</code></pre>

<p>The problem is that when I run it, it says:</p>

<pre><code>Traceback (most recent call last):
  File ""C:\Users\Yobob\Documents\cours\ISN\ProjetISN\testPython.py"", line 3, in &lt;module&gt;
    if li[choice[1]]==""t"":
TypeError: 'int' object is not subscriptable
</code></pre>
"
"60475057","<p>You can not pass the list of URL.</p>

<pre><code>for url in urls:
   soup = BeautifulSoup(urllib.request.urlopen(url))
</code></pre>
","0","","0","924","0","5","55","60474932","60475791","<pre><code>from bs4 import BeautifulSoup
import urllib.request

urls = [
""https://archillect.com/1"",
""https://archillect.com/2"",
""https://archillect.com/3"",
]

soup = BeautifulSoup(urllib.request.urlopen(urls))

for u in urls:
   for img in soup.find_all(""img"", src=True):
    print(img[""src""])
</code></pre>

<p><strong><em>AttributeError: 'list' object has no attribute 'timeout'</em></strong></p>
"
"60475791","<p>@krishna has given you the answer. I'll give you another solution for reference only.</p>
<pre><code>from simplified_scrapy import Spider, SimplifiedDoc, SimplifiedMain, utils
class ImageSpider(Spider):
  name = 'archillect'
  start_urls = [&quot;https://archillect.com/1&quot;,&quot;https://archillect.com/2&quot;,&quot;https://archillect.com/3&quot;]
  def afterResponse(self, response, url, error=None, extra=None):
    try:
      # Create file name
      end = url.find('?') if url.find('?')&gt;0 else len(url)
      name = 'data'+url[url.rindex('/',0,end):end]
      # save image
      if utils.saveResponseAsFile(response,name,'image'):
        return None 
      else:
        return Spider.afterResponse(self, response, url, error)
    except Exception as err:
      print (err)
  def extract(self,url,html,models,modelNames):
    doc = SimplifiedDoc(html)
    urls = doc.listImg(url=url.url)
    return {'Urls':urls} 
SimplifiedMain.startThread(ImageSpider()) # Start
</code></pre>
<p>Here are more examples: <a href=""https://github.com/yiyedata/simplified-scrapy-demo/tree/master/spider_examples"" rel=""nofollow noreferrer"">https://github.com/yiyedata/simplified-scrapy-demo/tree/master/spider_examples</a></p>
","0","2020-06-30 10:09:22","0","2231","56","0","189","60474932","60475791","<pre><code>from bs4 import BeautifulSoup
import urllib.request

urls = [
""https://archillect.com/1"",
""https://archillect.com/2"",
""https://archillect.com/3"",
]

soup = BeautifulSoup(urllib.request.urlopen(urls))

for u in urls:
   for img in soup.find_all(""img"", src=True):
    print(img[""src""])
</code></pre>

<p><strong><em>AttributeError: 'list' object has no attribute 'timeout'</em></strong></p>
"
"60475006","<p>When you do this, you are just creating copies of list, n times. </p>

<p>So the inner lists here are actually the same list. When you modify the first one, you're also modifying the second. If you don't want that functionality, you can do this instead:</p>

<pre><code>a = [[1 for _ in range(2)] for _ in range(2)]
</code></pre>
","2","","1","2489","54","19","236","60474939","60475039","<p>Why the output here is [[2, 1], [<strong>2</strong>, 1]] and not [[2,1],[<strong><em>1</em></strong>,1]]</p>

<pre><code>a = [[1] * 2] * 2
a[0][0]=2
print (a)
</code></pre>

<p>I have done quite research on the * operator in list but it doesn't seem to get me to the correct understanding </p>
"
"60475039","<p>It's due to the fact, how Python handles objects in memory. When you are using the <code>* 2</code> to duplicate the list, Python does not create a separate list object in memory, it only copies the memory pointer for the second list position. Due to this behaviour when you mutate the first element, it affects the second too.
You can use the <code>id()</code> function to check the object ids within Python. You will see that <code>a[0]</code> and <code>a[1]</code> will have the same ids.</p>

<pre><code>&gt;&gt;&gt; a = [[1] * 2] * 2
&gt;&gt;&gt; a[0][0] = 2
&gt;&gt;&gt; a
[[2, 1], [2, 1]]
&gt;&gt;&gt; id(a[0])
140608840898432
&gt;&gt;&gt; id(a[1])
140608840898432
&gt;&gt;&gt; id(a[0]) == id(a[1])
True
</code></pre>
","0","","1","71","14","0","6","60474939","60475039","<p>Why the output here is [[2, 1], [<strong>2</strong>, 1]] and not [[2,1],[<strong><em>1</em></strong>,1]]</p>

<pre><code>a = [[1] * 2] * 2
a[0][0]=2
print (a)
</code></pre>

<p>I have done quite research on the * operator in list but it doesn't seem to get me to the correct understanding </p>
"
"60475001","<p>Use <a href=""http://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.core.groupby.GroupBy.transform.html"" rel=""nofollow noreferrer""><code>GroupBy.transform</code></a> for <code>max</code> values per groups compared by <code>Lenght</code> column by <a href=""http://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.eq.html"" rel=""nofollow noreferrer""><code>Series.eq</code></a> for equality and for map to <code>True-&gt;1</code> and <code>False-&gt;0</code> cast values to integers by <a href=""http://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.astype.html"" rel=""nofollow noreferrer""><code>Series.astype</code></a>:</p>

<pre><code>#added first row data by second row
df = pd.DataFrame({'Name': ['Karl', 'Karl', 'Billy', 'Abe', 'Karl', 'Billy', 'Abe', 'Karl', 'Billy'], 
               'Lenght': ['12.5', '12.5', '11', '12.5', '12', '11', '12.5', '10', '5'],
              'Try': [0,0,0,1,1,1,2,2,2],
              'Batch':[0,0,0,0,0,0,0,0,0]})
</code></pre>

<hr>

<pre><code>df['Lenght'] = df['Lenght'].astype(float)


m1 = df.groupby('Batch')['Lenght'].transform('max').eq(df['Lenght'])

df1 = df[m1]
m2 = df1.groupby('Name')['Try'].transform('nunique').eq(1)
m3 = ~df1.duplicated(['Name','Batch'])

df['new'] = ((m2 | m3) &amp; m1).astype(int)
print (df)
    Name  Lenght  Try  Batch  new
0   Karl    12.5    0      0    1
1   Karl    12.5    0      0    1
2  Billy    11.0    0      0    0
3    Abe    12.5    1      0    1
4   Karl    12.0    1      0    0
5  Billy    11.0    1      0    0
6    Abe    12.5    2      0    0
7   Karl    10.0    2      0    0
8  Billy     5.0    2      0    0
</code></pre>
","8","2020-03-01 12:59:13","2","615041","23439","1483","126104","60474979","60475001","<p>I have a DataFrame that has below columns:</p>

<pre><code>df = pd.DataFrame({'Name': ['Abe', 'Karl', 'Billy', 'Abe', 'Karl', 'Billy', 'Abe', 'Karl', 'Billy'], 
               'Lenght': ['10', '12.5', '11', '12.5', '12', '11', '12.5', '10', '5'],
              'Try': [0,0,0,1,1,1,2,2,2],
              'Batch':[0,0,0,0,0,0,0,0,0]})
</code></pre>

<p>In each <code>batch</code> a <code>name</code> gets arbitrary many tries to get the greatest <code>lenght.</code> 
What I want to do is create a column <code>win</code> that has the value 1 for greatest <code>lenght</code> in a <code>batch</code> and 0 otherwise, with the following conditions.</p>

<ul>
<li><p>If one  <code>name</code> hold the greatest <code>lenght</code> in a batch in multiple <code>try</code> only the first <code>try</code> will have the value 1 in <code>win</code>(See ""Abe in example above"")</p></li>
<li><p>If two separate <code>name</code> holds equal greatest <code>lenght</code> then both will have value 1 in <code>win</code> </p></li>
</ul>

<p>What I have managed to do so far is:</p>

<pre><code>df.groupby(['Batch', 'name'])['lenght'].apply(lambda x: (x == x.max()).map({True: 1, False: 0}))
</code></pre>

<p>But it doesn't support all the conditions, any insight would be highly </p>

<p>Expected outout:</p>

<pre><code>df = pd.DataFrame({'Name': ['Abe', 'Karl', 'Billy', 'Abe', 'Karl', 'Billy', 'Abe', 'Karl', 'Billy'], 
                   'Lenght': ['10', '12.5', '11', '12.5', '12', '11', '12.5', '10', '5'],
                  'Try': [0,0,0,1,1,1,2,2,2],
                  'Batch':[0,0,0,0,0,0,0,0,0],
                  'win':[0,1,0,1,0,0,0,0,0]})
</code></pre>

<p>appreciated.
Many thanks,</p>
"
"60475425","<p>You can rewrite your cycle like this:</p>

<pre><code>while counter &lt;= 71:
    plt.cla() # clean current axis
    plt.plot(t, packet(E0,t,w0,T,i),label = 't = %d' %(i))
    plt.ylim([-1.1, 1.1]) # establish limits for better visualization
    plt.savefig(""time%d.jpg"" %i)
    i += 1
    counter += 1
</code></pre>

<p>also you can create <a href=""https://matplotlib.org/3.1.3/gallery/animation/simple_anim.html"" rel=""nofollow noreferrer"">animation</a> according this example</p>
","0","2020-03-01 13:37:09","0","26","0","0","2","60474987","60475425","<p>Im trying to animate a non-dispersive wave packet. My idea is to output the wave function at many different time points and then add individuals photos to make an animation. My Python code kind of the job but it repeats the previous plots in all following plots and i dont know how to fix it.</p>

<pre><code>import matplotlib.pyplot as plt
import numpy as np

k = np.linspace(1,100,1000)
#x = np.linspace(-n&lt;p.pi,np.pi,100)
x = np.linspace(0,70,71)
fac = np.linspace(0,1,1000)
result = []
n = 800
t = np.linspace(-150,150,n)
vp = -1
E0 = 1
w0 = 1
T = 10
def wave(k,x):
    return abs(np.sin(x-k))

def packet(E0,t,w0,T,x):
    return E0*np.cos(w0*(t+vp*x))*np.exp(-(t+vp*x)**2/T**2)

j = len(fac)-1
    #while j &gt;= 0:
    #for i in range(len(k)):
    #   result.append(wave(k[i],x))
            #j -= 1

b = np.array(result)
c = np.sum(b,axis = 0)
    #plt.plot(x,c)
    #plt.show()

counter = 0
i=0
while counter &lt;= 71:
    plt.plot(t,packet(E0,t,w0,T,i),label = 't = %d' %(i))
    plt.savefig(""time%d.pdf"" %i)
    i += 1
    counter += 1
</code></pre>
"
"60475370","<p>Change the line:</p>

<pre><code>X_train[:,8] = impC.fit_transform(X_train[:,8].reshape(-1,1))
</code></pre>

<p>to </p>

<pre><code>X_train[:,8] = impC.fit_transform(X_train[:,8].reshape(-1,1)).ravel()
</code></pre>

<p>and your error will disappear.</p>

<p>It's assigning imputed values back what causes issues on your code.</p>
","3","2020-03-01 13:09:37","2","15516","968","609","1473","60475098","60475370","<p>I'm trying to impute 1D array with shape (14599,) with simple imputer with most_frequent strategy but it said it expected 2D array, i already tried reshaping it (-1,1) and (1,-1) but its error ValueError: could not broadcast input array from shape (14599,1) into shape (14599) how can i impute this since reshaping wont solve the problem? i dont understand why it throws error. I already tried to ask it in <a href=""https://datascience.stackexchange.com/questions/68874/cannot-impute-1d-array/68890#68890"">DS stackexchange</a> and someone answered maybe it's the pandas series but i made the x,y in numpy array then pass it into the parameter for X,y/train,test so i'm not sure</p>

<pre><code>##libraries
import pandas as pd
import seaborn as sns
import numpy as np
import matplotlib.pyplot as plt
from sklearn.impute import SimpleImputer
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder

##codes
plt.close('all')
avo_sales = pd.read_csv('avocados.csv')
avo_sales.rename(columns = {'4046':'small PLU sold',
                            '4225':'large PLU sold',
                            '4770':'xlarge PLU sold'},
                 inplace= True)

avo_sales.columns = avo_sales.columns.str.replace(' ','')

plt.scatter(avo_sales.Date,avo_sales.TotalBags)

x = np.array(avo_sales.drop(['TotalBags','Unnamed:0','year','region','Date'],1))
y = np.array(avo_sales.TotalBags)

X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2)

impC = SimpleImputer(strategy='most_frequent')
X_train[:,8] = impC.fit_transform(X_train[:,8].reshape(-1,1)) &lt;-- error here

imp = SimpleImputer(strategy='median')
X_train[:,1:8] = imp.fit_transform(X_train[:,1:8])

le = LabelEncoder()
X_train[:,8] = le.fit_transform(X_train[:,8])
</code></pre>
"
"60475147","<p>The VGG16 architecture does not contain a dropout layer by default. You would need to insert a dropout layer in the model.</p>

<p>Here is a post I found useful to solve this:
<a href=""https://stackoverflow.com/questions/42475381/add-dropout-layers-between-pretrained-dense-layers-in-keras"">Add dropout layers between pretrained dense layers in keras</a></p>
","1","","1","350","1196","4","32","60475122","60475147","<p>I'm using Tensorflow 2.0 and a pre-trained VGG16 model and want to activate dropout during prediction. So far I tried the following without success:</p>

<pre><code>model = tf.keras.applications.VGG16(input_shape=(224, 224, 3), weights='imagenet', is_training=True)

model = tf.keras.applications.VGG16(input_shape=(224, 224, 3), weights='imagenet', dropout_rate=0.5)
</code></pre>

<p>However, none of these approaches worked. How can I enable dropout during the prediction phase?</p>
"
"60475681","<p>You <em>think</em> it exists, but when you call <code>message_widget()</code> it does not exist yet.</p>

<p>In fact, you are calling that function <em>before</em> this line:</p>

<pre><code>self.scrollAreaWidgetContents = QtWidgets.QWidget()
</code></pre>

<p>So, it <em>could</em> work if you put that function at least <em>after</em> creating that widget.</p>

<p><br/>
Unfortunately, there are other serious issues with your code.</p>

<p>The most important one is that you are modifying the output of pyuic to create your program, which is highly discouraged (and the <code>WARNING</code> message at the beginning should be a hint).</p>

<p>The python scripts generated from UI files should <strong>NEVER</strong> be edited, but used as an import in your actual program files. The most obvious reason is that as soon as you want to do some changes in the ui, you'll find yourself in the mess of trying to merge the new generated code with what you've written so far.</p>

<p>To know more about this, read the documentation about <a href=""https://www.riverbankcomputing.com/static/Docs/PyQt5/designer.html"" rel=""nofollow noreferrer"">using Designer</a>.</p>

<p>Other issues in your code:</p>

<ul>
<li>threading in Qt should be used with Qt's own QThread as much as possible;</li>
<li>UI objects should <em>never</em> be accessed nor modified by an external thread; to do that you have to use a QThread, and communicate with the main Qt thread using signals and slots;</li>
<li><code>QLabel.text()</code> does not accept parameters, as it is used to access the text property; to set the text of a label, use <code>setText()</code>;</li>
</ul>
","1","","0","18223","101","602","1897","60475128","60475681","<pre><code># -*- coding: utf-8 -*-

# Form implementation generated from reading ui file 'messagerGUI.ui'
#
# Created by: PyQt5 UI code generator 5.13.0
#
# WARNING! All changes made in this file will be lost!
# """"

from PyQt5 import QtCore, QtGui, QtWidgets
import socket
import threading


class Ui_MainWindow(object):
    sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
    header = 12
    connections = []
    ip = socket.gethostname()
    port = 1234
    connections_allowed = 3
    sock.bind((ip, port))
    sock.listen(connections_allowed)
    new_message = False

    def start(self):
        while True:
            self.conn, self.addr = self.sock.accept()
            threading.Thread(target=self.receive_data, args=[
                             self.conn], daemon=True).start()
            self.connections.append(self.conn)

    def receive_data(self, conn):
        self.reply = """"
        while True:
            try:

                message_lenth = conn.recv(self.header)
                lenth_of_message = message_lenth.decode(""utf-8"")

                if not message_lenth:
                    break

                elif message_lenth:
                    data = conn.recv(int(lenth_of_message))
                    self.reply = data.decode(""utf-8"")

                    print(self.reply)
                    self.new_message = True

                    for connection in self.connections:
                        if connection != conn:
                            connection.send(message_lenth.encode(""utf-8""))
                            connection.send(self.reply.encode(""utf-8""))

            except:
                break

    def packing_data_lenth(self, text):
        return len(text) * 4

    def send_data(self, data):
        try:
            for connection in self.connections:
                connection.send(
                    bytes(str(self.packing_data_lenth(data)), ""utf-8""))
                connection.send(bytes(data, ""utf-8""))
        except:
            pass


    def setupUi(self, MainWindow):
        threading.Thread(target=self.start, daemon=True).start()
        MainWindow.setObjectName(""MainWindow"")
        MainWindow.resize(499, 367)
        MainWindow.setStyleSheet(""background-color: #113e4a;"")
        self.centralwidget = QtWidgets.QWidget(MainWindow)
        self.centralwidget.setObjectName(""centralwidget"")
        self.horizontalLayout = QtWidgets.QHBoxLayout(self.centralwidget)
        self.horizontalLayout.setContentsMargins(5, 5, 5, 5)
        self.horizontalLayout.setSpacing(5)
        self.horizontalLayout.setObjectName(""horizontalLayout"")

        self.info = QtWidgets.QWidget(self.centralwidget)
        sizePolicy = QtWidgets.QSizePolicy(
            QtWidgets.QSizePolicy.Maximum, QtWidgets.QSizePolicy.Minimum)
        sizePolicy.setHeightForWidth(
            self.info.sizePolicy().hasHeightForWidth())
        self.info.setSizePolicy(sizePolicy)
        self.info.setMinimumSize(QtCore.QSize(178, 357))
        self.info.setStyleSheet(""background-color: #429178;\n""
                                ""border-radius: 2px;"")
        self.info.setObjectName(""info"")
        self.verticalLayout_3 = QtWidgets.QVBoxLayout(self.info)

        self.verticalLayout_3.setObjectName(""verticalLayout_3"")
        self.label_3 = QtWidgets.QLabel(self.info)
        self.label_3.setObjectName(""label_3"")
        self.verticalLayout_3.addWidget(self.label_3)
        spacerItem = QtWidgets.QSpacerItem(
            20, 317, QtWidgets.QSizePolicy.Minimum, QtWidgets.QSizePolicy.Expanding)
        self.verticalLayout_3.addItem(spacerItem)
        self.horizontalLayout.addWidget(self.info)

        self.message_widget()

        self.chat_area = QtWidgets.QWidget(self.centralwidget)
        sizePolicy = QtWidgets.QSizePolicy(
            QtWidgets.QSizePolicy.Minimum, QtWidgets.QSizePolicy.Minimum)
        sizePolicy.setHeightForWidth(
            self.chat_area.sizePolicy().hasHeightForWidth())
        self.chat_area.setSizePolicy(sizePolicy)
        self.chat_area.setMinimumSize(QtCore.QSize(306, 0))
        self.chat_area.setStyleSheet(""background-color: #429178;"")
        self.chat_area.setObjectName(""chat_area"")
        self.verticalLayout = QtWidgets.QVBoxLayout(self.chat_area)
        self.verticalLayout.setContentsMargins(2, 2, 2, 2)
        self.verticalLayout.setSpacing(1)
        self.verticalLayout.setObjectName(""verticalLayout"")

        self.messages_area = QtWidgets.QScrollArea(self.chat_area)
        sizePolicy = QtWidgets.QSizePolicy(
            QtWidgets.QSizePolicy.Expanding, QtWidgets.QSizePolicy.MinimumExpanding)
        sizePolicy.setHeightForWidth(
            self.messages_area.sizePolicy().hasHeightForWidth())
        self.messages_area.setSizePolicy(sizePolicy)
        self.messages_area.setMinimumSize(QtCore.QSize(0, 259))
        self.messages_area.setStyleSheet(""background-color: #113e4a;"")
        self.messages_area.setWidgetResizable(True)
        self.messages_area.setObjectName(""messages_area"")

        self.scrollAreaWidgetContents = QtWidgets.QWidget()
        self.scrollAreaWidgetContents.setGeometry(QtCore.QRect(0, 0, 300, 316))
        sizePolicy = QtWidgets.QSizePolicy(
            QtWidgets.QSizePolicy.Preferred, QtWidgets.QSizePolicy.Minimum)
        sizePolicy.setHeightForWidth(
            self.scrollAreaWidgetContents.sizePolicy().hasHeightForWidth())
        self.scrollAreaWidgetContents.setSizePolicy(sizePolicy)
        self.scrollAreaWidgetContents.setLayoutDirection(QtCore.Qt.LeftToRight)
        self.scrollAreaWidgetContents.setObjectName(""scrollAreaWidgetContents"")
        self.verticalLayout_2 = QtWidgets.QVBoxLayout(
            self.scrollAreaWidgetContents)
        self.verticalLayout_2.setSizeConstraint(
            QtWidgets.QLayout.SetNoConstraint)
        self.verticalLayout_2.setSpacing(6)
        self.verticalLayout_2.setObjectName(""verticalLayout_2"")

        spacerItem1 = QtWidgets.QSpacerItem(
            20, 40, QtWidgets.QSizePolicy.Minimum, QtWidgets.QSizePolicy.MinimumExpanding)
        self.verticalLayout_2.addItem(spacerItem1)
        self.messages_area.setWidget(self.scrollAreaWidgetContents)
        self.verticalLayout.addWidget(self.messages_area)

        self.input_area = QtWidgets.QWidget(self.chat_area)
        self.input_area.setMinimumSize(QtCore.QSize(0, 30))
        self.input_area.setObjectName(""input_area"")
        self.horizontalLayout_2 = QtWidgets.QHBoxLayout(self.input_area)
        self.horizontalLayout_2.setContentsMargins(1, 1, 1, 1)
        self.horizontalLayout_2.setSpacing(1)
        self.horizontalLayout_2.setObjectName(""horizontalLayout_2"")
        self.userInput = QtWidgets.QLineEdit(self.input_area)
        sizePolicy = QtWidgets.QSizePolicy(
            QtWidgets.QSizePolicy.MinimumExpanding, QtWidgets.QSizePolicy.Minimum)
        sizePolicy.setHorizontalStretch(0)
        sizePolicy.setVerticalStretch(0)
        sizePolicy.setHeightForWidth(
            self.userInput.sizePolicy().hasHeightForWidth())
        self.userInput.setSizePolicy(sizePolicy)
        self.userInput.setMinimumSize(QtCore.QSize(22, 32))
        font = QtGui.QFont()
        font.setPointSize(12)
        self.userInput.setFont(font)
        self.userInput.setStyleSheet(""background-color: rgb(17, 62, 74);\n""
                                     ""color: #d0e8ce;\n""
                                     ""border: 0px;"")
        self.userInput.setInputMethodHints(QtCore.Qt.ImhNone)
        self.userInput.setFrame(True)
        self.userInput.setDragEnabled(True)
        self.userInput.setPlaceholderText(""Type a message"")
        self.userInput.setObjectName(""userInput"")
        self.horizontalLayout_2.addWidget(self.userInput)
        self.sendButton = QtWidgets.QPushButton(self.input_area)
        sizePolicy = QtWidgets.QSizePolicy(
            QtWidgets.QSizePolicy.Minimum, QtWidgets.QSizePolicy.Minimum)
        sizePolicy.setHorizontalStretch(0)
        sizePolicy.setVerticalStretch(0)
        sizePolicy.setHeightForWidth(
            self.sendButton.sizePolicy().hasHeightForWidth())
        self.sendButton.setSizePolicy(sizePolicy)
        self.sendButton.setMinimumSize(QtCore.QSize(12, 32))
        font = QtGui.QFont()
        font.setPointSize(12)
        self.sendButton.setFont(font)
        self.sendButton.setCursor(QtGui.QCursor(QtCore.Qt.PointingHandCursor))
        self.sendButton.setMouseTracking(True)
        self.sendButton.setObjectName(""sendButton"")
        self.sendButton.clicked.connect(self.get_user_input)
        self.horizontalLayout_2.addWidget(self.sendButton)
        self.verticalLayout.addWidget(self.input_area)
        self.horizontalLayout.addWidget(self.chat_area)
        MainWindow.setCentralWidget(self.centralwidget)

        self.retranslateUi(MainWindow)
        QtCore.QMetaObject.connectSlotsByName(MainWindow)

</code></pre>

<p>In this part(function message_widget) i get an error:</p>

<blockquote>
  <p>self.widget = QtWidgets.QWidget(self.scrollAreaWidgetContents)
  AttributeError: 'Ui_MainWindow' object has no attribute 'scrollAreaWidgetContents'</p>
</blockquote>

<p>Even though i did something similar in the get_user_input function,
i know the code is a mess but the only part that is not working is this part, 
the socket server and client are both working properly, i tested printing the 
text received in the terminal, so yeah, i wanna know why do i get this error?</p>

<pre><code>    def message_widget(self):
        self.widget = QtWidgets.QWidget(self.scrollAreaWidgetContents)
        sizePolicy = QtWidgets.QSizePolicy(
            QtWidgets.QSizePolicy.Preferred, QtWidgets.QSizePolicy.Minimum)
        sizePolicy.setHeightForWidth(
            self.widget.sizePolicy().hasHeightForWidth())
        self.widget.setSizePolicy(sizePolicy)
        self.widget.setMinimumSize(QtCore.QSize(158, 25))
        self.widget.setLayoutDirection(QtCore.Qt.LeftToRight)
        self.widget.setStyleSheet(
            ""background-color: #d35439;\n"" ""border-radius: 4px;"")
        self.widget.setObjectName(""widget"")
        self.horizontalLayout_3 = QtWidgets.QHBoxLayout(self.widget)
        self.horizontalLayout_3.setObjectName(""horizontalLayout_3"")

        self.label = QtWidgets.QLabel(self.widget)
        self.label.setScaledContents(True)
        self.label.setObjectName(""label"")
        self.label.text(self.reply)
        self.horizontalLayout_3.addWidget(self.label)
        self.verticalLayout_2.addWidget(self.widget)

    def get_user_input(self):
        self.user_msg = self.userInput.text()

        threading.Thread(target=self.send_data, args=[
                         self.user_msg], daemon=True).start()

        self.widget_2 = QtWidgets.QWidget(self.scrollAreaWidgetContents)
        sizePolicy = QtWidgets.QSizePolicy(
            QtWidgets.QSizePolicy.Minimum, QtWidgets.QSizePolicy.Minimum)
        sizePolicy.setHeightForWidth(
            self.widget_2.sizePolicy().hasHeightForWidth())
        self.widget_2.setSizePolicy(sizePolicy)
        self.widget_2.setMinimumSize(QtCore.QSize(182, 25))
        self.widget_2.setLayoutDirection(QtCore.Qt.RightToLeft)
        self.widget_2.setStyleSheet(""background-color: rgb(236, 172, 55);\n""
                                    ""border-radius: 4px;"")
        self.widget_2.setObjectName(""widget_2"")
        self.horizontalLayout_4 = QtWidgets.QHBoxLayout(self.widget_2)
        self.horizontalLayout_4.setObjectName(""horizontalLayout_4"")

        self.label_2 = QtWidgets.QLabel(self.widget_2)
        self.label_2.setLayoutDirection(QtCore.Qt.RightToLeft)
        self.label_2.setAlignment(
            QtCore.Qt.AlignRight | QtCore.Qt.AlignTrailing | QtCore.Qt.AlignVCenter)
        self.label_2.setObjectName(""label_2"")
        self.label_2.setText(self.user_msg)
        self.horizontalLayout_4.addWidget(self.label_2)
        self.verticalLayout_2.addWidget(self.widget_2)
        self.userInput.setText("""")

    def retranslateUi(self, MainWindow):
        _translate = QtCore.QCoreApplication.translate
        MainWindow.setWindowTitle(_translate(""MainWindow"", ""PadoMessager""))
        self.label_3.setText(_translate(""MainWindow"", ""Server""))
        self.sendButton.setText(_translate(""MainWindow"", ""Send""))
        self.sendButton.setShortcut(_translate(""MainWindow"", ""Return""))


if __name__ == ""__main__"":
    import sys
    app = QtWidgets.QApplication(sys.argv)
    MainWindow = QtWidgets.QMainWindow()
    ui = Ui_MainWindow()
    ui.setupUi(MainWindow)
    MainWindow.show()
    sys.exit(app.exec_())
</code></pre>
"
"60475388","<blockquote>
  <p>No. But I think except Exception as e, catch all errors? Am I wrong?</p>
</blockquote>

<p>All built-in, <code>non-system-exiting</code> exceptions are derived from <code>Exception</code> class. All user-defined exceptions should also be derived from this class.</p>

<p>However, The <code>FileNotFoundError</code> exception is subclasses of <a href=""https://docs.python.org/3/library/exceptions.html#OSError"" rel=""nofollow noreferrer"">OSError</a>.</p>

<p>Try this:</p>

<pre><code>try:
    image = loadImage(filename)
except OSError as e:
   print(""Error"",e)
</code></pre>

<p>A small example code:</p>

<pre><code>try:
    image = open(""i_donot_exist"")
except OSError as e:
   print(""Exception Raised"", e)
</code></pre>

<p>Outputs:</p>

<pre><code>Exception Raised [Errno 2] No such file or directory: 'hehe'
</code></pre>

<blockquote>
  <p>Any way to catch all types of errors? Programmer defined, built-in defined and all types on earth?</p>
</blockquote>

<p>You need to put multiple <code>except</code> blocks to catch all type of exception. See an example below:</p>

<pre><code>try:
    f = open('myfile.txt')
    s = f.readline()
    i = int(s.strip())
except IOError as (errno, strerror):
    print ""I/O error({0}): {1}"".format(errno, strerror)
except ValueError:
    print ""Could not convert data to an integer.""
except:
    print ""Unexpected error:"", sys.exc_info()[0]
    raise
</code></pre>

<p>You can also catch multiple exceptions in one line. 
From <a href=""https://docs.python.org/3/tutorial/errors.html#handling-exceptions"" rel=""nofollow noreferrer"">Python Documentation</a>, An except clause may name multiple exceptions as a parenthesized tuple. See <a href=""https://stackoverflow.com/questions/6470428/catch-multiple-exceptions-in-one-line-except-block"">this</a> link for more information. For example,</p>

<pre><code>try:
    may_raise_specific_errors():
except (SpecificErrorOne, SpecificErrorTwo) as error:
    handle(error) # might log or have some other default behavior...
</code></pre>
","5","2020-03-01 13:42:44","1","7385","7807","4","901","60475216","60475388","<p>This is my short code:</p>

<pre><code>def loadImage(img_file):
    img = io.imread(img_file)           # RGB order
    if img.shape[0] == 2: img = img[0]
    if len(img.shape) == 2 : img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)
    if img.shape[2] == 4:   img = img[:,:,:3]
    img = np.array(img)

    return img
try:
    image = loadImage(filename)
except Exception as e:
   print(""Error"",e)
</code></pre>

<p>The image inside loadImage does not exist. So the error happens at this line <code>img = io.imread(img_file</code>. But Python is not catching it</p>

<p>Full error trace:</p>

<pre><code>Traceback (most recent call last):
  File ""text_ocr.py"", line 393, in processFiles
    image = loadImage(filename)
  File ""text_ocr.py"", line 129, in loadImage
    img = io.imread(img_file)           # RGB order
  File ""C:\Anaconda3\lib\site-packages\skimage\io\_io.py"", line 48, in imread
    img = call_plugin('imread', fname, plugin=plugin, **plugin_args)
  File ""C:\Anaconda3\lib\site-packages\skimage\io\manage_plugins.py"", line 210, in call_plugin
    return func(*args, **kwargs)
  File ""C:\Anaconda3\lib\site-packages\skimage\io\_plugins\imageio_plugin.py"", line 10, in imread
    return np.asarray(imageio_imread(*args, **kwargs))
  File ""C:\Anaconda3\lib\site-packages\imageio\core\functions.py"", line 264, in imread
    reader = read(uri, format, ""i"", **kwargs)
  File ""C:\Anaconda3\lib\site-packages\imageio\core\functions.py"", line 173, in get_reader
    request = Request(uri, ""r"" + mode, **kwargs)
  File ""C:\Anaconda3\lib\site-packages\imageio\core\request.py"", line 126, in __init__
    self._parse_uri(uri)
  File ""C:\Anaconda3\lib\site-packages\imageio\core\request.py"", line 278, in _parse_uri
    raise FileNotFoundError(""No such file: '%s'"" % fn)
FileNotFoundError: No such file: 'D:\Program\OCR\test_ocr\3.png'
</code></pre>
"
"60475478","<p>You can just print the whole traceback error with importing <code>tracaback</code> like this : </p>

<pre><code>import traceback
try:
    #code that might produce error
except:
    traceback.print_exc()
    pass
</code></pre>

<p>This actually doesn't catch the raised exceptions - the errors are shown in cli likewise if there were no try except block.</p>
","0","","0","6314","2100","843","1012","60475216","60475388","<p>This is my short code:</p>

<pre><code>def loadImage(img_file):
    img = io.imread(img_file)           # RGB order
    if img.shape[0] == 2: img = img[0]
    if len(img.shape) == 2 : img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)
    if img.shape[2] == 4:   img = img[:,:,:3]
    img = np.array(img)

    return img
try:
    image = loadImage(filename)
except Exception as e:
   print(""Error"",e)
</code></pre>

<p>The image inside loadImage does not exist. So the error happens at this line <code>img = io.imread(img_file</code>. But Python is not catching it</p>

<p>Full error trace:</p>

<pre><code>Traceback (most recent call last):
  File ""text_ocr.py"", line 393, in processFiles
    image = loadImage(filename)
  File ""text_ocr.py"", line 129, in loadImage
    img = io.imread(img_file)           # RGB order
  File ""C:\Anaconda3\lib\site-packages\skimage\io\_io.py"", line 48, in imread
    img = call_plugin('imread', fname, plugin=plugin, **plugin_args)
  File ""C:\Anaconda3\lib\site-packages\skimage\io\manage_plugins.py"", line 210, in call_plugin
    return func(*args, **kwargs)
  File ""C:\Anaconda3\lib\site-packages\skimage\io\_plugins\imageio_plugin.py"", line 10, in imread
    return np.asarray(imageio_imread(*args, **kwargs))
  File ""C:\Anaconda3\lib\site-packages\imageio\core\functions.py"", line 264, in imread
    reader = read(uri, format, ""i"", **kwargs)
  File ""C:\Anaconda3\lib\site-packages\imageio\core\functions.py"", line 173, in get_reader
    request = Request(uri, ""r"" + mode, **kwargs)
  File ""C:\Anaconda3\lib\site-packages\imageio\core\request.py"", line 126, in __init__
    self._parse_uri(uri)
  File ""C:\Anaconda3\lib\site-packages\imageio\core\request.py"", line 278, in _parse_uri
    raise FileNotFoundError(""No such file: '%s'"" % fn)
FileNotFoundError: No such file: 'D:\Program\OCR\test_ocr\3.png'
</code></pre>
"
"60485619","<p>I think you need to:</p>

<ul>
<li>Derive a class from <a href=""https://pyftpdlib.readthedocs.io/en/latest/api.html#pyftpdlib.filesystems.AbstractedFS"" rel=""nofollow noreferrer""><code>AbstractedFS</code></a>.</li>
<li>Reimplement its <a href=""https://pyftpdlib.readthedocs.io/en/latest/api.html#pyftpdlib.filesystems.AbstractedFS.listdir"" rel=""nofollow noreferrer""><code>listdir</code> method</a>.</li>
<li>Assign your implementation of <code>AbstractedFS</code> to <code>FTPHandler.abstracted_fs</code>.</li>
</ul>

<pre><code>class FilteredFS(AbstractedFS):
    def listdir(self, path):
        files = os.listdir(path)
        # filter as you need
        return files

handler = FTPHandler
# ...
handler.abstracted_fs = FilteredFS
server = FTPServer(('', 21), handler)
server.serve_forever()
</code></pre>
","0","2020-03-04 11:45:04","0","144036","8283","6276","21385","60475241","60485619","<p>In pyftpdlid how to filter the list of directories returned based on specific conditions, I want to hide some directories and files.I think it may be related to the 'def ftp_LIST(self, path):' method. I've tried multiple variations of this, but none of them seem to work. Any ideas?</p>
"
"60475330","<p>You can simply override the <code>get_context_data</code>. You can let the Django <code>ListView</code> handle one of the lists, and handle the other one yourself:</p>

<pre><code>class ChatOverView(ListView):
    model = Message
    <b>context_object_name = 'sent'</b>
    template_name = 'chat/home-chat.html'

    def <b>get_queryset</b>(self):
        return super().get_queryset().filter(
            sender=self.request.user
        )

    def <b>get_context_data</b>(self, *args, **kwargs):
        context = super().get_context_data(*args, **kwargs)
        context.update(
            received=Message.objects.filter(receiver=self.request.user)
        )
        return context</code></pre>
","4","","1","312807","16628","2518","41861","60475247","60475330","<p>i'm trying to sort some model-data inside a class based view by the currently logged in user. How do i do that?
I tried the following, but it didnt work:</p>

<pre><code>class ChatOverView(ListView):
    def get_queryset(self):
        return [Message.objects.filter(sender=self.request.user),
                Message.objects.filter(receiver=self.request.user)]

    model = {""received"": get_queryset()[0], ""sent"": get_queryset()[1]}
    template_name = ""chat/home-chat.html""
</code></pre>

<p>Im getting the following error message: <code>TypeError: get_queryset() missing 1 required positional argument: 'self'</code></p>

<p>Thanks for Your Help!</p>

<p><strong>Edit</strong>
I am aiming to implement a chat-system on my website. In order to do that, i set up a database which stores all sent messages. Each entry contains a ""sender"" and a ""receiver"" field.
With Help of this View i want to display all messages the currently logged in user received or sent.</p>
"
"60475292","<p><code>n in val</code> checks whether the value <code>n</code> is in the iterable <code>val</code>. The correct check here is <code>n == val</code></p>
","0","","1","188","57","14","18","60475249","60475292","<p>i want to detect when the program sees the value 26, i have a function that looks like this</p>

<pre><code>val = 26
for n in range (0,101):
    if n in val:
        print(n,""is the value i am looking for"")
        break
    else:
        print(n)
</code></pre>

<p>I keep getting this error:</p>

<pre><code>TypeError: argument of type 'int' is not iterable
</code></pre>

<p>What is wrong with this function</p>
"
"60475584","<p>You can use a GUI automation package like pyautogui. Explanation in code comments.</p>

<pre><code>import pyautogui
import time

# To simulate a Save As dialog. You can remove this since you'll be saving/downloading a file from a link
pyautogui.hotkey('ctrl', 's')
# Wait for the Save As dialog to load. Might need to increase the wait time on slower machines
time.sleep(1)
# File path + name
FILE_NAME = 'C:\\path\\to\\file\\file.ext'
# Type the file path and name is Save AS dialog
pyautogui.typewrite(FILE_NAME)
#Hit Enter to save
pyautogui.hotkey('enter')
</code></pre>
","3","","4","1541","222","23","129","60475367","60475584","<p>So i'm using Selenium with Python to navigate through a website, and to click a button that opens a ""Save as"" window. How can i control that window ? I need to send a path first where the file should be saved and also to modify the name of the file, then to click ""Save"".</p>

<p>I think i cannot do this using Selenium because the ""Save as"" window that opens it is a system dialog window.</p>

<p>What tool or Python script should i use instead to accomplish what i need to do ?
How to control a system dialog window using Python ?</p>
"
"60544899","<p>Solved it by editing the .jason file and providing the right path to the environment executable.</p>
","0","","1","168","43","2","28","60475373","60544899","<p>I have anaconda base environment and 1 other environment where i have tensorflow installed which i am trying to import in my jupyter notebook after changing the kernel.</p>

<p>i installed jupyter notebook in my conda base environment using the following command:</p>

<p><code>conda install -c conda-forge jupyterhub</code>
and by simply doing:
<code>pip install jupyter</code></p>

<p>after that i added my new environment with tensorflow and some other additional packages with this command:
<code>python -m ipykernel install --user --name env_cod --display-name ""Python (env_cod)""</code></p>

<p>So now i launch jupyter notebook by simple (jupyter-notebook) in the desired directory and i also tried launching jupyter-notebook after activating the env_cod environment from terminal. But still i am not able to import tensorflow in my jupyter notebook after changing the kernal by selecting from the kernel tab also when i create new jupyter notebook by selecting env_cod environment i am not able to import tensorflow and get this error : 
<code>no module named tensorflow</code></p>

<p>I already tried uninstalling and installing jupyter in my both base and env_cod environment.</p>

<p>Also there is nothing wrong with my env_cod environment and tensorflow is working perfectly fine along with other packages when i run my scripts through PyCharm after selecting env_cod environment. The Problem is Only with Jupyter Notebook.</p>
"
"60475432","<p>Try this:</p>

<pre><code>def outside_variable_show(status):
    global crrnt_nmbr
    if status == 1:
        crrnt_nmbr = crrnt_nmbr + 1
        print (crrnt_nmbr)

status = 1
crrnt_nmbr = 0
print (crrnt_nmbr)
outside_variable_show(1)
</code></pre>
","0","","0","484","430","29","54","60475398","60475432","<p>I just create the function (Python) and want to use the variable that was defined outside the function and an error has occurred</p>

<pre><code>def outside_variable_show(status):
    if status == 1:
        crrnt_nmbr = crrnt_nmbr + 1
        print (crrnt_nmbr)

status = 1
crrnt_nmbr = 0
print (crrnt_nmbr)
outside_variable_show(1)
</code></pre>

<p>note: ""crrnt_nmbr"" must use in and outside the function.</p>

<p>please tell me the way to implementation with it. Thank you so much.</p>
"
"60497203","<p>1) RS232 is a combination of UART with certain voltage levels for the high and low (i.e. +3 to +15V and -3 to -15V afaik. Never ever connect a RS232 adapter to standard 3.3V  or 5V devices e.g. UART, TTL-UART etc. The Lattice Semiconductor document just plainly missuses the term RS232 - try not to fall for it (IMHO the performance of their products strongly anticorrelates with the quality of their documentation and support). </p>

<p>2) page 19 of the linked doc shows the sections: Ordering Information, Technical Support Assistance, Revision History. Shifted by one page?</p>

<p>3) The FT2232H can be used in multiple modes. This depends on the way how it is addressed and of the settings flashed to the EEPROM connected to it (on the dev board is one placed but the FT2232H can be used without as well). The dev board is in the standard configuration designed to be programmed via the JTAG pins and the FT2232H is opened via the D2XX driver by lattice diamond. For that reason they flashed the EEPROM with settings which prohibits the use as virtual com port. The FTDI flash software can be used to change that behavior - for each bank seperately.</p>

<p>4) The solder bridges can be used to rearrange the connections (e.g. if one wants to change from the JTAG interface to the SPI or I2C programming interface). In your case you most likely want to place bridges on R14 and R15 to make the proper connection for an UART link to the port B of the FT2232H. EDIT: <em>This way Port A can be used in JTAG mode to program the FT2232H and port B to communicate via e.g. UART or even other modes like the fast opto or the parallel bus/FIFO - if the correct bridges are soldered. Changing the EEPROM settings might be still required to make Port B visible as VCP if one want to avoid the usage of the D2XXX driver</em>.</p>
","4","2020-03-04 07:36:41","1","578","7","2","76","60475411","60497203","<p>first sorry if this is a simple question but I can't figure this out. I have this <a href=""http://www.latticesemi.com/en/Products/DevelopmentBoardsAndKits/MachXO3LStarterKit.aspx"" rel=""nofollow noreferrer"">development board</a> and on page 19 on the kits <a href=""http://www.latticesemi.com/view_document?document_id=50873"" rel=""nofollow noreferrer"">user guide</a> the block diagram shows a RS232 line and on page 20 and 22 the schematic show the pins I need to connect to use RS232. My problem is that, despite being able to configure the fpga/cpld, I cannot find the com port on my computer (using pyserial and the following <a href=""https://stackoverflow.com/questions/12090503/listing-available-com-ports-with-python"">code</a>(I tried changing COM%s in line 15 to FTUSB-%s)). So my questions are: </p>

<p>What interface does the FTDI, ft2232h USB to UART/FIFO,  chip use (Serial, parallel... ) on the computer's end (like arduino's virtual COM port)?</p>

<p>On lattice's software there are 3 options to program the device. the program shows the following: HW-USBN-2b (FTDI) (with port as FTUSB-0), HW-USBN-2b (with port as ezUSB-0) and HW-DLN-3C. How can I use either of them to communicate with the device outside of Lattice's software?</p>

<p>thanks for you time.</p>
"
"60479016","<p>Two issues.</p>

<ul>
<li>The CommCtrl.h header uses a 1-byte packing.  Add <code>_pack_ = 1</code> before <code>_fields_</code> definition in all structures.</li>
<li>The two <code>_TASKDIALOG_BUTTON</code> fields should be type <code>ctypes.POINTER(_TASKDIALOG_BUTTON)</code>.</li>
</ul>

<p>I tracked these down by using a C program to print the size of the structure and the offsets of a few fields and printed the same info in Python:</p>

<pre><code>#include &lt;windows.h&gt;
#include &lt;commctrl.h&gt;
#include &lt;stdio.h&gt;
#include &lt;stdlib.h&gt;

int main()
{
    printf(""%zu\n"",sizeof(TASKDIALOGCONFIG));
    printf(""%zu\n"",offsetof(TASKDIALOGCONFIG,pszWindowTitle));
    printf(""%zu\n"",offsetof(TASKDIALOGCONFIG,pszMainInstruction));
    printf(""%zu\n"",offsetof(TASKDIALOGCONFIG,pszFooter));
}
</code></pre>

<pre><code>tdc = TaskDialogConfig()
print(tdc.cbSize)
print(TaskDialogConfig.pszWindowTitle)
print(TaskDialogConfig.pszMainInstruction)
print(TaskDialogConfig.pszFooter)
</code></pre>
","1","","2","130384","1343","1379","5540","60475469","60479016","<p>I want to call Windows <a href=""https://docs.microsoft.com/en-us/windows/win32/api/commctrl/nf-commctrl-taskdialogindirect"" rel=""nofollow noreferrer"">TaskDialogIndirect</a> function from Python.
It needs <a href=""https://docs.microsoft.com/ru-ru/windows/win32/api/commctrl/ns-commctrl-taskdialogconfig"" rel=""nofollow noreferrer"">TaskDialogConfig</a> (it's pretty big) structure to be passed as a pointer.</p>

<p>Here is my ready to run example. It gives me ""-2147024809"" (The parameter is incorrect) and I can't figure out what is wrong.</p>

<p>Python 3.7.4 x32, Windows 7 x64</p>

<pre><code>import ctypes
from ctypes.wintypes import *

TDF_ALLOW_DIALOG_CANCELLATION = 8
TDCBF_OK_BUTTON = 1

class TaskDialogConfig(ctypes.Structure):
    class DUMMYUNIONNAME(ctypes.Union):
        _fields_ = [
            ('hMainIcon', HICON)
            , ('pszMainIcon', LPCWSTR)
        ]

    class DUMMYUNIONNAME2(ctypes.Union):
        _fields_ = [
            ('hFooterIcon', HICON)
            , ('sFooterIcon', LPCWSTR)
        ]

    class _TASKDIALOG_BUTTON(ctypes.Structure):
        _fields_ = [
            ('nButtonID', INT)
            , ('pszButtonText', LPCWSTR)
        ]

    _fields_ = [
        ('cbSize', UINT)
        , ('hwndParent', HWND)
        , ('hInstance', HINSTANCE)
        , ('dwFlags', UINT)
        , ('dwCommonButtons', UINT)
        , ('pszWindowTitle', LPCWSTR)
        , ('DUMMYUNIONNAME', DUMMYUNIONNAME)
        , ('pszMainInstruction', LPCWSTR)
        , ('pszContent', LPCWSTR)
        , ('cButtons', UINT)
        , ('pButtons', _TASKDIALOG_BUTTON)
        , ('nDefaultButton', INT)
        , ('cRadioButtons', UINT)
        , ('pRadioButtons', _TASKDIALOG_BUTTON)
        , ('nDefaultRadioButton', INT)
        , ('pszVerificationText', LPCWSTR)
        , ('pszExpandedInformation', LPCWSTR)
        , ('pszExpandedControlText', LPCWSTR)
        , ('pszCollapsedControlText', LPCWSTR)
        , ('DUMMYUNIONNAME2', DUMMYUNIONNAME2)
        , ('pszFooter', LPCWSTR)
        , ('pfCallBack', ctypes.POINTER(None))
        , ('lpCallbackData', LPLONG)
        , ('cxWidth', UINT)
    ]

    def __init__(s):
        s.cbSize = ctypes.sizeof(s)

tdi = ctypes.WinDLL('comctl32.dll').TaskDialogIndirect
tdc = TaskDialogConfig()
tdc.hwndParent = None
tdc.hInstance = None
tdc.dwFlags = TDF_ALLOW_DIALOG_CANCELLATION
tdc.dwCommonButtons = TDCBF_OK_BUTTON
tdc.pszWindowTitle = ctypes.c_wchar_p('Title')
tdc.pszMainInstruction = ctypes.c_wchar_p('Main instruction')
tdc.pszContent = ctypes.c_wchar_p('Content')
print( tdi(ctypes.byref(tdc), None, None, None) )
</code></pre>
"
"60475664","<p>You can use <code>requests</code> to download files and <code>apply</code> to apply a function to each row of the dataframe:</p>

<pre><code>import os
import requests


def download(row):
   filename = os.path.join(root_folder,
                           '_'.join([row['Color'],
                                     row['Gender'],
                                     row['Model']],
                           str(row.name) + im_extension)

   # create folder if it doesn't exist
   os.makedirs(os.path.dirname(filename), exist_ok=True)

   url = row.link
   print(f""Downloading {url} to {filename}"")
   r = requests.get(url, allow_redirects=True)
   with open(filename, 'wb') as f:
       f.write(r.content)

root_folder = '/path/to/download/folder'
im_extension = '.jpg'  # or whatever type of images you are downloading

df.apply(download, axis=1)
</code></pre>
","0","2020-03-02 09:06:37","1","1630","315","21","115","60475568","60475664","<p>I am pretty new in python and coding;</p>

<p>I have a dataframe looks like below;</p>

<pre><code>Color    Gender    Model        link
Black    Man       Sneakers     https://....
Black    Man       Boots        https://....
White    Woman     Sneakers     https://....
Brown    Woman     Sneakers     https://....
Black    Man       Sneakers     https://....
White    Woman     Boots        https://....
</code></pre>

<p>I want to download those image links and save them in a directory which based on color-gender-model combination.</p>

<p>In the end I need Black_Man_Sneakers folder and all related images(for this example first and sixth links) should be in that folder.</p>

<p>How should I start? any comment would be helpful</p>

<p>Thanks a lot</p>
"
"60477554","<blockquote>
  <p><strong>Question</strong>: first I will select that rectangle with ""Button 1"" and then I will right-click and delete</p>
</blockquote>

<ol>
<li>Create the rectangles ...</li>
</ol>

<pre><code>        canvas.create_rectangle(75, 75, 100, 100, tags=""DnD"")
        canvas.create_rectangle(100, 100, 125, 125, tags=""DnD"")
</code></pre>

<ol start=""2"">
<li>Bind event <code>""&lt;ButtonPress-1&gt;""</code> to the <code>Canvas</code>  </li>
</ol>

<pre><code>        canvas.bind(""&lt;ButtonPress-1&gt;"", self.on_button_1)
</code></pre>

<ol start=""3"">
<li>Prepare the <code>popup</code>, to delete <code>items</code> with <code>tag='DELETE'</code></li>
</ol>

<pre><code>        self.popup.add_command(label=""delete"", 
                               command=lambda: canvas.delete(canvas.find_withtag('DELETE')))
</code></pre>

<ol start=""4"">
<li>Define the event <code>""&lt;ButtonPress-1&gt;""</code> callback.<br>
Here, the matching item get added <code>tags='DELETE'</code> and outlined <code>'red'</code>.</li>
</ol>

<pre><code>    def on_button_1(self, event):
        iid = canvas.find_enclosed(event.x - 26, event.y - 26, event.x + 26, event.y + 26)
        canvas.itemconfigure(iid, tags='DELETE', outline='red')
</code></pre>
","0","","0","13198","207","7779","3141","60475640","60477554","<p>I'm creating two rectangles. I want to delete rectangles from the canvas by right-clicking. The code is able to delete only 1 rectangle but not the other one. I used tag_bind(""Button1"") function but only bottom one is getting deleted.
Tag_bind function should be able to get the id and delete any of the selected rectangles but it is not happening.</p>

<pre><code>    #import sys, os, string, time
import tkinter
tk = tkinter
root =tk.Tk()
root.title (""Drag-N-Drop Demo"")
# A Python example of drag and drop functionality within a single Tk widget.
# The trick is in the bindings and event handler functions.
# Tom Vrankar twv at ici.net


canvas =tk.Canvas ( width =256, height =256,
      relief =tk.RIDGE, background =""white"", borderwidth =1)
class CanvasDnD (tk.Frame):



  def __init__ (self, master):
    self.master =master
    self.loc =self.dragged =0
    tk.Frame.__init__ (self, master)
    id=canvas.create_rectangle(75,75,100,100,tags=""DnD"")
    canvas.tag_bind(id,""&lt;ButtonPress-1&gt;"")
    id=canvas.create_rectangle(100,100,125,125,tags=""DnD"")
    canvas.tag_bind(id,""&lt;ButtonPress-1&gt;"")
    canvas.pack (expand =1, fill =tk.BOTH)
    canvas.tag_bind (""DnD"", ""&lt;ButtonPress-1&gt;"", self.down)
    canvas.tag_bind (""DnD"", ""&lt;ButtonRelease-1&gt;"", self.chkup)
    canvas.tag_bind (""DnD"", ""&lt;Enter&gt;"", self.enter)
    canvas.tag_bind (""DnD"", ""&lt;Leave&gt;"", self.leave)
    self.popup = tk.Menu(root, tearoff=0)
    self.popup.add_command(label=""delete"",command=lambda: self.dele(id))
    root.bind(""&lt;Button-3&gt;"", self.do_popup)

  def do_popup(self,event):
      # display the popup menu
    try:
      self.popup.tk_popup(event.x_root, event.y_root, 0)
    finally:
          # make sure to release the grab (Tk 8.0a1 only)
      self.popup.grab_release()  
  # empirical events between dropee and target, as determined from Tk 8.0
  # down.
  # leave.
  # up, leave, enter.



  def down (self, event):
    #print (""Click on %s"" %event.widget.itemcget (tk.CURRENT, ""text""))
    self.loc =1
    self.dragged =0
    event.widget.bind (""&lt;Motion&gt;"", self.motion)

  def motion (self, event):
    root.config (cursor =""exchange"")
    cnv = event.widget
    cnv.itemconfigure (tk.CURRENT, fill =""blue"")
    x,y = cnv.canvasx(event.x), cnv.canvasy(event.y)
    a,b = cnv.canvasx(event.x + 25), cnv.canvasy(event.y+25)
    got = event.widget.coords (tk.CURRENT, x, y, a, b)

  def leave (self, event):
    self.loc =0

  def enter (self, event):
    self.loc =1
    if self.dragged ==event.time:
      self.up (event)

  def chkup (self, event):
    event.widget.unbind (""&lt;Motion&gt;"")
    root.config (cursor ="""")
    self.target =event.widget.find_withtag (tk.CURRENT)
    #event.widget.itemconfigure (tk.CURRENT, fill =self.defaultcolor)
    if self.loc: # is button released in same widget as pressed?
      self.up (event)
    else:
      self.dragged =event.time

  def up (self, event):
    event.widget.unbind (""&lt;Motion&gt;"")
    if (self.target ==event.widget.find_withtag (tk.CURRENT)):
      print(""1"")
     # print (""Select %s"" %event.widget.itemcget (tk.CURRENT, ""text""))
    else:
      event.widget.itemconfigure (tk.CURRENT, fill =""blue"")
      self.master.update()
      time.sleep (.1)
      print (""%s Drag-N-Dropped onto %s"" \
        %(event.widget.itemcget (self.target, ""text"")),
   event.widget.itemcget (tk.CURRENT, ""text""))
      event.widget.itemconfigure (tk.CURRENT, fill =self.defaultcolor)

  def dele(self,id):
    canvas.delete(id)

CanvasDnD (root).pack()
root.mainloop()
</code></pre>
"
"60476002","<p>You can do this with <a href=""https://docs.python.org/3/library/re.html"" rel=""nofollow noreferrer""><code>re</code></a> regular expression module:</p>

<pre><code>import re

#assume that resp is response from API
resp = ""NetRange: 185.0.0.0 - 185.255.255.255 CIDR: 185.0.0.0/8 NetName: RIPE-185 NetHandle: NET-185-0-0-0-1 Parent: () NetType: Allocated to RIPE NCC OriginAS: Organization: RIPE Network Coordination Centre (RIPE) RegDate: 2011-01-04 Updated: 2011-02-08 Comment: These addresses have been further assigned to users in Comment: the RIPE NCC region. Contact information can be found in Comment: the RIPE database at http://www.ripe.net/whois Ref: https://rdap.arin.net/registry/ip/185.0.0.0 ResourceLink: https://apps.db.ripe.net/search/query.html ResourceLink: whois.ripe.net OrgName: RIPE Network Coordination Centre OrgId: RIPE Address: P.O. Box 10096 City: Amsterdam StateProv: PostalCode: 1001EB Country: NL RegDate: Updated: 2013-07-29 Ref: https://rdap.arin.net/registry/entity/RIPE ReferralServe ""

regex = r""OrgName:\s(.+?)\sOrgId""
orgName = re.findall(regex, resp)[0]
print(orgName) #RIPE Network Coordination Centre
</code></pre>
","0","","0","618","176","3","64","60475655","60476002","<p>The response I receive from api is in the below format:</p>

<pre><code>""NetRange: 185.0.0.0 - 185.255.255.255 CIDR: 185.0.0.0/8 NetName: RIPE-185 NetHandle: NET-185-0-0-0-1 Parent: () NetType: Allocated to RIPE NCC OriginAS: Organization: RIPE Network Coordination Centre (RIPE) RegDate: 2011-01-04 Updated: 2011-02-08 Comment: These addresses have been further assigned to users in Comment: the RIPE NCC region. Contact information can be found in Comment: the RIPE database at http://www.ripe.net/whois Ref: https://rdap.arin.net/registry/ip/185.0.0.0 ResourceLink: https://apps.db.ripe.net/search/query.html ResourceLink: whois.ripe.net **OrgName: RIPE Network Coordination Centre** OrgId: RIPE Address: P.O. Box 10096 City: Amsterdam StateProv: PostalCode: 1001EB Country: NL RegDate: Updated: 2013-07-29 Ref: https://rdap.arin.net/registry/entity/RIPE ReferralServe ""
</code></pre>

<p>But I only need the value pair as highlighted. How exactly the formatting should be done for the same in python?
I'm using python 3.</p>
"
"60476379","<p>This is a simple parser of the data you are getting:</p>

<pre><code>def parse_reply(data):
    tmp = []
    result = {}
    kvdata = data.split()
    key = kvdata[0]
    for e in kvdata[1:]:
        if e.endswith(':'):
            result[key] = "" "".join(tmp)
            key = e[:-1]
            tmp.clear()
        else:
            tmp.append(e)
    return result


rep = parse_reply(data)
print(rep['OrgName'])

</code></pre>
","0","","0","1174","59","8","101","60475655","60476002","<p>The response I receive from api is in the below format:</p>

<pre><code>""NetRange: 185.0.0.0 - 185.255.255.255 CIDR: 185.0.0.0/8 NetName: RIPE-185 NetHandle: NET-185-0-0-0-1 Parent: () NetType: Allocated to RIPE NCC OriginAS: Organization: RIPE Network Coordination Centre (RIPE) RegDate: 2011-01-04 Updated: 2011-02-08 Comment: These addresses have been further assigned to users in Comment: the RIPE NCC region. Contact information can be found in Comment: the RIPE database at http://www.ripe.net/whois Ref: https://rdap.arin.net/registry/ip/185.0.0.0 ResourceLink: https://apps.db.ripe.net/search/query.html ResourceLink: whois.ripe.net **OrgName: RIPE Network Coordination Centre** OrgId: RIPE Address: P.O. Box 10096 City: Amsterdam StateProv: PostalCode: 1001EB Country: NL RegDate: Updated: 2013-07-29 Ref: https://rdap.arin.net/registry/entity/RIPE ReferralServe ""
</code></pre>

<p>But I only need the value pair as highlighted. How exactly the formatting should be done for the same in python?
I'm using python 3.</p>
"
"60475733","<p>In the dockerfile add:</p>

<pre><code>ADD /path/to/local/file /path/inside/docker
</code></pre>

<p>or </p>

<pre><code>COPY /path/to/local/file /path/inside/docker
</code></pre>
","0","","1","1630","315","21","115","60475682","60475733","<p>I need to copy a file from local to Dockerfile. I need to copy a python file from local to inside of a docker image to run a pyspark application. </p>

<p>Docker is placed in </p>

<p>mkdir -p /root/temp/dockerTest/
cd /root/temp/dockerTest/</p>

<p>DockerFile content's</p>

<pre><code>FROM ubuntu:latest
RUN apt-get update
RUN apt-get install -y openjdk-8-jdk
RUN apt-get update
RUN apt-get install git -y
RUN apt-get update
RUN apt-get install wget -y
RUN mkdir -p /usr/soft/bin/temp/
RUN cd /usr/soft/bin/temp/
RUN wget ""https://downloads.apache.org/spark/spark-2.4.5/spark-2.4.5-bin-hadoop2.7.tgz""
RUN tar -xzvf spark-2.4.5-bin-hadoop2.7.tgz
RUN rm -r spark-2.4.5-bin-hadoop2.7.tgz
RUN mkdir -p /usr/inputFiles/
RUN cd /usr/inputFiles/
RUN wget ""https://introcs.cs.princeton.edu/java/data/sdss6949386.csv"" 
RUN apt-get install -y python3-pip python3-dev
RUN apt-get update
RUN pip3 install --upgrade pip
RUN cd /usr/local/bin
RUN ln -s /usr/bin/python3 python
RUN pip install pyspark
RUN mkdir -p /usr/soft/inputFilesConatiner 
CMD cp /usr/soft/inputFilesConatiner/test.py /usr/soft/bin/temp/spark-2.4.5-bin-hadoop2.7/bin/test.py
CMD /usr/soft/bin/temp/spark-2.4.5-bin-hadoop2.7/bin/spark-submit --num-executors 1 --executor-cores 2 --executor-memory 1g --driver-cores 1 --driver-memory 1g test.py
</code></pre>

<p>Docker is built by :</p>

<p>cd /root/temp/</p>

<p>docker build dockerTest</p>

<pre><code>CMD cp /usr/soft/inputFilesConatiner/test.py /usr/soft/bin/temp/spark-2.4.5-bin-hadoop2.7/bin/test.py
</code></pre>

<p>docker run -t -i (id) </p>

<p>it throw's error.</p>

<p>I need to copy the file from local to dockerImage or session.</p>

<p>Can you folks help we with this?</p>
"
"60476147","<p>After some additional searching I found out that the logging level that is set for the handler is separate from the level that is set for the logger.</p>

<p>meaning, that adding:</p>

<pre><code>logger.setLevel(logging.INFO)
</code></pre>

<p>fixes the problem.</p>
","0","","0","2672","151","11","191","60475707","60476147","<p>I want to create a custom python logging <code>Handler</code> to send messages via slack.</p>

<p>I found this <a href=""https://github.com/mathiasose/slacker_log_handler"" rel=""nofollow noreferrer"">package</a> however its no longer being updated so i created a very bare bone version of it. however it doesnt seem to work, I added a <code>print</code> call for debugging purposes and <code>emit</code> is not being evoked. </p>

<pre><code>import logging
# import slacker

class SlackerLogHandler(logging.Handler):
    def __init__(self, api_key, channel):
        super().__init__()
        self.channel = channel
        # self.slacker = slacker.Slacker(api_key)

    def emit(self, record):
        message = self.format(record)
        print('works')
        # self.slacker.chat.post_message(text=message, channel=self.channel)

slack_handler = SlackerLogHandler('token', 'channel')
slack_handler.setLevel(logging.INFO)
formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
slack_handler.setFormatter(formatter)

logger = logging.getLogger('my_app')
logger.addHandler(slack_handler)
logger.info('info_try')  # 'works' is not printed and no slack message is sent
</code></pre>

<hr>

<p>I saw this <a href=""https://stackoverflow.com/questions/3118059/how-to-write-custom-python-logging-handler"">answer</a> and tried to also inherit from <code>StreamHandler</code> but to no avail.</p>

<p>I think I am missing something very basic.</p>

<p>edited to remove slack logic for ease of reproduction.</p>
"
"60475862","<p>you can find the line that has 5 fields by doing:</p>

<pre><code>with open(csv_file, 'r') as f:
   for i, l in f.readlines():
       if len(l.split(',') &gt; 4:
           print(i)
</code></pre>

<p>then open the file with an editor and correct it</p>
","0","","2","1630","315","21","115","60475772","60475862","<p>I'm trying to import a .csv file in Python using pandas but the output is an error code.</p>

<p>It's my very beginning with python and also with pandas, i started with a good tutorial on youtube where the test data was also an .csv file and with this file my code works. </p>

<p>The file wich i want to use is a .csv file but it has already seperated columns, the test data file didn't have seperate columns and the data is seperated with "","".</p>

<p>So does anyone have a suggestion to solve my problem?</p>

<pre><code>import pandas as pd
df = pd.read_csv(""feedPreview.csv"")
print(df)
</code></pre>

<p><strong>Output:</strong></p>

<pre><code>ParserError                               Traceback (most recent call last)
&lt;ipython-input-2-09462199d5bd&gt; in &lt;module&gt;
      1 import pandas as pd
      2 
----&gt; 3 df = pd.read_csv(""feedPreview.csv"")
      4 
      5 print(df)

~\Anaconda3\lib\site-packages\pandas\io\parsers.py in parser_f(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)
    683         )
    684 
--&gt; 685         return _read(filepath_or_buffer, kwds)
    686 
    687     parser_f.__name__ = name

~\Anaconda3\lib\site-packages\pandas\io\parsers.py in _read(filepath_or_buffer, kwds)
    461 
    462     try:
--&gt; 463         data = parser.read(nrows)
    464     finally:
    465         parser.close()

~\Anaconda3\lib\site-packages\pandas\io\parsers.py in read(self, nrows)
   1152     def read(self, nrows=None):
   1153         nrows = _validate_integer(""nrows"", nrows)
-&gt; 1154         ret = self._engine.read(nrows)
   1155 
   1156         # May alter columns / col_dict

~\Anaconda3\lib\site-packages\pandas\io\parsers.py in read(self, nrows)
   2057     def read(self, nrows=None):
   2058         try:
-&gt; 2059             data = self._reader.read(nrows)
   2060         except StopIteration:
   2061             if self._first_chunk:

pandas\_libs\parsers.pyx in pandas._libs.parsers.TextReader.read()

pandas\_libs\parsers.pyx in pandas._libs.parsers.TextReader._read_low_memory()

pandas\_libs\parsers.pyx in pandas._libs.parsers.TextReader._read_rows()

pandas\_libs\parsers.pyx in pandas._libs.parsers.TextReader._tokenize_rows()

pandas\_libs\parsers.pyx in pandas._libs.parsers.raise_parser_error()

ParserError: Error tokenizing data. C error: Expected 4 fields in line 33, saw 5
</code></pre>
"
"60475982","<p>It's hard to say for sure without seeing the data, but it seems that the line 33 of your file has 5 fields instead of 4. If you think you can import the data without this line (and other lines that may have the same problem), you can try this:</p>

<pre><code> df = pd.read_csv('feedPreview.csv', error_bad_lines=False)
</code></pre>

<p>As said in pandas documentation <a href=""https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html"" rel=""nofollow noreferrer"">here</a>:</p>

<p>""Lines with too many fields (e.g. a csv line with too many commas) will by default cause an exception to be raised, and no DataFrame will be returned. If False, then these â€œbad linesâ€ will dropped from the DataFrame that is returned.""</p>
","0","","1","303","301","1","70","60475772","60475862","<p>I'm trying to import a .csv file in Python using pandas but the output is an error code.</p>

<p>It's my very beginning with python and also with pandas, i started with a good tutorial on youtube where the test data was also an .csv file and with this file my code works. </p>

<p>The file wich i want to use is a .csv file but it has already seperated columns, the test data file didn't have seperate columns and the data is seperated with "","".</p>

<p>So does anyone have a suggestion to solve my problem?</p>

<pre><code>import pandas as pd
df = pd.read_csv(""feedPreview.csv"")
print(df)
</code></pre>

<p><strong>Output:</strong></p>

<pre><code>ParserError                               Traceback (most recent call last)
&lt;ipython-input-2-09462199d5bd&gt; in &lt;module&gt;
      1 import pandas as pd
      2 
----&gt; 3 df = pd.read_csv(""feedPreview.csv"")
      4 
      5 print(df)

~\Anaconda3\lib\site-packages\pandas\io\parsers.py in parser_f(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)
    683         )
    684 
--&gt; 685         return _read(filepath_or_buffer, kwds)
    686 
    687     parser_f.__name__ = name

~\Anaconda3\lib\site-packages\pandas\io\parsers.py in _read(filepath_or_buffer, kwds)
    461 
    462     try:
--&gt; 463         data = parser.read(nrows)
    464     finally:
    465         parser.close()

~\Anaconda3\lib\site-packages\pandas\io\parsers.py in read(self, nrows)
   1152     def read(self, nrows=None):
   1153         nrows = _validate_integer(""nrows"", nrows)
-&gt; 1154         ret = self._engine.read(nrows)
   1155 
   1156         # May alter columns / col_dict

~\Anaconda3\lib\site-packages\pandas\io\parsers.py in read(self, nrows)
   2057     def read(self, nrows=None):
   2058         try:
-&gt; 2059             data = self._reader.read(nrows)
   2060         except StopIteration:
   2061             if self._first_chunk:

pandas\_libs\parsers.pyx in pandas._libs.parsers.TextReader.read()

pandas\_libs\parsers.pyx in pandas._libs.parsers.TextReader._read_low_memory()

pandas\_libs\parsers.pyx in pandas._libs.parsers.TextReader._read_rows()

pandas\_libs\parsers.pyx in pandas._libs.parsers.TextReader._tokenize_rows()

pandas\_libs\parsers.pyx in pandas._libs.parsers.raise_parser_error()

ParserError: Error tokenizing data. C error: Expected 4 fields in line 33, saw 5
</code></pre>
"
"60475876","<p>Use <a href=""http://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.str.extract.html"" rel=""nofollow noreferrer""><code>Series.str.extract</code></a> with escape <code>\.</code> because special regex character, then remove possible missing values if no match by <a href=""http://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.dropna.html"" rel=""nofollow noreferrer""><code>Series.dropna</code></a> and last convert output to list:</p>

<pre><code>df = pd.DataFrame({'a':range(3)}, index=['point.subclase.optimum.R31.done',
                                         'point.subclase',
                                         'point.subclase.optimum.R98.done'])
print (df)
                                 a
point.subclase.optimum.R31.done  0
point.subclase                   1
point.subclase.optimum.R98.done  2

L = (df.index.str.extract(r'point\.subclase\.optimum\.(.*)\.done', expand=False)
             .dropna()
             .tolist())
print (L)
['R31', 'R98']
</code></pre>
","1","","1","615041","23439","1483","126104","60475845","60475876","<p>I have a dataframe with some text indexes which contains a necessary information that I want to copy into a list.</p>

<p>I don't know how is the text info specifically (the word always changes), but I know where is located in the index:</p>

<p><em>'point.subclase.optimum.<strong>R31</strong>.done'</em>. R31 is the value which I would like to write in a list, so I know that that text, that is always different, is between <strong><em>point.subclase.optimum.</em></strong> and <strong><em>.done</em></strong>.</p>

<p>I've tried with:</p>

<pre><code>info_list = []
for col in df.columns:
    if ('point.subclase.optimum.' in col) and ('.done' in col):
        info_list.append(col)
</code></pre>

<p>But that script just provide me the entire index in the list.</p>

<p>Does anyone know how to solve it?</p>
"
"60476065","<p>25th percentile is ""bottom fourth out of those who took the thing"", and 75th percentile is ""top fourth"", regardless of the actual score. So what you need to do is sort the list, then take a slice out of the middle, based on the index.</p>

<p>Here's what I think you're trying to do:</p>

<pre><code>import math

students = ['student1','student2','student3','student4','student5','student6','student7','student8','student9','student10']
marks = [45, 78, 12, 14, 48, 43, 45, 98, 35, 80]

# zip() will bind together corresponding elements of students and marks
# e.g. [('student1', 45), ('student2', 78), ...]
grades = list(zip(students, marks))

# once that's all in one list of 2-tuples, sort it by calling .sort() or using sorted()
# give it a ""key"", which specifies what criteria it should sort on
# in this case, it should sort on the mark, so the second element (index 1) of the tuple
grades.sort(key=lambda e:e[1])
# [('student3', 12), ('student4', 14), ('student9', 35), ('student6', 43), ('student1', 45), ('student7', 45), ('student5', 48), ('student2', 78), ('student10', 80), ('student8', 98)]

# now, just slice out the 25th and 75th percentile based on the length of that list
twentyfifth = math.ceil(len(grades) / 4)
seventyfifth = math.floor(3 * len(grades) / 4)
middle = grades[twentyfifth : seventyfifth]

print(middle)
# [('student6', 43), ('student1', 45), ('student7', 45), ('student5', 48)]
</code></pre>

<p>You have 10 students here, so how you round <code>twentyfifth</code> and <code>seventyfifth</code> is up to you (I chose to include those strictly those within 25-75th percentile, by rounding 'inwards' - you could do the opposite by switching <code>ceil</code> and <code>floor</code>, and get your final list to have two more elements in this case - or you could round them both the same way).</p>
","1","","0","18009","875","52","1348","60475885","60476151","<p>Consider the marks list of class students given in two lists</p>

<pre><code>Students = ['student1','student2','student3','student4','student5','student6','student7','student8','student9','student10']
Marks = [45, 78, 12, 14, 48, 43, 45, 98, 35, 80]
</code></pre>

<p>from the above two lists the Student[0] got Marks[0], Student[1] got Marks[1] and so on
Who got marks between >25th percentile &lt;75th percentile, in the increasing order of marks </p>

<p>My question - 
Can't we use simple code in python to solve this problem..?</p>

<p>I have written code till this. To find the numbers >25 and &lt;75 but unable to make it in ascending order. Sort() is not working and sorted is also not working. Please help how to extract the particular array values and assign to another array to solve this problem.</p>

<pre><code>for i in range(0,10):
    if Marks[i]&gt;25 and Marks[i]&lt;75: 
        print(Students[i],Marks[i])
        print(i)
</code></pre>
"
"60476151","<p>A small addition to your code can solve this issue, below is the solution</p>

<pre><code>Students = ['student1','student2','student3','student4','student5','student6','student7','student8','student9','student10']
Marks = [45, 78, 12, 14, 48, 43, 45, 98, 35, 80]

Students,Marks=zip(*sorted(zip(Students, Marks))) #addition to your code

for i in range(0,10):
    if Marks[i]&gt;25 and Marks[i]&lt;75: 
        print(Students[i],Marks[i])

</code></pre>
","0","","1","673","9","55","92","60475885","60476151","<p>Consider the marks list of class students given in two lists</p>

<pre><code>Students = ['student1','student2','student3','student4','student5','student6','student7','student8','student9','student10']
Marks = [45, 78, 12, 14, 48, 43, 45, 98, 35, 80]
</code></pre>

<p>from the above two lists the Student[0] got Marks[0], Student[1] got Marks[1] and so on
Who got marks between >25th percentile &lt;75th percentile, in the increasing order of marks </p>

<p>My question - 
Can't we use simple code in python to solve this problem..?</p>

<p>I have written code till this. To find the numbers >25 and &lt;75 but unable to make it in ascending order. Sort() is not working and sorted is also not working. Please help how to extract the particular array values and assign to another array to solve this problem.</p>

<pre><code>for i in range(0,10):
    if Marks[i]&gt;25 and Marks[i]&lt;75: 
        print(Students[i],Marks[i])
        print(i)
</code></pre>
"
"60476223","<p>Looks like <a href=""https://stackoverflow.com/users/2648811/green-cloak-guy"">@Green Cloak Guy</a> answer is the correct. But anyway, if what you want is to get the data of students with marks between two ranges I'll do it like this:</p>

<pre><code># Get a dict of students with it's mark, filtered by those with mark between 25 and 75
students_mark = {s: m for s, m in zip(Students, Marks) if m &gt; 25 and m &lt; 75}
# Sort results
res = dict(sorted(students_mark.items(), key=lambda i: i[1])
# res: {'student9': 35, 'student6': 43, 'student1': 45, 'student7': 45, 'student5': 48}

# In one line
res = {s: m for s, m in sorted(zip(Students, Marks), key=lambda i: i[1]) if m &gt; 25 and m &lt; 75}
</code></pre>

<p>As a summary: first link each student with it's score, and then filter and sort. I stored the result as dictionary because it seems more convinient.</p>
","0","2020-03-01 14:48:55","1","133","500","0","11","60475885","60476151","<p>Consider the marks list of class students given in two lists</p>

<pre><code>Students = ['student1','student2','student3','student4','student5','student6','student7','student8','student9','student10']
Marks = [45, 78, 12, 14, 48, 43, 45, 98, 35, 80]
</code></pre>

<p>from the above two lists the Student[0] got Marks[0], Student[1] got Marks[1] and so on
Who got marks between >25th percentile &lt;75th percentile, in the increasing order of marks </p>

<p>My question - 
Can't we use simple code in python to solve this problem..?</p>

<p>I have written code till this. To find the numbers >25 and &lt;75 but unable to make it in ascending order. Sort() is not working and sorted is also not working. Please help how to extract the particular array values and assign to another array to solve this problem.</p>

<pre><code>for i in range(0,10):
    if Marks[i]&gt;25 and Marks[i]&lt;75: 
        print(Students[i],Marks[i])
        print(i)
</code></pre>
"
"60476089","<p>A bit elaborated from my comment:
You could first merge all dataframes with <code>pd.concat()</code>, then select the matching rows and create new dataframes from them:</p>

<pre><code>merged_frame = pd.concat(df_countries)
country_dict = {}
for country in country_names:
    country_dict[country] = merged_frame[merged_frame['Country'] == country]
</code></pre>

<p>Optionally you can also call <code>country_dict[country].reset_index()</code> to fix the indices of the new frames.</p>
","0","","1","515","63","7","46","60475987","60476089","<p><strong>Task Description</strong></p>

<p>I am wanting to merge a list of DataFrames based on string in a column (Country) and then convert this to a dictionary and have the Country column as the key and the merged DataFrames as the values. Example of the data:</p>

<p><strong>List of country names</strong></p>

<pre><code>country_names = ['ITA', USA', 'UK', 'ARG']
</code></pre>

<p><strong>List of DataFrames named <code>df_countries</code></strong></p>

<pre><code>df_countries[0]

  index   Date      A   B   C  Country     
    1   2019-12-31  x   y   z    ITA
    2   2019-12-30  x   y   z    ITA    

df_countries[1]

  index   Date      A   B   C  Country     
    1   2019-12-31  x   y   z    ITA
    2   2019-12-30  x   y   z    ITA    

df_countries[2]

  index   Date      A   B   C  Country     
    1   2019-12-31  x   y   z    USA
    2   2019-12-30  x   y   z    USA    

df_countries[3]

  index   Date      A   B   C  Country     
    1   2019-12-31  x   y   z    ARG
    2   2019-12-30  x   y   z    ARG    
</code></pre>

<p>I would like, for example, ITA to look like the following once merged and then a dictionary created from this with ITA as the key etc. :</p>

<pre><code>  index   Date      A   B   C  Country     
    1   2019-12-31  x   y   z    ITA
    2   2019-12-30  x   y   z    ITA       
    3   2019-12-31  x   y   z    ITA
    4   2019-12-30  x   y   z    ITA  
</code></pre>

<p>Any help would be super!</p>
"
"60476592","<p>As @Vaishali commented, this is <code>groupby</code> and <code>cumsum</code>. You may want to do <code>sort_values</code> to make sure that the data is sorted in order, although it appears already so:</p>

<pre><code># sort by `c_id` and `a_date`
df = df.sort_values(['c_id','a_date'])

df['balance'] = df.groupby('c_id')['c_action'].cumsum()
</code></pre>

<p>Output:</p>

<pre><code>        a_date  c_id c_name  c_action  balance
0   2016-01-01     1   King      1000     1000
1   2016-01-02     1   King      -200      800
2   2016-01-03     1   King       100      900
3   2016-01-04     1   King      -400      500
4   2016-01-05     1   King       200      700
5   2016-01-06     1   King      -200      500
6   2016-01-01     2  Smith      1000     1000
7   2016-01-02     2  Smith      -300      700
8   2016-01-03     2  Smith      -600      100
9   2016-01-04     2  Smith       100      200
10  2016-01-05     2  Smith      -100      100
</code></pre>
","0","","1","112902","3825","17","9360","60476010","60476592","<p>Have table: </p>

<pre><code>list_1= [['2016-01-01',1,'King', 1000],    
        ['2016-01-02',1,'King', -200],    
        ['2016-01-03',1,'King', 100],    
        ['2016-01-04',1,'King',-400],    
        ['2016-01-05',1,'King', 200],    
        ['2016-01-06',1,'King',  -200],    
        ['2016-01-01',2,'Smith',  1000],    
        ['2016-01-02',2,'Smith',  -300],    
        ['2016-01-03',2,'Smith',  -600],    
        ['2016-01-04',2,'Smith',  100],    
        ['2016-01-05',2,'Smith',  -100]]
labels=['a_date','c_id','c_name','c_action']
df=pd.DataFrame(list_1,columns=labels)
df
</code></pre>

<p>OUT:</p>

<pre><code>    a_date       c_id   c_name  c_action
0   2016-01-01     1    King    1000
1   2016-01-02     1    King    -200
2   2016-01-03     1    King    100
3   2016-01-04     1    King    -400
4   2016-01-05     1    King    200
5   2016-01-06     1    King    -200
6   2016-01-01     2    Smith   1000
7   2016-01-02     2    Smith   -300
8   2016-01-03     2    Smith   -600
9   2016-01-04     2    Smith   100
10  2016-01-05     2    Smith   -100
</code></pre>

<p>Need to get table:</p>

<pre><code>a_date      c_id    c_name  c_amount    Balance
2016-01-01     1    King    1000        1000
2016-01-02     1    King    -200        800
2016-01-03     1    King    100         900
2016-01-04     1    King    -400        500
2016-01-05     1    King    200         700
2016-01-06     1    King    -200        500
2016-01-01     2    Smith   1000        1000
2016-01-02     2    Smith   -300        700
2016-01-03     2    Smith   -600        100
2016-01-04     2    Smith   100         200
2016-01-05     2    Smith   -100        100
</code></pre>

<p>So i need make ""Balance"" column with cumulative amount after each action for each customer.
This equivalent for SQL query :</p>

<pre><code>SELECT *,
        SUM(c_amount) OVER (PARTITION BY c_id ORDER BY a_date) AS 'Balance'
FROM account_actions
</code></pre>

<p>For both customers the solution is not difficult, can divide table by c_id, summarize and consolidate back.But it should be a dynamic solution for 10000 customers ...</p>
"
"60476086","<p>Try:</p>

<pre class=""lang-py prettyprint-override""><code>train[[""Minimum Temperature"", ""Maximum Temperature""]]=train[""Cellar Temperature""].str.split(""-"", expand=True, n=1)
</code></pre>

<p><code>str.split()</code> will split string by provided delimiter - <code>-</code> in this case. Then <code>expand</code> will explode splitted array, so every element will go into separate column. Then <code>n=1</code> will limit max splits to 1 (otherwise you would get an error, in case if you would have more than 1 hyphen in any cell).</p>
","0","","1","11365","152","50","745","60476022","60476086","<p>I have a dataframe, whose one particular column has temperature values like shown below</p>

<pre><code>'35-40',
 '35-40',
 '40-45',
 '40-45',
 '45-50',
 '40-45',
 '40-45',
 nan,
 '40-45',
 nan,
 '40-45',
 '40-45',
 '35-40',
</code></pre>

<p>I am trying to create a new column separating minimum and maximum temperatures.
In the rows filled with 'nan', I want the values after ',' to also be 'nan'. how should I do this? I have tried the code below but it didn't work.</p>

<pre><code>train[""Maximum Temperature""] = train[""Cellar Temperature""].apply(lambda x: np.nan if train[""Cellar Temperature""][0]==np.nan else (str(x).split(""-"")[1]))
</code></pre>

<p>Whenever I run the above code I get the following error</p>

<pre><code>IndexError: list index out of range
</code></pre>

<p>Please help me.</p>
"
"60476486","<p>You can use <code>extract</code> to get both:</p>

<pre><code>df['temp'].str.extract('(?P&lt;minimum&gt;\d+)-(?P&lt;maximum&gt;\d+)')
</code></pre>

<p>Output:</p>

<pre><code>   minimum maximum
0       35      40
1       35      40
2       40      45
3       40      45
4       45      50
5       40      45
6       40      45
7      NaN     NaN
8       40      45
9      NaN     NaN
10      40      45
11      40      45
12      35      40
</code></pre>
","0","","1","112902","3825","17","9360","60476022","60476086","<p>I have a dataframe, whose one particular column has temperature values like shown below</p>

<pre><code>'35-40',
 '35-40',
 '40-45',
 '40-45',
 '45-50',
 '40-45',
 '40-45',
 nan,
 '40-45',
 nan,
 '40-45',
 '40-45',
 '35-40',
</code></pre>

<p>I am trying to create a new column separating minimum and maximum temperatures.
In the rows filled with 'nan', I want the values after ',' to also be 'nan'. how should I do this? I have tried the code below but it didn't work.</p>

<pre><code>train[""Maximum Temperature""] = train[""Cellar Temperature""].apply(lambda x: np.nan if train[""Cellar Temperature""][0]==np.nan else (str(x).split(""-"")[1]))
</code></pre>

<p>Whenever I run the above code I get the following error</p>

<pre><code>IndexError: list index out of range
</code></pre>

<p>Please help me.</p>
"
"60484870","<p>To directly correct your code, try</p>

<pre><code>train[""Maximum Temperature""] = train[""Cellar Temperature""].apply(lambda x: np.nan if pd.isnull(x) else x.split(""-"")[1])
</code></pre>
","0","","0","106","33","0","4","60476022","60476086","<p>I have a dataframe, whose one particular column has temperature values like shown below</p>

<pre><code>'35-40',
 '35-40',
 '40-45',
 '40-45',
 '45-50',
 '40-45',
 '40-45',
 nan,
 '40-45',
 nan,
 '40-45',
 '40-45',
 '35-40',
</code></pre>

<p>I am trying to create a new column separating minimum and maximum temperatures.
In the rows filled with 'nan', I want the values after ',' to also be 'nan'. how should I do this? I have tried the code below but it didn't work.</p>

<pre><code>train[""Maximum Temperature""] = train[""Cellar Temperature""].apply(lambda x: np.nan if train[""Cellar Temperature""][0]==np.nan else (str(x).split(""-"")[1]))
</code></pre>

<p>Whenever I run the above code I get the following error</p>

<pre><code>IndexError: list index out of range
</code></pre>

<p>Please help me.</p>
"
"60476165","<p>Open your file in append mode:</p>

<pre><code>with open(""Output.txt"", ""ab"") as text_file:
</code></pre>
","0","","3","885","79","6","101","60476093","60476165","<p>I am receiving data blocks from a server that sends out the data block as a string with the first 3 bytes representing the number of bytes of the data. The rest of the data are separated by tabs between them. I want to receive them in my client and write it to the text file. <strong>But when I write it to the .txt file, the previous data is getting re-written. Also, I want to limit the number of data blocks being received.</strong>
Here is my code:</p>

<p>Server.py</p>

<pre><code>def Main():
    host = '127.0.0.1'
    port = 5003
    s = socket.socket()
    s.bind((host,port))
    s.listen(5)
    print(""Server started"")

    while True:
        c,addr = s.accept()
        print(""Client connected ip:&lt;"" + str(addr) + ""&gt;"")
        #c.sendall('232 23/02/2020  18:11:56    567 4   1   6   0   0   0   0   1510.26 1524.211    1536.369    1550.656    1563.790    1577.245    45  58  41  53  47  52  2   10  0   0   0   0   1510.83 1518.992    1526.89 1534.056    1542.597    1550.394    1558.07 1566.34 1574.286    1582.056    44  60  42  41  47  48  42  44  42  49  3   7   0   0   0   0   1510.95 1518.936    1528.055    1536.916    1545.605    1555.107    1563.437    1572.349    1582.091    59  41  46  45  41  53  42  43  60  4   15  0   0   0   0   1510.72 1516    1520.677    1526.604    1531.569    1537.594    1542.333    1547.744    1553.187    1558.118    1564.245    1569.357    1574.308    1579.758    1585.661    54  53  40  52  45  49  47  48  50  42  58  54  46  48  60'.encode())   
        # t = threading.Thread(target = RetrFile, args=(""retrThread"", c,))
        #c.sendall('232 24/02/2020  18:11:56    567 4   1   6   0   0   0   0   1510.26 1524.211    1536.369    1550.656    1563.790    1577.245    45  58  41  53  47  52  2   10  0   0   0   0   1510.83 1518.992    1526.89 1534.056    1542.597    1550.394    1558.07 1566.34 1574.286    1582.056    44  60  42  41  47  48  42  44  42  49  3   7   0   0   0   0   1510.95 1518.936    1528.055    1536.916    1545.605    1555.107    1563.437    1572.349    1582.091    59  41  46  45  41  53  42  43  60  4   15  0   0   0   0   1510.72 1516    1520.677    1526.604    1531.569    1537.594    1542.333    1547.744    1553.187    1558.118    1564.245    1569.357    1574.308    1579.758    1585.661    54  53  40  52  45  49  47  48  50  42  58  54  46  48  60'.encode())   
        #c.sendall('\t')
        # t.start()
        c.sendall('67 24/02/2020    18:11:56    567 4   1   6   0   0   0   0   1510.26 1524.211    1536.369    155'.encode())
        c.sendall('67 25/02/2020    18:11:56    567 4   1   6   0   0   0   0   1510.26 1524.211    1536.369    156'.encode())
        c.close()

    # s.close()

if __name__ == '__main__':
    Main()

</code></pre>

<p>Client.py</p>

<pre><code>def Main():
    host = '127.0.0.1'
    port = 5003
    s = socket.socket()
    s.connect((host,port))

    i = 0
    #for i &lt; 2:
    len_message = s.recv(3)
    print(len_message)
    while len_message:
        bytes_length = int(len_message.decode())
        #data_length = (bytes_length + 3)
        print(bytes_length)
        #print(data_length)
        data = s.recv(bytes_length)
        print(data)
        write_file(data)
        len_message = s.recv(3)
    #i+=1
    s.close()

def write_file(data):
        with open(""Output.txt"", ""wb"") as text_file:
            text_file.write(data)
            text_file.write('\n'.encode())


if __name__ == '__main__':
    Main()

</code></pre>
"
"60480634","<p>Matplotlib's plot can draw a curve over any existing plot. To plot the logistic function, just plot <code>1 / (1 + exp(-beta0 - beta1 * x))</code> where beta0 and beta1 are the result of fitting a logistic function to the given data. Scikit Learn's <code>LogisticRegression</code> is a function that can fit such a function and return the parameters:</p>

<pre><code>import matplotlib.pyplot as plt
from sklearn.linear_model import LogisticRegression
import seaborn as sns
import pandas as pd
import numpy as np

def draw_logistic_regression_curve(beta0, beta1, x, **kwargs):
    y = 1 / (1 + np.exp(-beta0 - beta1 * x))
    plt.plot(x, y, '-', **kwargs)


hours = np.array([0.50, 0.75, 1.00, 1.25, 1.50, 1.75, 1.75, 2.00, 2.25, 2.50, 2.75,
                  3.00, 3.25, 3.50, 4.00, 4.25, 4.50, 4.75, 5.00, 5.50])
passed = np.array([0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1])
df = pd.DataFrame({""hours_study"": hours, ""passed"": passed})
sns.scatterplot(df.hours_study, df.passed)

clf = LogisticRegression().fit(hours.reshape(-1, 1), passed)
beta0 = clf.intercept_ # -3.13952411
beta1 = clf.coef_[0] # 1.14860386
x = np.linspace(min(hours) - 0.5, max(hours) + 0.5, 500)
draw_logistic_regression_curve(beta0, beta1, x, color='crimson', label=""Sklearn's default estimate"")
draw_logistic_regression_curve(-4.0777, 1.5046, x, color='limegreen', label=""Wikipedia's estimate"")
plt.legend(loc='center right')
plt.show()
</code></pre>

<p><a href=""https://i.stack.imgur.com/d7QQL.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/d7QQL.png"" alt=""resulting plot""></a></p>
","2","2020-03-02 18:02:52","1","34973","1481","136","1951","60476203","60480634","<p>I would like to be able to create the following plot in python (taken from <a href=""https://en.wikipedia.org/wiki/Logistic_regression#Logistic_model"" rel=""nofollow noreferrer"">https://en.wikipedia.org/wiki/Logistic_regression#Logistic_model</a>) </p>

<p><a href=""https://i.stack.imgur.com/OtlXe.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/OtlXe.png"" alt=""enter image description here""></a></p>

<p>The data is: </p>

<pre class=""lang-py prettyprint-override""><code>hours = [
    0.50,
    0.75,
    1.00,
    1.25,
    1.50,
    1.75,
    1.75,
    2.00,
    2.25,
    2.50,
    2.75,
    3.00,
    3.25,
    3.50,
    4.00,
    4.25,
    4.50,
    4.75,
    5.00,
    5.50,
]

passed = [0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1]
df = pd.DataFrame({""hours_study"": hours, ""passed"": passed})
</code></pre>

<p>A scatter plot is easily created with the following: </p>

<pre class=""lang-py prettyprint-override""><code>sns.scatterplot(df.hours_study, df.passed)
</code></pre>

<p>Giving </p>

<p><a href=""https://i.stack.imgur.com/42wkY.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/42wkY.png"" alt=""enter image description here""></a></p>

<p>But I'm not sure how I can then add lines to the plot (in this case the logistic curve). </p>
"
"60477081","<p>As @Pedro Lobito noted, the data should be adjusted with stocks split times. So, after using <code>get_daily_adjusted</code> function and plotting <code>'5. adjusted close'</code> values, the result is as expected:
<a href=""https://i.stack.imgur.com/WTbJA.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/WTbJA.png"" alt=""enter image description here""></a></p>

<p>Code:</p>

<pre class=""lang-py prettyprint-override""><code>from alpha_vantage.timeseries import TimeSeries
import matplotlib.pyplot as plt
ts = TimeSeries(key='YOUR_API_KEY', output_format='pandas')

data, meta_data = ts.get_daily_adjusted(symbol='AAPL', outputsize='full')
plt.figure(figsize=(10,6))

data['5. adjusted close'].plot()

plt.grid(linestyle='-', linewidth=2)
plt.title('AAPL stock price daily')
plt.savefig('sample.png')
plt.show()
</code></pre>
","0","2020-03-01 23:11:47","3","4549","1302","28","299","60476268","60477081","<p>I'm using the following code to download and plot AAPL daily stock prices:</p>

<pre class=""lang-py prettyprint-override""><code>from alpha_vantage.timeseries import TimeSeries
import matplotlib.pyplot as plt

ts = TimeSeries(key='YOUR_API_KEY', output_format='pandas')

data, meta_data = ts.get_daily(symbol='AAPL', outputsize='full')
plt.figure(figsize=(10,6))

data['3. low'].plot()
plt.grid(linestyle='-', linewidth=2)
plt.title('AAPL stock price daily')
plt.savefig('sample.png')
plt.show()
</code></pre>

<p>This is the plot that I am getting:
<a href=""https://i.stack.imgur.com/hEUsc.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/hEUsc.png"" alt=""enter image description here""></a></p>

<p>Obviously, this price drop in 2015 doesn't look right. Also AAPL has never been that expensive. Moreover, this data contradicts with other stock prices sources, e.g. Google.</p>

<p>Am I misusing the API? Is this a bug?</p>
"
"60476442","<p>Generally <code>matplotlib</code> do not show all labels, if there is a lof them, as it would look cluttered. If you want to show all dates nonetheless you might add following line:</p>

<pre><code>plt.xticks(your_full_list_of_dates)
</code></pre>

<p>above:</p>

<pre><code>plt.show()
</code></pre>

<p><a href=""https://matplotlib.org/api/pyplot_api.html#matplotlib.pyplot.xticks"" rel=""nofollow noreferrer"">xticks</a> might be also used for styling.</p>
","2","2020-03-01 15:11:00","1","8910","0","0","376","60476274","60476442","<p><strong>Update:</strong> </p>

<p>add codes as below fix the issues</p>

<pre><code>import matplotlib.dates as mdates
fig.gca().xaxis.set_major_formatter(mdates.DateFormatter('%Y/%m/%d'))
fig.gca().xaxis.set_major_locator(mdates.DayLocator())
'''this for minor ticks'''
fig.gca().xaxis.set_minor_formatter(mdates.DateFormatter('%Y/%m/%d'))
fig.gca().xaxis.set_minor_locator(mdates.WeekdayLocator(mdates.MONDAY))
'''disabled major and minor overlapping'''
fig.gca().xaxis.remove_overlapping_locs = False
</code></pre>

<p>or:
    <code>plt.xticks(days, [i.date() for i in days])</code></p>

<p><a href=""https://i.stack.imgur.com/kYnLQ.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/kYnLQ.png"" alt=""enter image description here""></a></p>

<p>========================================================================</p>

<p>I am doing the exercrise follow by the book, when i use<code>datetime.strptime()</code>to convert the date from <code>.csv</code> file in matlibplot, it not shows the whole date on x axis
for example, the convert date in list is <strong>[2014-07-01,2014-07-02,...,2014-07-31]</strong> totally 32 in list.</p>

<p>but finally when i plot it in matpltlib it only shows <strong>[2014-07-01,2014-07-05,2014-07-09,2014-07-13]</strong> on x axis
<a href=""https://i.stack.imgur.com/mw4yl.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/mw4yl.png"" alt=""enter image description here""></a>
why it not shows the whole date? and can i modify it?</p>

<p>here's the code:</p>

<pre><code>import csv
from matplotlib import pyplot as plt
from datetime import datetime


filename='sitka_weather_07-2014.csv'
with open(filename,'r') as f,open('xx.csv','w') as w:
    content=csv.reader(f,delimiter=',',quotechar='""')
    '''shift to title'''
    header=next(content)
    days,temps=[],[]
    for value in content:
        '''value[0] for the Date'''
        a=datetime.strptime(value[0],'%Y/%m/%d')
        days.append(a)
        '''value[1] for Temp'''
        b=int(value[1])
        temps.append(b)
    print(len(days))
   #&gt;&gt; 31 #here is 32 days in list  



fig=plt.figure(figsize=(10,6))
font={'weight':'normal',
      'color':'cyan',
      'fontsize':24,
       }
plt.title('Weather',fontdict=font)
plt.xlabel('Date',fontdict=font)
plt.ylabel('Temperature',fontdict=font)
fig.autofmt_xdate()
for x,y in zip(days,temps):
    plt.text(x,y+0.1,y,ha='center',va='bottom',fontsize=8,color='red')
plt.plot(days,temps,marker='o',mfc='red',mec='None')
plt.show()
</code></pre>
"
"60477417","<p>Yeah, you are right. We need to give the path to the file which needs to be uploaded. 
<code>request.files['file']</code> gives the file pointer and using that pointer, you can save the file into a location. The path where the file will be saved can be done using <code>os.path.join(UPLOAD_FOLDER, f.filename)</code> as shown below:</p>

<pre><code>@app.route(""/upload"", methods=['POST'])
def upload():
    if request.method == ""POST"":
        f = request.files['file']
        file_path=os.path.join(UPLOAD_FOLDER, f.filename) # path where file can be saved
        f.save(file_path)
        upload_file(file_path, BUCKET) # send the file path
        return redirect(""/storage"")
</code></pre>

<p>After that, as it can be seen, I called <code>upload_file</code> method which will write to s3 and the code for that function is given below:</p>

<pre><code>BUCKET = ""flaskdrive""
AWS_ACCESS_KEY=""aws_access_key""
AWS_SECERT_KEY=""aws_secret_key""

def upload_file(file_name, bucket):
    """"""
    Function to upload a file to an S3 bucket
    """"""
    object_name = file_name
    s3_client = boto3.client('s3',
                             aws_access_key_id=AWS_ACCESS_KEY,
                             aws_secret_access_key=AWS_SECERT_KEY)
    response = s3_client.upload_file(filename=file_name, bucket=bucket, key=object_name)

    return response
</code></pre>

<p>Let me know if this helps!</p>
","1","","3","1444","3","8","195","60476326","60477417","<p>What I am trying to do is </p>

<p>first, get the input as an excel form from the user </p>

<p>second, process it with python code,</p>

<p>third, upload it to aws s3 with boto3 </p>

<p>But I am having a trouble uploading to s3 </p>

<pre><code>s3 = boto3.client(
""s3"",
aws_access_key_id=access_key,
aws_secret_access_key=secret_key
)
bucket_resource = s3
</code></pre>

<p>I created s3 object first, and </p>

<pre><code>        excel_file = pd.read_excel(file.stream)
    try:
        result = compute.select_bestitem(excel_file, brand_name, col_name, methods, operator, value)
        filename = secure_filename(file.filename)
        bucket_resource.upload_file(
            Bucket=bucket_name,
            Filename=,
            Key=filename
        )
</code></pre>

<p>I already got file as file = request.files['file'], and passed it to the function I defined earlier </p>

<p><strong>Now, the file which I want to upload to S3 is 'result object'</strong>, which is the result of select_bestitem function </p>

<p>But I don't know what to pass to Filename argument </p>

<p>It seems like I have to give file path to it, but I can't find the path of file stored in localstorage </p>

<p>Plus, I am really not sure if it works even if I pass the correct file path, since the type of the file </p>

<p>I am trying to upload is string </p>

<p>(I created the 'result' object with Pandas to_csv command, and it looks like somehow boto3 rejects this type) </p>

<p>I am quite new to python and flask stuff, so any help would be great! Thanks in advance :) </p>
"
"60476530","<p>You have to get the value of data attribute from the link. You can try this code -</p>

<pre class=""lang-py prettyprint-override""><code>import requests
from bs4 import BeautifulSoup

raw = requests.get('https://www.iproperty.com.my/property/findanagent.aspx?ty=as&amp;ak=&amp;rk=&amp;pg=1&amp;rmp=10&amp;st=KL&amp;ct=&amp;st1=&amp;ct1=#40091').text
raw = raw.replace(""&lt;/br&gt;"", """")

soup = BeautifulSoup(raw, 'html.parser')

import re
#['data-content'])[0][1:][:-1] ## note sure what is this
# for d in soup.find_all('a',{'class':'csagentphonelead'}):
name = [x.text.strip().split(""\r\n"")[-1].strip() for x in soup.find_all(""p"", class_='box-listing_agentCS')]
phone = [x['data'].strip().split(""\r\n"")[-1].strip() for x in soup.find_all(""a"", class_='csagentphonelead')] 
website = [x['data'].strip().split(""\r\n"")[-1].strip() for x in soup.find_all(""a"", class_='csagentemaillead')] 

num_page_items = len(name)
with open('results180.csv', 'a') as f:
    for i in range(num_page_items):
        f.write(name[i] + "","" + phone[i] + "","" + website[i] + "","" + ""\n"")
</code></pre>
","0","","1","536","22","2","61","60476361","60476530","<p>I am doing web scraping using beautifulSoup. I managed to scrape the name, however the problem is, I don't really sure how to scrape if the data is in the elements for example the phone number and email are located as in the pictures below:</p>

<p><a href=""https://i.stack.imgur.com/hXHZ2.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/hXHZ2.png"" alt=""The email""></a></p>

<p><a href=""https://i.stack.imgur.com/JSIAf.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/JSIAf.png"" alt=""The phone""></a></p>

<p>My code:</p>

<pre><code> import requests
    from bs4 import BeautifulSoup

    raw = requests.get('https://www.iproperty.com.my/property/findanagent.aspx?ty=as&amp;ak=&amp;rk=&amp;pg=1&amp;rmp=10&amp;st=KL&amp;ct=&amp;st1=&amp;ct1=#40091').text
    raw = raw.replace(""&lt;/br&gt;"", """")

    soup = BeautifulSoup(raw, 'html.parser')

    import re

phone = ['data-content'])[0][1:][:-1] for d in soup.find_all('a',{'class':'csagentphonelead'})]
    name = [x.text.strip().split(""\r\n"")[-1].strip() for x in soup.find_all(""p"", class_='box-listing_agentCS')]
    website = [x.text.strip().split(""\r\n"")[-1].strip() for x in soup.find_all(""a"", class_='csagentemaillead')] 

    num_page_items = len(name)
    with open('results180.csv', 'a') as f:
        for i in range(num_page_items):
        f.write(name[i] + "","" + phone[i] + "","" + website[i] + "","" + ""\n"")
</code></pre>

<p>My results from scraping is ""Click for Email"" and ""Click for Phone"".
What should I fix so that the results are proper email and phone number?</p>
"
"60482516","<p>This gets you a list of dataframes that match the content of the dataframe <code>sub</code>, but for all results of the <code>.groupby()</code>:</p>

<pre><code>import numpy
import pandas

source = pandas.DataFrame(
    {'id_1': [1, 2, 1, 1, 1, 1, 1, 2, 2, 2, 2],
     'id_2': [1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2],
     'v_1': [2, 1, 1, 3, 2, 1, 2, 4, 1, 1, 2],
     'v_2': [1, 1, 1, 1, 2, 2, 2, 1, 1, 2, 2],
     'v_3': [3, 3, 3, 3, 4, 4, 4, 3, 3, 3, 3]})


def add_v4(df):
    df['v_4'] = numpy.where(df['v_1'] == df['v_2'].shift(), 'A', numpy.where(df['v_1'] == df['v_3'].shift(), 'B', 'C'))
    return df


dfs = [add_v4(pandas.DataFrame(slice)) for _, slice in source.groupby(by=['id_1', 'id_2'])]
print(dfs)
</code></pre>

<p>About this line:</p>

<pre><code>dfs = [add_v4(pandas.DataFrame(slice)) for _, slice in source.groupby(by=['id_1', 'id_2'])]
</code></pre>

<p>It's a list comprehension that gets all the slices from the <code>groupby</code> and turns them into actual new dataframes before passing them to <code>add_v4</code>, which returns the modified dataframe to be added to the list.</p>
","2","","1","12065","76","218","1202","60476373","60482516","<pre><code>import pandas
import numpy

df = pandas.DataFrame({'id_1' : [1,2,1,1,1,1,1,2,2,2,2], 
                      'id_2' :  [1,1,1,1,1,2,2,2,2,2,2],
                      'v_1' :   [2,1,1,3,2,1,2,4,1,1,2],
                      'v_2' :   [1,1,1,1,2,2,2,1,1,2,2],
                      'v_3' :   [3,3,3,3,4,4,4,3,3,3,3]})


In [4]: df                                                                                                                                                                                                  
Out[4]: 
    id_1  id_2  v_1  v_2  v_3
0      1     1    2    1    3
1      2     1    1    1    3
2      1     1    1    1    3
3      1     1    3    1    3
4      1     1    2    2    4
5      1     2    1    2    4
6      1     2    2    2    4
7      2     2    4    1    3
8      2     2    1    1    3
9      2     2    1    2    3
10     2     2    2    2    3

sub = df[(df['id_1'] == 1) &amp; (df['id_2'] == 1)].copy()
sub['v_4'] = numpy.where(sub['v_1'] == sub['v_2'].shift(), 'A', \
                         numpy.where(sub['v_1'] == sub['v_3'].shift(), 'B', 'C'))


In [6]: sub                                                                                                                                                                                                 
Out[6]: 
   id_1  id_2  v_1  v_2  v_3 v_4
0     1     1    2    1    3   C
2     1     1    1    1    3   A
3     1     1    3    1    3   B
4     1     1    2    2    4   C

</code></pre>

<p>I have a dataframe as defined above. I would like to perform some operation, basically categorize whether v_1 equals the previous v_2 or v_3 for each group of (id_1, id_2)
I have done the the operation which performs on a sub df. And I would like to have a one line code to combine the following groupby together with the operation I have on the sub df together.</p>

<pre><code>gbdf = df.groupby(by=['id_1', 'id_2'])
</code></pre>

<p>I have tried something like</p>

<pre><code>gbdf['v_4'] = numpy.where(gbdf['v_1'] == gbdf['v_2'].shift(), 'A', \
                         numpy.where(gbdf['v_1'] == gbdf['v_3'].shift(), 'B', 'C'))
</code></pre>

<p>and the error was</p>

<pre><code>'DataFrameGroupBy' object does not support item assignment
</code></pre>

<p>I also tried</p>

<pre><code>df['v_4'] = numpy.where(gbdf['v_1'] == gbdf['v_2'].shift(), 'A', \
                         numpy.where(gbdf['v_1'] == gbdf['v_3'].shift(), 'B', 'C'))

</code></pre>

<p>which I believe the result was wrong, it does not align the groupby result with the original ordering.</p>

<p>I am wondering whether there is an elegant way to achieve this.</p>
"
"60476422","<p>Use <a href=""http://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.factorize.html"" rel=""nofollow noreferrer""><code>factorize</code></a> with both columns joined with <code>-</code> and converted to strings, because need combination values of both columns:</p>

<pre><code>df['group_num'] = pd.factorize(df['room'].astype(str) + '-' + df['box_num'].astype(str))[0]
</code></pre>

<p>Or convert both columns to <code>list of tuple</code>s by <code>map</code>:</p>

<pre><code>df['group_num'] = pd.factorize(list(map(tuple, df[['room','box_num']].values)))[0]
</code></pre>

<hr>

<pre><code>print (df)
      ml  room  box_num  group_num
0   1526   106       11          0
3   1608   106        9          1
9   1601   106        8          2
13  1603   106        8          2
17  1604   106        8          2
22  1558   106        5          3
24  1556   106        2          4
28  1557   106        2          4
32  1534     9       19          5
39  1552     9      104          6
43  1551     9      105          7
49  1550     9      102          8
57  1539     9       23          9
65  1546     9       23          9
73  1560     9       28         10
</code></pre>

<p><strong>Detail</strong>:</p>

<pre><code>print (df['room'].astype(str) + '-' + df['box_num'].astype(str))
0     106-11
3      106-9
9      106-8
13     106-8
17     106-8
22     106-5
24     106-2
28     106-2
32      9-19
39     9-104
43     9-105
49     9-102
57      9-23
65      9-23
73      9-28
dtype: object

print (list(map(tuple, df[['room','box_num']].values)))
[(106, 11), (106, 9), (106, 8), (106, 8), (106, 8), (106, 5), 
 (106, 2), (106, 2), (9, 19), (9, 104), (9, 105), (9, 102), (9, 23), (9, 23), (9, 28)]
</code></pre>
","0","2020-03-01 15:11:31","1","615041","23439","1483","126104","60476390","60476422","<p>Here is a dataframe:</p>

<pre><code>    ml  room    box_num
0   1526    106     11
3   1608    106     9
9   1601    106     8
13  1603    106     8
17  1604    106     8
22  1558    106     5
24  1556    106     2
28  1557    106     2
32  1534    009     19
39  1552    009     104
43  1551    009     105
49  1550    009     102
57  1539    009     23
65  1546    009     23
73  1560    009     28
</code></pre>

<p>I need to add a group number for unique values of <code>[room, box_num]</code>, so that it will look like this:</p>

<pre><code>    ml  room    box_num  group_num
0   1526    106     11   0
3   1608    106     9    1
9   1601    106     8    2
13  1603    106     8    2
17  1604    106     8    2
22  1558    106     5    3
24  1556    106     2    4
28  1557    106     2    4
32  1534    009     19   5
39  1552    009     104  6
43  1551    009     105  7
49  1550    009     102  8
57  1539    009     23   9
65  1546    009     23   9
73  1560    009     28   10
</code></pre>

<p>How to do it?</p>
"
"60477015","<p>You are indexing the dataframe along columns. So when using lambda, specify the axis as 1:</p>

<pre><code>df['diffval'] = df.apply(lambda x: x['diffval'] * -1 if x['GL'].str[0] in ['4', '0'] else x['diffval'], axis=1)
</code></pre>

<p>Just noticed your comment,</p>

<p>You do not need to specify .str as it is already a string.</p>

<pre><code>df['diffval'] = df.apply(lambda x: x['diffval'] * -1 if x['GL'][0] in ['4', '0'] else x['diffval'], axis=1)
</code></pre>

<p>If it is required to convert to string, you may use, </p>

<pre><code>df['diffval'] = df.apply(lambda x: x['diffval'] * -1 if str(x['GL'])[0] in ['4', '0'] else x['diffval'], axis=1)
</code></pre>

<p>Does this work, or am I missing something?</p>
","1","2020-03-01 16:11:48","1","482","16","2","43","60476396","60477015","<p>I have a dataframe
type are:</p>

<pre><code>FiscalYear      int64
GL             object
GLID            int64
GL_Debit      float64
GL_Credit     float64
month          object
diffDebit     float64
diffCredit    float64
diffval       float64
</code></pre>

<p>I try to modify a float column (diffvalue) to multiply it on a condition
My code is:</p>

<pre><code>df['diffval'] =  df.apply(lambda x: x['diffval']*-1 if x['GL'].str[0] in ['4','0'] else x['diffval'])
</code></pre>

<p>Im trying to do this but I have an error:</p>

<blockquote>
  <p>KeyError: ('GL', 'occurred at index FiscalYear')</p>
</blockquote>

<p>dataframe sample :</p>

<p>[![enter image description here][1]][1]
thanks</p>

<pre><code>FiscalYear  GL  GLID    GL_Debit    GL_Credit   month   diffDebit   diffCredit  diffval
2020    1001 Banque:RBC 06621-1006014 (Salle PrivÃ©e)    70  19386,69    0   2020-01-01  19386,69    0   19386,69
2020    1001 Banque:RBC 06621-1006014 (Salle PrivÃ©e)    70  0   5074,84 2020-02-01  -19386,69   5074,84 -24461,53
2020    1002 Banque:Desjardins 0282527 (Traiteurs)  71  2758,45 0   2020-01-01  2758,45 0   2758,45
2020    1002 Banque:Desjardins 0282527 (Traiteurs)  71  2765,64 0   2020-02-01  7,19    0   7,19
2020    1003 Banque:Desjardins 0282857 (ED) 54  36725,91    0   2020-01-01  36725,91    0   36725,91
2020    1003 Banque:Desjardins 0282857 (ED) 54  117149,35   0   2020-02-01  80423,44    0   80423,44
2020    1004 Banque:RBC 05261-1020403   231 30282,34    0   2020-01-01  30282,34    0   30282,34
2020    1004 Banque:RBC 05261-1020403   231 2277,34 0   2020-02-01  -28005  0   -28005
2020    1061 DÃ©pÃ´t Stripe Ã  recevoir:Stripe - Salle PrivÃ©e  219 7208,32 0   2020-01-01  7208,32 0   7208,32
2020    1061 DÃ©pÃ´t Stripe Ã  recevoir:Stripe - Salle PrivÃ©e  219 6015,4  0   2020-02-01  -1192,92    0   -1192,92
2020    1062 DÃ©pÃ´t Stripe Ã  recevoir:Stripe - Traiteurs.Co  220 1643,28 0   2020-01-01  1643,28 0   1643,28
2020    1062 DÃ©pÃ´t Stripe Ã  recevoir:Stripe - Traiteurs.Co  220 2678,28 0   2020-02-01  1035    0   1035
2020    1099 Fonds non dÃ©posÃ©s  8   1200    0   2020-01-01  1200    0   1200
2020    1099 Fonds non dÃ©posÃ©s  8   0   0   2020-02-01  -1200   0   -1200
2020    1100 Compte clients (C/C)   74  65665,57    0   2020-01-01  65665,57    0   65665,57
2020    1100 Compte clients (C/C)   74  94235,09    0   2020-02-01  28569,52    0   28569,52
2020    1300 Actif du stock 68  0   0   2020-01-01  0   0   0
2020    1300 Actif du stock 68  0   0   2020-02-01  0   0   0
</code></pre>
"
"60477245","<p>For your problem, you don't need to use the <code>apply</code> command (which is slow). You can solve this using <code>loc</code>. <br> 
Select rows where <strong>GL</strong> starts with '4' or '0' and then multiply to -1 the <strong>diffval</strong> column</p>

<pre><code>mask = df['GL'].str[0].isin(['4','0'])

df.loc[mask, 'diffval'] = df.loc[mask, 'diffval'] * -1
</code></pre>
","0","","1","2311","369","31","122","60476396","60477015","<p>I have a dataframe
type are:</p>

<pre><code>FiscalYear      int64
GL             object
GLID            int64
GL_Debit      float64
GL_Credit     float64
month          object
diffDebit     float64
diffCredit    float64
diffval       float64
</code></pre>

<p>I try to modify a float column (diffvalue) to multiply it on a condition
My code is:</p>

<pre><code>df['diffval'] =  df.apply(lambda x: x['diffval']*-1 if x['GL'].str[0] in ['4','0'] else x['diffval'])
</code></pre>

<p>Im trying to do this but I have an error:</p>

<blockquote>
  <p>KeyError: ('GL', 'occurred at index FiscalYear')</p>
</blockquote>

<p>dataframe sample :</p>

<p>[![enter image description here][1]][1]
thanks</p>

<pre><code>FiscalYear  GL  GLID    GL_Debit    GL_Credit   month   diffDebit   diffCredit  diffval
2020    1001 Banque:RBC 06621-1006014 (Salle PrivÃ©e)    70  19386,69    0   2020-01-01  19386,69    0   19386,69
2020    1001 Banque:RBC 06621-1006014 (Salle PrivÃ©e)    70  0   5074,84 2020-02-01  -19386,69   5074,84 -24461,53
2020    1002 Banque:Desjardins 0282527 (Traiteurs)  71  2758,45 0   2020-01-01  2758,45 0   2758,45
2020    1002 Banque:Desjardins 0282527 (Traiteurs)  71  2765,64 0   2020-02-01  7,19    0   7,19
2020    1003 Banque:Desjardins 0282857 (ED) 54  36725,91    0   2020-01-01  36725,91    0   36725,91
2020    1003 Banque:Desjardins 0282857 (ED) 54  117149,35   0   2020-02-01  80423,44    0   80423,44
2020    1004 Banque:RBC 05261-1020403   231 30282,34    0   2020-01-01  30282,34    0   30282,34
2020    1004 Banque:RBC 05261-1020403   231 2277,34 0   2020-02-01  -28005  0   -28005
2020    1061 DÃ©pÃ´t Stripe Ã  recevoir:Stripe - Salle PrivÃ©e  219 7208,32 0   2020-01-01  7208,32 0   7208,32
2020    1061 DÃ©pÃ´t Stripe Ã  recevoir:Stripe - Salle PrivÃ©e  219 6015,4  0   2020-02-01  -1192,92    0   -1192,92
2020    1062 DÃ©pÃ´t Stripe Ã  recevoir:Stripe - Traiteurs.Co  220 1643,28 0   2020-01-01  1643,28 0   1643,28
2020    1062 DÃ©pÃ´t Stripe Ã  recevoir:Stripe - Traiteurs.Co  220 2678,28 0   2020-02-01  1035    0   1035
2020    1099 Fonds non dÃ©posÃ©s  8   1200    0   2020-01-01  1200    0   1200
2020    1099 Fonds non dÃ©posÃ©s  8   0   0   2020-02-01  -1200   0   -1200
2020    1100 Compte clients (C/C)   74  65665,57    0   2020-01-01  65665,57    0   65665,57
2020    1100 Compte clients (C/C)   74  94235,09    0   2020-02-01  28569,52    0   28569,52
2020    1300 Actif du stock 68  0   0   2020-01-01  0   0   0
2020    1300 Actif du stock 68  0   0   2020-02-01  0   0   0
</code></pre>
"
"60477123","<p>Found a possible solution with some playing around from the dictionary output from the original flatten_json() function. Not sure how efficient this is but it seems to work:</p>

<pre><code>dictionary = flatten_json(data2)
all_values = list(dictionary.values())

index_list = []
for key in dictionary:
    x = tuple(key.split(""-""))
    index_list.append(x)

index = pd.MultiIndex.from_tuples(index_list)

df = pd.Series(all_values, index=index).to_frame()
</code></pre>

<p>Any suggestions or comments welcome...</p>
","2","2020-03-01 17:10:47","0","143","0","0","9","60476491","60477123","<p>I am seeking to convert a deeply nested json string into a Pandas Dataframe with hierarchical multiindex based on the hierarchy within the json.</p>

<p>I don't know the structure of the json and this will be used on a list of jsons with will likely have different hierarchies so this needs to be dynamic and cannot be hardcoded.</p>

<p>For the purpose of this question I'm using the following the ""Example 2"" data from the following link (though the actual data is much larger and more deeply nested): <a href=""https://support.oneskyapp.com/hc/en-us/articles/208047697-JSON-sample-files"" rel=""nofollow noreferrer"">https://support.oneskyapp.com/hc/en-us/articles/208047697-JSON-sample-files</a> </p>

<p>I am using the following code to interatively flatten the json:</p>

<pre><code>import itertools as it
import pandas as pd

def flatten_json (dictionary):

    def unpack(parent_key,parent_value):
        if isinstance (parent_value,dict):
            for key, value in parent_value.items():
                temp = parent_key + ""-"" + key
                print(""parent_key: "", parent_key,"" key: "", key)
                yield temp, value
        elif isinstance(parent_value, list):
            i = 0
            for value in parent_value:
                temp2 = parent_key + ""_"" + str(i)
                i += 1
                yield temp2, value
        else:
            yield parent_key, parent_value
    while True:
        dictionary = dict(it.chain.from_iterable(it.starmap(unpack,dictionary.items())))

        if not any(isinstance(value,dict) for value in dictionary.values()) and not any(isinstance(value,list) for value in dictionary.values()):
            break

    return dictionary

data = ***json data from link above as a string - omitting due to length***
output_table = pd.Series(flatten_json(data)).to_frame()
</code></pre>

<p>The produces the following output:</p>

<p><a href=""https://i.stack.imgur.com/jaVKx.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/jaVKx.png"" alt=""enter image description here""></a></p>

<p>I want to produce the following output:</p>

<p><a href=""https://i.stack.imgur.com/33bT5.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/33bT5.png"" alt=""enter image description here""></a></p>
"
"60477711","<p>You can also flatten out the dictionary into a list of lists, make a DataFrame out of it, and then set the index to get the required output:</p>

<pre><code>def flatten_json(dictionary):
    flattened = []

    def flatten(data, name=''):
        if type(data) is dict:
            for d in data:
                flatten(data[d], name + d + ',')
        elif type(data) is list:
            i = 0
            for l in data:
                flatten(l, name[:-1] + '_' + str(i) + ',')
                i += 1
        else:
            flattened.append((name[:-1] + ',' + data).split(','))

    flatten(dictionary)
    return flattened

list_obj=flatten_json(dict_obj)
pd.DataFrame(list_obj).set_index(list(range(len(list_obj[0])-1)))
</code></pre>

<p>Works fine for the example given and is less complicated even.</p>
","0","","0","46","9","0","2","60476491","60477123","<p>I am seeking to convert a deeply nested json string into a Pandas Dataframe with hierarchical multiindex based on the hierarchy within the json.</p>

<p>I don't know the structure of the json and this will be used on a list of jsons with will likely have different hierarchies so this needs to be dynamic and cannot be hardcoded.</p>

<p>For the purpose of this question I'm using the following the ""Example 2"" data from the following link (though the actual data is much larger and more deeply nested): <a href=""https://support.oneskyapp.com/hc/en-us/articles/208047697-JSON-sample-files"" rel=""nofollow noreferrer"">https://support.oneskyapp.com/hc/en-us/articles/208047697-JSON-sample-files</a> </p>

<p>I am using the following code to interatively flatten the json:</p>

<pre><code>import itertools as it
import pandas as pd

def flatten_json (dictionary):

    def unpack(parent_key,parent_value):
        if isinstance (parent_value,dict):
            for key, value in parent_value.items():
                temp = parent_key + ""-"" + key
                print(""parent_key: "", parent_key,"" key: "", key)
                yield temp, value
        elif isinstance(parent_value, list):
            i = 0
            for value in parent_value:
                temp2 = parent_key + ""_"" + str(i)
                i += 1
                yield temp2, value
        else:
            yield parent_key, parent_value
    while True:
        dictionary = dict(it.chain.from_iterable(it.starmap(unpack,dictionary.items())))

        if not any(isinstance(value,dict) for value in dictionary.values()) and not any(isinstance(value,list) for value in dictionary.values()):
            break

    return dictionary

data = ***json data from link above as a string - omitting due to length***
output_table = pd.Series(flatten_json(data)).to_frame()
</code></pre>

<p>The produces the following output:</p>

<p><a href=""https://i.stack.imgur.com/jaVKx.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/jaVKx.png"" alt=""enter image description here""></a></p>

<p>I want to produce the following output:</p>

<p><a href=""https://i.stack.imgur.com/33bT5.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/33bT5.png"" alt=""enter image description here""></a></p>
"
"60502645","<p>The issue was resolved, in the Jenkins the full path is different than I thought it was.
Anyway, ran pwd and saw where I was - added the path where the file was and worked.</p>

<p>Thanks friends !</p>
","0","","0","47","0","0","16","60476494","60502645","<p>I'm using Locust for load testing - creating a lot of post requests to a server.
Because I need to generate different fields for every request, The best way to do it in my opinion is to read the body from a file, change the relevant fields and send the request.</p>

<p>The problem occurs when I open the file</p>

<p>I see in the Jenkins log that there is a FileNotFound exception - even though I see the file in the git repo from where the Jenkins runs the code.</p>

<p>I tried putting the full path in the <code>with</code> statement but still got the same exception.</p>

<pre><code>    ...
    with open('postRequest.json', 'r') as jsonFile:
        data = json.load(jsonFile)

    data[""a""] = b
    data[""x""] = y
    data[[""something""] = something_else
    return json.dumps(data)
</code></pre>

<p>Jenkins fails opening the file.</p>

<p><strong>Note : The code works when I don't read the file, but just create a very long JSON string.</strong></p>

<p>Thanks all !! ;)</p>
"
"60485745","<p>It's probably more difficult for the network to find the matching class between 20 classes than between two classes. </p>

<p>For example if you give it a dog image and it need to classify it between cat, dog and horse it could send 60% cat, 30% dog 10% horse and then be wrong
while if it needs to classify it only between dog and horse it would give may be 75% dog, 25% horse and then be wright. </p>

<p>The finetunnig will also be longer so you could have better result if you train it longer with the 20 classes if you haven't stop it after convergence but after a fix number of epochs.</p>
","2","","0","592","10","1","21","60476501","60485745","<p>I have just started an image classification project according to the tutorial from the documentation on the pytorch website(<a href=""https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html"" rel=""nofollow noreferrer"">this</a>).In the tutorial, there is a part of code like this:</p>

<pre><code>model_ft = models.resnet50(pretrained=True)
num_ftrs = model_ft.fc.in_features
model_ft.fc = nn.Linear(num_ftrs, 20)
</code></pre>

<p>And I have known the reason why the fc layer is supposed to be changed .Since my project needs to classify 20 classes , so I just changed the parameters from 2 to 20. But , I just get the accuracy of around 60%. When I dont change the fc layer like this:</p>

<pre><code>model_ft = se_resnet50(pretrained = True)
</code></pre>

<p>It turned out that the accuracy reaches 93.75% which is much better compared with the former results.</p>

<p>I just couldnt figure out why I get worse classification results when I modify the fc layer. Shouldn't it be modified?</p>
"
"60477345","<p><strong>Assuming that you don't have any strange filenames:</strong></p>

<pre><code>find . \! -name '.' -type d -prune | 
     grep  -v -f ids.txt | 
     xargs echo rm -rf 
</code></pre>

<p>This should work with any POSIX <a href=""https://pubs.opengroup.org/onlinepubs/009695399/utilities/find.html"" rel=""nofollow noreferrer"">find</a>/<a href=""https://pubs.opengroup.org/onlinepubs/009695399/utilities/grep.html"" rel=""nofollow noreferrer"">grep</a>/<a href=""https://pubs.opengroup.org/onlinepubs/009695399/utilities/xargs.html"" rel=""nofollow noreferrer"">xargs</a>. Remove the <code>echo</code> when you are satisfied, remove <code>-v</code> to delete the matching directories.</p>

<ul>
<li><strong>find</strong> - search for files

<ul>
<li><code>\! -name '.'</code> - file is not named '.', so it doesn't include the root directory (you might need to adapt that if you run this from another directory)</li>
<li><code>-type d</code> - select only directories</li>
<li><code>-prune</code> - once found, don't enter a directory, just print it</li>
</ul></li>
<li><strong>grep</strong> - filter

<ul>
<li><code>-f ids.txt</code> - load patterns from file ids.txt</li>
<li><code>-v</code> - return lines that don't match</li>
</ul></li>
<li><strong>xargs</strong> - run a command with arguments from standard input</li>
</ul>

<p><strong>Note:</strong> if you run find from another directory, you will need to change <code>-name</code> to match the base directory where your directories are. Example:</p>

<pre><code>$ find ./60476598/ \! -name '.' -type d -prune
./60476598/
$ find ./60476598/ \! -name '60476598' -type d -prune
./60476598/chain_asd123
./60476598/hello?_1effaj
$ find /home/sorin/tmp/60476598/ \! -name '60476598' -type d -prune
/home/sorin/tmp/60476598/chain_asd123
/home/sorin/tmp/60476598/hello?_1effaj
</code></pre>

<p>In this case, I have my test setup in a directory named 60476598 (the question id). If you don't take that in account, the you can see that it will return only the base directory, but if you change the <code>-name '.'</code> to <code>-name '60476598'</code> it will work as expected. You have to use just the name of the directory, not the entire path.  </p>

<p><strong>A slightly better approach</strong>, if you have a set of utilities that support null separation of records:</p>

<pre><code>find . \! -name '.' -type d -prune -print0 | 
     grep -v -z -f ids.txt | 
     xargs --null echo rm -rf
</code></pre>

<p>In this case <a href=""https://www.gnu.org/software/findutils/manual/html_mono/find.html#Print-File-Name"" rel=""nofollow noreferrer""><code>-print0</code></a> tells <code>find</code> to output results separated by the null char, <a href=""https://www.gnu.org/software/grep/manual/grep.html#Other-Options"" rel=""nofollow noreferrer""><code>-z</code></a> tells <code>grep</code> that lines are separated by the null char, and <code>--null</code> tells <a href=""https://www.gnu.org/software/findutils/manual/html_mono/find.html#xargs-options"" rel=""nofollow noreferrer""><code>xargs</code></a> that input lines are separated by null. These options are not required by POSIX compatibility however they are available for GNU variants of these tools.</p>

<p><strong>What is the difference ?</strong></p>

<p>Suppose you have a directory that has a new line in its name:</p>

<pre><code>ls -1la
total 28
drwxr-xr-x  6 sorin pi 4096 Mar  1 18:18 .
drwxr-xr-x 31 sorin pi 4096 Mar  1 17:26 ..
drwxr-xr-x  2 sorin pi 4096 Mar  1 17:26 chain_asd123
drwxr-xr-x  2 sorin pi 4096 Mar  1 17:26 hello_1afadf
drwxr-xr-x  2 sorin pi 4096 Mar  1 18:18 hello_1effaj
drwxr-xr-x  2 sorin pi 4096 Mar  1 18:17 hello?_1effaj
-rw-r--r--  1 sorin pi   29 Mar  1 17:28 ids.txt
</code></pre>

<p>In this case hello?_1effaj has a newline embedded in the name.</p>

<p>For the first command the output would be:</p>

<pre><code>$ find . \! -name '.' -type d -prune | grep  -f ids.txt | xargs echo rm -rf
rm -rf _1effaj ./hello_1effaj
</code></pre>

<p>(it would try to delete a directory named <code>_1effaj</code> but <code>hello?_1effaj</code> would be untouched)</p>

<pre><code>$ find . \! -name '.' -type d -prune -print0 | grep  -z -f ids.txt | xargs --null echo rm -rf
rm -rf ./hello
_1effaj ./hello_1effaj
</code></pre>

<p>This would successfully delete the directory <code>hello?_1effaj</code>.</p>

<p><strong>How do I check if I have such a filename ?</strong>:</p>

<pre><code>find -name '*
*'
</code></pre>

<p>this should work in any POSIX shell.</p>

<p>Or in bash you can use: <code>find -name \*$'\n'\*</code></p>
","2","2020-03-02 07:29:19","1","4560","238","568","597","60476598","60477345","<p>Assuming input *.txt file contains</p>

<pre><code>//this text file usually contains unique id's
1effaj
21easd
231asd
71823aq
</code></pre>

<p>One of my main directories contains child directories like below</p>

<pre><code>hello_1afadf
ring_1effaj
chain_asd123
</code></pre>

<p>Using the *.txt file as input, I want to remove all 1st level directories that either match or do not match the above pattern</p>

<p>If I want to remove all directories that match the pattern from the text file, then only ""ring_1effaj"" should be removed / deleted.</p>

<p>Or can someone suggest how can I use multiple indexes of an array if the lines of that input text are stored in multiple array's.</p>

<pre><code>rm -rf $(ls -aI ""*_${b[1]}"")
</code></pre>
"
"60476677","<p>The <a href=""https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html"" rel=""nofollow noreferrer"">LabelEncoder</a> don't need to extract information from the data to work, this program just run on the series and transform the target values in numbers. </p>

<p>The <a href=""https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html"" rel=""nofollow noreferrer"">StandardScale</a> compute mean and variance of the column to scale them. </p>

<p>Seen this, the x and y column may have 2 different mean and standard deviation, needing to be computed separately and that is why they created 2 objects. </p>
","1","","1","332","24","5","34","60476605","60476677","<p>I just learned something from <a href=""https://analyticsindiamag.com/data-pre-processing-in-python/"" rel=""nofollow noreferrer"">this site</a>. I do not understand that in the post the writer create 2 standard scaler object <code>sc_X = StandardScaler()</code> and <code>sc_y = StandardScaler()</code>, assigning same <code>Standard Scaler</code> to two different variables <code>sc_X</code> and <code>sc_y</code> and use <strong>each</strong> for <code>X</code> and <code>y</code> <strong>separately</strong>. While previous line he creates <code>le_X = LabelEncoder()</code> assigning <code>LabelEncoder()</code> to one variable <code>le_X</code> to be used on <strong>both</strong> <code>X</code> and <code>y</code>. I do not understand why he creates two variables for same function to be used separately on <strong>*each</strong> <code>X</code> and <code>y</code> and then create one variable to be used for <strong>both</strong> <code>X</code> and <code>y</code>. I'm so confused right now. Please someone explain why is it like that</p>
"
"60476736","<p>You can use <code>np.polyfit</code> for linear regression:</p>

<pre><code>pd.DataFrame(np.polyfit(df['Base'], df.filter(like='Thing'), deg=1)).T
</code></pre>

<p>Output:</p>

<pre><code>           0            1
0   3.002379    -0.714256
1   6.002379    -0.714256
2   12.002379   -0.714256
3   4.002379    -0.714256
4   2.672379    -0.714256
</code></pre>
","0","","1","112902","3825","17","9360","60476704","60476736","<p>I have a Pandas DataFrame where I need to calculate a large numbers of regression coefficients. Each calculation will be only two dimensional. The independent variable will be a <code>['Base']</code> which is the same for all cases. The dependent variable series is organized along columns in my  DataFrame.</p>

<p>This is easy to accomplish with a <code>for</code> loop but in my real life DataFrame I have thousands of columns on which to run the regression, so it takes forever. Is there a vectorized way to accomplish this?</p>

<p>Below is a MRE:</p>

<pre><code>import pandas as pd
import numpy as np
from sklearn import linear_model
import time

df_data = {
        'Base':np.random.randint(1, 100, 1000),
        'Adder':np.random.randint(-3, 3, 1000)}

df = pd.DataFrame(data=df_data)
result_df = pd.DataFrame()

df['Thing1'] = df['Base'] * 3 + df['Adder']
df['Thing2'] = df['Base'] * 6 + df['Adder']
df['Thing3'] = df['Base'] * 12 + df['Adder']
df['Thing4'] = df['Base'] * 4 + df['Adder']
df['Thing5'] = df['Base'] * 2.67 + df['Adder']

things = ['Thing1', 'Thing2', 'Thing3', 'Thing4', 'Thing5']

for t in things:
    reg = linear_model.LinearRegression()
    X, y = df['Base'].values.reshape(-1,1), df[t].values.reshape(-1,1)
    reg.fit(X, y)
    b = reg.coef_[0][0]
    result_df.loc[t, 'Beta'] = b

print(result_df.to_string())

</code></pre>
"
"60479612","<p>@Quang-Hoang 's idea of using df.filter solves the problem. If you really want to use sklearn, this also works:</p>

<pre><code>reg = linear_model.LinearRegression()
X = df['Base'].values.reshape(-1,1)
y = df.filter(items=things).values
reg.fit(X, y)
result_df['Betas'] = reg.coef_
y_predict = reg.predict(X)
result_df['Rsq'] = r2_score(y, y_predict)
</code></pre>
","0","","1","709","225","0","87","60476704","60476736","<p>I have a Pandas DataFrame where I need to calculate a large numbers of regression coefficients. Each calculation will be only two dimensional. The independent variable will be a <code>['Base']</code> which is the same for all cases. The dependent variable series is organized along columns in my  DataFrame.</p>

<p>This is easy to accomplish with a <code>for</code> loop but in my real life DataFrame I have thousands of columns on which to run the regression, so it takes forever. Is there a vectorized way to accomplish this?</p>

<p>Below is a MRE:</p>

<pre><code>import pandas as pd
import numpy as np
from sklearn import linear_model
import time

df_data = {
        'Base':np.random.randint(1, 100, 1000),
        'Adder':np.random.randint(-3, 3, 1000)}

df = pd.DataFrame(data=df_data)
result_df = pd.DataFrame()

df['Thing1'] = df['Base'] * 3 + df['Adder']
df['Thing2'] = df['Base'] * 6 + df['Adder']
df['Thing3'] = df['Base'] * 12 + df['Adder']
df['Thing4'] = df['Base'] * 4 + df['Adder']
df['Thing5'] = df['Base'] * 2.67 + df['Adder']

things = ['Thing1', 'Thing2', 'Thing3', 'Thing4', 'Thing5']

for t in things:
    reg = linear_model.LinearRegression()
    X, y = df['Base'].values.reshape(-1,1), df[t].values.reshape(-1,1)
    reg.fit(X, y)
    b = reg.coef_[0][0]
    result_df.loc[t, 'Beta'] = b

print(result_df.to_string())

</code></pre>
"
"60478035","<p>If the only objective of the use of QGraphicsItemGroup is to enable the movement of a group of items then the procedure is to select the items, add them to the group, move the items and before any action remove the items from the group. Thus, it will not be necessary for the items to permanently belong to the group but only when necessary avoiding side effects such as the non-transmission of events.</p>
","1","","2","184341","3940","32065","41961","60476803","60478035","<p>I want to catch mouse events for some <code>QGraphicsItem</code>. When the item is added directly to a <code>QGraphicsScene</code>, everything works as expected: when using option 1 below, the console prints ""foo"" when the user clicks within the rectangle.</p>

<p>However, if the item is added indirectly via a group, it does not receive events anymore (option 2 below). It seems the event chain is broken that way. I tried to set <code>scene</code> as the parent to the <code>QGraphicsItem</code> to restore the chain but it results in an error, obviously I am not doing it the right way?</p>

<p>What is the correct way to add a <code>QGraphicsItem</code> to a group and still receive mouse events?</p>

<pre><code>from PyQt5.QtWidgets import QApplication, QGraphicsRectItem, QGraphicsScene, QGraphicsView, QMainWindow


class Rect(QGraphicsRectItem):
  def mousePressEvent(self, event):
    print(""foo"")


app = QApplication([])
window = QMainWindow()
window.setGeometry(100, 100, 400, 400)
view = QGraphicsView()
scene = QGraphicsScene()

rect = Rect(0, 0, 150, 150)

# Option 1.
# scene.addItem(rect)  # works fine, prints 'foo' when clicked
# Option 2.
group = scene.createItemGroup([rect])  # no mouse event received by rect

view.setScene(scene)
window.setCentralWidget(view)
window.show()
app.exec()
</code></pre>
"
"60720234","<p>I did not get exactly what you are looking for, lm mean linear model, you could try linear regression in sklearn as follows:</p>

<pre><code>    import numpy as np
    from sklearn.linear_model import LinearRegression
    import matplotlib.pyplot as plt

    year        = np.arange(0, 100, 1)
    year = np.reshape(year, (1, -1))
    year_predict        = np.arange(100, 200, 1)
    year_predict        = np.reshape(year_predict, (1, -1))

    y   = np.sin(2*np.pi*year/15)+np.cos(2*np.pi*year/15)
    lm = LinearRegression()
    lm.fit(year, y)

    y_pred = lm.predict(year_predict)

    plt.plot(year[0,:], y[0,:])
    plt.plot(year_predict[0,:], y_pred[0,:])
    plt.ylabel('np.sin(2*pi*year/15)+np.cos(2*pi*year/15)')
    plt.show()
</code></pre>

<p>More info you can find here: <a href=""https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html"" rel=""nofollow noreferrer"">https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html</a> </p>

<p>If you have something unclear, write here. We could help you</p>
","0","","0","5626","1528","0","427","60476920","60720234","<p>I am trying to transition from R to Python for my time series analysis - but am finding it quite hard. The code below is what I would have used in R - to regress a sine curve onto some data with a known period.</p>

<pre><code>year &lt;- c(0:100)
lm(data~sin(2*pi*year/15)+cos(2*pi*year/15))
</code></pre>

<p>Now I want to do the same in Python I am coming across very long methods involving making initial guesses then optimising etc. What is the simplest way to achieve the comparable result?</p>
"
"60621952","<p>I suspect your issue has to do with your outputs / <code>data[1]</code> (it would help if you show examples of your train_set). Running the following piece of code gives no nan, but I forced shape of output by hand before calling the <code>loss_fn(pred, outputs)</code> :</p>

<pre><code>class BaselineModel(nn.Module):
    def __init__(self, feature_dim=5, hidden_size=5, num_layers=2, batch_size=32):
        super(BaselineModel, self).__init__()
        self.num_layers = num_layers
        self.hidden_size = hidden_size

        self.lstm = nn.LSTM(input_size=feature_dim,
                            hidden_size=hidden_size, num_layers=num_layers)

    def forward(self, x, hidden):
        lstm_out, hidden = self.lstm(x, hidden)
        return lstm_out, hidden

    def init_hidden(self, batch_size):
        hidden = Variable(next(self.parameters()).data.new(
            self.num_layers, batch_size, self.hidden_size))
        cell = Variable(next(self.parameters()).data.new(
            self.num_layers, batch_size, self.hidden_size))
        return (hidden, cell)

model = BaselineModel(batch_size=32)
optimizer = optim.Adam(model.parameters(), lr=0.01, weight_decay=0.0001)
loss_fn = torch.nn.MSELoss(reduction='sum')

hidden = model.init_hidden(10)
model.zero_grad()
pred, hidden = model(torch.randn(2,10,5), hidden)
pred.size() #torch.Size([2, 10, 5])
outputs = torch.zeros(2,10,5)

loss = loss_fn(pred, outputs)
loss

loss.backward()
torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)
optimizer.step()
print(loss)
</code></pre>

<p>Please note a common reason for nan values can be related to numerical stability of your learning phase, but usually you have values for the first steps before you see the divergence happening, which is apparently not the case here.</p>
","0","2020-03-10 16:41:18","2","1195","248","2","81","60476943","60621952","<p>My model is:</p>

<pre><code>class BaselineModel(nn.Module):
    def __init__(self, feature_dim=5, hidden_size=5, num_layers=2, batch_size=32):
        super(BaselineModel, self).__init__()
        self.num_layers = num_layers
        self.hidden_size = hidden_size

        self.lstm = nn.LSTM(input_size=feature_dim,
                            hidden_size=hidden_size, num_layers=num_layers)

    def forward(self, x, hidden):
        lstm_out, hidden = self.lstm(x, hidden)
        return lstm_out, hidden

    def init_hidden(self, batch_size):
        hidden = Variable(next(self.parameters()).data.new(
            self.num_layers, batch_size, self.hidden_size))
        cell = Variable(next(self.parameters()).data.new(
            self.num_layers, batch_size, self.hidden_size))
        return (hidden, cell)
</code></pre>

<p>Training looks like:</p>

<pre><code>train_loader = torch.utils.data.DataLoader(
    train_set, batch_size=BATCH_SIZE, shuffle=True, **params)

model = BaselineModel(batch_size=BATCH_SIZE)
optimizer = optim.Adam(model.parameters(), lr=0.01, weight_decay=0.0001)
loss_fn = torch.nn.MSELoss(reduction='sum')

for epoch in range(250):

    # hidden = (torch.zeros(2, 13, 5),
    #           torch.zeros(2, 13, 5))
    # model.hidden = hidden
    for i, data in enumerate(train_loader):
        hidden = model.init_hidden(13)
        inputs = data[0]
        outputs = data[1]

        print('inputs',  inputs.size())
        # print('outputs', outputs.size())

        # optimizer.zero_grad()
        model.zero_grad()

        # print('inputs', inputs)
        pred, hidden = model(inputs, hidden)

        loss = loss_fn(pred, outputs)

        loss.backward()
        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)
        optimizer.step()

        print('Epoch: ', epoch, '\ti: ', i, '\tLoss: ', loss)
</code></pre>

<p>I have gradient clipping set already, which seems to be the recommended solution. But after even the first step, I get:</p>

<blockquote>
  <p>Epoch:  0       i:  0   Loss:  tensor(nan, grad_fn=)</p>
</blockquote>
"
"60477205","<p>Remove <code>l=sorted(l)</code> step because it changes the order of indices of numbers since one of the constraints say <code>i &lt; j &lt; k</code>.</p>

<p>Consider below case:</p>

<p><code>4 2 1</code></p>

<p>Answer should be <code>0</code> but your code will return <code>1</code>. </p>

<hr>

<p>Regarding efficiency, you can count how many numbers each number divides from the right. For <code>1,2,3,4,5,6</code> the counts for each would look like:</p>

<pre><code>1 2 3 4 5 6
5 2 1 0 0 0 
</code></pre>

<p>For <code>1</code>, when you come to <code>2</code>, <code>2</code> already has <code>2</code> in the cached array, so now you got 2 triplets to add to the final answer. You get <code>1</code> triplet when you come to <code>3</code>, So <code>2+1</code> = <code>3</code>.</p>

<p><strong>Time Complexity:</strong> O(n^2)</p>

<p><strong>Space Complexity:</strong> O(n)</p>

<hr>

<p>Since, the question says <code>The elements of l are between 1 and 999999 inclusive</code>, I think you can just go the factorial way. </p>

<p>First collect all value counts in a map.</p>

<p>Now, go every multiple for every number and add the triplets from last to first. Like below:</p>

<pre><code>triplet_map = {}
map = {}
for every number in array: # from last to first
   if number in triplet_map:
       triplets += triplet_map(number)
       continue
   cnt = 0
   for(i = number; i &lt; 1000000; i *= number) 
     if i in map:
         if map(i) &gt; 0: 
           cnt += map(i)
     map(number,map(number) + 1)
   triplets += cnt
   triplet_map(number,cnt)
</code></pre>

<p>This way, it's like logarithmic time for each number. Didn't test this much but seems to work.</p>
","4","2020-03-01 16:36:33","2","11694","807","83","2040","60477022","60477205","<p><strong>Question</strong></p>

<p>Write a function answer(l) that takes a list of positive integers l and counts the number of ""lucky triples"" of (lst[i], lst[j], lst[k]) where i &lt; j &lt; k. The length of l is between 2 and 2000 inclusive. The elements of l are between 1 and 999999 inclusive. The answer fits within a signed 32-bit integer. Some of the lists are purposely generated without any access codes to throw off spies, so if no triples are found, return 0.</p>

<p>Lucky Triples are basically tuples (x,y,z) where x divides y and y divides z. e.g (1,2,4).</p>

<p>For example, [1, 2, 3, 4, 5, 6] has the triples: [1, 2, 4], [1, 2, 6], [1, 3, 6], making the answer 3 total.</p>

<p><strong>My Code</strong></p>

<pre><code>def isLuckyTriple(a,b,c):
    if b%a==0 and c%b==0:
        return True
    return False
def solution(l):
    count=0
    l=sorted(l)
    for i in range(len(l)-2):
        for j in range(i+1,len(l)-1):
            for k in range(j+1,len(l)):
                if isLuckyTriple(l[i],l[j],l[k]):
                    count+=1
    return count
</code></pre>

<p><strong>My problem</strong></p>

<p>I have viewed a few stackoverflow answers regarding this question. I know how to do it in a different and more optimal way. The only problem is that my above code passes only 2 test cases out of 5 given test cases. I want to understand what I am doing wrong in the <strong>above code</strong>. I am more interested in figuring my mistake out instead of doing it in a better way.  </p>

<p>If you do not think the code is incorrect, then could it be failing the test cases because the solution is very slow?</p>

<p>Any kind of help would be appreciated.</p>
"
"64255097","<pre><code>def answer(l):
    triples_count=0

    p=len(l)
    print l
    for i in xrange(p-2):
        for j in xrange(i+1, p-1):
            if l[j] % l[i] == 0:
                for k in xrange(j+1, p):
                    if l[k] % l[j] == 0:
                        #print l[i], l[j], l[k]
                        triples_count=triples_count+1
    return(triples_count)
</code></pre>
","0","","1","615","171","1","77","60477022","60477205","<p><strong>Question</strong></p>

<p>Write a function answer(l) that takes a list of positive integers l and counts the number of ""lucky triples"" of (lst[i], lst[j], lst[k]) where i &lt; j &lt; k. The length of l is between 2 and 2000 inclusive. The elements of l are between 1 and 999999 inclusive. The answer fits within a signed 32-bit integer. Some of the lists are purposely generated without any access codes to throw off spies, so if no triples are found, return 0.</p>

<p>Lucky Triples are basically tuples (x,y,z) where x divides y and y divides z. e.g (1,2,4).</p>

<p>For example, [1, 2, 3, 4, 5, 6] has the triples: [1, 2, 4], [1, 2, 6], [1, 3, 6], making the answer 3 total.</p>

<p><strong>My Code</strong></p>

<pre><code>def isLuckyTriple(a,b,c):
    if b%a==0 and c%b==0:
        return True
    return False
def solution(l):
    count=0
    l=sorted(l)
    for i in range(len(l)-2):
        for j in range(i+1,len(l)-1):
            for k in range(j+1,len(l)):
                if isLuckyTriple(l[i],l[j],l[k]):
                    count+=1
    return count
</code></pre>

<p><strong>My problem</strong></p>

<p>I have viewed a few stackoverflow answers regarding this question. I know how to do it in a different and more optimal way. The only problem is that my above code passes only 2 test cases out of 5 given test cases. I want to understand what I am doing wrong in the <strong>above code</strong>. I am more interested in figuring my mistake out instead of doing it in a better way.  </p>

<p>If you do not think the code is incorrect, then could it be failing the test cases because the solution is very slow?</p>

<p>Any kind of help would be appreciated.</p>
"
"60484910","<p>You can shuffle siteid parameter.
But much more robust approach is to create currencies rates on Your own, lets say:</p>

<pre><code>import numpy as np
eur_rate=4.3008 #EUR to PLN rate
usd_rate=3.9047 #USD to PLN rate
gbp_rate=5.0411 #GBP to PLN rate
a = np.array([[""EUR"",eur_rate]], dtype=object)
b = [[""USD"", usd_rate]]
c = [[""GBP"", gbp_rate]]
curr_rates = np.vstack((a,np.asarray(b,object)))
curr_rates = np.vstack((curr_rates,np.asarray(c,object)))
</code></pre>

<p>Here is my python repository: <a href=""https://github.com/Brat-Pit/eBay"" rel=""nofollow noreferrer"">https://github.com/Brat-Pit/eBay</a></p>
","2","","0","364","8","0","49","60477052","60484910","<p>I use</p>

<pre><code>response = api.execute('findItemsAdvanced', {'keywords': keyWords,
                                                'paginationInput': {
                                                'pageNumber': pageNumber,
                                            },
                                            'sortOrder': 'PricePlusShippingLowest',
                                            'itemFilter':itemFilter})
</code></pre>

<p>Is it possible to make it retrieve price:
1. in local currency
2. in particular currency,</p>

<p>For example the ebay site gives you approximate price.</p>
"
"60494484","<p>The issue was occurring due to folder permissions issue.
This was resolved by giving the proper permissions to the folder containing the .db file (in this case the application only had read permissions, that is why this issue was only occurring when trying to change or create content in it) these permissions being read and write.</p>

<p>So in my case I used chmod to change the permissions of my /var/www/FlaskApp/FlaskApp folder (which contains all my flask files and my .db file) and this resolved the issue</p>
","0","","1","50","7","0","17","60477091","60494484","<p>I have been trying to deploy my flask app on an apache web sever and have gotten it to somewhat function.
I am now facing the issue that the only page on which I need to either create a new entry in my database (using peewee sqlite for all things database related) or make changes to an already exciting entry I receive the 500 Internal Server Error. </p>

<p>It seems to be fully functional when reading the database, but unable to write to it. I have updated the .db files permissions to be 777, but that did not help.</p>

<p>The following code is in the Flask file and declares the path to the .db file:</p>

<pre><code>APP_DIR = os.path.dirname(os.path.realpath(__file__))

# Specifying the path of the DB file
DATABASE = 'sqliteext:///%s' % os.path.join(APP_DIR, 'blog.db')
</code></pre>

<p>I have placed the latest error log below, it occurred when trying to create a new entry, any ideas are much appreciated. </p>

<pre><code>[Sun Mar 01 15:59:58.008931 2020] [wsgi:error] [pid 5311:tid 139974393460480] [client 86.52.107.75:54947] hello: INDEX, referer: http://35.204.127.172/26-th/
[Sun Mar 01 15:59:58.010272 2020] [wsgi:error] [pid 5311:tid 139974393460480] [client 86.52.107.75:54947] totentries no search:  26, referer: http://35.204.127.172/26-th/
[Sun Mar 01 15:59:58.011008 2020] [wsgi:error] [pid 5311:tid 139974393460480] [client 86.52.107.75:54947] SELECT ""t1"".""id"", ""t1"".""auth"", ""t1"".""title"", ""t1"".""slug"", ""t1"".""content"", ""t1"".""published"", ""t1"".""timestamp"" FROM ""entry"" AS ""t1"" WHERE (""t1"".""published"" = 1) ORDER BY ""t1"".""timestamp"" DESC LIMIT 7 OFFSET 0, referer: http://35.204.127.172/26-th/
[Sun Mar 01 15:59:59.766531 2020] [wsgi:error] [pid 5311:tid 139974385067776] [client 86.52.107.75:54947] rasmus1, referer: http://35.204.127.172/index
[Sun Mar 01 15:59:59.767495 2020] [wsgi:error] [pid 5311:tid 139974385067776] [client 86.52.107.75:54947] entry 26, referer: http://35.204.127.172/index
[Sun Mar 01 16:00:02.433956 2020] [wsgi:error] [pid 5311:tid 139974376675072] [client 86.52.107.75:54947] rasmus1, referer: http://35.204.127.172/26-th/
[Sun Mar 01 16:00:02.434670 2020] [wsgi:error] [pid 5311:tid 139974376675072] [client 86.52.107.75:54947] entry 26, referer: http://35.204.127.172/26-th/
[Sun Mar 01 16:00:02.435722 2020] [wsgi:error] [pid 5311:tid 139974376675072] [client 86.52.107.75:54947] 26, referer: http://35.204.127.172/26-th/
[Sun Mar 01 16:00:02.439363 2020] [wsgi:error] [pid 5311:tid 139974376675072] [client 86.52.107.75:54947] ERROR:FlaskApp:Exception on /26-th/ [POST], referer: http://35.204.127.172/26-th/
[Sun Mar 01 16:00:02.439380 2020] [wsgi:error] [pid 5311:tid 139974376675072] [client 86.52.107.75:54947] Traceback (most recent call last):, referer: http://35.204.127.172/26-th/
[Sun Mar 01 16:00:02.439384 2020] [wsgi:error] [pid 5311:tid 139974376675072] [client 86.52.107.75:54947]   File ""/usr/local/lib/python3.5/dist-packages/peewee.py"", line 3057, in execute_sql, referer: http://35.204.127.172/26-th/
[Sun Mar 01 16:00:02.439388 2020] [wsgi:error] [pid 5311:tid 139974376675072] [client 86.52.107.75:54947]     cursor.execute(sql, params or ()), referer: http://35.204.127.172/26-th/
[Sun Mar 01 16:00:02.439391 2020] [wsgi:error] [pid 5311:tid 139974376675072] [client 86.52.107.75:54947] sqlite3.OperationalError: unable to open database file, referer: http://35.204.127.172/26-th/
[Sun Mar 01 16:00:02.439394 2020] [wsgi:error] [pid 5311:tid 139974376675072] [client 86.52.107.75:54947] , referer: http://35.204.127.172/26-th/
[Sun Mar 01 16:00:02.439398 2020] [wsgi:error] [pid 5311:tid 139974376675072] [client 86.52.107.75:54947] During handling of the above exception, another exception occurred:, referer: http://35.204.127.172/26-th/
[Sun Mar 01 16:00:02.439401 2020] [wsgi:error] [pid 5311:tid 139974376675072] [client 86.52.107.75:54947] , referer: http://35.204.127.172/26-th/
[Sun Mar 01 16:00:02.439404 2020] [wsgi:error] [pid 5311:tid 139974376675072] [client 86.52.107.75:54947] Traceback (most recent call last):, referer: http://35.204.127.172/26-th/
[Sun Mar 01 16:00:02.439407 2020] [wsgi:error] [pid 5311:tid 139974376675072] [client 86.52.107.75:54947]   File ""/usr/local/lib/python3.5/dist-packages/flask/app.py"", line 2446, in wsgi_app, referer: http://35.204.127.172/26-th/
[Sun Mar 01 16:00:02.439410 2020] [wsgi:error] [pid 5311:tid 139974376675072] [client 86.52.107.75:54947]     response = self.full_dispatch_request(), referer: http://35.204.127.172/26-th/
[Sun Mar 01 16:00:02.439423 2020] [wsgi:error] [pid 5311:tid 139974376675072] [client 86.52.107.75:54947]   File ""/usr/local/lib/python3.5/dist-packages/flask/app.py"", line 1951, in full_dispatch_request, referer: http://35.204.127.172/26-th/
[Sun Mar 01 16:00:02.439427 2020] [wsgi:error] [pid 5311:tid 139974376675072] [client 86.52.107.75:54947]     rv = self.handle_user_exception(e), referer: http://35.204.127.172/26-th/
[Sun Mar 01 16:00:02.439429 2020] [wsgi:error] [pid 5311:tid 139974376675072] [client 86.52.107.75:54947]   File ""/usr/local/lib/python3.5/dist-packages/flask/app.py"", line 1820, in handle_user_exception, referer: http://35.204.127.172/26-th/
[Sun Mar 01 16:00:02.439432 2020] [wsgi:error] [pid 5311:tid 139974376675072] [client 86.52.107.75:54947]     reraise(exc_type, exc_value, tb), referer: http://35.204.127.172/26-th/
[Sun Mar 01 16:00:02.439435 2020] [wsgi:error] [pid 5311:tid 139974376675072] [client 86.52.107.75:54947]   File ""/usr/local/lib/python3.5/dist-packages/flask/_compat.py"", line 39, in reraise, referer: http://35.204.127.172/26-th/
[Sun Mar 01 16:00:02.439438 2020] [wsgi:error] [pid 5311:tid 139974376675072] [client 86.52.107.75:54947]     raise value, referer: http://35.204.127.172/26-th/
[Sun Mar 01 16:00:02.439441 2020] [wsgi:error] [pid 5311:tid 139974376675072] [client 86.52.107.75:54947]   File ""/usr/local/lib/python3.5/dist-packages/flask/app.py"", line 1949, in full_dispatch_request, referer: http://35.204.127.172/26-th/
[Sun Mar 01 16:00:02.439444 2020] [wsgi:error] [pid 5311:tid 139974376675072] [client 86.52.107.75:54947]     rv = self.dispatch_request(), referer: http://35.204.127.172/26-th/
[Sun Mar 01 16:00:02.439447 2020] [wsgi:error] [pid 5311:tid 139974376675072] [client 86.52.107.75:54947]   File ""/usr/local/lib/python3.5/dist-packages/flask/app.py"", line 1935, in dispatch_request, referer: http://35.204.127.172/26-th/
[Sun Mar 01 16:00:02.439450 2020] [wsgi:error] [pid 5311:tid 139974376675072] [client 86.52.107.75:54947]     return self.view_functions[rule.endpoint](**req.view_args), referer: http://35.204.127.172/26-th/
[Sun Mar 01 16:00:02.439452 2020] [wsgi:error] [pid 5311:tid 139974376675072] [client 86.52.107.75:54947]   File ""/var/www/FlaskApp/FlaskApp/__init__.py"", line 403, in detail, referer: http://35.204.127.172/26-th/
[Sun Mar 01 16:00:02.439455 2020] [wsgi:error] [pid 5311:tid 139974376675072] [client 86.52.107.75:54947]     create_comment(slug), referer: http://35.204.127.172/26-th/
[Sun Mar 01 16:00:02.439458 2020] [wsgi:error] [pid 5311:tid 139974376675072] [client 86.52.107.75:54947]   File ""/var/www/FlaskApp/FlaskApp/__init__.py"", line 364, in create_comment, referer: http://35.204.127.172/26-th/
[Sun Mar 01 16:00:02.439461 2020] [wsgi:error] [pid 5311:tid 139974376675072] [client 86.52.107.75:54947]     commentContent=request.form.get('comment'), referer: http://35.204.127.172/26-th/
[Sun Mar 01 16:00:02.439464 2020] [wsgi:error] [pid 5311:tid 139974376675072] [client 86.52.107.75:54947]   File ""/usr/local/lib/python3.5/dist-packages/peewee.py"", line 6235, in create, referer: http://35.204.127.172/26-th/
[Sun Mar 01 16:00:02.439466 2020] [wsgi:error] [pid 5311:tid 139974376675072] [client 86.52.107.75:54947]     inst.save(force_insert=True), referer: http://35.204.127.172/26-th/
[Sun Mar 01 16:00:02.439469 2020] [wsgi:error] [pid 5311:tid 139974376675072] [client 86.52.107.75:54947]   File ""/usr/local/lib/python3.5/dist-packages/peewee.py"", line 6433, in save, referer: http://35.204.127.172/26-th/
[Sun Mar 01 16:00:02.439472 2020] [wsgi:error] [pid 5311:tid 139974376675072] [client 86.52.107.75:54947]     pk = self.insert(**field_dict).execute(), referer: http://35.204.127.172/26-th/
[Sun Mar 01 16:00:02.439475 2020] [wsgi:error] [pid 5311:tid 139974376675072] [client 86.52.107.75:54947]   File ""/usr/local/lib/python3.5/dist-packages/peewee.py"", line 1845, in inner, referer: http://35.204.127.172/26-th/
[Sun Mar 01 16:00:02.439478 2020] [wsgi:error] [pid 5311:tid 139974376675072] [client 86.52.107.75:54947]     return method(self, database, *args, **kwargs), referer: http://35.204.127.172/26-th/
[Sun Mar 01 16:00:02.439484 2020] [wsgi:error] [pid 5311:tid 139974376675072] [client 86.52.107.75:54947]   File ""/usr/local/lib/python3.5/dist-packages/peewee.py"", line 1916, in execute, referer: http://35.204.127.172/26-th/
[Sun Mar 01 16:00:02.439487 2020] [wsgi:error] [pid 5311:tid 139974376675072] [client 86.52.107.75:54947]     return self._execute(database), referer: http://35.204.127.172/26-th/
[Sun Mar 01 16:00:02.439490 2020] [wsgi:error] [pid 5311:tid 139974376675072] [client 86.52.107.75:54947]   File ""/usr/local/lib/python3.5/dist-packages/peewee.py"", line 2665, in _execute, referer: http://35.204.127.172/26-th/
[Sun Mar 01 16:00:02.439493 2020] [wsgi:error] [pid 5311:tid 139974376675072] [client 86.52.107.75:54947]     return super(Insert, self)._execute(database), referer: http://35.204.127.172/26-th/
[Sun Mar 01 16:00:02.439496 2020] [wsgi:error] [pid 5311:tid 139974376675072] [client 86.52.107.75:54947]   File ""/usr/local/lib/python3.5/dist-packages/peewee.py"", line 2400, in _execute, referer: http://35.204.127.172/26-th/
[Sun Mar 01 16:00:02.439499 2020] [wsgi:error] [pid 5311:tid 139974376675072] [client 86.52.107.75:54947]     cursor = database.execute(self), referer: http://35.204.127.172/26-th/
[Sun Mar 01 16:00:02.439501 2020] [wsgi:error] [pid 5311:tid 139974376675072] [client 86.52.107.75:54947]   File ""/usr/local/lib/python3.5/dist-packages/peewee.py"", line 3070, in execute, referer: http://35.204.127.172/26-th/
[Sun Mar 01 16:00:02.439504 2020] [wsgi:error] [pid 5311:tid 139974376675072] [client 86.52.107.75:54947]     return self.execute_sql(sql, params, commit=commit), referer: http://35.204.127.172/26-th/
[Sun Mar 01 16:00:02.439507 2020] [wsgi:error] [pid 5311:tid 139974376675072] [client 86.52.107.75:54947]   File ""/usr/local/lib/python3.5/dist-packages/peewee.py"", line 3064, in execute_sql, referer: http://35.204.127.172/26-th/
[Sun Mar 01 16:00:02.439510 2020] [wsgi:error] [pid 5311:tid 139974376675072] [client 86.52.107.75:54947]     self.commit(), referer: http://35.204.127.172/26-th/
[Sun Mar 01 16:00:02.439513 2020] [wsgi:error] [pid 5311:tid 139974376675072] [client 86.52.107.75:54947]   File ""/usr/local/lib/python3.5/dist-packages/peewee.py"", line 2831, in __exit__, referer: http://35.204.127.172/26-th/
[Sun Mar 01 16:00:02.439515 2020] [wsgi:error] [pid 5311:tid 139974376675072] [client 86.52.107.75:54947]     reraise(new_type, new_type(exc_value, *exc_args), traceback), referer: http://35.204.127.172/26-th/
[Sun Mar 01 16:00:02.439518 2020] [wsgi:error] [pid 5311:tid 139974376675072] [client 86.52.107.75:54947]   File ""/usr/local/lib/python3.5/dist-packages/peewee.py"", line 183, in reraise, referer: http://35.204.127.172/26-th/
[Sun Mar 01 16:00:02.439521 2020] [wsgi:error] [pid 5311:tid 139974376675072] [client 86.52.107.75:54947]     raise value.with_traceback(tb), referer: http://35.204.127.172/26-th/
[Sun Mar 01 16:00:02.439524 2020] [wsgi:error] [pid 5311:tid 139974376675072] [client 86.52.107.75:54947]   File ""/usr/local/lib/python3.5/dist-packages/peewee.py"", line 3057, in execute_sql, referer: http://35.204.127.172/26-th/
[Sun Mar 01 16:00:02.439527 2020] [wsgi:error] [pid 5311:tid 139974376675072] [client 86.52.107.75:54947]     cursor.execute(sql, params or ()), referer: http://35.204.127.172/26-th/
[Sun Mar 01 16:00:02.439531 2020] [wsgi:error] [pid 5311:tid 139974376675072] [client 86.52.107.75:54947] peewee.OperationalError: unable to open database file, referer: http://35.204.127.172/26-th/
[Sun Mar 01 16:00:02.439547 2020] [wsgi:error] [pid 5311:tid 139974376675072] [client 86.52.107.75:54947] , referer: http://35.204.127.172/26-th/
</code></pre>

<p>EDIT: Solved by comment</p>
"
"60477240","<p>Here is a way to do it. First create the countup flag, and then perform a cumsum. Then correct it with the NaN values.</p>

<pre><code>import pandas as pd
import numpy as np

df = pd.DataFrame({'Signal_1' : [0,0,0,1,1,0,0,1,1,1,1,0,0,0,1,1,1,1,1]})

# Only count up when the previous sample = 0, and the current sample = 1
df[""shift""] = df[""Signal_1""].shift(1)
df[""countup""] = np.where((df[""Signal_1""] == 1) &amp; (df[""shift""] == 0),1,0)

# Cumsum the countup flag and set to NaN when sample = 0
df[""result""] = df[""countup""].cumsum()
df[""result""] = np.where(df[""Signal_1""] == 0, np.NaN, df[""result""] )

</code></pre>
","0","","0","206","1","0","39","60477143","60477240","<p>I have a dataframe and I would like to creat a column with event labels. If a condition is true, then the event would get a number. But I want to give the same event label if the successive values are events. Do you have any idea? I tried to use .apply and .rolling, but without any success.</p>

<p>DataFrame:                </p>

<pre><code>df = pd.DataFrame({'Signal_1' : [0,0,0,1,1,0,0,1,1,1,1,0,0,0,1,1,1,1,1]})

    Signal_1  ExpectedColumn
0          0             NaN 
1          0             NaN
2          0             NaN
3          1               1
4          1               1
5          0             NaN
6          0             NaN
7          1               2
8          1               2
9          1               2
10         1               2
11         0             NaN
12         0             NaN
13         0             NaN
14         1               3
15         1               3
16         1               3
17         1               3
18         1               3
</code></pre>
"
"60477289","<pre><code>^(?:#(.*?)#)?\s*\{?(.*?)\}?\s*(?:\((#.*?)\))*\s*(?:&lt;(\d.*?)&gt;)*$
</code></pre>

<p><a href=""https://regex101.com/r/ETbK93/1"" rel=""nofollow noreferrer"">Demo here</a></p>
","2","","1","3019","170","38","254","60477188","60477289","<p>I which to match 4 patterns in a string, 3 of which are optional</p>

<p>strings can look as follows:</p>

<pre><code>form1 = ""N-e-1-[(5E)-5,6-e]-4 c""
form2 = ""#3,4# N-e-1-[(5E)-5,6-e]-4 c &lt;5,6,7&gt;""
form3 = ""#1,2,3# {N-e-1-[(5E)-5,6-e]-4 c} (#4,5# comments &lt;6,7&gt;) &lt;8,9,10&gt;""
</code></pre>

<p>and i want to match:</p>

<pre><code>assert pattern.match(form1).groups() == (None, 'N-e-1-[(5E)-5,6-e]-4 c', None, None)
assert pattern.match(form2).groups() == ('3,4', 'N-e-1-[(5E)-5,6-e]-4 c', None, '5,6,7')
assert pattern.match(form3).groups() == ('1,2,3', 'N-e-1-[(5E)-5,6-e]-4 c', '#4,5# comments &lt;6,7&gt;', '8,9,10')
</code></pre>

<p>but I'm not quite getting there. This is what I have so far:</p>

<pre><code># match any digits, comma or space separated, enclosed by ""#"", at the start of the line
optional_first_part = r'^#?([,\d\s]+)?#?' 
# match anything up to the start of an optional third or fourth part
second_part = r'(.*?)(?:&lt;\d+|\(#|$)'
# match anything between ""(#X"" and ""X&gt;)"", where X are integers
optional_third_part = r'\(?(#\d+.*\d+\&gt;)?\)?'
# match any digits, comma or space separated, enclosed by ""&lt;"" and ""&gt;"", at the end of the line
optional_fourth_part = r'&lt;?([,\d\s]+)?&gt;?$'
# compile pattern
pattern = re.compile(r'{0}{1}{2}{3}'.format(optional_first_part, second_part, 
                                            optional_third_part, optional_fourth_part))
</code></pre>

<p>and what I now get:</p>

<pre><code>pattern.match(form1).groups()
&gt;&gt;&gt; (None, 'N - e - 1 - [(5E) - 5, 6 - e] - 4c', None, None)
pattern.match(form2).groups()
&gt;&gt;&gt; ('3,4', ' N-e-1-[(5E)-5,6-e]-4 c ', None, ',6,7')  # unwanted white spaces, losing start of the fourth part
pattern.match(form3).groups()
&gt;&gt;&gt; ('1,2,3', ' {N-e-1-[(5E)-5,6-e]-4 c} (#4,5# comments &lt;6,7&gt;) ', None, '9,10')  # completely horrible
</code></pre>

<p>part of the issue is the lookahead: since I match ""&lt;\d+"" there, the optional fourth part actually doesn't match it. Somehow I need to be able to capture it again in fourth part</p>

<p>In the last example i don't seem able to non-greedily match up to the occurrence of ""(#\d+"" in the second_part, and thus the third_part is not used</p>

<p>any suggestions? </p>
"
"60479405","<p>You can use the following regular expression:</p>

<pre><code>/^(?:#(\d+(?:,\d+)*)#)? *([^&lt;]+?) *(?:\(([^()]*)\))? *(?:&lt;(\d+(?:,\d+)*)&gt;)?$/
</code></pre>

<p><a href=""https://regex101.com/r/ifR7I8/5/"" rel=""nofollow noreferrer"">demo</a></p>

<p>We can write it in <em>free spacing mode</em> to make it self-documenting:</p>

<pre><code>/
^             # match beginning of line
(?:           # begin non-capture group
  #           # match '#'
  (           # begin capture group 1
    \d+       # match 1+ digits  
    (?:,\d+)* # match a comma then 1+ digits in non-capture
              # group, executed 0+ times (*)
  )           # end capture group #1
  #           # match '#'
)?            # end non-capture group and make it optional

\ *           # match 0+ spaces
(.+?)         # match any char 1+ times (+), non-greedily
              # in capture group 2 (not optional)

\ *           # match 0+ spaces
(?:           # begin non-capture group
  \(          # match '('
  ([^()]*)    # match 0+ (*) chars other than '(' and
              # ')' in capture group 3 
  \)          # match ')'       
)?            # end non-capture group and make it optional

\ *           # match 0+ spaces
(?:           # begin non-capture group
  &lt;           # match '&lt;'
  (           # begin capture group 4 
    \d+       # match 1+ digits
    (?:,\d+)* # match a comma then 1+ digits in non-
              # capture group, 0+ times
  )           # end capture group 4
  &gt;           # match '&gt;'
)?            # end non-capture group and make it optional
$             # match end of line
/x            # free-spacing regex definition mode
</code></pre>
","4","2020-03-02 05:59:15","2","93421","7912","102","9185","60477188","60477289","<p>I which to match 4 patterns in a string, 3 of which are optional</p>

<p>strings can look as follows:</p>

<pre><code>form1 = ""N-e-1-[(5E)-5,6-e]-4 c""
form2 = ""#3,4# N-e-1-[(5E)-5,6-e]-4 c &lt;5,6,7&gt;""
form3 = ""#1,2,3# {N-e-1-[(5E)-5,6-e]-4 c} (#4,5# comments &lt;6,7&gt;) &lt;8,9,10&gt;""
</code></pre>

<p>and i want to match:</p>

<pre><code>assert pattern.match(form1).groups() == (None, 'N-e-1-[(5E)-5,6-e]-4 c', None, None)
assert pattern.match(form2).groups() == ('3,4', 'N-e-1-[(5E)-5,6-e]-4 c', None, '5,6,7')
assert pattern.match(form3).groups() == ('1,2,3', 'N-e-1-[(5E)-5,6-e]-4 c', '#4,5# comments &lt;6,7&gt;', '8,9,10')
</code></pre>

<p>but I'm not quite getting there. This is what I have so far:</p>

<pre><code># match any digits, comma or space separated, enclosed by ""#"", at the start of the line
optional_first_part = r'^#?([,\d\s]+)?#?' 
# match anything up to the start of an optional third or fourth part
second_part = r'(.*?)(?:&lt;\d+|\(#|$)'
# match anything between ""(#X"" and ""X&gt;)"", where X are integers
optional_third_part = r'\(?(#\d+.*\d+\&gt;)?\)?'
# match any digits, comma or space separated, enclosed by ""&lt;"" and ""&gt;"", at the end of the line
optional_fourth_part = r'&lt;?([,\d\s]+)?&gt;?$'
# compile pattern
pattern = re.compile(r'{0}{1}{2}{3}'.format(optional_first_part, second_part, 
                                            optional_third_part, optional_fourth_part))
</code></pre>

<p>and what I now get:</p>

<pre><code>pattern.match(form1).groups()
&gt;&gt;&gt; (None, 'N - e - 1 - [(5E) - 5, 6 - e] - 4c', None, None)
pattern.match(form2).groups()
&gt;&gt;&gt; ('3,4', ' N-e-1-[(5E)-5,6-e]-4 c ', None, ',6,7')  # unwanted white spaces, losing start of the fourth part
pattern.match(form3).groups()
&gt;&gt;&gt; ('1,2,3', ' {N-e-1-[(5E)-5,6-e]-4 c} (#4,5# comments &lt;6,7&gt;) ', None, '9,10')  # completely horrible
</code></pre>

<p>part of the issue is the lookahead: since I match ""&lt;\d+"" there, the optional fourth part actually doesn't match it. Somehow I need to be able to capture it again in fourth part</p>

<p>In the last example i don't seem able to non-greedily match up to the occurrence of ""(#\d+"" in the second_part, and thus the third_part is not used</p>

<p>any suggestions? </p>
"
"60477275","<p>nums and nums[:] have indeed the same value (that you check using ==), but the are different objects (that you can check using the 'is' keyword). Sequences are mutable, therefore you can change the values they contain without changing the object itself.
The [:] simply creates a copy of an existing sequence. This way you have a different object with all the values of the previous one</p>

<p>EDIT:
the reason is that, when you append nums to results, nums can still be changed even if it's inside results. Therefore the elements inside results will be changed everytime you change the original nums (in fact in the result all the values are identical). If you create a copy for each element you put in results, instead, the elements will all have different values.</p>
","5","2020-03-01 17:11:11","3","326","32","3","54","60477206","60477275","<p>So, I was solving(or rather, looking at the solution haha) a question on <a href=""https://leetcode.com/problems/permutations/"" rel=""nofollow noreferrer"">Leetcode</a>, and this was a solution to allow you to generate all possible permutations of an array with unique integers.</p>

<pre><code>class Solution:
    def permute(self, nums: List[int]) -&gt; List[List[int]]:

        length = len(nums)
        results = []

        def backtrack(first_char_index):
            if first_char_index == length:
                # print(nums == nums[:])
                results.append(nums)

            for index in range(first_char_index, length):
                nums[first_char_index], nums[index] = nums[index], nums[first_char_index]
                backtrack(first_char_index + 1)
                nums[first_char_index], nums[index] = nums[index], nums[first_char_index]

        backtrack(0)
        return results
</code></pre>

<p>So, I was testing out the solution, and I realized that this solution only works if inside the <code>if</code> condition inside of the <code>backtrack</code> function, I use <code>results.append(nums[:])</code> instead of the above <code>results.append(nums)</code>. </p>

<p>So I initially figured that this was probably because <code>nums[:]</code> should be used because we need to generate a new copy, but then I had that print statement added before <code>results.append(nums)</code>, and found that all of the print statements gave me a <code>True</code> result.</p>

<p>I remember seeing a few solutions with this pattern of having <code>nums[:]</code> instead of <code>nums</code>, and would like to ask if anyone could shed light on what exactly does the extra [:] do? I know that it creates a new copy (i.e different object, but same value), but since it has the same value, why does result in a different result? </p>

<p>To illustrate this, the result with an input of <code>[1, 2, 3]</code> gives </p>

<pre><code>[[1,2,3],[1,2,3],[1,2,3],[1,2,3],[1,2,3],[1,2,3]]
</code></pre>

<p>when using <code>nums</code>, and </p>

<pre><code>[[1,2,3],[1,3,2],[2,1,3],[2,3,1],[3,1,2],[3,2,1]]
</code></pre>

<p>(the correct answer), when using <code>nums[:]</code>.</p>

<p>Thanks in advance!</p>

<p>EDIT: For some reason, this question is being recognized to be the same as others that are regarding deep/shallow copy. However, I guess what I'm asking here is that since <code>[:]</code> results in a new, different object with the <strong>same value</strong>, and with the fact that the value of <code>nums</code> and <code>nums[:]</code> is the same (it prints out to be the altered value), shouldn't it be appending an array with the altered value, instead of the original untouched <code>nums</code> array?</p>
"
"60477910","<p>Flask needs to know that it is receiving ""json"". In your PHP script you need to add additional ""Content-Type"" header.</p>

<pre><code>&lt;?php
$url = 'http://127.0.0.1:34000/reg';
$data = array(""collection"" =&gt; ""RapidAPI"");
$curl = curl_init($url);
curl_setopt($curl, CURLOPT_RETURNTRANSFER, true);
curl_setopt($curl, CURLOPT_POST, true);
curl_setopt($curl, CURLOPT_POSTFIELDS,  json_encode($data));
curl_setopt($curl, CURLOPT_HTTPHEADER, [
   'Content-Type: application/json'
]);
$response = curl_exec($curl);
echo $response;
curl_close($curl);
</code></pre>
","0","","1","324","23","0","8","60477235","60477910","<p>I'm trying to run a flask API in a specific port number as below,</p>

<pre><code>from flask import Flask, request
from pymongo import MongoClient
import json


app = Flask(__name__)

@app.route(""/"")
def hello():
    return ""Befriend Registration""
@app.route(""/reg"", methods=[""POST""])
def pushDB():
    somedata= request.get_json()
    return json.dumps({""status"":""OK"", ""Data"": somedata})

if __name__ == '__main__':
    app.run(port= 34000, debug=True)
</code></pre>

<p>And trying to send data using PHP</p>

<pre><code>&lt;?php
    $url = 'http://127.0.0.1:34000/reg';
    $data = array(""collection"" =&gt; ""RapidAPI"");
    $curl = curl_init($url);
    curl_setopt($curl, CURLOPT_RETURNTRANSFER, true);
    curl_setopt($curl, CURLOPT_POST, true);
    curl_setopt($curl, CURLOPT_POSTFIELDS,  json_encode($data));
    $response = curl_exec($curl);
    echo $response;
    curl_close($curl);
?&gt;
</code></pre>

<p>But every time API is receiving <code>null</code> 
The response body is something like</p>

<pre><code>{
status: ""OK"",
Data: null
}
</code></pre>
"
"60477491","<p><code>easygui.enterbox</code> returns the text that the user entered, or None if he cancels the operation. You will have to convert the text returned to byte array. <a href=""http://easygui.sourceforge.net/api.html"" rel=""nofollow noreferrer"">Docs</a></p>

<pre><code>if l is not None:
    f = hashlib.sha256(l.encode()).hexdigest()
</code></pre>
","1","2020-03-01 17:02:33","2","12487","27","13","826","60477353","60477491","<p>I am trying to hash a user input which is entered through easygui. Easygui stores the input into an array (I think), so when I try to hash the userinput I am not sure how to turn it into a byte.</p>

<p>Here is my code:</p>

<pre><code>import hashlib
import easygui


g = hashlib.sha256(b'helloworld').hexdigest()

l = easygui.enterbox('enter password')

f = hashlib.sha256([l]).hexdigest()

print(g)
print(f)
</code></pre>

<p>ideally if I type 'helloworld' into the easygui, it should return the same hashed output.</p>

<p>The error currently is: </p>

<pre><code>""TypeError: object supporting the buffer API required"" at the line f = haslib.sha256([l]).hexdigest()
</code></pre>
"
"60477536","<p>You have to encode your given string bevor you can hash it. The easiest way would, to just use the for strings implemented encode() method.</p>

<p><code>f = hashlib.sha256(l.encode()).hexdigest()
print(f)</code></p>

<p>with return your sha256 hash.</p>
","0","","1","108","9","0","11","60477353","60477491","<p>I am trying to hash a user input which is entered through easygui. Easygui stores the input into an array (I think), so when I try to hash the userinput I am not sure how to turn it into a byte.</p>

<p>Here is my code:</p>

<pre><code>import hashlib
import easygui


g = hashlib.sha256(b'helloworld').hexdigest()

l = easygui.enterbox('enter password')

f = hashlib.sha256([l]).hexdigest()

print(g)
print(f)
</code></pre>

<p>ideally if I type 'helloworld' into the easygui, it should return the same hashed output.</p>

<p>The error currently is: </p>

<pre><code>""TypeError: object supporting the buffer API required"" at the line f = haslib.sha256([l]).hexdigest()
</code></pre>
"
"60477770","<p>Discarding the imaginary part of the FFT (and also the sign of the real part) is exactly what the problem is leading to the 'backfolding' of the inverted image into itself. The FFT of a function that is symmetric about its origin is real (i.e. imaginary part 0). By discarding the imaginary part, the image has thus been somehow 'symmetrized'.</p>

<p>After performing operations on the complex FFT result in Fourier space, one can take the inverse FFT, and then only plot the real part <code>np.fft.ifft2((imgRadius(amp,43))).real</code> of it.</p>
","4","","3","431","25","0","106","60477377","60481431","<p>In the following code I have a function which returns an image cropped to a centered circle of a certain radius. Then I perform fourier-tranformation of an image, and reverse fourier-transformation again, to restore the image, which works fine.</p>

<p>Then I have calculated, that a centered circle with radius of 43 of the energy spectrum (excluded here) will yield 99% of the energy of the original image. But when I try to apply my function ""imgRadius"" to the amplitude-spectrum (the fourier-transformed image), and then perform inverse-fourier-tranformation on that image, I get this weird upside-down overlap of the original image.</p>

<pre><code>def imgRadius(img, radius):
    result = np.zeros(img.shape,np.float64)
    centerX = (img.shape[0])/2
    centerY = (img.shape[1])/2
    for m in range(img.shape[0]):
        for n in range(img.shape[1]):
            if math.sqrt((m-centerX)**2+(n-centerY)**2) &lt; radius:
                result[m,n] = img[m,n]
    return result

imgpath = directory+""NorbertWiener.JPG""
img = cv.imread(imgpath, cv.IMREAD_GRAYSCALE)
norm_image = cv.normalize(img, None, alpha=0, beta=1, norm_type=cv.NORM_MINMAX, dtype=cv.CV_32F)
amp = (np.fft.fftshift(np.fft.fft2(norm_image)))
amp_log = np.log(np.abs(amp))
norm_amp = cv.normalize(amp_log, None, alpha=0, beta=1, norm_type=cv.NORM_MINMAX, dtype=cv.CV_32F)
restoredAMP = np.abs(np.fft.ifft2(np.fft.ifftshift(amp)))
radamp = imgRadius(norm_amp,43)
rest99 = np.abs(np.fft.ifft2((imgRadius(amp,43))))

plt.subplot(231),plt.imshow(norm_image, ""gray"", vmin=0, vmax=1),plt.title('Image')
plt.xticks([]), plt.yticks([])
plt.subplot(232),plt.imshow(norm_amp, ""gray"", vmin=0, vmax=1),plt.title('Amplitude')
plt.xticks([]), plt.yticks([])
plt.subplot(233),plt.imshow(restoredAMP, ""gray"", vmin=0, vmax=1),plt.title('Restored from amplitude')
plt.xticks([]), plt.yticks([])
plt.subplot(235),plt.imshow(rest99, ""gray"", vmin=0, vmax=1),plt.title('Restored from r=43')
plt.xticks([]), plt.yticks([])
plt.subplot(234),plt.imshow(radamp, ""gray"", vmin=0, vmax=1),plt.title('Amplitude r=43')
plt.xticks([]), plt.yticks([])
plt.show()
</code></pre>

<p><img src=""https://i.stack.imgur.com/axJ7H.png"" alt=""See the resulting subplots here""></p>

<p>Does it somehow have anything to do with the fact that I use absolute values? I don't see how I should be able to plot the image without getting rid of the imaginary parts of the images, but I can see how maybe some information gets lost in the inverse fft.</p>

<p>I just don't get why I don't get problems when performing IFFT on the original amplitude spectrum.</p>
"
"60480549","<p>The following works for me in Python/OpenCV/Numpy and shows the difference between using a sharp boundary circle and one that has been smoothed by Gaussian blurring in order to mitigate ringing artifacts</p>

<p>Input:</p>

<p><a href=""https://i.stack.imgur.com/6et6q.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/6et6q.png"" alt=""enter image description here""></a></p>

<pre><code>import numpy as np
import cv2

# read input and convert to grayscale
img = cv2.imread('lena_gray.png', cv2.IMREAD_GRAYSCALE)

# do dft saving as complex output
dft = np.fft.fft2(img)

# apply shift of origin to center of image
dft_shift = np.fft.fftshift(dft)

# generate spectrum from magnitude image (for viewing only)
mag = np.abs(dft_shift)
spec = np.log(mag) / 20

# create circle mask
radius = 32
mask = np.zeros_like(img)
cy = mask.shape[0] // 2
cx = mask.shape[1] // 2
cv2.circle(mask, (cx,cy), radius, (255,255,255), -1)[0]

# blur the mask
mask2 = cv2.GaussianBlur(mask, (19,19), 0)

# apply mask to dft_shift
dft_shift_masked = np.multiply(dft_shift,mask) / 255
dft_shift_masked2 = np.multiply(dft_shift,mask2) / 255


# shift origin from center to upper left corner
back_ishift = np.fft.ifftshift(dft_shift)
back_ishift_masked = np.fft.ifftshift(dft_shift_masked)
back_ishift_masked2 = np.fft.ifftshift(dft_shift_masked2)


# do idft saving as complex output
img_back = np.fft.ifft2(back_ishift)
img_filtered = np.fft.ifft2(back_ishift_masked)
img_filtered2 = np.fft.ifft2(back_ishift_masked2)

# combine complex components to form original image again
img_back = np.abs(img_back).clip(0,255).astype(np.uint8)
img_filtered = np.abs(img_filtered).clip(0,255).astype(np.uint8)
img_filtered2 = np.abs(img_filtered2).clip(0,255).astype(np.uint8)


cv2.imshow(""ORIGINAL"", img)
cv2.imshow(""SPECTRUM"", spec)
cv2.imshow(""MASK"", mask)
cv2.imshow(""MASK2"", mask2)
cv2.imshow(""ORIGINAL DFT/IFT ROUND TRIP"", img_back)
cv2.imshow(""FILTERED DFT/IFT ROUND TRIP"", img_filtered)
cv2.imshow(""FILTERED2 DFT/IFT ROUND TRIP"", img_filtered2)
cv2.waitKey(0)
cv2.destroyAllWindows()

# write result to disk
cv2.imwrite(""lena_dft_numpy_mask.png"", mask)
cv2.imwrite(""lena_dft_numpy_mask_blurred.png"", mask2)
cv2.imwrite(""lena_dft_numpy_roundtrip.png"", img_back)
cv2.imwrite(""lena_dft_numpy_lowpass_filtered1.png"", img_filtered)
cv2.imwrite(""lena_dft_numpy_lowpass_filtered2.png"", img_filtered2)
</code></pre>

<p><br>
Sharp Mask:</p>

<p><a href=""https://i.stack.imgur.com/lKUuq.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/lKUuq.png"" alt=""enter image description here""></a></p>

<p>Blurred Mask:</p>

<p><a href=""https://i.stack.imgur.com/nBCji.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/nBCji.png"" alt=""enter image description here""></a></p>

<p>Simple Round Trip:</p>

<p><a href=""https://i.stack.imgur.com/m2HEr.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/m2HEr.png"" alt=""enter image description here""></a></p>

<p>Low Pass Filtered Result from sharp mask (ringing obvious):</p>

<p><a href=""https://i.stack.imgur.com/imN7I.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/imN7I.png"" alt=""enter image description here""></a></p>

<p>Low Pass Filtered Result from blurred mask (ringing mitigated):</p>

<p><a href=""https://i.stack.imgur.com/Jwh0H.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/Jwh0H.png"" alt=""enter image description here""></a></p>
","1","2020-03-02 02:21:59","2","26665","2157","177","2926","60477377","60481431","<p>In the following code I have a function which returns an image cropped to a centered circle of a certain radius. Then I perform fourier-tranformation of an image, and reverse fourier-transformation again, to restore the image, which works fine.</p>

<p>Then I have calculated, that a centered circle with radius of 43 of the energy spectrum (excluded here) will yield 99% of the energy of the original image. But when I try to apply my function ""imgRadius"" to the amplitude-spectrum (the fourier-transformed image), and then perform inverse-fourier-tranformation on that image, I get this weird upside-down overlap of the original image.</p>

<pre><code>def imgRadius(img, radius):
    result = np.zeros(img.shape,np.float64)
    centerX = (img.shape[0])/2
    centerY = (img.shape[1])/2
    for m in range(img.shape[0]):
        for n in range(img.shape[1]):
            if math.sqrt((m-centerX)**2+(n-centerY)**2) &lt; radius:
                result[m,n] = img[m,n]
    return result

imgpath = directory+""NorbertWiener.JPG""
img = cv.imread(imgpath, cv.IMREAD_GRAYSCALE)
norm_image = cv.normalize(img, None, alpha=0, beta=1, norm_type=cv.NORM_MINMAX, dtype=cv.CV_32F)
amp = (np.fft.fftshift(np.fft.fft2(norm_image)))
amp_log = np.log(np.abs(amp))
norm_amp = cv.normalize(amp_log, None, alpha=0, beta=1, norm_type=cv.NORM_MINMAX, dtype=cv.CV_32F)
restoredAMP = np.abs(np.fft.ifft2(np.fft.ifftshift(amp)))
radamp = imgRadius(norm_amp,43)
rest99 = np.abs(np.fft.ifft2((imgRadius(amp,43))))

plt.subplot(231),plt.imshow(norm_image, ""gray"", vmin=0, vmax=1),plt.title('Image')
plt.xticks([]), plt.yticks([])
plt.subplot(232),plt.imshow(norm_amp, ""gray"", vmin=0, vmax=1),plt.title('Amplitude')
plt.xticks([]), plt.yticks([])
plt.subplot(233),plt.imshow(restoredAMP, ""gray"", vmin=0, vmax=1),plt.title('Restored from amplitude')
plt.xticks([]), plt.yticks([])
plt.subplot(235),plt.imshow(rest99, ""gray"", vmin=0, vmax=1),plt.title('Restored from r=43')
plt.xticks([]), plt.yticks([])
plt.subplot(234),plt.imshow(radamp, ""gray"", vmin=0, vmax=1),plt.title('Amplitude r=43')
plt.xticks([]), plt.yticks([])
plt.show()
</code></pre>

<p><img src=""https://i.stack.imgur.com/axJ7H.png"" alt=""See the resulting subplots here""></p>

<p>Does it somehow have anything to do with the fact that I use absolute values? I don't see how I should be able to plot the image without getting rid of the imaginary parts of the images, but I can see how maybe some information gets lost in the inverse fft.</p>

<p>I just don't get why I don't get problems when performing IFFT on the original amplitude spectrum.</p>
"
"60481431","<p>The problem happens here:</p>

<pre><code>def imgRadius(img, radius):
    result = np.zeros(img.shape,np.float64)
</code></pre>

<p>You are creating a real-valued array, and copying over the complex values. Likely either the real component or the magnitude is written to the array. In any case, the complex-valued frequency domain data becomes real-valued. The inverse transform is a symmetric matrix.</p>

<p>To solve the problem, initialize <code>result</code> as a complex-valued array.</p>

<p>After this, make sure to use the real component of the inverse transform, not the magnitude, as <a href=""https://stackoverflow.com/a/60477770/7328782"">Gianluca already suggested in their answer</a>.</p>
","2","","3","42543","6046","915","6722","60477377","60481431","<p>In the following code I have a function which returns an image cropped to a centered circle of a certain radius. Then I perform fourier-tranformation of an image, and reverse fourier-transformation again, to restore the image, which works fine.</p>

<p>Then I have calculated, that a centered circle with radius of 43 of the energy spectrum (excluded here) will yield 99% of the energy of the original image. But when I try to apply my function ""imgRadius"" to the amplitude-spectrum (the fourier-transformed image), and then perform inverse-fourier-tranformation on that image, I get this weird upside-down overlap of the original image.</p>

<pre><code>def imgRadius(img, radius):
    result = np.zeros(img.shape,np.float64)
    centerX = (img.shape[0])/2
    centerY = (img.shape[1])/2
    for m in range(img.shape[0]):
        for n in range(img.shape[1]):
            if math.sqrt((m-centerX)**2+(n-centerY)**2) &lt; radius:
                result[m,n] = img[m,n]
    return result

imgpath = directory+""NorbertWiener.JPG""
img = cv.imread(imgpath, cv.IMREAD_GRAYSCALE)
norm_image = cv.normalize(img, None, alpha=0, beta=1, norm_type=cv.NORM_MINMAX, dtype=cv.CV_32F)
amp = (np.fft.fftshift(np.fft.fft2(norm_image)))
amp_log = np.log(np.abs(amp))
norm_amp = cv.normalize(amp_log, None, alpha=0, beta=1, norm_type=cv.NORM_MINMAX, dtype=cv.CV_32F)
restoredAMP = np.abs(np.fft.ifft2(np.fft.ifftshift(amp)))
radamp = imgRadius(norm_amp,43)
rest99 = np.abs(np.fft.ifft2((imgRadius(amp,43))))

plt.subplot(231),plt.imshow(norm_image, ""gray"", vmin=0, vmax=1),plt.title('Image')
plt.xticks([]), plt.yticks([])
plt.subplot(232),plt.imshow(norm_amp, ""gray"", vmin=0, vmax=1),plt.title('Amplitude')
plt.xticks([]), plt.yticks([])
plt.subplot(233),plt.imshow(restoredAMP, ""gray"", vmin=0, vmax=1),plt.title('Restored from amplitude')
plt.xticks([]), plt.yticks([])
plt.subplot(235),plt.imshow(rest99, ""gray"", vmin=0, vmax=1),plt.title('Restored from r=43')
plt.xticks([]), plt.yticks([])
plt.subplot(234),plt.imshow(radamp, ""gray"", vmin=0, vmax=1),plt.title('Amplitude r=43')
plt.xticks([]), plt.yticks([])
plt.show()
</code></pre>

<p><img src=""https://i.stack.imgur.com/axJ7H.png"" alt=""See the resulting subplots here""></p>

<p>Does it somehow have anything to do with the fact that I use absolute values? I don't see how I should be able to plot the image without getting rid of the imaginary parts of the images, but I can see how maybe some information gets lost in the inverse fft.</p>

<p>I just don't get why I don't get problems when performing IFFT on the original amplitude spectrum.</p>
"
"60478060","<p>You could do something like</p>

<pre class=""lang-py prettyprint-override""><code>class Contact:
    def __init__(self, first_name, last_name, phone_num, email):
        self.first_name = first_name
        self.last_name = last_name
        self.phone_num = phone_num
        self.email = email

    def __str__(self):
        return ""~"".join([self.first_name, self.last_name, self.phone_num, self.email])

address_book = []
try:
    with open(""save.txt"") as save_file:
        for contact in save_file:
            address_book.append(Contact(*contact.rstrip().split(""~"")))
except FileNotFoundError as fefe:
    pass

print(""Hello I am an addressbook! What do you want to do?\n1.Add contact"")
print(""2.Print out contacts\n3.Search for and edit a contact\n4.Exit\n"")
while True:
    choice = int(input(""Choice: ""))
    if choice == 1:
        address_book.append(Contact(input(""First name?""), input(""Last name?""), input(""Phone number?""), input(""Email?"")))
    elif choice == 2:
        print(*[contact for contact in address_book], sep=""\n"")
    elif choice == 3:
        pass
    elif choice == 4:
        with open(""save.txt"", ""w"") as save_file:
            for contact in address_book:
                save_file.write(str(contact) + ""\n"")
            break
</code></pre>
","7","","0","7789","823","247","820","60477378","60478060","<p>I'm trying to revise this syntax to save an input contact to the save.txt file when the user chooses option 1 and print the contents of save.txt when the user chooses option 2.  Please help?  Thank you!</p>

<p>This is Addressbook.py:</p>

<pre><code>from contact import Contact

addressBook = []
choice = 0
save = open(""save.txt"", 'r')
s = save.read()
s = s.split(""~"")

while len(s)-4 &gt;= 0:
    addressBook.append(Contact(s.pop(0), s.pop(0), s.pop(0), s.pop(0)))

print(""Hello I am an addressbook! What do you want to do?\n1.Add contact"")
print(""2.Print out contacts\n3.Search for and edit a contact\n4.Exit\n"")
choice = int(input())
while choice != 4:
    if choice == 1:
        addressBook.append(Contact(input(""First name?""), input(""Last name?""), input(""Phone number?""), input(""Email?"")))
    elif choice == 2:
        for x in range(len(addressBook)):
            print(addressBook[x].ToString())
    elif choice == 3:
        print(""????"")
    choice = int(input(""What do you want to do?\n1.Add contact\n2.Print out contacts\n3.Search for and edit a contact\n4.Exit\n""))
</code></pre>
"
"60477561","<p>It looks like it might be an import issue or you need to define method for <code>show_grid(x,y)</code>. Let me know if this helps!</p>
","0","","1","1444","3","8","195","60477495","60477561","<p>I have an assignment that is requiring us to create a dot grid along with a curser that moves up, down, right, left, on the grid when given the command. I can't get my move functions to work along with the grid showing with the updated coordinate. This is what I have so far. </p>
"
"60477826","<p>You just need to refresh the window.<br>
I've added a colour toggle so it will toggle between grey and white on a click.</p>

<pre><code>import wx
import wx.grid as gridlib
class MyForm(wx.Frame):

    def __init__(self):
        wx.Frame.__init__(self, None, wx.ID_ANY, ""Sample grid"")

        self.grid = gridlib.Grid(self)
        self.grid.CreateGrid(5,4)
        self.grid.SetCellSize(4,1,1,2)

        self.grid.SetDefaultCellAlignment(wx.ALIGN_CENTRE, wx.ALIGN_CENTRE)

        self.grid.SetColLabelSize(0)            # eliminates spreadsheet-style row &amp; col headers
        self.grid.SetRowLabelSize(0)

        self.grid.SetCellBackgroundColour(4, 3, wx.LIGHT_GREY)

        rowHeight = 50
        colWidth  = 50
        for i in range(1,5):
            self.grid.SetRowSize(i, rowHeight)
        for i in range(0,4):
            self.grid.SetColSize(i, colWidth)

        self.grid.Bind(gridlib.EVT_GRID_CELL_LEFT_CLICK, self.GridLeftClick, self.grid)

    def GridLeftClick(self, event):
        col = event.GetCol()
        row = event.GetRow()
        clr = self.grid.GetCellBackgroundColour(row, col)
        if clr != wx.LIGHT_GREY:
            self.grid.SetCellBackgroundColour(row, col, wx.LIGHT_GREY)
        else:
            self.grid.SetCellBackgroundColour(row, col, wx.WHITE)
        self.Refresh()

app = wx.App()
frame = MyForm().Show()
app.MainLoop()
</code></pre>

<p><a href=""https://i.stack.imgur.com/qictb.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/qictb.png"" alt=""enter image description here""></a></p>
","0","","2","16833","416","37","1242","60477525","60477826","<p>I have the following program that creates a wx grid, sets the background color of one cell, and then handles a left click event by setting the background color of the cell clicked:</p>

<pre><code>import wx
import wx.grid as gridlib
class MyForm(wx.Frame):

    def __init__(self):
        wx.Frame.__init__(self, None, wx.ID_ANY, ""Sample grid"")

        self.grid = gridlib.Grid(self)
        self.grid.CreateGrid(5,4)
        self.grid.SetCellSize(4,1,1,2)

        self.grid.SetDefaultCellAlignment(wx.ALIGN_CENTRE, wx.ALIGN_CENTRE)

        self.grid.SetColLabelSize(0)            # eliminates spreadsheet-style row &amp; col headers
        self.grid.SetRowLabelSize(0)

        self.grid.SetCellBackgroundColour(4, 3, wx.LIGHT_GREY)

        rowHeight = 50
        colWidth  = 50
        for i in range(1,5):
            self.grid.SetRowSize(i, rowHeight)
        for i in range(0,4):
            self.grid.SetColSize(i, colWidth)

        self.grid.Bind(gridlib.EVT_GRID_CELL_LEFT_CLICK, self.GridLeftClick, self.grid)

    def GridLeftClick(self, event):
        col = event.GetCol()
        row = event.GetRow()
        print(f""Got col {col} and row {row}"")
        self.grid.SetCellBackgroundColour(row, col, wx.LIGHT_GREY)

app = wx.App()
frame = MyForm().Show()
app.MainLoop()
</code></pre>

<p>Everything works as I expect except the <code>self.grid.SetCellBackgroundColor(row, col, wx.LIGHT_GREY)</code> statement. The call works when I'm setting up the grid, so I think I have that correct. I get the print statement, so the event binding is working. What else do I have to do for that method to put a background color on the clicked cell?</p>
"
"60477569","<p>You are looking for <a href=""https://docs.python.org/3/library/functions.html#input"" rel=""nofollow noreferrer"">input()</a> function, <a href=""https://docs.python.org/2/tutorial/datastructures.html"" rel=""nofollow noreferrer"">append()</a> method of list. See <a href=""https://stackoverflow.com/a/3940137/5735010"">this</a> answer to know how to reverse a list.</p>

<p>Try this:</p>

<pre><code>array = []
num = int(input(""Enter the length of array: "")) # You need to convert str returned by input to an int using int() constructor
for i in range(num):
    array.append(input(""Enter a number: "")) # You need to use append() method of list
print(array)
print(array[::-1])
</code></pre>

<p>Or </p>

<p>Using <a href=""https://docs.python.org/3/tutorial/datastructures.html#list-comprehensions"" rel=""nofollow noreferrer"">list comprehension</a>:</p>

<pre><code>array = [input(""Enter a number: "") for i in range(int(input(""Enter the length of array: "")))]
</code></pre>

<p>To reverse a list, use</p>

<pre><code>print(array[::-1])
</code></pre>
","0","2020-03-01 17:11:44","1","7385","7807","4","901","60477533","60477569","<pre><code>array=[]
for i in range(5):
    array=input(""Enter a number"")
print(array)
</code></pre>

<p>I need to ask the user to input 5 numbers and then store them within a list, at the end I have to reverse it. </p>
"
"60477592","<p>To add an element at the end of the list you have to use <code>.append</code> method.</p>

<p>try this.</p>

<pre><code>array=[]
for _ in range(5):
    array.append(input())  # use int(input()) to so that you have int type elements

print(array[::-1])  # to print array in reverse order.
</code></pre>

<hr>

<p>You can use list comprehension here.</p>

<pre><code>[input() for _ in range(5)][::-1]  # use int(input()) to so that you have int type elements
</code></pre>
","0","2020-03-01 21:10:33","2","14733","1831","61","1931","60477533","60477569","<pre><code>array=[]
for i in range(5):
    array=input(""Enter a number"")
print(array)
</code></pre>

<p>I need to ask the user to input 5 numbers and then store them within a list, at the end I have to reverse it. </p>
"
"60478222","<p>""tooltipstered"" class is added by javascript and is not available in the plain html document returned by the server.
You can see that when you open the ""source"" of the page not using browser inspector.</p>

<p>As you can see ""tooltipster"" is some jquery plugin, you will need to use some other tool to scrape this page (eg.: selenium).</p>

<pre><code>&lt;script type=""text/javascript"" src=""https://tmssl.akamaized.net//assets/e17e6900/js/jquery.tooltipster.js?lm=1574952016""&gt;&lt;/script&gt;
</code></pre>
","2","","0","324","23","0","8","60477574","60478222","<p>I am trying to srape data from <a href=""https://www.transfermarkt.co.uk/premier-league/startseite/wettbewerb/GB1"" rel=""nofollow noreferrer"">https://www.transfermarkt.co.uk/premier-league/startseite/wettbewerb/GB1</a></p>

<p>I have used this code to do so:</p>

<pre><code>headers = {'User-Agent': 
           'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/47.0.2526.106 Safari/537.36'}

page = 'https://www.transfermarkt.co.uk/premier-league/startseite/wettbewerb/GB1'
pageTree = requests.get(page, headers=headers)
pageTree_text = pageTree.text

pageSoup = BeautifulSoup(pageTree_text, 'html.parser')
</code></pre>

<p>After, I want to find all the links that is connected to each team name, and use this code:</p>

<pre><code>linkLocation = pageSoup.find_all(""a"", {""class"": ""vereinprofil_tooltip tooltipstered""})
linkLocation[0].text
</code></pre>

<p>output:</p>

<hr>

<p>IndexError                                Traceback (most recent call last)
 in 
      1 linkLocation = pageSoup.find_all(""a"", {""class"": ""vereinprofil_tooltip tooltipstered""})
----> 2 linkLocation[0].text</p>

<p>IndexError: list index out of range</p>

<p>Why doesn`t the list have any of the links within it?</p>

<p>Thnx in advcance!</p>
"
"60477683","<p>Convert the list to a set, which automatically gets rid of duplicates. Then compare their size:</p>

<pre class=""lang-py prettyprint-override""><code>l = [1,2,3,4,5,6,7,7,6,5,4]
print(len(l) - len(set(l)))
</code></pre>
","0","","1","3674","7445","142","610","60477597","60477812","<p>I have a code which gives back 10 lists of numbers.</p>

<pre><code>def my_random_list(l: list):
    return sorted(random.sample(list(set(l)), 6))


for _ in range(10):
    print(sorted(my_random_list([i for i in range(1, 43)])))
</code></pre>

<p>I need to count how many duplicates are there in this 10 lists.
How to do it in short and efficient way?</p>
"
"60477736","<p>If your intention is to find out the duplicates across the 10 lists, you can try the following - </p>

<pre class=""lang-py prettyprint-override""><code># Import Counter from collections 
In [11]: from collections import Counter

# Your definition of my_random_list
In [12]: def my_random_list(l: list):
    ...:     return sorted(random.sample(list(set(l)), 6))
    ...:

# Copying your version of creating 10 lists into a lists variable (calling the sorted() here is superfluous in my opinion)
In [13]: lists = [sorted(my_random_list([i for i in range(1, 43)])) for _ in range(10)]

# Count all the entries across all the 10 lists
In [14]: counter = Counter([])

# You can add multiple Counter instances to produce a ""merged"" Counter
In [15]: for l in lists:
    ...:     counter += Counter(l)

# Find the entries whose value exists more than once
In [16]: duplicates = [k for k,v in counter.items() if v &gt; 1]

# Printing all the duplicate entries across the lists
In [17]: duplicates
Out[17]: [6, 16, 20, 37, 38, 2, 9, 29, 1, 18, 33, 3, 17, 19, 31, 15, 21, 42, 41, 11]

# Length of the duplicate list
In [18]: len(duplicates)
Out[18]: 20
</code></pre>

<p>You can read-up on <code>Counter</code> <a href=""https://docs.python.org/2/library/collections.html#collections.Counter"" rel=""nofollow noreferrer"">here</a></p>
","0","2020-03-01 17:29:09","1","5228","3106","0","384","60477597","60477812","<p>I have a code which gives back 10 lists of numbers.</p>

<pre><code>def my_random_list(l: list):
    return sorted(random.sample(list(set(l)), 6))


for _ in range(10):
    print(sorted(my_random_list([i for i in range(1, 43)])))
</code></pre>

<p>I need to count how many duplicates are there in this 10 lists.
How to do it in short and efficient way?</p>
"
"60477812","<p>You can use:</p>

<pre><code>import random
from collections import defaultdict

def my_random_list(l: list):
    return sorted(random.sample(list(set(l)), 6))

repeated = defaultdict(int)
for _ in range(10):
    rl = my_random_list([i for i in range(1, 43)])
    for x in rl:
        repeated[x] += 1
    print(sorted(rl))

repeated = {k:v for k,v in repeated.items() if v &gt; 1}
print(repeated)
# {2: 2, 5: 3, 19: 4, 21: 4, 4: 3, 8: 2, 14: 2, 38: 3, 9: 3, 24: 2, 40: 3, 42: 2, 10: 2, 22: 3, 32: 2, 18: 3, 34: 2, 30: 2, 31: 3}
print(len(repeated.keys())) # how many duplicates
</code></pre>

<p><a href=""https://trinket.io/python3/baca95387b"" rel=""nofollow noreferrer"">Demo</a></p>
","0","2020-03-01 17:34:36","1","74108","5063","858","7248","60477597","60477812","<p>I have a code which gives back 10 lists of numbers.</p>

<pre><code>def my_random_list(l: list):
    return sorted(random.sample(list(set(l)), 6))


for _ in range(10):
    print(sorted(my_random_list([i for i in range(1, 43)])))
</code></pre>

<p>I need to count how many duplicates are there in this 10 lists.
How to do it in short and efficient way?</p>
"
"60477875","<p>A statement of problem is not clear, I assume you want to calculate duplicates in concatenation of these 10 arrays. In this case you could use advantages of <code>numpy.unique</code>:</p>

<pre><code>import random
import numpy as np
collection = [my_random_list(list(range(1, 43))) for i in range(10)]
conc = np.concatenate(collection) # concatenated list
items, cnt = np.unique(conc, return_counts=True) # sorted set of unique items and their counts
output = items[cnt&gt;1] # items that appears more than once
</code></pre>
","0","","1","3747","281","19","426","60477597","60477812","<p>I have a code which gives back 10 lists of numbers.</p>

<pre><code>def my_random_list(l: list):
    return sorted(random.sample(list(set(l)), 6))


for _ in range(10):
    print(sorted(my_random_list([i for i in range(1, 43)])))
</code></pre>

<p>I need to count how many duplicates are there in this 10 lists.
How to do it in short and efficient way?</p>
"
"60477883","<p><code>collections.Counter</code> and <code>itertools.chain</code> will be helpful.</p>

<pre class=""lang-py prettyprint-override""><code>import random

source = [i for i in range(1, 43)]


def my_random_list():
    return sorted(random.sample(source, 6))


random_lists = [my_random_list() for _ in range(10)]
print(random_lists)
</code></pre>

<p>Here are 10 random lists(6 length for each).</p>

<pre><code>&gt;&gt;&gt; [[2, 4, 10, 18, 20, 30], [4, 12, 13, 19, 21, 27], [10, 11, 18, 26, 32, 33], [4, 11, 12, 17, 38, 42], [12, 22, 28, 38, 40, 41], [2, 11, 22, 30, 35, 36], [4, 6, 22, 24, 32, 34], [1, 3, 5, 25, 31, 33], [25, 29, 31, 32, 33, 35], [12, 16, 28, 31, 37, 41]]
</code></pre>

<p>Then you can count it.</p>

<pre class=""lang-py prettyprint-override""><code>from collections import Counter
from itertools import chain


counter = Counter(chain(*random_lists))
print(counter)
</code></pre>

<pre><code>&gt;&gt;&gt; Counter({4: 4, 12: 4, 11: 3, 32: 3, 33: 3, 22: 3, 31: 3, 2: 2, 10: 2, 18: 2, 30: 2, 38: 2, 28: 2, 41: 2, 35: 2, 25: 2, 20: 1, 13: 1, 19: 1, 21: 1, 27: 1, 26: 1, 17: 1, 42: 1, 40: 1, 36: 1, 6: 1, 24: 1, 34: 1, 1: 1, 3: 1, 5: 1, 29: 1, 16: 1, 37: 1})
</code></pre>

<p>And filter the counter with comprehension.</p>

<pre class=""lang-py prettyprint-override""><code>results = [k for k, v in counter.items() if v &gt;= 2]
print(results)
</code></pre>

<pre><code>&gt;&gt;&gt; [2, 4, 10, 18, 30, 12, 11, 32, 33, 38, 22, 28, 41, 35, 25, 31]
</code></pre>
","0","","1","2217","279","150","156","60477597","60477812","<p>I have a code which gives back 10 lists of numbers.</p>

<pre><code>def my_random_list(l: list):
    return sorted(random.sample(list(set(l)), 6))


for _ in range(10):
    print(sorted(my_random_list([i for i in range(1, 43)])))
</code></pre>

<p>I need to count how many duplicates are there in this 10 lists.
How to do it in short and efficient way?</p>
"
"60477782","<p>Use <code>explode</code> and <code>map</code>, then you can do a little grouping to get your output:</p>

<pre><code>(df.set_index('Student ID')['Subjects']
   .str.split(', ')
   .explode()
   .map(df2.set_index('Subjects')['Subject ID'])
   .reset_index()
   .groupby('Subjects')['Student ID']
   .agg(list))

Subjects
Bio13                            [S1, S4]
Che13                    [S1, S2, S3, S4]
Eco13                                [S6]
EngLit13                         [S5, S9]
FMat13                               [S7]
Geo13                                [S6]
His13                                [S5]
Mat13       [S1, S2, S3, S4, S6, S7, S10]
Phy13                            [S1, S7]
Name: Student ID, dtype: object
</code></pre>

<p>From here, call <code>.to_dict()</code> if you want the result in a dictionary.</p>
","0","","1","266035","10142","8528","64481","60477626","60477782","<p>I am very new to Python and came across a problem that I could not solve.</p>

<p>I have two Dataframe extracted columns only needed to consider, for example,</p>

<pre><code>df1 
    Student ID                                          Subjects
0           S1                Maths, Physics, Chemistry, Biology
1           S2                       Maths, Chemistry, Computing
2           S3                       Maths, Chemistry, Computing
3           S4                         Biology, Chemistry, Maths
4           S5               English Literature, History, French
5           S6                       Economics, Maths, Geography
6           S7               Further Mathematics, Maths, Physics
7           S8                    Arts, Film Studies, Psychology
8           S9   English Literature, English Language, Classical
9          S10                        Business, Computing, Maths

df2
   Subject ID             Subjects
58      Che13            Chemistry
59      Bio13              Biology
60      Mat13                Maths
61     FMat13  Further Mathematics
62      Phy13              Physics
63      Eco13            Economics
64      Geo13            Geography
65      His13              History
66  EngLang13     English Langauge
67   EngLit13   English Literature
</code></pre>

<p>How can I compare for every df2 subjects, if there is a student taking that subject, make a dictionary with key ""Subject ID"" and values ""student ID""?</p>

<p>Desired output will be something like;</p>

<pre><code>Che13:[S1, S2, S3, ...]
Bio13:[S1,S4,...]
</code></pre>
"
"60478142","<p>Not pythonic but simple</p>

<pre><code>{row['Subject ID'] : 
      df1[df1.Subjects.str.contains(row['Subjects'])]['Student ID'].to_list() 
      for _, row in df2.iterrows()}
</code></pre>

<p>What are we doing :</p>

<p>Iterate over all the Subjects and check if the Subject string lies in the subjects taken by a student. If so, get the students ID. </p>
","0","","0","12487","27","13","826","60477626","60477782","<p>I am very new to Python and came across a problem that I could not solve.</p>

<p>I have two Dataframe extracted columns only needed to consider, for example,</p>

<pre><code>df1 
    Student ID                                          Subjects
0           S1                Maths, Physics, Chemistry, Biology
1           S2                       Maths, Chemistry, Computing
2           S3                       Maths, Chemistry, Computing
3           S4                         Biology, Chemistry, Maths
4           S5               English Literature, History, French
5           S6                       Economics, Maths, Geography
6           S7               Further Mathematics, Maths, Physics
7           S8                    Arts, Film Studies, Psychology
8           S9   English Literature, English Language, Classical
9          S10                        Business, Computing, Maths

df2
   Subject ID             Subjects
58      Che13            Chemistry
59      Bio13              Biology
60      Mat13                Maths
61     FMat13  Further Mathematics
62      Phy13              Physics
63      Eco13            Economics
64      Geo13            Geography
65      His13              History
66  EngLang13     English Langauge
67   EngLit13   English Literature
</code></pre>

<p>How can I compare for every df2 subjects, if there is a student taking that subject, make a dictionary with key ""Subject ID"" and values ""student ID""?</p>

<p>Desired output will be something like;</p>

<pre><code>Che13:[S1, S2, S3, ...]
Bio13:[S1,S4,...]
</code></pre>
"
"65602375","<p>The answer is to make a function (I called it Â«camera_enemyÂ Â») that returns the value of <code>enemy.pos.x+background.pos.x</code>. Then, when blitting the enemy, write <code>win.blit(enemy_img, (camera_enemy, enemy.pos.y))</code></p>
","0","","1","134","3","1","21","60477678","65602375","<p>I'd like to have the enemy doing the same thing in loop : it goes left to x = 150 and then goes right to x = 1300. But when the player moves, the background moves also, and I want the enemy to go right and left between to specific points on the background, and not between the two coordinates of the game window.
It's hard to explain, so ask if you want something more precise.
I don't really know what code I need to show, so here's the code for player movement and enemy movement :</p>
<pre><code>bg_speed = 0
player_speed = 100
enemy_speed = 80

#Enemy
if enemy_animation:
    win.blit(enemy[enemycount//3], (enemyX, enemyY)) 
    enemycount += 1

    if enemy_vel &gt; 0:
        if enemyX &gt;= 1300:
            enemy_vel = -1
        else:
            if left == True and playerX &lt;= 100:
                enemyX += (enemy_speed + player_speed) * dt
            elif left == True and playerX &gt; 100:
                enemyX += (enemy_speed + (player_speed / 5)) * dt
            elif right == True and playerX &gt;= 1350:
                enemyX += (enemy_speed - player_speed) * dt
            elif right == True and playerX &lt; 1350:
                enemyX += (enemy_speed - (player_speed / 5)) * dt
            else:
                enemyX += enemy_speed * dt
    elif enemy_vel &lt; 0:
        if enemyX &lt;= 150:
            enemy_vel = 1
        else:
            if left == True and playerX &lt;= 100:
                enemyX -= (enemy_speed - player_speed) * dt
            elif left == True and playerX &gt; 100:
                enemyX -= (enemy_speed - (player_speed / 5)) * dt
            elif right == True and playerX &gt;= 1350:
                enemyX -= (enemy_speed + player_speed) * dt
            elif right == True and playerX &lt; 1350:
                enemyX -= (enemy_speed + (player_speed / 5)) * dt
            else:
                enemyX -= enemy_speed * dt

#Player :
if left:
    win.blit(walkLeft[walkcount//1], (playerX-20,playerY))

    if playerX &gt; 100:
        playerX -= (player_speed + (player_speed / 5)) * dt  #vitesse du joueur = 1/3
        backgroundX += (player_speed / 5) * dt #vitesse du fond d'Ã©cran = 2/3
        if playerX == 100: 
            playerX -= 0
            backgroundX += player_speed * dt
    else:
        backgroundX += player_speed * dt

elif right:
    win.blit(walkRight[walkcount//1], (playerX-50,playerY))

    if playerX &lt; 1350:
        playerX += (player_speed + (player_speed / 5)) * dt
        backgroundX -= (player_speed / 5) * dt
        if playerX == 1350:
            playerX += 0
            backgroundX -= player_speed * dt
    else:
        backgroundX -= player_speed * dt
</code></pre>
"
"60477804","<p>Here's your answer: <a href=""https://stackoverflow.com/questions/24108507/beautiful-soup-resultset-object-has-no-attribute-find-all"">Beautiful Soup: &#39;ResultSet&#39; object has no attribute &#39;find_all&#39;?</a></p>

<p>However, I tried running your script and was running into a different issue. The ""table"" element didn't even exist. </p>
","0","","0","1588","202","71","228","60477682","60478613","<p>im trying to scrape the first major table from the following site using BeautifulSoup :
<a href=""https://dailyfantasyrankings.com.au/resources/nba/cheatsheet/moneyball/allproj.php"" rel=""nofollow noreferrer"">https://dailyfantasyrankings.com.au/resources/nba/cheatsheet/moneyball/allproj.php</a></p>

<p>Im receiving the error:
AttributeError: ResultSet object has no attribute 'find_all'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?</p>

<p>Im sure other parts of my code arent quite right but was hoping someone could assist!</p>

<p>Code:</p>

<pre><code>import requests
from urllib.request import urlopen
from bs4 import BeautifulSoup
import pandas as pd

URL = 'https://dailyfantasyrankings.com.au/resources/nba/cheatsheet/moneyball/allproj.php'
response = requests.get(URL)
html = response.content
soup = BeautifulSoup(response.content, 'html.parser')

table = soup.find('table', attrs={'class': 'xl12520945'})

columns = ['#', 'PLAYER', 'POS', '@', 'TEAM', 'OPP', 'M-UP', 'PACE', 'REST', 'PRICE', 'PROJ', 'VALUE', 'AVE']
df = pd.DataFrame(columns=columns)

trs = table.find_all('tr')
for tr in trs:
    tds = tr.find_all('td')
    row = [td.text.replace('\n','') for td in tds]
    df = df.append(pd.Series(row, index=columns), ignore_index=True)

df.to_csv('dfr_proj.csv', index = False)
</code></pre>
"
"60478613","<p>The table you're trying to scrape is in an iframe, so it's better to get the iframe source html instead of the page html</p>

<pre><code>URL = 'https://dailyfantasyrankings.com.au/resources/nba/htm/projections/mballproj.htm'
</code></pre>

<p>Get the table with CSS selector instead of class name because there is an issue with how HTML is formatted on the source page:</p>

<pre><code>table = soup.select(""#Finish_20945 &gt; table"")[0]
</code></pre>

<p>Working code. Change are marked with code comments:</p>

<pre><code>import requests
from bs4 import BeautifulSoup
import pandas as pd
#CHANGED LINE BELOW
URL = 'https://dailyfantasyrankings.com.au/resources/nba/htm/projections/mballproj.htm'
response = requests.get(URL)
soup = BeautifulSoup(response.content, 'html.parser')
#CHANGED LINE BELOW
table = soup.select(""#Finish_20945 &gt; table"")[0]
columns = ['#', 'PLAYER', 'POS', '@', 'TEAM', 'OPP', 'M-UP', 'PACE', 'REST', 'PRICE', 'PROJ', 'VALUE', 'AVE']
df = pd.DataFrame(columns=columns)
trs = table.find_all('tr')
for tr in trs:
    tds = tr.find_all('td')
    row = [td.text.replace('\n', '') for td in tds]
    print(row)
    # df = df.append(pd.Series(row, index=columns), ignore_index=True)

df.to_csv('dfr_proj.csv', index=False)
</code></pre>

<p>Output:</p>

<pre><code>['', '', '', '', '', '', '', '', '', '', '', 'â†“', 'â†“', '', '\xa0', '\xa0', '\xa0', '\xa0', '\xa0']
['#', 'Player', '\xa0', 'Pos', '@', 'Team', 'Opp', 'M-UP', 'Pace', 'Rest', 'Price', 'Proj', 'Value', 'Ave', 'Last 5 Games']
['1', 'A. Davis', '\xa0', 'PF', 'A', 'LAL', 'NOP', '18', '3.5', 'B2B', '$10,800', '61', '5.6', '51', '70', '52', '61', '41', '37']
['2', 'B. Beal', '\xa0', 'SG', 'A', 'WAS', 'GSW', '5', '0.3', '1', '$9,600', '57', '5.9', '46', '34', '67', '53', '51', '67']
['3', 'L. James', '\xa0', 'SF', 'A', 'LAL', 'NOP', '3', '3.5', 'B2B', '$10,400', '53', '5.1', '51', '51', '50', '55', '\xa0', '45']
['4', 'N. Jokic', '\xa0', 'C', 'H', 'DEN', 'TOR', '19', '0.4', '1', '$10,100', '47', '4.7', '45', '53', '52', '50', '35', '35']
['5', 'P. Siakam', '\xa0', 'SF', 'A', 'TOR', 'DEN', '26', '-3.0', '1', '$8,400', '45', '5.4', '41', '34', '63', '28', '33', '50']
['6', 'K. Lowry', '\xa0', 'PG', 'A', 'TOR', 'DEN', '11', '-3.0', '1', '$7,600', '44', '5.8', '38', '43', '31', '57', '23', '47']
['7', 'A. Wiggins', '\xa0', 'SF', 'H', 'GSW', 'WAS', '11', '3.0', 'B2B', '$7,700', '42', '5.5', '36', '34', '34', '16', '\xa0', '46']
['8', 'B. Ingram', '\xa0', 'SF', 'H', 'NOP', 'LAL', '16', '0.5', '1', '$7,900', '40', '5.1', '40', '\xa0', '26', '32', '47', '47']
['9', 'C. Wood', 'GTD', 'PF', 'A', 'DET', 'SAC', '26', '-2.0', '1', '$7,900', '39', '4.9', '23', '48', '35', '44', '36', '48']
['10', 'D. Fox', 'GTD', 'PG', 'H', 'SAC', 'DET', '3', '-2.4', '1', '$7,500', '38', '5.1', '37', '34', '35', '36', '\xa0', '42']
['11', 'J. Holiday', '\xa0', 'SG', 'H', 'NOP', 'LAL', '24', '0.5', '1', '$8,900', '38', '4.3', '40', '35', '44', '52', '33', '40']
['12', 'D. Rose', '\xa0', 'PG', 'A', 'DET', 'SAC', '18', '-2.0', '1', '$6,000', '36', '6.0', '30', '11', '19', '17', '32', '47']
['13', 'Z. Williamson', '\xa0', 'PF', 'H', 'NOP', 'LAL', '16', '0.5', '1', '$8,300', '36', '4.3', '33', '41', '37', '41', '41', '33']
['14', 'D. Lee', '\xa0', 'SG', 'H', 'GSW', 'WAS', '7', '3.0', 'B2B', '$6,100', '34', '5.7', '24', '26', '36', '32', '25', '41']
['15', 'M. Chriss', '\xa0', 'C', 'H', 'GSW', 'WAS', '21', '3.0', 'B2B', '$6,400', '34', '5.3', '22', '21', '\xa0', '37', '20', '36']
['16', 'O. Anunoby', '\xa0', 'SF', 'A', 'TOR', 'DEN', '27', '-3.0', '1', '$5,000', '33', '6.7', '24', '12', '31', '19', '29', '49']
['17', 'J. Murray', '\xa0', 'PG', 'H', 'DEN', 'TOR', '15', '0.4', '1', '$7,200', '32', '4.4', '33', '49', '35', '29', '39', '17']
['18', 'L. Ball', '\xa0', 'PG', 'H', 'NOP', 'LAL', '30', '0.5', '1', '$6,900', '32', '4.6', '32', '33', '32', '33', '30', '46']
['19', 'E. Paschall', '\xa0', 'PF', 'H', 'GSW', 'WAS', '21', '3.0', 'B2B', '$4,600', '30', '6.5', '23', '21', '20', '20', '30', '34']
['20', 'N. Powell', '\xa0', 'SG', 'A', 'TOR', 'DEN', '10', '-3.0', '1', '$4,500', '28', '6.2', '26', '\xa0', '\xa0', '\xa0', '\xa0', '27']
['21', 'R. Hachimura', '\xa0', 'PF', 'A', 'WAS', 'GSW', '15', '0.3', '1', '$5,100', '28', '5.4', '25', '36', '25', '22', '20', '31']
['22', 'B. Hield', '\xa0', 'SG', 'H', 'SAC', 'DET', '26', '-2.4', '1', '$6,000', '27', '4.4', '32', '39', '12', '32', '24', '24']
['23', 'W. Barton', '\xa0', 'SF', 'H', 'DEN', 'TOR', '11', '0.4', '1', '$5,800', '26', '4.5', '31', '\xa0', '35', '25', '16', '25']
['24', 'H. Giles III', '\xa0', 'PF', 'H', 'SAC', 'DET', '7', '-2.4', '1', '$5,100', '26', '5.1', '15', '15', '33', '33', '29', '30']
['25', 'N. Bjelica', '\xa0', 'PF', 'H', 'SAC', 'DET', '11', '-2.4', '1', '$5,100', '26', '5.1', '27', '26', '24', '10', '31', '31']
['26', 'J. Grant', '\xa0', 'PF', 'H', 'DEN', 'TOR', '23', '0.4', '1', '$4,500', '25', '5.5', '21', '26', '8', '17', '35', '35']
['27', 'S. Napier', '\xa0', 'PG', 'A', 'WAS', 'GSW', '6', '0.3', '1', '$5,000', '24', '4.7', '22', '18', '17', '46', '22', '13']
['28', 'D. Bender', '\xa0', 'PF', 'H', 'GSW', 'WAS', '21', '3.0', 'B2B', '$3,900', '23', '5.9', '12', '\xa0', '20', '8', '13', '39']
['29', 'D. Favors', '\xa0', 'C', 'H', 'NOP', 'LAL', '30', '0.5', '1', '$5,400', '23', '4.3', '27', '21', '27', '24', '18', '37']
['30', 'K. Bazemore', '\xa0', 'SF', 'H', 'SAC', 'DET', '26', '-2.4', '1', '$5,400', '23', '4.2', '19', '25', '47', '28', '18', '26']
['31', 'D. Bertans', '\xa0', 'PF', 'A', 'WAS', 'GSW', '24', '0.3', '1', '$5,100', '23', '4.5', '26', '26', '25', '\xa0', '23', '19']
['32', 'H. Barnes', '\xa0', 'SF', 'H', 'SAC', 'DET', '29', '-2.4', '1', '$5,200', '23', '4.4', '25', '35', '36', '24', '29', '15']
['33', 'T. Bryant', '\xa0', 'C', 'A', 'WAS', 'GSW', '11', '0.3', '1', '$4,100', '23', '5.5', '25', '20', '13', '\xa0', '15', '22']
['34', 'B. Knight', '\xa0', 'PG', 'A', 'DET', 'SAC', '23', '-2.0', '1', '$3,900', '22', '5.8', '11', '\xa0', '1', '22', '25', '28']
['35', 'R.\r  Hollis-Jefferson', '\xa0', 'PF', 'A', 'TOR', 'DEN', '26', '-3.0', '1', '$4,000', '22', '5.4', '19', '12', '22', '18', '25', '15']
['36', 'I. Smith', '\xa0', 'PG', 'A', 'WAS', 'GSW', '8', '0.3', '1', '$5,000', '22', '4.3', '24', '26', '29', '30', '12', '16']
['37', 'R. Rondo', '\xa0', 'PG', 'A', 'LAL', 'NOP', '4', '3.5', 'B2B', '$4,300', '21', '4.9', '19', '14', '28', '7', '30', '10']
['38', 'A. Len', '\xa0', 'C', 'H', 'SAC', 'DET', '7', '-2.4', '1', '$4,000', '21', '5.2', '20', '\xa0', '16', '11', '26', '24']
['39', 'B. Bogdanovic', '\xa0', 'SG', 'H', 'SAC', 'DET', '25', '-2.4', '1', '$5,100', '20', '4.0', '24', '16', '32', '28', '23', '24']
['40', 'D. Howard', '\xa0', 'C', 'A', 'LAL', 'NOP', '29', '3.5', 'B2B', '$4,400', '20', '4.6', '22', '12', '20', '15', '36', '20']
['41', 'M. Mulder', '\xa0', '-', 'H', 'GSW', 'WAS', '7', '3.0', 'B2B', '-', '20', '-', '-', '\xa0', '\xa0', '\xa0', '7', '21']
['42', 'M. Morris', '\xa0', 'PG', 'H', 'DEN', 'TOR', '15', '0.4', '1', '$4,600', '19', '4.2', '19', '26', '12', '34', '29', '18']
['43', 'J. Henson', '\xa0', 'C', 'A', 'DET', 'SAC', '21', '-2.0', '1', '$4,500', '19', '4.3', '17', '4', '12', '31', '14', '21']
['44', 'N. Melli', '\xa0', 'PF', 'H', 'NOP', 'LAL', '30', '0.5', '1', '$4,100', '19', '4.7', '14', '17', '24', '30', '22', '20']
['45', 'K. Caldwell-Pope', '\xa0', 'SG', 'A', 'LAL', 'NOP', '2', '3.5', 'B2B', '$4,200', '19', '4.5', '17', '19', '16', '22', '20', '16']
['46', 'T. Brown Jr.', '\xa0', 'SF', 'A', 'WAS', 'GSW', '24', '0.3', '1', '$4,400', '19', '4.3', '23', '24', '17', '9', '12', '24']
['47', 'K. Looney', '\xa0', 'C', 'H', 'GSW', 'WAS', '15', '3.0', 'B2B', '$3,500', '19', '5.3', '10', '12', '15', '14', '16', '22']
['48', 'S. Mykhailiuk', '\xa0', 'SG', 'A', 'DET', 'SAC', '23', '-2.0', '1', '$3,500', '18', '5.2', '15', '13', '16', '8', '10', '27']
['49', 'L. Galloway', '\xa0', 'SG', 'A', 'DET', 'SAC', '18', '-2.0', '1', '$4,100', '18', '4.4', '17', '17', '13', '26', '14', '12']
['50', 'J. Toscano-Anderson', '\xa0', 'SF', 'H', 'GSW', 'WAS', '11', '3.0', 'B2B', '$4,300', '18', '4.2', '18', '32', '38', '13', '10', '15']
['51', 'A. Bradley', '\xa0', 'SG', 'A', 'LAL', 'NOP', '3', '3.5', 'B2B', '$4,000', '18', '4.4', '15', '33', '10', '8', '19', '8']
['52', 'P. Millsap', 'GTD', 'PF', 'H', 'DEN', 'TOR', '23', '0.4', '1', '$5,400', '17', '3.2', '25', '27', '11', '41', '17', '8']
['53', 'C. Boucher', '\xa0', 'PF', 'A', 'TOR', 'DEN', '25', '-3.0', '1', '$4,200', '17', '3.9', '16', '4', '21', '37', '20', '8']
['54', 'T. Snell', '\xa0', 'SG', 'A', 'DET', 'SAC', '23', '-2.0', '1', '$3,900', '17', '4.2', '15', '30', '15', '9', '28', '13']
['55', 'K. Kuzma', '\xa0', 'PF', 'A', 'LAL', 'NOP', '18', '3.5', 'B2B', '$4,400', '17', '3.8', '20', '17', '22', '13', '25', '16']
['56', 'A. Caruso', '\xa0', 'PG', 'A', 'LAL', 'NOP', '4', '3.5', 'B2B', '$4,000', '16', '4.1', '14', '18', '9', '32', '14', '14']
['57', 'M. Plumlee', '\xa0', 'C', 'H', 'DEN', 'TOR', '19', '0.4', '1', '$4,200', '16', '3.8', '19', '\xa0', '12', '17', '21', '16']
['58', 'T. Davis', '\xa0', 'SG', 'A', 'TOR', 'DEN', '10', '-3.0', '1', '$4,600', '16', '3.4', '16', '3', '19', '21', '20', '8']
['59', 'J. Hart', '\xa0', 'SG', 'H', 'NOP', 'LAL', '22', '0.5', '1', '$4,900', '15', '3.2', '24', '20', '33', '20', '17', '13']
['60', 'J. Robinson', '\xa0', 'PG', 'A', 'WAS', 'GSW', '19', '0.3', '1', '$3,900', '14', '3.6', '8', '14', '10', '10', '22', '18']
['61', 'G. Harris', '\xa0', 'SG', 'H', 'DEN', 'TOR', '21', '0.4', '1', '$4,300', '14', '3.3', '20', '18', '10', '24', '19', '10']
['62', 'C. Joseph', 'GTD', 'PG', 'H', 'SAC', 'DET', '3', '-2.4', '1', '$3,900', '14', '3.6', '17', '17', '5', '19', '33', '14']
['63', 'S. Doumbouya', '\xa0', 'PF', 'A', 'DET', 'SAC', '23', '-2.0', '1', '$3,500', '14', '4.0', '12', '10', '18', '14', '3', '14']
['64', 'M. Porter Jr.', '\xa0', 'PF', 'H', 'DEN', 'TOR', '23', '0.4', '1', '$3,900', '13', '3.4', '16', '\xa0', '5', '6', '22', '15']
['65', 'J. McGee', '\xa0', 'C', 'A', 'LAL', 'NOP', '29', '3.5', 'B2B', '$3,900', '12', '3.0', '20', '10', '14', '13', '21', '7']
['66', 'T. Maker', 'GTD', 'C', 'A', 'DET', 'SAC', '21', '-2.0', '1', '$4,600', '11', '2.5', '11', '25', '25', '16', '9', '6']
['67', 'I. Mahinmi', '\xa0', 'C', 'A', 'WAS', 'GSW', '11', '0.3', '1', '$4,100', '11', '2.6', '20', '18', '6', '21', '15', '14']
['68', 'M. Morris', '\xa0', 'SF', 'A', 'LAL', 'NOP', '18', '3.5', 'B2B', '$4,200', '10', '2.4', '19', '\xa0', '\xa0', '8', '13', '13']
['69', 'E. Moore', '\xa0', 'SF', 'H', 'NOP', 'LAL', '24', '0.5', '1', '$3,500', '9', '2.7', '16', '15', '10', '6', '3', '19']
['70', 'I. Bonga', '\xa0', 'SF', 'A', 'WAS', 'GSW', '19', '0.3', '1', '$3,500', '9', '2.7', '12', '8', '3', '13', '14', '7']
['71', 'T. Craig', '\xa0', 'SG', 'H', 'DEN', 'TOR', '21', '0.4', '1', '$3,900', '9', '2.3', '12', '20', '7', '6', '\xa0', '12']
['72', 'M. Wagner', '\xa0', 'C', 'A', 'WAS', 'GSW', '11', '0.3', '1', '$4,000', '8', '2.1', '20', '11', '12', '28', '8', '4']
['73', 'P. McCaw', '\xa0', 'SG', 'A', 'TOR', 'DEN', '10', '-3.0', '1', '$3,500', '8', '2.3', '13', '9', '\xa0', '\xa0', '\xa0', '7']
['74', 'M. Thomas', '\xa0', 'SG', 'A', 'TOR', 'DEN', '10', '-3.0', '1', '$3,500', '7', '2.0', '8', '1', '1', '18', '14', '4']
['75', 'J. Hayes', '\xa0', 'C', 'H', 'NOP', 'LAL', '30', '0.5', '1', '$3,500', '3', '0.9', '17', '11', '9', '0', '\xa0', '10']
['76', 'P. Dozier', '\xa0', 'SG', 'H', 'DEN', 'TOR', '15', '0.4', '1', '$3,500', '3', '0.7', '10', '6', '\xa0', '0', '3', '6']
['77', 'J. McRae', '\xa0', 'SG', 'H', 'DEN', 'TOR', '11', '0.4', '1', '$4,100', '2', '0.6', '20', '6', '\xa0', '0', '\xa0', '3']
['78', 'J. Okafor', '\xa0', 'C', 'H', 'NOP', 'LAL', '30', '0.5', '1', '$3,500', '2', '0.6', '16', '\xa0', '\xa0', '\xa0', '2', '\xa0']
['79', 'F. Jackson', '\xa0', 'PG', 'H', 'NOP', 'LAL', '30', '0.5', '1', '$3,500', '1', '0.2', '9', '7', '0', '\xa0', '\xa0', '4']
</code></pre>
","4","","0","1541","222","23","129","60477682","60478613","<p>im trying to scrape the first major table from the following site using BeautifulSoup :
<a href=""https://dailyfantasyrankings.com.au/resources/nba/cheatsheet/moneyball/allproj.php"" rel=""nofollow noreferrer"">https://dailyfantasyrankings.com.au/resources/nba/cheatsheet/moneyball/allproj.php</a></p>

<p>Im receiving the error:
AttributeError: ResultSet object has no attribute 'find_all'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?</p>

<p>Im sure other parts of my code arent quite right but was hoping someone could assist!</p>

<p>Code:</p>

<pre><code>import requests
from urllib.request import urlopen
from bs4 import BeautifulSoup
import pandas as pd

URL = 'https://dailyfantasyrankings.com.au/resources/nba/cheatsheet/moneyball/allproj.php'
response = requests.get(URL)
html = response.content
soup = BeautifulSoup(response.content, 'html.parser')

table = soup.find('table', attrs={'class': 'xl12520945'})

columns = ['#', 'PLAYER', 'POS', '@', 'TEAM', 'OPP', 'M-UP', 'PACE', 'REST', 'PRICE', 'PROJ', 'VALUE', 'AVE']
df = pd.DataFrame(columns=columns)

trs = table.find_all('tr')
for tr in trs:
    tds = tr.find_all('td')
    row = [td.text.replace('\n','') for td in tds]
    df = df.append(pd.Series(row, index=columns), ignore_index=True)

df.to_csv('dfr_proj.csv', index = False)
</code></pre>
"
"60485517","<p>Another option is just use Pandas to read in the table (it uses Beautifulsoup under the hood)</p>

<pre><code>import pandas as pd

URL = 'https://dailyfantasyrankings.com.au/resources/nba/htm/projections/mballproj.htm'
df = pd.read_html(URL)[0]
df.columns = df.iloc[1,:]
df = df.iloc[2:,:]

df.to_csv('dfr_proj.csv', index=False)
</code></pre>

<p><strong>Output:</strong></p>

<pre><code>print(df.to_string())
1      #              Player  NaN Pos  @ Team  Opp M-UP  Pace Rest    Price Proj Value Ave Last 5 Games Last 5 Games Last 5 Games Last 5 Games Last 5 Games
2      1            A. Davis  GTD  PF  A  LAL  NOP   18   3.5  B2B  $10,800   59   5.5  51           70           52           61           41           37
3      2             B. Beal  NaN  SG  A  WAS  GSW    5   0.3    1   $9,600   57   5.9  46           34           67           53           51           67
4      3            L. James  NaN  SF  A  LAL  NOP    3   3.5  B2B  $10,400   53   5.1  51           51           50           55          NaN           45
5      4            N. Jokic  NaN   C  H  DEN  TOR   19   0.4    1  $10,100   51   5.1  45           53           52           50           35           35
6      5           P. Siakam  NaN  SF  A  TOR  DEN   26  -3.0    1   $8,400   45   5.4  41           34           63           28           33           50
7      6            K. Lowry  NaN  PG  A  TOR  DEN   11  -3.0    1   $7,600   45   5.9  38           43           31           57           23           47
8      7          A. Wiggins  NaN  SF  H  GSW  WAS   11   3.0  B2B   $7,700   42   5.5  36           34           34           16          NaN           46
9      8             C. Wood  NaN  PF  A  DET  SAC   26  -2.0    1   $7,900   42   5.3  23           48           35           44           36           48
10     9           B. Ingram  NaN  SF  H  NOP  LAL   16   0.5    1   $7,900   40   5.1  40          NaN           26           32           47           47
11    10              D. Fox  NaN  PG  H  SAC  DET    3  -2.4    1   $7,500   38   5.1  37           34           35           36          NaN           42
12    11          J. Holiday  NaN  SG  H  NOP  LAL   24   0.5    1   $8,900   38   4.3  40           35           44           52           33           40
13    12             D. Rose  NaN  PG  A  DET  SAC   18  -2.0    1   $6,000   36   6.0  30           11           19           17           32           47
14    13       Z. Williamson  NaN  PF  H  NOP  LAL   16   0.5    1   $8,300   36   4.3  33           41           37           41           41           33
15    14           M. Chriss  NaN   C  H  GSW  WAS   21   3.0  B2B   $6,400   34   5.3  22           21          NaN           37           20           36
16    15          O. Anunoby  NaN  SF  A  TOR  DEN   27  -3.0    1   $5,000   33   6.7  24           12           31           19           29           49
17    16              D. Lee  NaN  SG  H  GSW  WAS    7   3.0  B2B   $6,100   32   5.3  24           26           36           32           25           41
18    17           J. Murray  NaN  PG  H  DEN  TOR   15   0.4    1   $7,200   32   4.4  33           49           35           29           39           17
19    18             L. Ball  NaN  PG  H  NOP  LAL   30   0.5    1   $6,900   32   4.6  32           33           32           33           30           46
20    19           N. Powell  NaN  SG  A  TOR  DEN   10  -3.0    1   $4,500   30   6.7  26          NaN          NaN          NaN          NaN           27
21    20         E. Paschall  NaN  PF  H  GSW  WAS   21   3.0  B2B   $4,600   30   6.5  23           21           20           20           30           34
22    21            J. Grant  NaN  PF  H  DEN  TOR   23   0.4    1   $4,500   30   6.6  21           26            8           17           35           35
23    22        R. Hachimura  NaN  PF  A  WAS  GSW   15   0.3    1   $5,100   28   5.4  25           36           25           22           20           31
24    23            B. Hield  NaN  SG  H  SAC  DET   26  -2.4    1   $6,000   27   4.4  32           39           12           32           24           24
25    24           W. Barton  NaN  SF  H  DEN  TOR   11   0.4    1   $5,800   26   4.5  31          NaN           35           25           16           25
26    25        H. Giles III  NaN  PF  H  SAC  DET    7  -2.4    1   $5,100   26   5.1  15           15           33           33           29           30
27    26          N. Bjelica  NaN  PF  H  SAC  DET   11  -2.4    1   $5,100   26   5.1  27           26           24           10           31           31
28    27           S. Napier  NaN  PG  A  WAS  GSW    6   0.3    1   $5,000   24   4.7  22           18           17           46           22           13
29    28       M. Porter Jr.  NaN  PF  H  DEN  TOR   23   0.4    1   $3,900   23   6.0  16          NaN            5            6           22           15
30    29           D. Bender  NaN  PF  H  GSW  WAS   21   3.0  B2B   $3,900   23   5.9  12          NaN           20            8           13           39
31    30           D. Favors  NaN   C  H  NOP  LAL   30   0.5    1   $5,400   23   4.3  27           21           27           24           18           37
32    31         K. Bazemore  NaN  SF  H  SAC  DET   26  -2.4    1   $5,400   23   4.2  19           25           47           28           18           26
33    32          D. Bertans  NaN  PF  A  WAS  GSW   24   0.3    1   $5,100   23   4.5  26           26           25          NaN           23           19
34    33           H. Barnes  NaN  SF  H  SAC  DET   29  -2.4    1   $5,200   23   4.4  25           35           36           24           29           15
35    34           T. Bryant  NaN   C  A  WAS  GSW   11   0.3    1   $4,100   23   5.5  25           20           13          NaN           15           22
36    35           B. Knight  NaN  PG  A  DET  SAC   23  -2.0    1   $3,900   22   5.8  11          NaN            1           22           25           28
37    36           J. Henson  NaN   C  A  DET  SAC   21  -2.0    1   $4,500   22   5.0  17            4           12           31           14           21
38    37  R.  Hollis-Jeffers  NaN  PF  A  TOR  DEN   26  -3.0    1   $4,000   22   5.4  19           12           22           18           25           15
39    38            I. Smith  NaN  PG  A  WAS  GSW    8   0.3    1   $5,000   22   4.3  24           26           29           30           12           16
40    39              A. Len  NaN   C  H  SAC  DET    7  -2.4    1   $4,000   21   5.2  20          NaN           16           11           26           24
41    40       B. Bogdanovic  NaN  SG  H  SAC  DET   25  -2.4    1   $5,100   20   4.0  24           16           32           28           23           24
42    41           D. Howard  NaN   C  A  LAL  NOP   29   3.5  B2B   $4,400   20   4.6  22           12           20           15           36           20
43    42             J. Hart  NaN  SG  H  NOP  LAL   22   0.5    1   $4,900   19   4.0  24           20           33           20           17           13
44    43           M. Morris  NaN  PG  H  DEN  TOR   15   0.4    1   $4,600   19   4.2  19           26           12           34           29           18
45    44            R. Rondo  NaN  PG  A  LAL  NOP    4   3.5  B2B   $4,300   19   4.5  19           14           28            7           30           10
46    45        T. Brown Jr.  NaN  SF  A  WAS  GSW   24   0.3    1   $4,400   19   4.3  23           24           17            9           12           24
47    46            T. Davis  NaN  SG  A  TOR  DEN   10  -3.0    1   $4,600   19   4.1  16            3           19           21           20            8
48    47          C. Boucher  NaN  PF  A  TOR  DEN   25  -3.0    1   $4,200   19   4.4  16            4           21           37           20            8
49    48       S. Mykhailiuk  NaN  SG  A  DET  SAC   23  -2.0    1   $3,500   18   5.2  15           13           16            8           10           27
50    49     K. Caldwell-Pop  NaN  SG  A  LAL  NOP    2   3.5  B2B   $4,200   18   4.3  17           19           16           22           20           16
51    50         L. Galloway  NaN  SG  A  DET  SAC   18  -2.0    1   $4,100   18   4.4  17           17           13           26           14           12
52    51      J. Toscano-And  NaN  SF  H  GSW  WAS   11   3.0  B2B   $4,300   18   4.2  18           32           38           13           10           15
53    52            J. Poole  GTD  SG  H  GSW  WAS   18   3.0  B2B   $4,900   18   3.6  15           27           27           20           25          NaN
54    53           K. Looney  NaN   C  H  GSW  WAS   15   3.0  B2B   $3,500   18   5.1  10           12           15           14           16           22
55    54          A. Bradley  NaN  SG  A  LAL  NOP    3   3.5  B2B   $4,000   18   4.4  15           33           10            8           19            8
56    55            T. Snell  NaN  SG  A  DET  SAC   23  -2.0    1   $3,900   17   4.2  15           30           15            9           28           13
...
</code></pre>
","0","","0","16881","862","128","1314","60477682","60478613","<p>im trying to scrape the first major table from the following site using BeautifulSoup :
<a href=""https://dailyfantasyrankings.com.au/resources/nba/cheatsheet/moneyball/allproj.php"" rel=""nofollow noreferrer"">https://dailyfantasyrankings.com.au/resources/nba/cheatsheet/moneyball/allproj.php</a></p>

<p>Im receiving the error:
AttributeError: ResultSet object has no attribute 'find_all'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?</p>

<p>Im sure other parts of my code arent quite right but was hoping someone could assist!</p>

<p>Code:</p>

<pre><code>import requests
from urllib.request import urlopen
from bs4 import BeautifulSoup
import pandas as pd

URL = 'https://dailyfantasyrankings.com.au/resources/nba/cheatsheet/moneyball/allproj.php'
response = requests.get(URL)
html = response.content
soup = BeautifulSoup(response.content, 'html.parser')

table = soup.find('table', attrs={'class': 'xl12520945'})

columns = ['#', 'PLAYER', 'POS', '@', 'TEAM', 'OPP', 'M-UP', 'PACE', 'REST', 'PRICE', 'PROJ', 'VALUE', 'AVE']
df = pd.DataFrame(columns=columns)

trs = table.find_all('tr')
for tr in trs:
    tds = tr.find_all('td')
    row = [td.text.replace('\n','') for td in tds]
    df = df.append(pd.Series(row, index=columns), ignore_index=True)

df.to_csv('dfr_proj.csv', index = False)
</code></pre>
"
"60496218","<p>Here is a solution using np.r_, slicing and skimage.util.view_as_windows.</p>

<p>For simplicity, I just take np.arange as data. In your case of more than one Series of Data, you could repeat this for all rows for which you would like this backward averaging:</p>

<pre><code>from skimage.util import view_as_windows

numberOfDataItems=500
sumwindow=100
data=np.arange(numberOfDataItems)
</code></pre>

<p>Using np.r_, I can roll that data stepwise to make it array-shaped with dimension len(data)xlen(data)</p>

<pre><code>b = np.r_[data,np.full(len(data)-1,data[:-1])]
c=view_as_windows(b,len(data))
c
Out[]: 
array([[ 0,  1,  2, ..., 47, 48, 49],
       [ 1,  2,  3, ..., 48, 49,  0],
       [ 2,  3,  4, ..., 49,  0,  1],
       ...,
       [47, 48, 49, ..., 44, 45, 46],
       [48, 49,  0, ..., 45, 46, 47],
       [49,  0,  1, ..., 46, 47, 48]])
</code></pre>

<p>Basically that is np.roll(data) with stepsize i in column i, but without a loop.
Now I could sum the first, say 10 elements in column 0 as the values to work with for column 10, and so on for the further columns.</p>

<pre><code>d=c[:sumwindow,:-sumwindow].sum(axis=0)/sumwindow
Out[]: 
array([ 4.5,  5.5,  6.5,  7.5,  8.5,  9.5, 10.5, 11.5, 12.5, 13.5, 14.5,
       15.5, 16.5, 17.5, 18.5, 19.5, 20.5, 21.5, 22.5, 23.5, 24.5, 25.5,
       26.5, 27.5, 28.5, 29.5, 30.5, 31.5, 32.5, 33.5, 34.5, 35.5, 36.5,
       37.5, 38.5, 39.5, 40.5, 41.5, 42.5, 43.5])
</code></pre>

<p>Easy to see now, that if we wanted to take the mean of the last 10 elements in every column, then 4.5 would be the value for row 10, and the value would of course increase by 1 every column. </p>

<pre><code>e=np.array([data,data],dtype=float)
e[1,sumwindow:]=d
Out[]: 
array([[ 0. ,  1. ,  2. ,  3. ,  4. ,  5. ,  6. ,  7. ,  8. ,  9. , 10. ,
        11. , 12. , 13. , 14. , 15. , 16. , 17. , 18. , 19. , 20. , 21. ,
        22. , 23. , 24. , 25. , 26. , 27. , 28. , 29. , 30. , 31. , 32. ,
        33. , 34. , 35. , 36. , 37. , 38. , 39. , 40. , 41. , 42. , 43. ,
        44. , 45. , 46. , 47. , 48. , 49. ],
       [ 0. ,  1. ,  2. ,  3. ,  4. ,  5. ,  6. ,  7. ,  8. ,  9. ,  4.5,
         5.5,  6.5,  7.5,  8.5,  9.5, 10.5, 11.5, 12.5, 13.5, 14.5, 15.5,
        16.5, 17.5, 18.5, 19.5, 20.5, 21.5, 22.5, 23.5, 24.5, 25.5, 26.5,
        27.5, 28.5, 29.5, 30.5, 31.5, 32.5, 33.5, 34.5, 35.5, 36.5, 37.5,
        38.5, 39.5, 40.5, 41.5, 42.5, 43.5]])
</code></pre>

<p>Viewing initial data and result together, the first (sumwindow) values are the same, and from then it is always the avg of the (sumwindow) values before, just as you had for window 200 in your example.</p>

<p>I hope, that solution fits your needs.</p>
","0","2020-03-03 09:45:37","1","346","347","9","27","60477684","60496218","<p>I have a numpy array of size 5000 by 7.
I want to compute column 7 for all rows from position 200 to 4999 with the following formula:</p>

<p>
    dataset[i,7] = sum(dataset[i-200,0] + dataset[i-199,0] + dataset[i-198,0] + ... + dataset[i-1,0])/200</p>

<p>I have tried the following --which works--:</p>

<pre><code>import numpy as np

dataset = np.random.rand(numberOfDataItems, 7)
for i in range(200,numberOfDataItems):
    dataset[i,6] = np.sum(dataset[i-200:i,3])/200
</code></pre>

<p>My doubt is if the outer loop can be eliminated by using another approach using numpy.</p>
"
"60477765","<p>The <a href=""https://docs.python.org/3/library/functions.html#input"" rel=""nofollow noreferrer"">input()</a> returns a string not an int and if you multiply a string in Python with an integer <code>num</code>, then you will get a string repeated num times. For example,</p>

<pre><code>s = ""stack""
print(s * 3) # Returns ""stackstackstack""
</code></pre>

<p>You need to use <code>int()</code> constructor to cast the input from str to int.</p>

<pre><code>d =  int(input(""Enter the no. you want ""))
</code></pre>

<p>Try this:</p>

<pre><code>d = int(input(""Enter the no. you want ""))
for i in range(1,11):
    print(i * d)
</code></pre>

<p>In the above code, I have replaced your <code>while</code> loop construct with <a href=""https://wiki.python.org/moin/ForLoop"" rel=""nofollow noreferrer"">for loop</a> and <a href=""https://docs.python.org/3/library/functions.html#func-range"" rel=""nofollow noreferrer"">range()</a> to get sequence of numbers.</p>

<p><strong>BONUS:</strong></p>

<p>To print/display the table in a nice and better way, try the below code:</p>

<pre><code>for i in range(1,11):
    print(""%d X %d = %d"" % (d, i, i * d))
</code></pre>

<p>Outputs:</p>

<pre><code>Enter the no. you want 2
2 X 1 = 2
2 X 2 = 4
2 X 3 = 6
2 X 4 = 8
2 X 5 = 10
2 X 6 = 12
2 X 7 = 14
2 X 8 = 16
2 X 9 = 18
2 X 10 = 20
</code></pre>
","0","2020-03-01 17:30:33","3","7385","7807","4","901","60477739","60477765","<pre><code>i = 0
d =  input(""Enter the no. you want "")
while i &lt; 11 :
    print(i * d)
    i+= 1
</code></pre>

<p>It is supposed to give multiplication table of d but it gives the following result for eg. '3' instead</p>

<pre><code>3 

33

333

3333

33333

333333

3333333

33333333

333333333

3333333333
</code></pre>
"
"60485481","<p><strong>table_areas</strong> (not table_area) keyword argument works well and should be used (I use Camelot 0.7.3).</p>

<pre><code>tables = camelot.read_pdf('12s0324.pdf', flavor='stream', strip_text='\n', table_areas=['35,591,385,343'], pages = '1')
</code></pre>

<p>returns:</p>

<p><a href=""https://i.stack.imgur.com/Kio75.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/Kio75.png"" alt=""enter image description here""></a></p>

<p>which seems to be right.</p>
","1","","1","1730","120","4","120","60477763","60485481","<p>I have been trying to make Camelot work on specific areas of pdf pages for a good couple of days but it keeps puzzling me. I reviewed and tried the docs suggestions, a few bug reports and <a href=""https://stackoverflow.com/questions/53203779/headers-are-not-getting-extracted-from-pdf-while-extracting-the-table-data-from"">this SO question</a> to no avail. I could use some help.</p>

<p>I took an example from the docs, since it has more than one table, <a href=""https://camelot-py.readthedocs.io/en/master/user/advanced.html#strip-characters-from-text"" rel=""nofollow noreferrer"">this one</a>. I amended the original command to extract only one of the two tables, from:</p>

<p><code>tables = camelot.read_pdf('12s0324.pdf', flavor='stream', strip_text=' .\n')</code></p>

<p>to:</p>

<p><code>tables = camelot.read_pdf('12s0324.pdf', flavor='stream', strip_text='\n', table_area=['33,297,386,65'], pages = '1')</code></p>

<p>Whereas:</p>

<ul>
<li>I changed the regex because it was eliminating spaces between words,</li>
<li>used <code>table_area</code> instead of the docs' <code>table_areas</code> because the former triggers the elaboration, while the second an error (the bug is explained <a href=""https://github.com/atlanhq/camelot/issues/149#issuecomment-432013529"" rel=""nofollow noreferrer"">here</a>, and the docs still seem to be wrong)</li>
<li>tried to extract both tables and checked the respective areas using camelot's plot feature as explained in the <a href=""https://camelot-py.readthedocs.io/en/master/user/advanced.html#visual-debugging"" rel=""nofollow noreferrer"">docs here</a>, so they <em>should</em> be right,</li>
<li>tried also using <code>table_regions</code> and at least it pulls one table out instead of two, but it remains rather inaccurate (see comments below)</li>
</ul>

<p>So here are the results of my trials on the pdf mentioned above:</p>

<p>First one: using <code>table_area</code> on the <code>'35,591,385,343'</code> PDF area (top table)</p>

<pre><code>&gt;&gt;&gt; tables = camelot.read_pdf('12s0324.pdf', flavor='stream', strip_text='\n', table_area=['35,591,385,343'], pages = '1')
&gt;&gt;&gt; tables
&lt;TableList n=2&gt;
&gt;&gt;&gt; tables[0].df
                                                    0                                                  1         2         3         4         5         6         7         8         9
0   Program. Represents arrests reported (not char...                                                                                                                                   
1   by the FBI. Some persons may be arrested more ...                                                                                                                                   
2   could represent multiple arrests of the same p...                                                                                                                                   
3                                                                                                            Total                          Male                        Female          
4                                     Offense charged                                                     Under 18  18 years            Under 18  18 years            Under 18  18 years
5                                                                                                  Total     years  and over     Total     years  and over     Total     years  and over
6   Total   . . .  .  .  .  .  . .  . .  . .  . . ...                                          11,062 .6  1,540 .0  9,522 .6  8,263 .3  1,071 .6  7,191 .7  2,799 .2    468 .3  2,330 .9
7   Violent crime   .  .  .  .  .  .  .  . .  . . ...                                             467 .9     69 .1    398 .8    380 .2     56 .5    323 .7     87 .7     12 .6     75 .2
8                             Murder and nonnegligent                                                                                                                                   
9           manslaughter . . . . . . . .. .. .. .. ..                                               10.0       0.9       9.1       9.0       0.9       8.1       1.1         â€“       1.0
10       Forcible rape . . . . . . . .. .. .. .. .. .                                               17.5       2.6      14.9      17.2       2.5      14.7         â€“         â€“         â€“
11         Robbery . . . .. .. . .. . ... . ... . ...                                              102.1      25.5      76.6      90.0      22.9      67.1      12.1       2.5       9.5
....
34       Disorderly conduct . .. . . . . . .. .. .. .                                              529.5     136.1     393.3     387.1      90.8     296.2     142.4      45.3      97.1
35          Vagrancy . . . .. . . . ... .... .... ...                                               26.6       2.2      24.4      20.9       1.6      19.3       5.7       0.6       5.1
36         All other offenses (except traffic) . . ..                                              306.1     263.4   2,800.8   2,337.1     194.2   2,142.9     727.0      69.2     657.9
37      Suspicion . . . .. . . .. .. .. .. .. .. . ..                                                1.6         â€“       1.4       1.2         â€“       1.0         â€“         â€“         â€“
38            Curfew and loitering law violations  ..                                               91.0      91.0       (X)      63.1      63.1       (X)      28.0      28.0       (X)
39        Runaways  . . . . . . . .. .. .. .. .. ....                                               75.8      75.8       (X)      34.0      34.0       (X)      41.8      41.8       (X)
40                                                     â€“ Represents zero. X Not applicable. 1 Buying,...
</code></pre>

<p>Notice how the tables are two, and it includes unwanted text both at the top and bottom, which should not be inside the area chosen using <code>plot()</code>.</p>

<p>Second: using <code>table_regions</code> on the same <code>'35,591,385,343'</code> PDF area, top table</p>

<pre><code>&gt;&gt;&gt; tables = camelot.read_pdf('12s0324.pdf', flavor='stream', strip_text='\n', table_regions=['35,591,385,343'], pages = '1')
&gt;&gt;&gt; tables
&lt;TableList n=1&gt;
&gt;&gt;&gt; tables[0].df
                                                    0                                                  1         2         3         4         5         6         7         8         9
0   Program. Represents arrests reported (not char...                                                                                                                                   
1   by the FBI. Some persons may be arrested more ...                                                                                                                                   
2   could represent multiple arrests of the same p...                                                                                                                                   
3                                                                                                            Total                          Male                        Female          
4                                     Offense charged                                                     Under 18  18 years            Under 18  18 years            Under 18  18 years
5                                                                                                  Total     years  and over     Total     years  and over     Total     years  and over
6   Total   . . .  .  .  .  .  . .  . .  . .  . . ...                                          11,062 .6  1,540 .0  9,522 .6  8,263 .3  1,071 .6  7,191 .7  2,799 .2    468 .3  2,330 .9
7   Violent crime   .  .  .  .  .  .  .  . .  . . ...                                             467 .9     69 .1    398 .8    380 .2     56 .5    323 .7     87 .7     12 .6     75 .2
8                             Murder and nonnegligent                                                                                                                                   
9           manslaughter . . . . . . . .. .. .. .. ..                                               10.0       0.9       9.1       9.0       0.9       8.1       1.1         â€“       1.0
10       Forcible rape . . . . . . . .. .. .. .. .. .                                               17.5       2.6      14.9      17.2       2.5      14.7         â€“         â€“         â€“
11         Robbery . . . .. .. . .. . ... . ... . ...                                              102.1      25.5      76.6      90.0      22.9      67.1      12.1       2.5       9.5
....
34       Disorderly conduct . .. . . . . . .. .. .. .                                              529.5     136.1     393.3     387.1      90.8     296.2     142.4      45.3      97.1
35          Vagrancy . . . .. . . . ... .... .... ...                                               26.6       2.2      24.4      20.9       1.6      19.3       5.7       0.6       5.1
36         All other offenses (except traffic) . . ..                                              306.1     263.4   2,800.8   2,337.1     194.2   2,142.9     727.0      69.2     657.9
37      Suspicion . . . .. . . .. .. .. .. .. .. . ..                                                1.6         â€“       1.4       1.2         â€“       1.0         â€“         â€“         â€“
38            Curfew and loitering law violations  ..                                               91.0      91.0       (X)      63.1      63.1       (X)      28.0      28.0       (X)
39        Runaways  . . . . . . . .. .. .. .. .. ....                                               75.8      75.8       (X)      34.0      34.0       (X)      41.8      41.8       (X)
40                                                     â€“ Represents zero. X Not applicable. 1 Buying,... 
</code></pre>

<p>Just one table, same issue with unwanted text outside the selected area, apparently.</p>

<p>Third: Using <code>table_area</code> on the <code>'33,297,386,65'</code> PDF area (bottom table)</p>

<pre><code>&gt;&gt;&gt; tables = camelot.read_pdf('12s0324.pdf', flavor='stream', strip_text='\n', table_area=['33,297,386,65'], pages = '1')
&gt;&gt;&gt; tables
&lt;TableList n=2&gt;
&gt;&gt;&gt; tables[0].df
                                                    0                                                  1         2         3         4         5         6         7         8         9
0   Program. Represents arrests reported (not char...                                                                                                                                   
1   by the FBI. Some persons may be arrested more ...                                                                                                                                   
2   could represent multiple arrests of the same p...                                                                                                                                   
3                                                                                                            Total                          Male                        Female          
4                                     Offense charged                                                     Under 18  18 years            Under 18  18 years            Under 18  18 years
5                                                                                                  Total     years  and over     Total     years  and over     Total     years  and over
6   Total   . . .  .  .  .  .  . .  . .  . .  . . ...                                          11,062 .6  1,540 .0  9,522 .6  8,263 .3  1,071 .6  7,191 .7  2,799 .2    468 .3  2,330 .9
7   Violent crime   .  .  .  .  .  .  .  . .  . . ...                                             467 .9     69 .1    398 .8    380 .2     56 .5    323 .7     87 .7     12 .6     75 .2
8                             Murder and nonnegligent                                                                                                                                   
9           manslaughter . . . . . . . .. .. .. .. ..                                               10.0       0.9       9.1       9.0       0.9       8.1       1.1         â€“       1.0
10       Forcible rape . . . . . . . .. .. .. .. .. .                                               17.5       2.6      14.9      17.2       2.5      14.7         â€“         â€“         â€“
11         Robbery . . . .. .. . .. . ... . ... . ...                                              102.1      25.5      76.6      90.0      22.9      67.1      12.1       2.5       9.5
....
34       Disorderly conduct . .. . . . . . .. .. .. .                                              529.5     136.1     393.3     387.1      90.8     296.2     142.4      45.3      97.1
35          Vagrancy . . . .. . . . ... .... .... ...                                               26.6       2.2      24.4      20.9       1.6      19.3       5.7       0.6       5.1
36         All other offenses (except traffic) . . ..                                              306.1     263.4   2,800.8   2,337.1     194.2   2,142.9     727.0      69.2     657.9
37      Suspicion . . . .. . . .. .. .. .. .. .. . ..                                                1.6         â€“       1.4       1.2         â€“       1.0         â€“         â€“         â€“
38            Curfew and loitering law violations  ..                                               91.0      91.0       (X)      63.1      63.1       (X)      28.0      28.0       (X)
39        Runaways  . . . . . . . .. .. .. .. .. ....                                               75.8      75.8       (X)      34.0      34.0       (X)      41.8      41.8       (X)
40                                                     â€“ Represents zero. X Not applicable. 1 Buying,...
</code></pre>

<p>It picks up both tables and clearly the first one remains the top one. Same issue with unwanted text, but it is now expected.</p>

<p>Fourth: Using <code>table_regions</code> on the <code>'33,297,386,65'</code> PDF area (bottom table)</p>

<pre><code>&gt;&gt;&gt; tables = camelot.read_pdf('12s0324.pdf', flavor='stream', strip_text='\n', table_regions=['33,297,386,65'], pages = '1')
&gt;&gt;&gt; tables
&lt;TableList n=1&gt;
&gt;&gt;&gt; tables[0].df
                                                    0           1          2          3               4              5
0                    Table 325. Arrests by Race: 2009                                                                 
1   [Based on Uniform Crime Reporting (UCR) Progra...                                                                 
2   with a total population of 239,839,971 as esti...                                                                 
3                                                                                              American               
4                                     Offense charged                                    Indian/Alaskan  Asian Pacific
5                                                           Total      White      Black          Native       Islander
6   Total  . . . . .  . .  .  . .  .  . . .  .  . ...  10,690,561  7,389,208  3,027,153         150,544        123,656
7   Violent crime   .  .  .  .  .  .  .  . .  . . ...     456,965    268,346    177,766           5,608          5,245
8     Murder and nonnegligent manslaughter . .. ... .       9,739      4,741      4,801             100             97
9   Forcible rape . . . . . . . .. .. .. .. .... ....      16,362     10,644      5,319             169            230
10  Robbery . . . . .. . . . ... . ... . .... .......     100,496     43,039     55,742             726            989
11  Aggravated assault  . . . . . . . .. .. .........     330,368    209,922    111,904           4,613          3,929
....
34  All other offenses (except traffic) . .. .. .....   2,929,217  1,937,221    911,670          43,880         36,446
35  Suspicion . . .. . . . .. .. .. .. .. .. .. .....       1,513        677        828               1              7
36  Curfew and loitering law violations  . .. ... ...      89,578     54,439     33,207             872          1,060
37  Runaways  . . . . . . . .. .. .. .. .. .. .......      73,616     48,343     19,670           1,653          3,950
38           1 Except forcible rape and prostitution.
</code></pre>

<p>Better, yet it picks up unwanted text as above.</p>

<p>I would really value suggestions or pointers. Thanks in advance!</p>
"
"60480249","<p><strong>Cause of your error:</strong><br>
The vdim should be the name of the column you want to have on the y-axis, but the column name 'Fraction' doesn't exist, so you get the error.<br>
<br></p>

<p><strong>Here's a possible solution:</strong><br>
When you set hour as the index, you could specify: <code>kdim='hour'</code> and <code>vdim='blocked_driveway'</code>, but in this case you don't really need them and can leave them out:<br></p>

<pre><code># import libraries
import numpy as np
import pandas as pd
import holoviews as hv
hv.extension('bokeh')

# create sample data
data = {'hour': ['00', '01', '02'],
        'blocked_driveway': np.random.uniform(size=3),
        'illegal_parking': np.random.uniform(size=3),
        'street_condition': np.random.uniform(size=3),}

# create dataframe and set hour as index
df = pd.DataFrame(data).set_index('hour')

# create curves: 
# in this case the index is automatically taken as kdim
# and the series variable, e.g. blocked_driveway is taken as vdim
plot1 = hv.Curve(df['blocked_driveway'], label='blocked_driveway')
plot2 = hv.Curve(df['illegal_parking'], label='illegal_parking')
plot3 = hv.Curve(df['street_condition'], label='street_condition')

# put plots together
(plot1 * plot2 * plot3).opts(legend_position='top', width=600, height=400)
</code></pre>

<p><br>
<strong>Alternative and shorter solution:</strong><br>
In this case however I would use library <a href=""https://hvplot.holoviz.org/"" rel=""nofollow noreferrer"">hvplot</a> which is built on top of holoviews.<br>
It has even easier syntax and you need a lot less code to get the plot you want:</p>

<pre><code>import hvplot.pandas

# you don't have to set hour as index this time, but you could if you'd want to.
df.hvplot.line(
    x='hour', 
    y=['blocked_driveway', 
       'illegal_parking',
       'street_condition'],
)
</code></pre>

<p><br>
<strong>Resulting plot:</strong>
<a href=""https://i.stack.imgur.com/dr7gd.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/dr7gd.png"" alt=""multiple curves overlay with hvplot""></a></p>
","1","2020-03-02 10:09:42","2","6228","628","11","411","60477838","60480249","<pre><code>display(df_top5_frac.head())
</code></pre>

<p><a href=""https://i.stack.imgur.com/erzUk.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/erzUk.png"" alt=""Output""></a></p>

<p>The code below produces an error.</p>

<pre><code>%opts Overlay [width=800 height=600 legend_position='top_right'] Curve

hv.Curve((df_top5_frac['Blocked Driveway'])      , kdims = ['Hour'], vdims = ['Fraction'], label = 'Blocked Driveway') *\
hv.Curve((df_top5_frac['HEAT/HOT WATER'])        , kdims = ['Hour'], vdims = ['Fraction'], label = 'HEAT/HOT WATER') *\
hv.Curve((df_top5_frac['Illegal Parking'])       , kdims = ['Hour'], vdims = ['Fraction'], label = 'Illegal Parking') *\
hv.Curve((df_top5_frac['Street Condition'])      , kdims = ['Hour'], vdims = ['Fraction'], label = 'Street Condition') *\
hv.Curve((df_top5_frac['Street Light Condition']), kdims = ['Hour'], vdims = ['Fraction'], label = 'Street Light Condition')
</code></pre>

<p>Here is the error:</p>

<p><a href=""https://i.stack.imgur.com/szUEQ.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/szUEQ.png"" alt=""enter image description here""></a></p>
"
"60478680","<p>The issue is that you don't draw complete triangles. Comment out <code>draw_hexagon()</code> and <code>draw_squares()</code> and inspect the result:</p>

<p><a href=""https://i.stack.imgur.com/zs4ON.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/zs4ON.png"" alt=""enter image description here""></a></p>

<p>At some point you have to draw a complete triangle. e.g.:</p>

<pre class=""lang-py prettyprint-override""><code>begin_fill()
forward(side_length)
right(120)
forward(side_length)
right(120)
forward(side_length)
end_fill()
</code></pre>

<p>Draw the  triangle in case of <code>i%2==0:</code></p>

<pre class=""lang-py prettyprint-override""><code>def draw_triangles():

    color('black','yellow')  
    seth(180)#these 3 lines position the turtle at the starting place to start drawing the triangles
    back(50)
    left(60)
    for i in range(12):#these lines draw the 12 sides of the triangles
        if i%2==0:
            color('black','yellow')

            # draw filled triangle
            begin_fill()
            forward(side_length)
            right(120)
            forward(side_length)
            right(120)
            forward(side_length)
            end_fill()

            right(120)
            forward(side_length)
            right(30) 
        else:
            forward(side_length)
            right(30)
</code></pre>

<p><a href=""https://i.stack.imgur.com/Y0Z89.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/Y0Z89.png"" alt=""""></a>
<a href=""https://i.stack.imgur.com/9RFXM.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/9RFXM.png"" alt=""""></a></p>
","0","","0","136140","16645","626","8521","60477868","60478680","<p>I'm fairly new to python and I have an assignment of creating this <a href=""https://i.stack.imgur.com/MUox8.png"" rel=""nofollow noreferrer"">Figure</a> with turtle in python. I've managed to create the figure, however there is one last thing I cannot figure out and that is that I need to color the triangles but they don't get colored no matter where I place the begin_fill().</p>

<pre><code>from turtle import *
from math import *
from numpy import arange
#speed(3)
screensize(1200,1000)
tracer(False) #disables the turtle animation

start_x1 = -300
start_y1 = 0
side_length = 50 #defines that the side of each figure will be 50px
hexagon_height = float(sqrt(side_length**2-(side_length/2)**2)) #calculates the height of the hexagon
start_x2 = round(start_x1+hexagon_height + (side_length/2),2)
start_y2 = float((side_length/2)+hexagon_height+side_length)
distance_x = float(hexagon_height*2+side_length)#calculates the distance in the x-axis of each figure
distance_y = float(start_y2*2)


def draw_hexagon():

    color(""black"",""black"")
    begin_fill()
    seth(30)

    for i in range(6):
        left(60)
        forward(side_length)
    end_fill()

def draw_squares():

    for x in range (0,360,60):#This for loop increases the angle by 60 until 360 
        begin_fill()
        color('black','red')
        seth(x)#sets the initial angle to start drawing the square
        for i in range (3):
            forward(side_length)
            left(90)
        end_fill()
#This function draws the lines around the set hexagon+squares to form the triangles        

def draw_triangles():

    #begin_fill()
    #color('black','yellow')    
    seth(180)#these 3 lines position the turtle at the starting place to start drawing the triangles
    back(50)
    left(60)
    for i in range(12):#these lines draw the 12 sides of the triangles
        if i%2==0:
            begin_fill()
            color('black','yellow')
            forward(side_length)
            right(30) 
            end_fill()
        else:
            forward(side_length)
            right(30)

#this function creates two lines of figures starting at coordinates (-300,0) and (-300,236.6)
def create_line():

    for y in arange (start_y1,400,distance_y):#This will create the two lines of figures separated by 238 px in the y axis
        penup()
        for x in arange(start_x1,400,distance_x):#This will move the figures 136.6 pixels starting from the x position of -300 until it reaches x=400
            goto(x,y)#This moves the figures in the x and y axis 
            pendown()
            draw_hexagon()
            draw_squares()
            draw_triangles()

#this function creates one line of figures starting at coordinates (-231.7,118.3)        

def create_line2():

    for y in arange(start_y2,400,distance_y):
        penup()
        for x in arange(start_x2,476,distance_x):
            goto(x,y)
            pendown()
            draw_hexagon()
            draw_squares()
            draw_triangles()


create_line()

create_line2()
</code></pre>

<p>I tried adding in the function that creates the triangles an condition so that only the even triangles are colored but can't make it work.</p>

<p>Any help is highly appreciated.</p>
"
"60528411","<p>IUUC Here you have two options: a loop or convert your df from wide to long and use <code>plotly.express</code></p>

<pre class=""lang-py prettyprint-override""><code>import pandas as pd
import plotly.graph_objs as go
import plotly.express as px

from io import StringIO
df = """"""   200    300    400    500
0   1.2    2.2   12.3    4.2
1   2.7   13.1    9.8    3.3
2   1.8    1.5    5.1    9.8
3   3.9    3.3   12.1   12.2""""""

df = pd.read_csv(StringIO(df), delim_whitespace=True)

# as you want columns on x axis
df = df.T
</code></pre>

<h1>loop</h1>

<pre class=""lang-py prettyprint-override""><code>fig = go.Figure()
for col in df.columns:
    fig.add_trace(go.Line(x=df.index, y=df[col]))
fig.show()
</code></pre>

<p><a href=""https://i.stack.imgur.com/MenFl.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/MenFl.png"" alt=""enter image description here""></a></p>

<h1><code>plotly.express</code></h1>

<pre class=""lang-py prettyprint-override""><code>df['x'] = df.index
df_melt = pd.melt(df, id_vars=""x"", value_vars=df.columns[:-1])
px.line(df_melt, x=""x"", y=""value"",color=""variable"")
</code></pre>

<p><a href=""https://i.stack.imgur.com/FegN8.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/FegN8.png"" alt=""enter image description here""></a></p>
","0","","1","8483","1815","10","970","60477982","60528411","<p>I'm trying to plot a df which looks like the following:</p>

<pre><code>    200    300    400    500
0   1.2    2.2   12.3    4.2
1   2.7   13.1    9.8    3.3
2   1.8    1.5    5.1    9.8
3   3.9    3.3   12.1   12.2
</code></pre>

<p>Here is the code I am using: (courtesy: eyllanesc, thanks)</p>

<pre><code>import plotly


xy=px.line(self.predata,x=self.predata.columns.values,y=self.predata.index.values)
PlotlyPlot(self,xy)

def PlotlyPlot(self,tobeshown):

    raw_html = '&lt;html&gt;&lt;head&gt;&lt;meta charset=""utf-8"" /&gt;' 
    raw_html += '&lt;script src=""https://cdn.plot.ly/plotly-latest.min.js""&gt;&lt;/script&gt;&lt;/head&gt;' 
    raw_html += '&lt;body&gt;' 
    raw_html += plotly.offline.plot(tobeshown, include_plotlyjs=False, output_type='div', ) 
    raw_html += '&lt;/body&gt;&lt;/html&gt;'
    self.graphicsView.setHtml(raw_html)
</code></pre>

<p>I want the X axis to be the header (200,300,400...) and the Y axis to be the values in each of the rows (1.2,2.2 ...) in the plot. While this works for 1 line with length of x = length of y, it doesn't work otherwise.
When I run this, I get an error:</p>

<pre><code>All arguments should have the same length. The length of argument `y` is 243, whereas the length of previous arguments ['x'] is 143.
</code></pre>
"
"60478033","<p>You definitely <em>can</em> update, since there is no difference in the object constructed. The problem here is that all keys refer to the <em>same</em> dictionary object as values, not different objects with (possibly) the same data.</p>

<p>You thus can make copies of the dictionary with:</p>

<pre><code>def calendar_init(year, month, habits):
    date_list = dates_in_month(year, month)
    merged_dict = {**dict.fromkeys(habits, None), **{'mood': None}}
    calendar_init = {mydate: <b>dict(</b>merged_dict<b>)</b> for mydate in date_list}
    return calendar_init</code></pre>
","1","","1","312807","16628","2518","41861","60477997","60478033","<p>I can update a nested dictionary after initialising it using a for loop but not after using dictionary comprehension . Why is that ?</p>

<p>This works:</p>

<pre><code>def calendar_init(year, month, habits):
    date_list = dates_in_month(year, month)
    calendar_init = dict()
    for mydate in date_list:
        calendar_init[mydate] = {'mood': None}
        for habit in habits:
            calendar_init[mydate][habit] = None
    return calendar_init

def create_calendar(year, month, habits, entries, moods):
    new_calendar = calendar_init(year, month, habits)

    for entry in entries:
        new_calendar[entry.day][entry.habit] = entry
    for mood in moods:
        new_calendar[mood.day]['mood'] = mood

    return new_calendar
</code></pre>

<p>but this doesn't:</p>

<pre><code>def calendar_init(year, month, habits):
    date_list = dates_in_month(year, month)
    merged_dict = {**dict.fromkeys(habits, None), **{'mood': None}}
    calendar_init = {mydate: merged_dict for mydate in date_list}
    return calendar_init

def create_calendar(year, month, habits, entries, moods):
    new_calendar = calendar_init(year, month, habits)

    for entry in entries:
        new_calendar[entry.day][entry.habit] = entry
    for mood in moods:
        new_calendar[mood.day]['mood'] = mood

    return new_calendar
</code></pre>
"
"60478135","<p>Is this what you're looking for?</p>

<pre><code>data = [
    {k: v} 
    for k, v in df.groupby('source')['tables'].agg(
        lambda x: {v: {} for v in x}).items()
]

with open('data.json', 'w') as f:
    json.dump(data, f, indent=2)  
</code></pre>

<p>There are two layers to the answer here. To group the tables by source, use <code>groupby</code> first with an inner comprehension. You can use a list comprehension to assemble your data in this specific format overall.</p>

<pre><code>[
  {
    ""src1"": {
      ""table1"": {},
      ""table2"": {},
      ""table3"": {}
    }
  },
  {
    ""src2"": {
      ""table1"": {},
      ""table2"": {}
    }
  }
]
</code></pre>

<hr>

<p><strong>Example using <code>.apply</code> with arbitrary data</strong></p>

<pre><code>df['tables2'] = 'abc'

def func(g): 
    return {x: y for x, y in zip(g['tables'], g['tables2'])}

data = [{k: v} for k, v in df.groupby('source').apply(func).items()]
data
# [{'src1': {'table1': 'abc', 'table2': 'abc', 'table3': 'abc'}},
#  {'src2': {'table1': 'abc', 'table2': 'abc'}}]
</code></pre>

<p>Note that this will not work with pandas 1.0 (probably because of a bug)</p>
","6","2020-03-01 18:32:28","1","266035","10142","8528","64481","60478009","60478135","<p>Assume that I have a pandas dataframe called <code>df</code> similar to:</p>

<pre><code>source      tables
src1        table1       
src1        table2          
src1        table3       
src2        table1        
src2        table2 
</code></pre>

<p>I'm currently able to output a JSON file that iterates through the various sources, creating an object for each, with the code below:</p>

<pre><code>all_data = [] 

    for src in df['source']:
        source_data = {
            src: {
            }
        }
        all_data.append(source_data)

    with open('data.json', 'w') as f:
        json.dump(all_data, f, indent = 2)
</code></pre>

<p>This yields the following output:</p>

<pre><code>[
  {
    ""src1"": {}
  },
  {
    ""src2"": {}
  }
]
</code></pre>

<p>Essentially, what I want to do is also iterate through those list of sources and add the table objects corresponding to each source respectively. My desired output would look similar to as follows:</p>

<pre><code>[
  {
    ""src1"": {
      ""table1"": {},
      ""table2"": {},
      ""table3"": {}
    }
  },
  {
    ""src2"": {
      ""table1"": {},
      ""table2"": {}
    }
  }
]
</code></pre>

<p>Any assistance on how I can modify my code to also iterate through the tables column and append that to the respective source values would be greatly appreciated. Thanks in advance.</p>
"
"60479050","<p>For example, let's say your Python file is called <code>hello.py</code> and looks like this:</p>

<pre><code>print('Hello', input())
</code></pre>

<p>You can run it from the command line like this:</p>

<pre class=""lang-none prettyprint-override""><code>$ python3 hello.py
William
Hello William
</code></pre>

<p>Now say you have your name stored in <code>name.txt</code>. You can have the shell read it into your script's standard input (stdin) with <code>&lt;</code> like this:</p>

<pre class=""lang-none prettyprint-override""><code>$ python3 hello.py &lt; name.txt
Hello William
</code></pre>
","0","","0","15300","3115","1510","3211","60478048","60479050","<p>let say I have a .py file which get input with python built-in input function and I want to give this file multi inputs and process its output automatically.(built-it input function get input from keyboard)
how can I do this?</p>
"
"60478302","<p>If your data is a list of dicts then </p>

<pre><code>mpg = [ {'mpg' : 12,  'model': 'ford',  'year' : 2015 }, 
  {'mpg' : 13,  'model': 'amc',  'year' : 2016 }, 
  {'mpg' : 14,  'model': 'toyota',  'year' : 2014 }, 
  {'mpg' : 15,  'model': 'ford',  'year' : 2013 },
]

list(map(lambda x: (x['model'], x['mpg']), mpg))
</code></pre>
","0","","0","12487","27","13","826","60478147","60480627","<p>Following are the two columns(Table is given below) and apply simple for loop so that values that matches other column should appear in front of it.</p>

<p><code>
miles type  year
12   ford   2015
13   amc    2016
14   toyota 2014
15   ford   2013
</code></p>

<pre><code>modelclass=set(d['type'] for d in mpg)
miles=set(m['miles'] for m in mpg)
for d in modelclass: 
???
</code></pre>

<p>output should be:</p>

<p><code>[('ford',12),('amc',13),('toyota',14),('ford',15)]</code></p>
"
"60480627","<p>Not sure if this is what you mean, but you can get the desired output with</p>

<pre><code>result = [(i['model'], i['mpg']) for i in mpg]
</code></pre>
","0","","0","1342","35","17","63","60478147","60480627","<p>Following are the two columns(Table is given below) and apply simple for loop so that values that matches other column should appear in front of it.</p>

<p><code>
miles type  year
12   ford   2015
13   amc    2016
14   toyota 2014
15   ford   2013
</code></p>

<pre><code>modelclass=set(d['type'] for d in mpg)
miles=set(m['miles'] for m in mpg)
for d in modelclass: 
???
</code></pre>

<p>output should be:</p>

<p><code>[('ford',12),('amc',13),('toyota',14),('ford',15)]</code></p>
"
"60478228","<p>You can try this:</p>

<pre><code>L = ['8', 'K' , '&amp;' ,'2', '$' , '3' , 'T','R', 5.4, ""3.2""]
number_count = 0

for data in L:
    if isinstance(data,int) or isinstance(data, float) or data.replace('.','',1).isdigit():
        number_count += 1

print(""Number Count:"", number_count)
</code></pre>

<p>Output: <code>Number Count: 5</code></p>

<p>Code above will find for number / float in string, int, or float.</p>
","1","2020-03-01 18:23:03","0","3385","25","8","162","60478181","60478228","<p>I want to know how to count elements in a list with various types of elements(numbers/characters/symbols)?</p>

<pre><code>myList = ['8', 'K' , '&amp;' ,'2', '$' , '3' , 'T','R']
</code></pre>

<p>The result will be 3, if I want to count numbers.</p>

<pre><code>l=[""wael"", ""dd"", "";D""]
l.clear()
print(""Input the list size"")
n=(int(input()))
for i in range(1,n+1):
 print(""fill spot"",i,""of the list with"")
 l.append(input())
d=0
for i in range(1,n+1):
 if 0 or 1 or 2 or 3 or 4 or 5 or 6 or 7 or 8 or 9 in l:
    d=d+1
print(""number="",d)
</code></pre>
"
"60478281","<p>You can use:</p>

<pre><code>import string
from collections import defaultdict
letters = string.ascii_letters
digits = string.digits

L = ['8', 'K' , '&amp;' ,'2', '$' , '3' , 'T','R']

results = defaultdict(int)
for x in L:
    if x in letters:
        results[""letters""] += 1
    elif x in digits:
        results[""digits""] += 1
    else:
        results[""special""] += 1

print(dict(results))
# {'digits': 3, 'letters': 3, 'special': 2}
</code></pre>

<p><a href=""https://trinket.io/python3/3513b9b65b"" rel=""nofollow noreferrer"">Demo</a></p>
","1","2020-03-01 18:18:25","2","74108","5063","858","7248","60478181","60478228","<p>I want to know how to count elements in a list with various types of elements(numbers/characters/symbols)?</p>

<pre><code>myList = ['8', 'K' , '&amp;' ,'2', '$' , '3' , 'T','R']
</code></pre>

<p>The result will be 3, if I want to count numbers.</p>

<pre><code>l=[""wael"", ""dd"", "";D""]
l.clear()
print(""Input the list size"")
n=(int(input()))
for i in range(1,n+1):
 print(""fill spot"",i,""of the list with"")
 l.append(input())
d=0
for i in range(1,n+1):
 if 0 or 1 or 2 or 3 or 4 or 5 or 6 or 7 or 8 or 9 in l:
    d=d+1
print(""number="",d)
</code></pre>
"
"60478282","<p>You can use <code>string</code> module:</p>

<pre><code>&gt;&gt;&gt; from string import ascii_letters, digits, punctuation
&gt;&gt;&gt; L = ['8', 'K' , '&amp;' ,'2', '$' , '3' , 'T','R']
&gt;&gt;&gt; def categorical_counter(lst, category):
...     if category == 'letters':
...             return sum(1 for char in lst if char in ascii_letters)
...     elif category == 'numbers':
...             return sum(1 for char in lst if char in digits)
...     else:
...             return sum(1 for char in lst if char in punctuation)
...
&gt;&gt;&gt; categorical_counter(L, 'numbers')
3
</code></pre>
","2","","1","12268","1175","288","837","60478181","60478228","<p>I want to know how to count elements in a list with various types of elements(numbers/characters/symbols)?</p>

<pre><code>myList = ['8', 'K' , '&amp;' ,'2', '$' , '3' , 'T','R']
</code></pre>

<p>The result will be 3, if I want to count numbers.</p>

<pre><code>l=[""wael"", ""dd"", "";D""]
l.clear()
print(""Input the list size"")
n=(int(input()))
for i in range(1,n+1):
 print(""fill spot"",i,""of the list with"")
 l.append(input())
d=0
for i in range(1,n+1):
 if 0 or 1 or 2 or 3 or 4 or 5 or 6 or 7 or 8 or 9 in l:
    d=d+1
print(""number="",d)
</code></pre>
"
"60478318","<p>You can use <code>str.isdigit()</code> and <code>str.isalpha()</code> to check if characters/strings are numbers or letters, for example</p>

<pre><code>L = ['8', 'K' , '&amp;' ,'2', '$' , '3' , 'T','R']
number_count = 0
letter_count = 0
symbol_count = 0

for i in L:
    if i.isdigit(): # If string is only numeric digits
        number_count += 1
    elif i.isalpha(): # If string is only alphabetical characters
        letter_count += 1
    else: # Assume the rest are symbols
        symbol_count += 1
</code></pre>

<p>There are many other functions you can use to check what the string contains: <a href=""https://docs.python.org/3/library/stdtypes.html#str.isalnum"" rel=""nofollow noreferrer"">https://docs.python.org/3/library/stdtypes.html#str.isalnum</a></p>
","0","","0","26","43","0","1","60478181","60478228","<p>I want to know how to count elements in a list with various types of elements(numbers/characters/symbols)?</p>

<pre><code>myList = ['8', 'K' , '&amp;' ,'2', '$' , '3' , 'T','R']
</code></pre>

<p>The result will be 3, if I want to count numbers.</p>

<pre><code>l=[""wael"", ""dd"", "";D""]
l.clear()
print(""Input the list size"")
n=(int(input()))
for i in range(1,n+1):
 print(""fill spot"",i,""of the list with"")
 l.append(input())
d=0
for i in range(1,n+1):
 if 0 or 1 or 2 or 3 or 4 or 5 or 6 or 7 or 8 or 9 in l:
    d=d+1
print(""number="",d)
</code></pre>
"
"60478754","<p>try this :D</p>

<pre><code>l=[""wael"", ""dd"", "";D""]
l.clear()
print(""Input the list size"")
n=(int(input()))
for i in range(1,n+1):
 print(""fill spot"",i,""of the list with"")
 l.append(input())
d=0
for data in l:
    if data.isnumeric():
     d=d+1
print(""number="",d)
</code></pre>
","0","","0","1","0","0","6","60478181","60478228","<p>I want to know how to count elements in a list with various types of elements(numbers/characters/symbols)?</p>

<pre><code>myList = ['8', 'K' , '&amp;' ,'2', '$' , '3' , 'T','R']
</code></pre>

<p>The result will be 3, if I want to count numbers.</p>

<pre><code>l=[""wael"", ""dd"", "";D""]
l.clear()
print(""Input the list size"")
n=(int(input()))
for i in range(1,n+1):
 print(""fill spot"",i,""of the list with"")
 l.append(input())
d=0
for i in range(1,n+1):
 if 0 or 1 or 2 or 3 or 4 or 5 or 6 or 7 or 8 or 9 in l:
    d=d+1
print(""number="",d)
</code></pre>
"
"60478767","<pre class=""lang-py prettyprint-override""><code>file = ID3(""file.mp3"") # Load the file
file.delall(""APIC"") # Delete every APIC tag (Cover art)
file.save() # Save the file
</code></pre>
","0","","3","391","64","7","40","60478235","60478767","<p>I have a lot of mp3 files, most of them already with an album cover, now I want to use mutagen to update this cover art.</p>

<p>I have now run into a problem, apperantly mutagen sort of appends the new album art to the file instead of overwriting it, players then only see the first one and it looks to me as if it didn't work.</p>

<p>When I used ffmpeg to get rid of all tags from the file, my script worked just fine.</p>

<p>I either need to delete the existing coverart before adding a new one, or I need to tell mutagen to overwrite it, and I couldn't find any way to do that.</p>

<p>Using ffmpeg to get rid of the album art for all of my files and then running my script is not an option.</p>

<p>Here is my code so far:</p>

<pre class=""lang-py prettyprint-override""><code>from mutagen.id3 import APIC, ID3
file = ID3(""file.mp3"")

with open(""album.jpg"", 'rb') as albumart:
    file.add(APIC(
        encoding=3,
        mime='image/jpeg',
        type=3, desc=u'Cover',
        data=albumart.read()
    ))

file.save(v2_version=3)
</code></pre>
"
"60478330","<p>You chose a poor example. <code>int.__isub__</code> isn't defined, so <code>a -= 5</code> is exactly equal to <code>a = a - 5</code>, with no in-place modification of the original value.</p>

<p>Try with a set, which does implement <code>__isub__</code>.</p>

<pre><code>&gt;&gt;&gt; s = {1,2,3}
&gt;&gt;&gt; operator.isub(s, {2})
&gt;&gt;&gt; s
{1, 3}
</code></pre>

<p><code>a -= b</code> is implemented as <code>a.__isub__(b)</code> <em>if</em> <code>a.__isub__</code> is defined. Otherwise, it is equivalent to <code>a = a - b</code>, which is implemented as <code>a = a.__sub__(b)</code>. Thus, <code>isub(a, b)</code> is the same as <code>a -= b</code>, but that <em>doesn't</em> mean <code>isub(a, b)</code> can or does modify <code>a</code> in-place.</p>
","2","2020-03-01 18:29:25","5","383179","18330","5892","20227","60478284","60478330","<p>In the operator module, there is a method that is called <code>isub</code>, which takes two parameters, and dividing the first parameter in the second one.</p>

<p>Visual Studio Code says it does this: <strong>Same as a -= b</strong>, How?</p>

<p>In my example, I'm creating a variable called <code>a</code> and assigning 5 as its value, and then using the <code>isub</code> method, and saving the result into a variable, and then printing the result and <code>a</code>, but <code>a</code> is still 5, why?</p>

<pre><code>import operator

a = 5
result = operator.isub(a, 4)
print(result) # 1
print(a) # 5
</code></pre>
"
"60479408","<p>Your <code>select</code> tag needs a name. Replace: </p>

<pre class=""lang-html prettyprint-override""><code>&lt;select class=""form-control"" id=""continent_selector""&gt;
</code></pre>

<p>With: </p>

<pre class=""lang-html prettyprint-override""><code>&lt;select class=""form-control"" id=""continent_selector"" name=""select""&gt;
</code></pre>
","1","","1","943","82","16","40","60478309","60479408","<p>So, I am building a web form containing a SelectField using FlaskForm and wtforms. When the user submits the form, I can read StringFields without any problem, however, the SelectField's value is always None.</p>

<p>I've been looking to fix this problem for several hours now but could find neither an answer nor an explanation of what is going wrong in my code.</p>

<p>I looked at following threads without success:</p>

<ul>
<li><a href=""https://stackoverflow.com/questions/29134530/wtforms-selectfield-with-dynamic-choices-always-returns-none-for-data"">wtforms SelectField with dynamic choices always returns &quot;none&quot; for data</a></li>
<li><a href=""https://stackoverflow.com/questions/27576895/wtforms-returns-only-none"">wtforms returns only None</a></li>
</ul>

<p>and many more, that I couldn't find again. I also read through the <a href=""https://wtforms.readthedocs.io/en/stable/fields.html#wtforms.fields.SelectField"" rel=""nofollow noreferrer"">documentation</a> and <a href=""https://www.programcreek.com/python/example/82256/wtforms.SelectField"" rel=""nofollow noreferrer"">these</a> examples.</p>

<p>Here is some code to reproduce the problem:</p>

<pre><code>from flask import Flask, url_for, redirect, request, render_template_string
from flask_wtf import FlaskForm
from wtforms import SelectField, SubmitField

app = Flask(__name__)
app.config[""SECRET_KEY""] = ""very_secret""

# basic html template
my_html = """"""
&lt;div class=""content-section""&gt;
        &lt;form method=""POST"" action="".""&gt;
            {{form.hidden_tag()}}
            &lt;fieldset class=""form-group""&gt;
                &lt;legend class=""border-bottom mb-4""&gt;New Task&lt;/legend&gt;


                &lt;div class=""form-group""&gt;
                    {{ form.select.label(class=""form-control-label"")}}
                    &lt;select class=""form-control"" id=""continent_selector""&gt;
                        {% for choice in form.select.choices %}
                            &lt;option value=""{{ choice[1] }}""&gt;{{ choice[0] }}&lt;/option&gt;
                        {% endfor %}
                      &lt;/select&gt;
                &lt;/div&gt;


            &lt;/fieldset&gt;
            &lt;div class=""form-group""&gt;
                {{ form.submit(class=""btn btn-outline-info"")}}
            &lt;/div&gt;
        &lt;/form&gt;
    &lt;/div&gt;
""""""


class TaskForm(FlaskForm):
    tuple_list = [(""Choice_0"", 0), (""Choice_1"", 1)]
    select = SelectField(""select"", choices=tuple_list)
    submit = SubmitField(""Create Task"")


@app.route(""/"", methods=[""GET"", ""POST""])
def new_task():
    form = TaskForm()
    if request.method == ""POST"": 
        print(""-------------FORM--------------"")
        print(form.data)
        print(""-------------END--------------"")
        return str(form.select.data)
    return render_template_string(my_html, title=""New Task"", form=form)


if __name__ == ""__main__"":
    app.run(debug=True)
</code></pre>

<p>Printing out the form.data looks like this:</p>

<pre><code>{'select': 'None', 'submit': True, 'csrf_token': 'some_hash'}
</code></pre>

<p>It would be great if someone could point out to me what I'm doing wrong :)</p>
"
"60478429","<pre><code>data =  'Emma', 'F', '20799\nOlivia', 'F', '19674\nSophia', 'F', '18490\nIsabella', 'F', '16950\nAva','Emma', 'F', '20799\nOlivia', 'F', '19674\nSophia', 'F', '18490\nIsabella', 'F', '16950\nAva'
sum((s.split('\n') for s in data), [])
</code></pre>

<p>['Emma', 'F', '20799', 'Olivia', 'F', '19674', 'Sophia', 'F', '18490', 'Isabella', 'F', '16950', 'Ava', 'Emma', 'F', '20799', 'Olivia', 'F', '19674', 'Sophia', 'F', '18490', 'Isabella', 'F', '16950', 'Ava']</p>

<p>or if it is a string like this below:</p>

<p>data =  ""'Emma', 'F', '20799\nOlivia', 'F', '19674\nSophia', 'F', '18490\nIsabella', 'F', '16950\nAva','Emma', 'F', '20799\nOlivia', 'F', '19674\nSophia', 'F', '18490\nIsabella', 'F', '16950\nAva'""</p>

<pre><code>import re
re.findall(r""[\w]+"", data)
</code></pre>

<p>['Emma', 'F', '20799', 'Olivia', 'F', '19674', 'Sophia', 'F', '18490', 'Isabella', 'F', '16950', 'Ava', 'Emma', 'F', '20799', 'Olivia', 'F', '19674', 'Sophia', 'F', '18490', 'Isabella', 'F', '16950', 'Ava']</p>
","5","2020-03-01 19:12:33","-1","416","78","1","43","60478368","60478447","<pre><code>def files_to_dict(folder_name):
    list_of_files = os.listdir(""./""+folder_name) #read file names of current dir in list
    newDict=dict()
    for year in (list_of_files):
        if(year!="".ipynb_checkpoints""):
            ofile = open(""./""+folder_name+""/""+year,""r"")
            data = ofile.read().split(',')

    return data
</code></pre>

<p>I am trying to remove all delimiters while reading file into a list, including '\n'. I have tried using the above method but it gives the output like</p>

<blockquote>
  <p>'Emma',
   'F',
   '20799\nOlivia',
   'F',
   '19674\nSophia',
   'F',
   '18490\nIsabella',
   'F',
   '16950\nAva',</p>
</blockquote>

<p>The list goes on will the same pattern.
I want to remove the '\n' from the middle of the string in a list. I want to find an efficient solution which doesn't involve running a loop on the entire list again and removing the '\n' from each index.</p>

<p>Expexted Output:</p>

<blockquote>
  <p>'Emma',
   'F',
   '20799', 'Olivia',
   'F',
   '19674', 'Sophia',
   'F',
   '18490', 'Isabella',
   'F',
   '16950', 'Ava',</p>
</blockquote>
"
"60478447","<p>I think you are trying to replace the ""\n"" characters with a delimiter rather than removing them:</p>

<pre><code>def files_to_dict(folder_name):
    list_of_files = os.listdir(""./""+folder_name) #read file names of current dir in list
    newDict=dict()
    for year in (list_of_files):
        if(year!="".ipynb_checkpoints""):
            with open(""./""+folder_name+""/""+year,""r"") as ofile:
                data = ofile.read().replace('\n', ',').split(',')
                return data
</code></pre>
","1","2020-03-03 00:08:54","1","26","43","0","1","60478368","60478447","<pre><code>def files_to_dict(folder_name):
    list_of_files = os.listdir(""./""+folder_name) #read file names of current dir in list
    newDict=dict()
    for year in (list_of_files):
        if(year!="".ipynb_checkpoints""):
            ofile = open(""./""+folder_name+""/""+year,""r"")
            data = ofile.read().split(',')

    return data
</code></pre>

<p>I am trying to remove all delimiters while reading file into a list, including '\n'. I have tried using the above method but it gives the output like</p>

<blockquote>
  <p>'Emma',
   'F',
   '20799\nOlivia',
   'F',
   '19674\nSophia',
   'F',
   '18490\nIsabella',
   'F',
   '16950\nAva',</p>
</blockquote>

<p>The list goes on will the same pattern.
I want to remove the '\n' from the middle of the string in a list. I want to find an efficient solution which doesn't involve running a loop on the entire list again and removing the '\n' from each index.</p>

<p>Expexted Output:</p>

<blockquote>
  <p>'Emma',
   'F',
   '20799', 'Olivia',
   'F',
   '19674', 'Sophia',
   'F',
   '18490', 'Isabella',
   'F',
   '16950', 'Ava',</p>
</blockquote>
"
"60478509","<p>I don't know what your files look like, but I see you're never using newDict so you just return the last file what was processed</p>

<p>Try seeing if the following is closer to what you want </p>

<pre><code>with open(""./""+folder_name+""/""+year) as ofile:
    data_lines = [s.rstrip() for s in ofile.readlines()] 
    # would be better if you used csv module 
    data = [s.split(',') for s in data_lines]
    print(data)
</code></pre>
","0","","0","124322","2234","5803","53684","60478368","60478447","<pre><code>def files_to_dict(folder_name):
    list_of_files = os.listdir(""./""+folder_name) #read file names of current dir in list
    newDict=dict()
    for year in (list_of_files):
        if(year!="".ipynb_checkpoints""):
            ofile = open(""./""+folder_name+""/""+year,""r"")
            data = ofile.read().split(',')

    return data
</code></pre>

<p>I am trying to remove all delimiters while reading file into a list, including '\n'. I have tried using the above method but it gives the output like</p>

<blockquote>
  <p>'Emma',
   'F',
   '20799\nOlivia',
   'F',
   '19674\nSophia',
   'F',
   '18490\nIsabella',
   'F',
   '16950\nAva',</p>
</blockquote>

<p>The list goes on will the same pattern.
I want to remove the '\n' from the middle of the string in a list. I want to find an efficient solution which doesn't involve running a loop on the entire list again and removing the '\n' from each index.</p>

<p>Expexted Output:</p>

<blockquote>
  <p>'Emma',
   'F',
   '20799', 'Olivia',
   'F',
   '19674', 'Sophia',
   'F',
   '18490', 'Isabella',
   'F',
   '16950', 'Ava',</p>
</blockquote>
"
"60479214","<p>It's  very simple ,use split() instead of split(',') in your code.I modified  your code and it is shown below:-</p>

<pre><code>def files_to_dict(folder_name):
list_of_files = os.listdir(""./""+folder_name) #read file names of current dir in list
newDict=dict()
for year in (list_of_files):
    if(year!="".ipynb_checkpoints""):
        ofile = open(""./""+folder_name+""/""+year,""r"")
        data = ofile.read().split()

return data
</code></pre>

<p>Please refer to the following code and output if any more confusion is there.To understand easily i executed the below code based on your input</p>

<p><strong>code:</strong></p>

<pre><code>fh=open(""trystack.txt"",'r')
for line in fh:
    lines=fh.read().split()
    print(lines)  
fh.close() 
</code></pre>

<p><strong>output:</strong></p>

<p>['Olivia', 'F', '19674', 'Sophia', 'F', '18490', 'Isabella', 'F', '16950']</p>

<p>My text file <strong>trystack.txt</strong>  contains:</p>

<p>Emma F 20799</p>

<p>Olivia F 19674</p>

<p>Sophia F 18490</p>

<p>Isabella F 16950</p>

<p>This will help you in achieving what you need i.e removing '\n'</p>

<p>ThankYou</p>
","3","","0","22","4","0","3","60478368","60478447","<pre><code>def files_to_dict(folder_name):
    list_of_files = os.listdir(""./""+folder_name) #read file names of current dir in list
    newDict=dict()
    for year in (list_of_files):
        if(year!="".ipynb_checkpoints""):
            ofile = open(""./""+folder_name+""/""+year,""r"")
            data = ofile.read().split(',')

    return data
</code></pre>

<p>I am trying to remove all delimiters while reading file into a list, including '\n'. I have tried using the above method but it gives the output like</p>

<blockquote>
  <p>'Emma',
   'F',
   '20799\nOlivia',
   'F',
   '19674\nSophia',
   'F',
   '18490\nIsabella',
   'F',
   '16950\nAva',</p>
</blockquote>

<p>The list goes on will the same pattern.
I want to remove the '\n' from the middle of the string in a list. I want to find an efficient solution which doesn't involve running a loop on the entire list again and removing the '\n' from each index.</p>

<p>Expexted Output:</p>

<blockquote>
  <p>'Emma',
   'F',
   '20799', 'Olivia',
   'F',
   '19674', 'Sophia',
   'F',
   '18490', 'Isabella',
   'F',
   '16950', 'Ava',</p>
</blockquote>
"
"60498356","<p>Use <code>data.strip()</code> to remove â€˜\nâ€™ from a string</p>
","0","2020-03-03 00:25:44","0","1508","486","108","140","60478368","60478447","<pre><code>def files_to_dict(folder_name):
    list_of_files = os.listdir(""./""+folder_name) #read file names of current dir in list
    newDict=dict()
    for year in (list_of_files):
        if(year!="".ipynb_checkpoints""):
            ofile = open(""./""+folder_name+""/""+year,""r"")
            data = ofile.read().split(',')

    return data
</code></pre>

<p>I am trying to remove all delimiters while reading file into a list, including '\n'. I have tried using the above method but it gives the output like</p>

<blockquote>
  <p>'Emma',
   'F',
   '20799\nOlivia',
   'F',
   '19674\nSophia',
   'F',
   '18490\nIsabella',
   'F',
   '16950\nAva',</p>
</blockquote>

<p>The list goes on will the same pattern.
I want to remove the '\n' from the middle of the string in a list. I want to find an efficient solution which doesn't involve running a loop on the entire list again and removing the '\n' from each index.</p>

<p>Expexted Output:</p>

<blockquote>
  <p>'Emma',
   'F',
   '20799', 'Olivia',
   'F',
   '19674', 'Sophia',
   'F',
   '18490', 'Isabella',
   'F',
   '16950', 'Ava',</p>
</blockquote>
"
"60479850","<p>With libraries like <code>pyinput</code> you can only emulate mouse events in the window that is in focus/foreground and only if it is in the same process. If you want to generally inject or monitor mouse or keyboard events also in processes different from the calling process (like in your case) you have to establish a <em>mouse hook</em> or <em>keyboard hook</em> in windows.</p>

<p><a href=""https://docs.microsoft.com/en-us/windows/win32/winmsg/about-hooks"" rel=""nofollow noreferrer"">https://docs.microsoft.com/en-us/windows/win32/winmsg/about-hooks</a>
<a href=""https://www.codeproject.com/Articles/19858/Global-Windows-Hooks"" rel=""nofollow noreferrer"">https://www.codeproject.com/Articles/19858/Global-Windows-Hooks</a></p>

<p>In linux is the <code>evdev</code> system and <code>xdotool</code></p>

<p>In java on windows you have to invoke JNI like in this library : <a href=""https://github.com/kwhat/jnativehook"" rel=""nofollow noreferrer"">https://github.com/kwhat/jnativehook</a></p>

<p>Also see this <strong><a href=""https://stackoverflow.com/questions/10355286/programmatically-mouse-click-in-another-window"">programmatically mouse click in another window</a></strong> and this git <strong><a href=""https://github.com/boppreh/mouse"" rel=""nofollow noreferrer"">https://github.com/boppreh/mouse</a></strong></p>
","0","2020-03-01 21:22:45","1","8021","737","2","567","60478419","60514532","<p>I want to generate a mouse click at a specific position inside a game(Everquest project 1999). As it turns out the game only takes mouse input directly from the port. I have previously used <code>PyAutoGUI</code> <code>Java Robot</code> <code>pywin32</code> and many similar modules and libraries but all fail to deliver a click inside the game since its not absorbing virtual clicks.
There is no possible solution for this on all of the internet. Is there any way to inject a mouse click in the IO stream like a natural mouse click. </p>

<pre class=""lang-py prettyprint-override""><code>import pyautogui
pyautogui.click(100, 150)
</code></pre>

<p>This is an example of a virtually generated click that doesn't gets absorbed by the game.</p>
"
"60514532","<p>Even the Windows hooks didn't work with the game. We ended up opening the game on a remote desktop server and running the automation code over it, which worked.</p>
","0","","0","75","347","0","271","60478419","60514532","<p>I want to generate a mouse click at a specific position inside a game(Everquest project 1999). As it turns out the game only takes mouse input directly from the port. I have previously used <code>PyAutoGUI</code> <code>Java Robot</code> <code>pywin32</code> and many similar modules and libraries but all fail to deliver a click inside the game since its not absorbing virtual clicks.
There is no possible solution for this on all of the internet. Is there any way to inject a mouse click in the IO stream like a natural mouse click. </p>

<pre class=""lang-py prettyprint-override""><code>import pyautogui
pyautogui.click(100, 150)
</code></pre>

<p>This is an example of a virtually generated click that doesn't gets absorbed by the game.</p>
"
"60479261","<p>The element ('//span[contains(@data-bind, ""text: formatCurrency"")]') can't be scrapped because it's in a collapsed accordion.</p>

<p>The best solution I could come up with is to scroll to an element below the ""Fuel and Service Rates"" button and then click on it and then scrape the price. </p>

<p>I'm sure someone else can come up with a better solution with fewer lines of code.</p>

<p>Explanation in code comment.</p>

<pre><code>from selenium import webdriver
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.common.by import By
from selenium.webdriver.common.action_chains import ActionChains

driver = webdriver.Chrome('./chromedriver')

driver.get(""https://www.signatureflight.com/locations/acy"")
# Get an element below the fees section to scroll to, so the Fuel &amp; Service Rate will be visible
scroll_to = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.ID, ""skyvector-heading"")))
actions = ActionChains(driver)
# Scroll to that element
actions.move_to_element(scroll_to).perform()
# Find the Fuel &amp; Service Rate link and click on it
btn = driver.find_element_by_css_selector(""a[href='#fees']"")
btn.click()
# Get the price
price = driver.find_element_by_xpath('//span[contains(@data-bind, ""text: formatCurrency"")]').text
print(price)
</code></pre>

<p>Output:</p>

<pre><code>$5.83
</code></pre>
","0","","2","1541","222","23","129","60478467","60479261","<p>I'm trying to scrape the tables which sit under the ""Fuel and Service Rates"" header on this site: <a href=""https://www.signatureflight.com/locations/acy"" rel=""nofollow noreferrer"">https://www.signatureflight.com/locations/acy</a>. This includes the ""$5.83 100LL Full Service"" bit as well as the table below with fees and additional benefits.</p>

<p>I can locate the first part by using <code>driver.find_element_by_xpath('//span[contains(@data-bind, ""text: formatCurrency"")]').text</code>, but this doesn't print anything. I'm using 'contains' in case the fuel type differs for other airports.</p>

<p>Any help would be appreciated.</p>

<p>HTML for reference:</p>

<pre><code>&lt;div class=""col-md-8 col-xs-7 fuelWrapper""&gt; 
&lt;span style=""color: #00263d; font-size:25px"" 
data-bind=""text: formatCurrency(Fuel100LL)""&gt;$5.83&lt;/span&gt;&lt;br&gt; 
&lt;span style=""color: #00263d; font-size: 11px""&gt;100LL Full Service&lt;/span&gt; &lt;/div&gt;
</code></pre>
"
"60478593","<p>You can use <code>sorted(iterable,key)</code>.</p>

<pre><code>&gt;&gt;&gt;sorted(list1,key=lambda x: (x[1],x[2],x[0])
#[(5, 3, 2), (2, 3, 4), (3, 4, 5)]
</code></pre>

<hr>

<p>If you don't want to use <code>lambda</code> you can use <code>itemgetter</code>.</p>

<pre><code>from operator import itemgetter
sorted(list1,key=itemgetter(1,2,0))
#[(5, 3, 2), (2, 3, 4), (3, 4, 5)]
</code></pre>
","2","","2","14733","1831","61","1931","60478559","60478593","<p>How can I sort a list in order? I have a list of tuples in a list and I need to sort them in order which I want.</p>

<pre><code>list1 = [(2,3,4),(3,4,5),(5,3,2)]
</code></pre>

<p>I need to sort them firstly by the second element of tuple, secondly(if the previous were equal) by the third and thirdly by the first. Is there any built-in function to do it?</p>
"
"60478737","<p>You can create samples where two features are independent of each other and a third feature is a linear combination of the other two. </p>

<p>For example: </p>

<pre><code>import numpy as np
from numpy.random import random

N_SAMPLES = 1000

samples = random((N_SAMPLES, 3))

# Let us suppose that the column `1` will have the dependent feature, the other two being independent

samples[:, 1] = 3 * samples[:, 0] - 2 * samples[:, 2]
</code></pre>

<p>Now if you run PCA to find two principal components on that sample, the ""explained variance"" should be equal to 1. </p>

<p>For example:</p>

<pre><code>from sklearn.decomposition import PCA

pca2 = PCA(2)
pca2.fit(samples)

assert sum(pca2.explained_variance_ratio_) == 1.0 # this should be true

</code></pre>
","2","2020-03-01 19:37:18","0","3349","277","19","129","60478562","60478737","<p>I would like to test my workflow for PCA, to do so I want to create a dataset with lets say 3 features with a set relationship between those features. then apply the PCA and check if the those relationships were captures, what is the most straightforward way to do it in Python ?</p>

<p>Thank you!</p>
"
"60479216","<p>You should always try to click on the element that can receive the click, in this case on the <code>button</code>  </p>

<p>xpath: <code>//div[@class='MEAGs']/button</code></p>
","2","","1","3998","61","76","447","60478655","60479216","<p>hello I cant find a way to make selenium click on the ... button on a post webpage like : <a href=""https://www.instagram.com/p/B9LHHvygBnz/"" rel=""nofollow noreferrer"">https://www.instagram.com/p/B9LHHvygBnz/</a></p>

<p>where the source code of the three dots on the corner of the post is like :</p>

<pre><code>&lt;div class=""MEAGs""&gt;
    &lt;button class=""wpO6b "" type=""button""&gt;
        &lt;div class=""                   Igw0E   rBNOH          YBx95       _4EzTm                                                                                                              "" style=""height: 24px; width: 24px;""&gt;
            &lt;svg aria-label=""More options"" class=""_8-yf5 "" fill=""#262626"" height=""16"" viewBox=""0 0 48 48"" width=""16""&gt;
                &lt;circle clip-rule=""evenodd"" cx=""8"" cy=""24"" fill-rule=""evenodd"" r=""4.5""&gt;&lt;/circle&gt; 
                &lt;circle clip-rule=""evenodd"" cx=""24"" cy=""24"" fill-rule=""evenodd"" r=""4.5""&gt;&lt;/circle&gt;
                &lt;circle clip-rule=""evenodd"" cx=""40"" cy=""24"" fill-rule=""evenodd"" r=""4.5""&gt;&lt;/circle&gt;
           &lt;/svg&gt;
        &lt;/div&gt;
    &lt;/button&gt;
</code></pre>

<p></p>

<p>I have tried as many as ways I tought would work but selenium does not point to it for example I tried :</p>

<pre><code>self.driver.find_element_by_xpath(""//div[@class='MEAGs']"")
</code></pre>

<p>and </p>

<pre><code>posts = self.driver.find_elements_by_xpath(""//div[@class='wpO6b ']"")
</code></pre>

<p>and many outher ways (I've been working on this specific line of code for 2 days!)</p>
"
"60478712","<p>We can make a utility function that filters out the <code>None</code>s. For example:</p>

<pre><code>from django.db.models import Q

def filter_without_none(**kwargs):
    return Q(**{k: v for k, v in kwargs.items() if v is not None and v != ''})</code></pre>

<p>Now we can filter with:</p>

<pre><code>Ingredient.objects.filter(
    <b>filter_without_none(</b>account=account, brand=brand, name=name, cost=cost<b>)</b>
)</code></pre>

<p>If one (or multiple) of the values like <code>account</code>, <code>brand</code> and/or <code>name</code> are <code>None</code>, these will <em>not</em> be taken into account for filtering.</p>
","4","2020-03-01 19:52:23","2","312807","16628","2518","41861","60478689","60478712","<p>I have a Django model which I'm doing a view for it, which filters results.</p>

<p>models.py:</p>

<pre><code>Ingredient(models.Model):
    account = models.ForeignKey(Account, on_delete=models.CASCADE, null=False)
    brand = models.ForeignKey(Brand, on_delete=models.CASCADE, null=False)
    name = models.CharField(max_length=100, null=False, blank=False)
    cost = models.DecimalField(max_digits=14, decimal_places=2, null=False)
</code></pre>

<p>Now the point is that the search form (which has every field except <code>account</code> of course), none of its fields are required, you can filter either by just a single field or two or the three of them.</p>

<p>The problem is that I can't do:</p>

<pre><code>Ingredient.objects.filter(account=account, brand=brand, name=name, cost=cost)
</code></pre>

<p>...because brand, name, and cost could be sent empty/null</p>

<p>How can I resolve this without making a filter line code for each filtering possibility?</p>
"
"60497298","<p>Turns out the environment variable was wrongly reading a double-quote a la <a href=""https://github.com/docker/compose/issues/3702"" rel=""nofollow noreferrer"">https://github.com/docker/compose/issues/3702</a></p>
","0","","0","1404","119","9","203","60478724","60497298","<p>I am pretty sure that this is a standard network socket problem. I am currently dockerizing my application which makes use of the python py-opcua ( OPC UA ) package. Do you have any ideas on how to resolve this, or any suggestions I could try out?</p>

<p>I have set up a mock server with nodes, which runs locally on my <strong>Mac</strong> machine (no Dockerization here!):</p>

<pre><code>        self.server = Server()
        self.server.set_endpoint(""opc.tcp://0.0.0.0:50001/"")

        # setup our own namespace, not really necessary but should as spec
        uri = ""http://some-uri.com""
        self.idx = self.server.register_namespace(uri)

        # get Objects node, this is where we should put our custom stuff
        self.objects = self.server.get_objects_node()
        self.root = self.objects.add_object(self.idx, ""Child"")

        self._populate_server_with_variables()
        self.server.iserver.history_manager.set_storage(HistorySQLite(""mock.db""))

        # Sample new values for all variables...
        self.start()

        self.make_all_variables_writable()
</code></pre>

<p>Now I am trying to connect to the above Server using the py-opcua <code>Client</code> class, which connects as follows (this part runs from within a docker container! again, from my local machine):</p>

<pre><code>        self.client = Client(
            ""opc.tcp://0.0.0.0:50001/"",
            timeout=60.
        )

        self.client.connect()  # Where my application fails from within Docker!

        self.root = self.client.get_root_node()
</code></pre>

<p>When I run the docker container, the client is not able to connect to the mock server. Specifically, when a connection is (tried to be) established, the docker container crashes.</p>

<p>I tried running the following <code>docker run</code> commands, which all produce the same error:</p>

<pre><code>docker run --env-file env/.local-docker.env -i --rm -p 50001:50001 image_name
</code></pre>

<pre><code>docker run --env-file env/.local-docker.env -i --rm --network host image_name
</code></pre>

<pre><code>docker run --env-file env/.local-docker.env -i --rm --network=host image_name
</code></pre>

<p>The error which I get, is always a failed socket connection from the client side. Specifically, I get the following error message:</p>

<pre><code>Logfile will be save in:  ./logs/log_2020-03-01 18:54:36.769166.log
Connecting to... ""opc.tcp://0.0.0.0:50001/""
  File ""/usr/local/lib/python3.6/runpy.py"", line 193, in _run_module_as_main
    ""__main__"", mod_spec)
  File ""/usr/local/lib/python3.6/runpy.py"", line 85, in _run_code
    exec(code, run_globals)
  File ""/app/deploy/middleware/loop.py"", line 96, in &lt;module&gt;
    opc_reader_rt = RealTimeReader(opc_path)
  File ""/app/deploy/opc_client/dataset.py"", line 40, in __init__
    self.client.connect()
  File ""/usr/local/lib/python3.6/site-packages/opcua/client/client.py"", line 256, in connect
    self.connect_socket()
  File ""/usr/local/lib/python3.6/site-packages/opcua/client/client.py"", line 281, in connect_socket
    self.uaclient.connect_socket(self.server_url.hostname, self.server_url.port)
  File ""/usr/local/lib/python3.6/site-packages/opcua/client/ua_client.py"", line 256, in connect_socket
    return self._uasocket.connect_socket(host, port)
  File ""/usr/local/lib/python3.6/site-packages/opcua/client/ua_client.py"", line 155, in connect_socket
    sock = socket.create_connection((host, port), timeout=self.timeout)
  File ""/usr/local/lib/python3.6/socket.py"", line 704, in create_connection
    for res in getaddrinfo(host, port, 0, SOCK_STREAM):
  File ""/usr/local/lib/python3.6/socket.py"", line 745, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.gaierror: [Errno -2] Name or service not known
</code></pre>
"
"60479496","<p>I found it:</p>

<p>kernel.json file was pointing to wrong python:</p>

<pre><code>{
 ""argv"": [
  ""/home/****/anaconda3/bin/python"",
  ""-m"",
  ""ipykernel_launcher"",
  ""-f"",
  ""{connection_file}""
 ],
 ""display_name"": ""myvirtenv"",
 ""language"": ""python""
}
</code></pre>

<p>Changed it to:</p>

<pre><code>{
 ""argv"": [
  ""/home/****/anaconda3/envs/myvirtenv/bin/python"",
  ""-m"",
  ""ipykernel_launcher"",
  ""-f"",
  ""{connection_file}""
 ],
 ""display_name"": ""myvirtenv"",
 ""language"": ""python""
}
</code></pre>
","0","","0","179","7","0","7","60478729","60479496","<p>I installed the anaconda python distribution on Ubuntu 16-04 (LTS release) and I want to use virtual environments with jupyter notebooks but I get some odd behavior:</p>

<pre><code>conda update conda

conda create -n myvirtenv python=3.6 anaconda

conda activate myvirtenv
</code></pre>

<p>added virtual enviroment to jupyter</p>

<pre><code>python -m ipykernel install --user â€“name=myvirtenv
</code></pre>

<p>When I start a jupyter notebook from my <em>default</em> enviroment and get the python version:</p>

<pre><code>import sys

print(sys.version)
3.7.4 (default, Aug 13 2019, 20:35:49) 
[GCC 7.3.0]
</code></pre>

<p>That is as expected but when I go to <strong>Kernel > change kernel</strong> and select <em>myvirtenv</em> I get the same output.</p>

<p>When I activate <em>myvirtenv</em> and start jupyter notebook with default kernel I get the following output:</p>

<pre><code>print(sys.version)
3.6.10 |Anaconda, Inc.| (default, Jan  7 2020, 21:14:29) 
[GCC 7.3.0]
</code></pre>

<p>When I change to kernel to <em>myvirtenv</em> I get the following output:</p>

<pre><code>print(sys.version)
3.7.4 (default, Aug 13 2019, 20:35:49) 
[GCC 7.3.0]
</code></pre>

<p>I would expect that when I start jupyter notebook from either the <em>default</em> environment or <em>myvirtenv</em> select the kernel myvirtenv it would use python 3.6.10 and the default kernel would use python 3.7.4? What can I do to ensure that kernel <em>myvirtenv</em> uses the correct virtual environment?</p>
"
"60544413","<p>Yes you can use <a href=""https://www.tensorflow.org/api_docs/python/tf/GradientTape"" rel=""nofollow noreferrer"">GradientTape</a>. The purpose of <code>tf.GradientTape</code> is to record operations for automatic differentiation or forÂ computing the gradient of an operation or computation with respect to its input variables.</p>

<p>According to <a href=""https://rads.stackoverflow.com/amzn/click/com/B07VWGN8NB"" rel=""nofollow noreferrer"" rel=""nofollow noreferrer"">What's New in TensorFlow 2.0</a>, to first implement the simple training of a model with tf.GradientTape, call the forward pass on the input tensor inside the tf.GradentTape context manager and then compute the loss function. <strong>This ensures that all of the computations will be recorded on the gradient tape.</strong></p>

<p>Then, compute the gradients with regard to all of the trainable variables in the model. Once the gradients are computed, any desired gradientÂ clipping, normalization, or transformation can be performed before passing them to the optimizer to apply them to the model variables.Â Take a look at the following example:</p>

<pre><code>NUM_EXAMPLES = 2000

input_x = tf.random.normal([NUM_EXAMPLES])
noise = tf.random.normal([NUM_EXAMPLES])
input_y = input_x * 5 + 2 + noise

def loss_fn(model, inputs, targets):
  error = model(inputs) - targets
  return tf.reduce_mean(tf.square(error))

def gradients(model, inputs, targets):
  with tf.GradientTape() as tape:
    loss_value = loss_fn(model, inputs, targets)
  return tape.gradient(loss_value, model.trainable_variables)

model = tf.keras.Sequential(tf.keras.layers.Dense(1))
optimizer = tf.keras.optimizers.Adam(learning_rate=0.01)
print(""Initial loss: {:.3f}"".format(loss_fn(model, input_x, input_y)))
for i in range(500):
  grads = gradients(model, input_x, input_y)
  optimizer.apply_gradients(zip(grads, model.trainable_variables))
  if i % 20 == 0:
    print(""Loss at step {:03d}: {:.3f}"".format(i, loss_fn(model, input_x, input_y)))
print(""Final loss: {:.3f}"".format(loss(model, input_x, input_y)))
print(""W = {}, B = {}"".format(*model.trainable_variables))
</code></pre>
","4","2020-03-05 12:34:17","2","8788","8668","329","2107","60478749","60567742","<p>I would like to get gradient of the model's loss function with respect to specific layer's output during training. What I want to do with it next, is using a value of that gradient to modify something in layer in the next learning epoch. 
So how to obtain that gradient?</p>

<p>Here's a minimal example. 
MinimalRNNCell code is copied from TensorFlow's website and toy data is provided only to reproduce the behavior.</p>

<pre><code>import tensorflow as tf 
from tensorflow.keras.layers import RNN, SimpleRNNCell, SimpleRNN, Layer, Dense, AbstractRNNCell
from tensorflow.keras import Model
import numpy as np
import tensorflow.keras.backend as K


class MinimalRNNCell(AbstractRNNCell):

    def __init__(self, units, **kwargs):
      self.units = units
      super(MinimalRNNCell, self).__init__(**kwargs)

    @property
    def state_size(self):
      return self.units

    def build(self, input_shape):
      self.kernel = self.add_weight(shape=(input_shape[-1], self.units),
                                    initializer='uniform',
                                    name='kernel')
      self.recurrent_kernel = self.add_weight(
          shape=(self.units, self.units),
          initializer='uniform',
          name='recurrent_kernel')
      self.built = True

    def call(self, inputs, states):
      prev_output = states[0]
      h = K.dot(inputs, self.kernel)
      output = h + K.dot(prev_output, self.recurrent_kernel)
      return output, output


class MyModel(Model):
    def __init__(self, size):
        super(MyModel, self).__init__()
        self.minimalrnn=RNN(MinimalRNNCell(size), name='minimalrnn')
        self.out=Dense(4)

    def call(self, inputs):
        out=self.minimalrnn(inputs)
        out=self.out(out)
        return out


x=np.array([[[3.],[0.],[1.],[2.],[3.]],[[3.],[0.],[1.],[2.],[3.]]])
y=np.array([[[0.],[1.],[2.],[3.]],[[0.],[1.],[2.],[3.]]])

model=MyModel(2)
model.compile(optimizer='sgd', loss='mse')
model.fit(x,y,epochs=10, batch_size=1, validation_split=0.2)



</code></pre>

<p>Now I want to get gradient of output of MyModel's minimalrnn layer (after every batch of data).</p>

<p>How to do this? I suppose I can try with GradientTape watching model.get_layer('minimalrnn').output, but I need more learning resources or examples. </p>

<p><strong>EDIT</strong></p>

<p>I used GradientTape as in code provided by Tiago Martins Peres, but I specifically want to obtain gradient wrt layer output, and I'm still not able to achieve that. </p>

<p>Now after class definitions my code looks like this:</p>

<pre><code>
x=np.array([[[3.],[0.],[1.],[2.],[3.]],[[3.],[0.],[1.],[2.],[3.]]])
y=np.array([[0., 1., 2., 3.],[0., 1., 2., 3.]])

model=MyModel(2)

#inputs = tf.keras.Input(shape=(2,5,1))
#model.call(x)

def gradients(model, inputs, targets):
    with tf.GradientTape() as tape:
        tape.watch(model.get_layer('minimalrnn').output)
        loss_value = loss_fn(model, inputs, targets)
    return tape.gradient(loss_value, model.trainable_variables)

def loss_fn(model, inputs, targets):
    error = model(inputs) - targets
    return tf.reduce_mean(tf.square(error))

optimizer = tf.keras.optimizers.Adam(learning_rate=0.01)
print(""Initial loss: {:.3f}"".format(loss_fn(model, x, y)))
for i in range(10):
    grads = gradients(model, x, y)
    optimizer.apply_gradients(zip(grads, model.trainable_variables))
    print(""Loss at step {:03d}: {:.3f}"".format(i, loss_fn(model, x, y)))
print(""Final loss: {:.3f}"".format(loss_fn(model, x, y)))
</code></pre>

<p>As you can see I added tape.watch in gradients function definition, because I want to watch layer output. However I'm getting error:</p>

<pre><code>Traceback (most recent call last):
  File ""/home/.../test2.py"", line 73, in &lt;module&gt;
    grads = gradients(model, x, y)
  File ""/home/.../test2.py"", line 58, in gradients
    print(model.get_layer('minimalrnn').output)
  File ""/home/.../.venv/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/base_layer.py"", line 1553, in output
    raise AttributeError('Layer ' + self.name + ' has no inbound nodes.')
AttributeError: Layer minimalrnn has no inbound nodes.
</code></pre>

<p>I also tried to call model on Input with specified size (commented lines), according to answer to this: <a href=""https://stackoverflow.com/questions/59383356/accessing-layers-input-output-using-tensorflow-2-0-model-sub-classing"">Accessing layer&#39;s input/output using Tensorflow 2.0 Model Sub-classing</a>. It didn't help. Specifying input shape in model's init function, like below,  also doesn't help - still the same error.</p>

<pre><code>self.minimalrnn=RNN(MinimalRNNCell(size), name='minimalrnn', input_shape=(2,5,1))
</code></pre>
"
"60567742","<p>Ok, so one answer that I finally found is hidden here: <a href=""https://stackoverflow.com/a/56567364/4750170"">https://stackoverflow.com/a/56567364/4750170</a>. I can even use subclassed model with this.</p>

<p>Additionally problem with AttributeError is strange, because when I used Sequential instead of subclassing Model, AttributeError magically disappeared, maybe it's connected with this issue <a href=""https://github.com/tensorflow/tensorflow/issues/34834"" rel=""nofollow noreferrer"">https://github.com/tensorflow/tensorflow/issues/34834</a>? </p>

<p>Still, I'd like to know why I can't just pass the layer's output as a second argument to tape.gradient.</p>
","4","2020-03-06 16:13:05","2","143","2","0","16","60478749","60567742","<p>I would like to get gradient of the model's loss function with respect to specific layer's output during training. What I want to do with it next, is using a value of that gradient to modify something in layer in the next learning epoch. 
So how to obtain that gradient?</p>

<p>Here's a minimal example. 
MinimalRNNCell code is copied from TensorFlow's website and toy data is provided only to reproduce the behavior.</p>

<pre><code>import tensorflow as tf 
from tensorflow.keras.layers import RNN, SimpleRNNCell, SimpleRNN, Layer, Dense, AbstractRNNCell
from tensorflow.keras import Model
import numpy as np
import tensorflow.keras.backend as K


class MinimalRNNCell(AbstractRNNCell):

    def __init__(self, units, **kwargs):
      self.units = units
      super(MinimalRNNCell, self).__init__(**kwargs)

    @property
    def state_size(self):
      return self.units

    def build(self, input_shape):
      self.kernel = self.add_weight(shape=(input_shape[-1], self.units),
                                    initializer='uniform',
                                    name='kernel')
      self.recurrent_kernel = self.add_weight(
          shape=(self.units, self.units),
          initializer='uniform',
          name='recurrent_kernel')
      self.built = True

    def call(self, inputs, states):
      prev_output = states[0]
      h = K.dot(inputs, self.kernel)
      output = h + K.dot(prev_output, self.recurrent_kernel)
      return output, output


class MyModel(Model):
    def __init__(self, size):
        super(MyModel, self).__init__()
        self.minimalrnn=RNN(MinimalRNNCell(size), name='minimalrnn')
        self.out=Dense(4)

    def call(self, inputs):
        out=self.minimalrnn(inputs)
        out=self.out(out)
        return out


x=np.array([[[3.],[0.],[1.],[2.],[3.]],[[3.],[0.],[1.],[2.],[3.]]])
y=np.array([[[0.],[1.],[2.],[3.]],[[0.],[1.],[2.],[3.]]])

model=MyModel(2)
model.compile(optimizer='sgd', loss='mse')
model.fit(x,y,epochs=10, batch_size=1, validation_split=0.2)



</code></pre>

<p>Now I want to get gradient of output of MyModel's minimalrnn layer (after every batch of data).</p>

<p>How to do this? I suppose I can try with GradientTape watching model.get_layer('minimalrnn').output, but I need more learning resources or examples. </p>

<p><strong>EDIT</strong></p>

<p>I used GradientTape as in code provided by Tiago Martins Peres, but I specifically want to obtain gradient wrt layer output, and I'm still not able to achieve that. </p>

<p>Now after class definitions my code looks like this:</p>

<pre><code>
x=np.array([[[3.],[0.],[1.],[2.],[3.]],[[3.],[0.],[1.],[2.],[3.]]])
y=np.array([[0., 1., 2., 3.],[0., 1., 2., 3.]])

model=MyModel(2)

#inputs = tf.keras.Input(shape=(2,5,1))
#model.call(x)

def gradients(model, inputs, targets):
    with tf.GradientTape() as tape:
        tape.watch(model.get_layer('minimalrnn').output)
        loss_value = loss_fn(model, inputs, targets)
    return tape.gradient(loss_value, model.trainable_variables)

def loss_fn(model, inputs, targets):
    error = model(inputs) - targets
    return tf.reduce_mean(tf.square(error))

optimizer = tf.keras.optimizers.Adam(learning_rate=0.01)
print(""Initial loss: {:.3f}"".format(loss_fn(model, x, y)))
for i in range(10):
    grads = gradients(model, x, y)
    optimizer.apply_gradients(zip(grads, model.trainable_variables))
    print(""Loss at step {:03d}: {:.3f}"".format(i, loss_fn(model, x, y)))
print(""Final loss: {:.3f}"".format(loss_fn(model, x, y)))
</code></pre>

<p>As you can see I added tape.watch in gradients function definition, because I want to watch layer output. However I'm getting error:</p>

<pre><code>Traceback (most recent call last):
  File ""/home/.../test2.py"", line 73, in &lt;module&gt;
    grads = gradients(model, x, y)
  File ""/home/.../test2.py"", line 58, in gradients
    print(model.get_layer('minimalrnn').output)
  File ""/home/.../.venv/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/base_layer.py"", line 1553, in output
    raise AttributeError('Layer ' + self.name + ' has no inbound nodes.')
AttributeError: Layer minimalrnn has no inbound nodes.
</code></pre>

<p>I also tried to call model on Input with specified size (commented lines), according to answer to this: <a href=""https://stackoverflow.com/questions/59383356/accessing-layers-input-output-using-tensorflow-2-0-model-sub-classing"">Accessing layer&#39;s input/output using Tensorflow 2.0 Model Sub-classing</a>. It didn't help. Specifying input shape in model's init function, like below,  also doesn't help - still the same error.</p>

<pre><code>self.minimalrnn=RNN(MinimalRNNCell(size), name='minimalrnn', input_shape=(2,5,1))
</code></pre>
"
"60479278","<p>first you have to use sheet_name as a string not an object and another thing is last for loop is not needed as we loop through sheet names.</p>

<pre><code>from pandas import ExcelWriter
import glob
import pandas as pd
import openpyxl


writer = ExcelWriter(""output.xlsx"")
for filename in glob.glob (r""C:\path\*.xlsx""):
    wb = openpyxl.load_workbook(filename)
    for ws in wb.sheetnames:
        ws1 = wb[ws]
        data = ws1.values
        columns = next(data)[0:]
        df= pd.DataFrame(data, columns=columns)
        df.to_excel(writer,sheet_name=ws,index = False)

writer.save()
</code></pre>
","6","2020-03-01 20:22:23","0","413","773","4","74","60478752","60479278","<p>So I've been trying to code a script which loads all excel files from a specific location and moves worksheets inside these files into one workbook. I'm ending with and error: </p>

<p><code>AttributeError: 'DataFrame' object has no attribute 'DataFrame'</code>. </p>

<p>I'm pretty new to this so I would really appreciate any tip on how to make that work. I can stick only 
with openpyxl because at the moment I cannot install xlrd module on my workstation.</p>

<pre><code>from pandas import ExcelWriter
import glob
import pandas as pd
import openpyxl

writer = ExcelWriter(""output.xlsx"")
for filename in glob.glob (r""C:\path\*.xlsx""):
    wb = openpyxl.load_workbook(filename)
    for ws in wb.sheetnames:
        ws = wb[ws]
        print (ws)
        data = ws.values
        columns = next(data)[0:]
        df= pd.DataFrame(data, columns=columns)
        print(df)
        for df in df.DataFrame:
            df.to_excel([writer,sheet_name= ws)

writer.save()
</code></pre>
"
"60479355","<p>You are getting GET parameters in your request so you need to pass that GET parameter in your url like this:</p>

<pre><code>https://url?parameter=2
</code></pre>

<p>so set the <code>cat=i</code> in your <code>bikes_all</code> url:</p>

<pre><code>{% url 'core:bikes_all' %}?cat=i
</code></pre>
","0","","2","680","178","6","67","60478833","60479355","<p>I am working with two pages and I would like to click on <code>a tag</code> on one page, which would insert a value to a search query on another page.</p>

<p>So here's my views.py:</p>

<pre><code>def bikes_all(request):
  item_list = Bike.objects.all()

  category_q = request.GET.get('cat')

  if category_q:
      item_list = item_list.filter(category__pk=category_q)

  paginator = Paginator(item_list, 10)

  page = request.GET.get('page')

  try:
      items = paginator.page(page)
  except PageNotAnInteger:
      items = paginator.page(1)
  except EmptyPage:
      items = paginator.page(paginator.num_pages)

  context = {
    'items': items,
  }

  return render(request, ""bikes_all.html"", context)
</code></pre>

<p>and my template:</p>

<pre><code>            &lt;form method=""GET"" action=""{% url 'core:bikes_all' %}""&gt;
            &lt;div class=""form-row ""&gt;
            &lt;div class=""form-group col-5""&gt;
                &lt;label for=""category""&gt;Category&lt;/label&gt;
                &lt;select id=""cat"" class=""form-control"" name=""cat""&gt;
                    &lt;option value="""" {% if not request.GET.cat %} selected {% endif %}&gt;Choose...&lt;/option&gt;
                    {% for cat in category_list %}
                    &lt;option value=""{{ cat.pk }}"" {% if request.GET.cat == cat.pk|slugify %} selected {% endif %}&gt;
                        {{ cat }}&lt;/option&gt;
                    {% endfor %}
                &lt;/select&gt;
            &lt;/div&gt;
        &lt;/div&gt;
        &lt;div class=""form-row""&gt;
            &lt;button type=""submit"" class=""btn btn-outline-primary btn-md""&gt;Search&lt;/button&gt;
        &lt;/div&gt;
    &lt;/form&gt;
</code></pre>

<p>and here's the <code>a tag</code> from another page:</p>

<pre><code>            &lt;div class=""col-md-4 overlay zoom""&gt;
            &lt;a href=""{% url 'core:bikes_all'  %}""&gt;
                &lt;div style=""position:relative;""&gt;
                    &lt;img src=""{% static '/img/category_choice/bike33.png' %}"" class=""img-fluid""&gt;
                    &lt;div class=""card-img-overlay""&gt;
                        &lt;h2 class=""card-title""
                            style=""text-align: center; color: aliceblue; position: absolute; bottom:5px;""&gt;
                            Road Bikes
                        &lt;/h2&gt;
                    &lt;/div&gt;
                &lt;/div&gt;
            &lt;/a&gt;
        &lt;/div&gt;
</code></pre>

<p>So I have <code>{% url 'core:bikes_all'  %}</code> in my href, which takes to <code>bikes_all.html</code> , but I would like to pass a search query within that href as well. I was trying to do <code>{% url 'core:bikes_all' request.GET.cat=2  %}</code> or <code>{% url 'core:bikes_all' category_q=2  %}</code>, but it didnt work.</p>

<p>The search query looks like that, when I filter the results by category <code>http://localhost:8000/bikes/all?cat=1</code>
So my aim is to redirect user to <code>http://localhost:8000/bikes/all?cat=2</code> , when he clicks on that <code>a tag</code> on first page.</p>
"
"60485719","<p>It was possible to avoid this error by downgrading to python 3.7.6</p>

<p>Remark: Unfortunately, the first step of the overall processing (run time 3 days on my GPU) creates intermediate results with pickel format 5, which is new in Python 3.8. Therefore, I either have to re-run the first step for 3 days or find another solution. The files with the intermediate results cannot be used with python 3.7.6</p>
","0","","0","605","156","1","68","60478862","60909819","<p>I am running a  <a href=""https://github.com/huangkuns/wireframe"" rel=""nofollow noreferrer"">pytorch solution for wireframe detection</a>. I am receiving a ""RuntimeError: error in LoadLibraryA"" when the solution executes ""forward return torch.cat(outputs, 1)""</p>

<p>I am not able to provide a minimal re-producable example. Therefore the quesion: Is it possible to produce just type of error in a microsoft library by python programming errors, or is this most likely a version (of python, pytorch, CUDA,...) problem or a bug in my installation?</p>

<p>I am using windows 10, python 3.8.1 and pytorch 1.4.0.</p>

<pre><code>File ""main.py"", line 144, in &lt;module&gt;
  main()
File ""main.py"", line 137, in main
  trainer.train(train_loader, val_loader=None)
File ""D:\Dev\Python\Projects\wireframe\wireframe\junc\trainer\balance_junction_trainer.py"", line 75, in train
  self.step(epoch, train_loader)
File ""D:\Dev\Python\Projects\wireframe\wireframe\junc\trainer\balance_junction_trainer.py"", line 176, in step
  ) = self.model(input_var, junc_conf, junc_res, bin_conf, bin_res)
File ""D:\Dev\Python\Environment\Environments\pytorch\lib\site-packages\torch\nn\modules\module.py"", line 532, in __call__
  result = self.forward(*input, **kwargs)
File ""D:\Dev\Python\Projects\wireframe\wireframe\junc\model\inception.py"", line 41, in forward
  base_feat = self.base_net(im_data)
File ""D:\Dev\Python\Environment\Environments\pytorch\lib\site-packages\torch\nn\modules\module.py"", line 532, in __call__
  result = self.forward(*input, **kwargs)
File ""D:\Dev\Python\Projects\wireframe\wireframe\junc\model\networks\inception_v2.py"", line 63, in forward
  x = self.Mixed_3b(x)
File ""D:\Dev\Python\Environment\Environments\pytorch\lib\site-packages\torch\nn\modules\module.py"", line 532, in __call__
  result = self.forward(*input, **kwargs)
File ""D:\Dev\Python\Projects\wireframe\wireframe\junc\model\networks\inception_v2.py"", line 97, in forward
  return torch.cat(outputs, 1)
RuntimeError: error in LoadLibraryA
</code></pre>
"
"60909819","<p>Try this workground: run the following code after import torch (should be fixed in 1.5):</p>

<pre><code>import ctypes
ctypes.cdll.LoadLibrary('caffe2_nvrtc.dll')
</code></pre>
","1","","4","309","53","1","15","60478862","60909819","<p>I am running a  <a href=""https://github.com/huangkuns/wireframe"" rel=""nofollow noreferrer"">pytorch solution for wireframe detection</a>. I am receiving a ""RuntimeError: error in LoadLibraryA"" when the solution executes ""forward return torch.cat(outputs, 1)""</p>

<p>I am not able to provide a minimal re-producable example. Therefore the quesion: Is it possible to produce just type of error in a microsoft library by python programming errors, or is this most likely a version (of python, pytorch, CUDA,...) problem or a bug in my installation?</p>

<p>I am using windows 10, python 3.8.1 and pytorch 1.4.0.</p>

<pre><code>File ""main.py"", line 144, in &lt;module&gt;
  main()
File ""main.py"", line 137, in main
  trainer.train(train_loader, val_loader=None)
File ""D:\Dev\Python\Projects\wireframe\wireframe\junc\trainer\balance_junction_trainer.py"", line 75, in train
  self.step(epoch, train_loader)
File ""D:\Dev\Python\Projects\wireframe\wireframe\junc\trainer\balance_junction_trainer.py"", line 176, in step
  ) = self.model(input_var, junc_conf, junc_res, bin_conf, bin_res)
File ""D:\Dev\Python\Environment\Environments\pytorch\lib\site-packages\torch\nn\modules\module.py"", line 532, in __call__
  result = self.forward(*input, **kwargs)
File ""D:\Dev\Python\Projects\wireframe\wireframe\junc\model\inception.py"", line 41, in forward
  base_feat = self.base_net(im_data)
File ""D:\Dev\Python\Environment\Environments\pytorch\lib\site-packages\torch\nn\modules\module.py"", line 532, in __call__
  result = self.forward(*input, **kwargs)
File ""D:\Dev\Python\Projects\wireframe\wireframe\junc\model\networks\inception_v2.py"", line 63, in forward
  x = self.Mixed_3b(x)
File ""D:\Dev\Python\Environment\Environments\pytorch\lib\site-packages\torch\nn\modules\module.py"", line 532, in __call__
  result = self.forward(*input, **kwargs)
File ""D:\Dev\Python\Projects\wireframe\wireframe\junc\model\networks\inception_v2.py"", line 97, in forward
  return torch.cat(outputs, 1)
RuntimeError: error in LoadLibraryA
</code></pre>
"
"60478934","<p>I am really not sure about my solution, but!!! If I remember correctly, you
can only serialize dictionaries in json, so maybe try this out:</p>

<pre class=""lang-py prettyprint-override""><code>def save(filename, budgets):
   """"""Saves the changes made into the accounts""""""

   with open(filename, 'w') as f_obj: 
       budgets2 = [budget.__dict__ for budget in budgets]
       json.dump(budgets2, f_obj)
</code></pre>
","1","","0","312","10","3","16","60478879","60478934","<p>I'm making an expense tracker. I've created an Account class, that registers a specific budget. All the accounts are saved in a Budgets list. Then I try to save the Budgets list into a json file using the save function, which returns an error. This is kinda obvious, but I can't think of any efficient alternative. Any solution? PD: I deleted all the structure not related with the problem, because it already works, and it doesn't let me send all the code. Sorry if something seems out of context.</p>

<pre><code>def initialize(filename):
   """"""
   Adjusts the starting parameters.
   """"""

   budgets = []

   try: 
   # Checks if the file exists, and executes the apropiate code
   # according to the situation.
       with open(filename, 'r') as f_obj: 
           budgets = json.load(f_obj) 
           # Loads the info from older sessions 
           # into the list.

   except FileNotFoundError: #If the file doesn't exist, we create it.
       print(""Seems you are the first one here!"")

       return budgets




class Account:
   """"""

   Simulates a budget with custom percentatges for each area of spending

   """"""
   def __init__(self, name, cash, percent):
       self.name = name
       self.cash = int(cash)
       self.percent = percent
       self.budget = {}

       for key, value in self.percent.items():
           self.budget[key] = self.cash * value / 100


def save(filename, budgets):
   """"""Saves the changes made into the accounts""""""

   with open(filename, 'w') as f_obj: 
       json.dump(budgets, f_obj)

def main():
   """"""Executes the main program""""""

   filename = ""budgets.json""

   budgets = initialize(filename)

   while True:
       a = input(""\nSelect the desired operation (h for help): "")

       if a == 'help':
           help()


       elif a == 'save':
           save(filename, budgets)
           print('account saved succesfully')

       elif a == 'exit':
           break

       else:
           print(""ERROR: The input is not an operation\n"")
</code></pre>
"
"60479916","<p>I believe this code will achieve the result you are looking for (note that call to grid_columnconfigure is on win, which is the parent of your frame widget):</p>

<pre><code>import tkinter
import tkinter.ttk

win = tkinter.Tk()
win.geometry('600x600')

frame = tkinter.Frame(win, bg='red', height=300)
frame.grid(row=0, column=0, sticky='ew')
win.grid_columnconfigure(0,weight=1)

win.mainloop()
</code></pre>
","1","","3","337","5","0","111","60478892","60479916","<p>I am learning Python GUI programming with tkinter. I wanted to place a frame in my root window using the grid geometry manager, specify a height, and have the frame expand to the full width of the root window. I tried to do this using the sticky options but this does not produce the desired result. How do I make the frame expand to the full width of the window without manually specifying the width?</p>

<p>Code:</p>

<pre><code>import tkinter
import tkinter.ttk

win = tkinter.Tk()
win.geometry('600x600')

frame = tkinter.Frame(win, height=300)
frame.configure(bg='red')
frame.grid(column=0, sticky=tkinter.E + tkinter.W)

win.mainloop()
</code></pre>

<p><a href=""https://i.stack.imgur.com/0sekk.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/0sekk.png"" alt=""enter image description here""></a></p>
"
"60479012","<p>You can try this.</p>

<pre><code>for lst in my_list:
    lst[2:]=[0,0,0,0]
print(my_list)
#[[1, 2, 0, 0, 0, 0], [2, 4, 0, 0, 0, 0], [10, 11, 0, 0, 0, 0]]
</code></pre>

<p>If you have different sizes of lists in list and you want to change only last 4 items to <em>0</em> try this.</p>

<pre><code>for lst in my_list:
    lst[-4:]=[0,0,0,0]
</code></pre>

<hr>

<p><strong>EDIT:</strong></p>

<p><em>I want to keep the first x elements, and change the rest to 0.</em></p>

<p>Try this.</p>

<pre><code>lst[x-len(lst):]=[0 for i in range(len(lst)-x)] #suggested by dcg
</code></pre>

<p>Or</p>

<pre><code>lst[x:]=[0]*(len(lst)-x)
</code></pre>
","3","2020-03-01 19:47:58","4","14733","1831","61","1931","60478978","60479012","<p>Suppose I have a list of list.</p>

<pre><code>[[1,2,3,4,5,6], [2,4,6,8,9,10], [10, 11, 12, 13, 14, 15]]
</code></pre>

<p>Now I want to a list of list such as</p>

<pre><code>[[1,2,0,0,0,0], [2,4,0,0,0,0], [10, 11, 0, 0, 0, 0]]
</code></pre>

<p>Is there a quick way to do it instead of using a loop to modify it. Thank you.</p>

<p>Edit: sorry for the confusion. I like to keep first <em>x</em> elements and modify rest to <code>0</code>. 
The size of each sublist is same.</p>
"
"60479113","<p>The following code is what you need:</p>

<pre><code>if __name__ == ""__main__"":
    # list modification with zeros
    alist = [[1,2,3,4,5,6], [2,4,6,8,9,10], [10, 11, 12, 13, 14, 15]]

    for x in alist: 
        x[2:] = [0]*4

    print(alist)
</code></pre>

<p>Output:</p>

<pre><code>[[1, 2, 0, 0, 0, 0], [2, 4, 0, 0, 0, 0], [10, 11, 0, 0, 0, 0]]
</code></pre>
","4","2020-03-01 19:54:20","0","413","32","0","12","60478978","60479012","<p>Suppose I have a list of list.</p>

<pre><code>[[1,2,3,4,5,6], [2,4,6,8,9,10], [10, 11, 12, 13, 14, 15]]
</code></pre>

<p>Now I want to a list of list such as</p>

<pre><code>[[1,2,0,0,0,0], [2,4,0,0,0,0], [10, 11, 0, 0, 0, 0]]
</code></pre>

<p>Is there a quick way to do it instead of using a loop to modify it. Thank you.</p>

<p>Edit: sorry for the confusion. I like to keep first <em>x</em> elements and modify rest to <code>0</code>. 
The size of each sublist is same.</p>
"
"60479076","<p>use <code>sum</code> method in pandas</p>

<pre><code>df.groupby('Length')['Duration'].sum()
</code></pre>

<p>Let me know if this helps!!</p>
","0","","2","1444","3","8","195","60479008","60479076","<p>I have a dataset, df1</p>

<pre><code> Length  Duration
  90     10
  90     3
  90     5
  80     2
  80     2
</code></pre>

<p>I need to groupby Length and then sum</p>

<p>I am thinking I will have to</p>

<pre><code>import pandas as pd
import numpy as np

df.groupby['Length'].count ???
</code></pre>

<p>Desired Output:</p>

<pre><code>Length    Sum

90         18      
80         4
</code></pre>

<p>dput</p>

<pre><code>structure(list(Duration = c(10L, 3L, 5L, 2L, 2L), Length = c(90L, 
90L, 90L, 80L, 80L)), class = ""data.frame"", row.names = c(NA, 
-5L))
</code></pre>
"
"60515381","<p>As already discussed in the comments, you don't want to add an extra new line with the print statement.
Instead you want to use the position argument in tqdm.
The use case for different threads is even mentioned in the <a href=""https://tqdm.github.io/docs/tqdm/"" rel=""nofollow noreferrer"">docs</a>.</p>

<pre><code>position : int, optional
  Specify the line offset to print this bar (starting from 0)
  Automatic if unspecified. Useful to manage multiple bars at once (eg, from threads).
</code></pre>

<p>Currently, this argument is set to 0, so it will start the progress bar each time new. Instead you want to use the number of the thread. Because of simplicity, you can convert the given text to an integer and use this. But this is not recommended for production.</p>

<pre class=""lang-py prettyprint-override""><code>import multiprocessing
import time

from tqdm import tqdm
from joblib import Parallel, delayed


def run_file_analysis(text):
    cool = []
    for i in tqdm(range(0, 10), position=int(text), leave=True, desc = f'Text : {text}'):
        cool.append(i)
        time.sleep(1)

num_cores = multiprocessing.cpu_count()
ls = ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10']

if __name__ == ""__main__"":
    processed_list = Parallel(n_jobs=num_cores)(delayed(run_file_analysis)(i) for i in ls)

</code></pre>

<p>If the text's can not directly converted to integer, 'enumerate' can be used an the index can be passed to the function.</p>

<pre class=""lang-py prettyprint-override""><code>import multiprocessing
import time

from tqdm import tqdm
from joblib import Parallel, delayed


def run_file_analysis(text, job_number):
    cool = []
    for i in tqdm(range(0, 10), position=job_number, leave=True, desc = f'Text : {text}'):
        cool.append(i)
        time.sleep(1)

num_cores = multiprocessing.cpu_count()
ls = ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10']

if __name__ == ""__main__"":
    processed_list = Parallel(n_jobs=num_cores)(delayed(run_file_analysis)(text, i) for i, text in enumerate(ls))
</code></pre>

<p><strong>Edit:</strong></p>

<p>Some raceconditions can be reduced by setting <code>prefer='threads'</code> to the Parallel constructor:</p>

<pre class=""lang-py prettyprint-override""><code>if __name__ == ""__main__"":
    processed_list = Parallel(n_jobs=num_cores, prefer=""threads"")(delayed(run_file_analysis)(text, i) for i, text in enumerate(ls))
</code></pre>
","7","2020-03-04 14:30:52","3","1890","89","67","84","60479039","60515381","<p>I am struggling with getting <code>tqdm</code>'s progress bar to stay and update as opposed to write to a new line. Note: I am using <code>multiprocessing</code> to parallelize my code, and <code>tqdm</code> is inside the function I am parallelizing. </p>

<p>I added a <code>print</code> statement so the files will all appear in my terminal when running the program. Reproducible example below:</p>

<pre class=""lang-py prettyprint-override""><code>import multiprocessing
import time

from tqdm import tqdm
from joblib import Parallel, delayed


def run_file_analysis(text):
    cool = []
    for i in tqdm(range(0, 10), position = 0, leave = True, desc = f'Text : {text}'):
        print('')
        cool.append(i)
        time.sleep(1)

num_cores = multiprocessing.cpu_count()
ls = ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10']

if __name__ == ""__main__"":
    processed_list = Parallel(n_jobs=num_cores)(delayed(run_file_analysis)(i) for i in ls)
</code></pre>

<p>Current output: 
<a href=""https://i.stack.imgur.com/jfzLm.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/jfzLm.png"" alt=""enter image description here""></a></p>

<p>The desired output would be the ten text objects - 1, 2, 3, ... , 10 and a corresponding updating progress bar for each. Not 100 different ones. I have tried following many stackoverflow questions relating to the topic of <code>tqdm</code> and <code>multiprocessing</code> integration, but none of them are as straightforward as I would like them to be. Any help would be appreciated. </p>
"
"60479312","<p>I am not familiar with this class but after looking at the source code it seems fairly straightforward to achieve this. Keep in mind that it picks the <em>next</em> closest business day meaning Saturday turns into Monday as opposed to Friday. Also making your index be non-unique will <a href=""https://stackoverflow.com/questions/16626058/what-is-the-performance-impact-of-non-unique-indexes-in-pandas"">decrease performance</a> on your DataFrame, so I suggest assigning these values to a new column.</p>

<p>The one prerequisite is you have to make sure your index is any of these three types, <a href=""https://github.com/pandas-dev/pandas/blob/v1.0.1/pandas/tseries/offsets.py#L1064"" rel=""nofollow noreferrer"">datetime</a>, <a href=""https://github.com/pandas-dev/pandas/blob/v1.0.1/pandas/tseries/offsets.py#L1079"" rel=""nofollow noreferrer"">timedelta, pd.tseries.offsets.Tick</a>.</p>

<pre><code>offset = pd.tseries.offsets.CustomBusinessDay(n=0)

df.assign(
    closest_business_day=df.index.to_series().apply(offset)
)

            V1  V2  V3  V4  V5 closest_business_day
2008-01-12   4  15  11   7   1           2008-01-14
2008-01-13   5   2   8   7   1           2008-01-14
2008-01-14  13  13   9   6   4           2008-01-14
2008-01-15  14  15  12   9   3           2008-01-15
2008-01-16   1  10   2  12  15           2008-01-16
2008-01-17  10   5   9   9   1           2008-01-17
2008-01-18  13  11   5   7   2           2008-01-18
2008-01-19   2   6   7   9   6           2008-01-21
2008-01-20   5   4  14   3   7           2008-01-21
2008-01-21  11  11   4   7  15           2008-01-21
2008-01-22   9   4  15  10   3           2008-01-22
2008-01-23   2  13  13  10   3           2008-01-23
2008-01-24  12  15  14  12   8           2008-01-24
2008-01-25   1   4   2   6  15           2008-01-25
</code></pre>
","0","","1","8935","225","249","1619","60479081","60479312","<p>I have a dataframe, ""df"", with a datetime index. Here is a rough snapshot of its dimensions:</p>

<pre><code>            V1  V2  V3  V4  V5
1/12/2008   4   15  11  7   1
1/13/2008   5   2   8   7   1
1/14/2008   13  13  9   6   4
1/15/2008   14  15  12  9   3
1/16/2008   1   10  2   12  15
1/17/2008   10  5   9   9   1
1/18/2008   13  11  5   7   2
1/19/2008   2   6   7   9   6
1/20/2008   5   4   14  3   7
1/21/2008   11  11  4   7   15
1/22/2008   9   4   15  10  3
1/23/2008   2   13  13  10  3
1/24/2008   12  15  14  12  8
1/25/2008   1   4   2   6   15
</code></pre>

<p>Some of the days in the index are weekends and holidays. </p>

<p>I would like to move all dates, in the datetime index of ""df"", to their respective closest (US) business day (i.e. Mon-Friday, excluding holidays). </p>

<p>How would you recommend for me to do this? I am aware that Pandas has a <a href=""https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.tseries.offsets.CustomBusinessDay.html"" rel=""nofollow noreferrer"">""timeseries offset""</a> facility for this. But, I haven't been able to find an example that walks a novice reader through this.</p>

<p>Can you help?</p>
"
"60479188","<p>The full signature of the <a href=""https://docs.python.org/3/library/functions.html#print"" rel=""nofollow noreferrer"">print</a> function is:</p>

<pre><code>print(*objects, sep=' ', end='\n', file=sys.stdout, flush=False)
</code></pre>

<p>The ""end"" paramter is the suffix appened to each print.
The default value is '\n' which is a new line.</p>

<pre><code>def fib(n):
    a = 0
    b = 1
    while a &lt; n :
        print(a)
        a = b
        b = a+b

fib(5)
</code></pre>
","0","","1","784","99","4","65","60479100","60479188","<p>I don't understand what the end sign means in this code.  </p>

<pre><code>def fib(n):
    a = 0
    b = 1
    while a &lt; n :
        print (a,end='')

        a = b
        b = a+b

        print()

fib(5)
</code></pre>
"
"60479298","<p>When you are encountering unknown Python construct, it can be often explained by built-in Python <code>help</code>. Simply launch python console and do <code>help(print)</code> to get description of <code>print</code>, which is as follows:</p>

<pre><code>Help on built-in function print in module builtins:

print(...)
    print(value, ..., sep=' ', end='\n', file=sys.stdout, flush=False)

    Prints the values to a stream, or to sys.stdout by default.
    Optional keyword arguments:
    file:  a file-like object (stream); defaults to the current sys.stdout.
    sep:   string inserted between values, default a space.
    end:   string appended after the last value, default a newline.
    flush: whether to forcibly flush the stream.
</code></pre>
","0","","1","8910","0","0","376","60479100","60479188","<p>I don't understand what the end sign means in this code.  </p>

<pre><code>def fib(n):
    a = 0
    b = 1
    while a &lt; n :
        print (a,end='')

        a = b
        b = a+b

        print()

fib(5)
</code></pre>
"
"60479352","<p>Can't you just <a href=""https://pandas.pydata.org/pandas-docs/stable/user_guide/groupby.html"" rel=""nofollow noreferrer"">group by</a> the year and month and then proceed from there?</p>

<pre><code>for _, v in df.groupby(['year', 'month'])['open']:
    tempOpenDF = v
    # do stuff
</code></pre>
","3","","1","8935","225","249","1619","60479144","60479352","<p>I am trying to grab all the values of one column based on the value of another. 
I found some helpful stackoverflow questions already that are related to mine, but the solution in those don't seem to work on a variable range. Do I need to do something different for a variable?  </p>

<p>I am trying to only grab the values of column 'open', from the dataset where the value of 'month' equals the month variable in the loop. </p>

<p>To be clear, the expected output is only the 'open' values. </p>

<pre><code>for year in dfClose['year'].unique():
        tempYearDF = dfClose[dfClose['year'] == year]
        for month in range(1,13):
            tempOpenDF = tempYearDF.loc[tempYearDF['month'] == month, 'open']
</code></pre>

<p>I plan to do more manipulating to the tempOpenDF variable after assigning the data, but I first need to verify it is populating. </p>

<p>Sample data</p>

<pre><code>dfClose

    open      year  month   day    date
0   30.490000   2010    1   4   2010-01-04
1   30.657143   2010    1   5   2010-01-05
2   30.625713   2010    1   6   2010-01-06
3   30.250000   2010    1   7   2010-01-07
4   30.042856   2010    1   8   2010-01-08
.
.
2551    297.260010  2020    2   24  2020-02-24
2552    300.950012  2020    2   25  2020-02-25
2553    286.529999  2020    2   26  2020-02-26
2554    281.100006  2020    2   27  2020-02-27
2555    257.260010  2020    2   28  2020-02-28
</code></pre>

<p>Output</p>

<pre><code>tempOpenDF
Series([], Name: open, dtype: float64)
</code></pre>

<p>Data types</p>

<pre><code>tempYearDF.dtypes

open     float64
year       int64
month      int64
day        int64
date      object
dtype: object
</code></pre>

<p>All the data for ""year"" is correctly separating, just having trouble grabbing month data now. </p>

<pre><code>tempYearDF

    open    year    month   day date
2516    296.239990  2020    1   2   2020-01-02
2517    297.149994  2020    1   3   2020-01-03
2518    293.790009  2020    1   6   2020-01-06
2519    299.839996  2020    1   7   2020-01-07
2520    297.160004  2020    1   8   2020-01-08
2521    307.239990  2020    1   9   2020-01-09
2522    310.600006  2020    1   10  2020-01-10
2523    311.640015  2020    1   13  2020-01-13
2524    316.700012  2020    1   14  2020-01-14
2525    311.850006  2020    1   15  2020-01-15
2526    313.589996  2020    1   16  2020-01-16
2527    316.269989  2020    1   17  2020-01-17
2528    317.190002  2020    1   21  2020-01-21
2529    318.579987  2020    1   22  2020-01-22
2530    317.920013  2020    1   23  2020-01-23
2531    320.250000  2020    1   24  2020-01-24
2532    310.059998  2020    1   27  2020-01-27
2533    312.600006  2020    1   28  2020-01-28
2534    324.450012  2020    1   29  2020-01-29
2535    320.540009  2020    1   30  2020-01-30
2536    320.929993  2020    1   31  2020-01-31
2537    304.299988  2020    2   3   2020-02-03
2538    315.309998  2020    2   4   2020-02-04
2539    323.519989  2020    2   5   2020-02-05
2540    322.570007  2020    2   6   2020-02-06
2541    322.369995  2020    2   7   2020-02-07
2542    314.179993  2020    2   10  2020-02-10
2543    323.600006  2020    2   11  2020-02-11
2544    321.470001  2020    2   12  2020-02-12
2545    324.190002  2020    2   13  2020-02-13
2546    324.739990  2020    2   14  2020-02-14
2547    315.359985  2020    2   18  2020-02-18
2548    320.000000  2020    2   19  2020-02-19
2549    322.630005  2020    2   20  2020-02-20
2550    318.619995  2020    2   21  2020-02-21
2551    297.260010  2020    2   24  2020-02-24
2552    300.950012  2020    2   25  2020-02-25
2553    286.529999  2020    2   26  2020-02-26
2554    281.100006  2020    2   27  2020-02-27
2555    257.260010  2020    2   28  2020-02-28
</code></pre>

<p>If I use an actual value for the equals too, I get the results I want. 
But when I try use that value based on the range loop value, it breaks. </p>

<p>Good</p>

<pre><code>tempYearDF.loc[tempYearDF['month'] == 1, 'open']

2516    296.239990
2517    297.149994
2518    293.790009
2519    299.839996
2520    297.160004
2521    307.239990
2522    310.600006
2523    311.640015
</code></pre>
"
"60479436","<p>Sample data frame:</p>

<pre><code>     0     1  2
0  123  2020  1
1  234  2020  2
2  543  2020  1
</code></pre>

<pre class=""lang-py prettyprint-override""><code># For all unique years
for y in df[1].unique():
    # For all unique months
    for m in df[2].unique():
        # Get the row based on the month
        row = df.loc[df[2] == m]
            # Print only the desired column
            print(row[0])
</code></pre>

<p>Output:</p>

<pre><code>0    123
2    543
Name: 0, dtype: int64
1    234
Name: 0, dtype: int64
</code></pre>
","0","","0","203","2009","0","27","60479144","60479352","<p>I am trying to grab all the values of one column based on the value of another. 
I found some helpful stackoverflow questions already that are related to mine, but the solution in those don't seem to work on a variable range. Do I need to do something different for a variable?  </p>

<p>I am trying to only grab the values of column 'open', from the dataset where the value of 'month' equals the month variable in the loop. </p>

<p>To be clear, the expected output is only the 'open' values. </p>

<pre><code>for year in dfClose['year'].unique():
        tempYearDF = dfClose[dfClose['year'] == year]
        for month in range(1,13):
            tempOpenDF = tempYearDF.loc[tempYearDF['month'] == month, 'open']
</code></pre>

<p>I plan to do more manipulating to the tempOpenDF variable after assigning the data, but I first need to verify it is populating. </p>

<p>Sample data</p>

<pre><code>dfClose

    open      year  month   day    date
0   30.490000   2010    1   4   2010-01-04
1   30.657143   2010    1   5   2010-01-05
2   30.625713   2010    1   6   2010-01-06
3   30.250000   2010    1   7   2010-01-07
4   30.042856   2010    1   8   2010-01-08
.
.
2551    297.260010  2020    2   24  2020-02-24
2552    300.950012  2020    2   25  2020-02-25
2553    286.529999  2020    2   26  2020-02-26
2554    281.100006  2020    2   27  2020-02-27
2555    257.260010  2020    2   28  2020-02-28
</code></pre>

<p>Output</p>

<pre><code>tempOpenDF
Series([], Name: open, dtype: float64)
</code></pre>

<p>Data types</p>

<pre><code>tempYearDF.dtypes

open     float64
year       int64
month      int64
day        int64
date      object
dtype: object
</code></pre>

<p>All the data for ""year"" is correctly separating, just having trouble grabbing month data now. </p>

<pre><code>tempYearDF

    open    year    month   day date
2516    296.239990  2020    1   2   2020-01-02
2517    297.149994  2020    1   3   2020-01-03
2518    293.790009  2020    1   6   2020-01-06
2519    299.839996  2020    1   7   2020-01-07
2520    297.160004  2020    1   8   2020-01-08
2521    307.239990  2020    1   9   2020-01-09
2522    310.600006  2020    1   10  2020-01-10
2523    311.640015  2020    1   13  2020-01-13
2524    316.700012  2020    1   14  2020-01-14
2525    311.850006  2020    1   15  2020-01-15
2526    313.589996  2020    1   16  2020-01-16
2527    316.269989  2020    1   17  2020-01-17
2528    317.190002  2020    1   21  2020-01-21
2529    318.579987  2020    1   22  2020-01-22
2530    317.920013  2020    1   23  2020-01-23
2531    320.250000  2020    1   24  2020-01-24
2532    310.059998  2020    1   27  2020-01-27
2533    312.600006  2020    1   28  2020-01-28
2534    324.450012  2020    1   29  2020-01-29
2535    320.540009  2020    1   30  2020-01-30
2536    320.929993  2020    1   31  2020-01-31
2537    304.299988  2020    2   3   2020-02-03
2538    315.309998  2020    2   4   2020-02-04
2539    323.519989  2020    2   5   2020-02-05
2540    322.570007  2020    2   6   2020-02-06
2541    322.369995  2020    2   7   2020-02-07
2542    314.179993  2020    2   10  2020-02-10
2543    323.600006  2020    2   11  2020-02-11
2544    321.470001  2020    2   12  2020-02-12
2545    324.190002  2020    2   13  2020-02-13
2546    324.739990  2020    2   14  2020-02-14
2547    315.359985  2020    2   18  2020-02-18
2548    320.000000  2020    2   19  2020-02-19
2549    322.630005  2020    2   20  2020-02-20
2550    318.619995  2020    2   21  2020-02-21
2551    297.260010  2020    2   24  2020-02-24
2552    300.950012  2020    2   25  2020-02-25
2553    286.529999  2020    2   26  2020-02-26
2554    281.100006  2020    2   27  2020-02-27
2555    257.260010  2020    2   28  2020-02-28
</code></pre>

<p>If I use an actual value for the equals too, I get the results I want. 
But when I try use that value based on the range loop value, it breaks. </p>

<p>Good</p>

<pre><code>tempYearDF.loc[tempYearDF['month'] == 1, 'open']

2516    296.239990
2517    297.149994
2518    293.790009
2519    299.839996
2520    297.160004
2521    307.239990
2522    310.600006
2523    311.640015
</code></pre>
"
"60479749","<pre><code>for month in range(1,13):
    tempOpenDF = tempYearDF.loc[tempYearDF['month'] == month, 'open']
</code></pre>

<p><code>loc</code> = location, or ""named"" items</p>

<p>You might want <code>iloc</code>, but also, isn't <code>tempYearDF['month']</code> an entire column?<br>
You might want to refer to <code>tempYearDF['month'].value</code> or <code>tempYearDF['month'].the_name_of_this_column</code> (or whatever the appropriate method/attribute is).</p>

<hr>

<p><code>df[df[""month""] ==1]</code> is a slice with 21 rows and all the columns
<code>df.loc[df[""month""] ==1]</code> is also a slice with 21 rows and all the columns
'<code>df.loc[df[""month""] ==1, ""open""</code> does return the 21 rows just in the <code>open</code> column when month equals <strong>1</strong>.</p>

<p>Where are you saving this too? <code>tempOpenDF</code> is <strong>within</strong> the <code>for</code> loop. Its value will just change with every index of the loop.</p>

<p>I would have to see more of where this is passed to. As it stands you filter correctly, but sending that filtered data to nowhere.</p>

<p>What you have works otherwise.</p>

<pre><code>import pandas as pd
df = pd.read_csv(""sample_data.csv"",sep='\t',parse_dates=[""date""])
# sample data is what you provided above, using tab separation
#

some_year = 2020
print(df.loc[df[""month""] == 1, 'open'],'\n')
print(df.loc[df[""year""] == 2020, 'open'],'\n')
# print(df.loc[(df[""month""] == 1 and df[""year""] == 2020), 'open'])

for i in range(1,13):
    dfy = df.loc[df[""year""] == 2020]
    mondata = dfy.loc[dfy[""month""] == i, ""open""]
    print(""Month: "",i,'\n',mondata,""\n"")
</code></pre>

<p><code>&gt;&gt;&gt; df.head()</code><br>
<code>some_index        open  year  month  day       date</code><br>
<code>0        2516  296.239990  2020      1    2 2020-01-02</code><br>
<code>1        2517  297.149994  2020      1    3 2020-01-03</code><br>
<code>2        2518  293.790009  2020      1    6 2020-01-06</code><br>
<code>3        2519  299.839996  2020      1    7 2020-01-07</code><br>
<code>4        2520  297.160004  2020      1    8 2020-01-08</code><br>
true index is 0,1, etc. <code>some_index</code> came from your data.</p>
","0","","0","1560","210","2","417","60479144","60479352","<p>I am trying to grab all the values of one column based on the value of another. 
I found some helpful stackoverflow questions already that are related to mine, but the solution in those don't seem to work on a variable range. Do I need to do something different for a variable?  </p>

<p>I am trying to only grab the values of column 'open', from the dataset where the value of 'month' equals the month variable in the loop. </p>

<p>To be clear, the expected output is only the 'open' values. </p>

<pre><code>for year in dfClose['year'].unique():
        tempYearDF = dfClose[dfClose['year'] == year]
        for month in range(1,13):
            tempOpenDF = tempYearDF.loc[tempYearDF['month'] == month, 'open']
</code></pre>

<p>I plan to do more manipulating to the tempOpenDF variable after assigning the data, but I first need to verify it is populating. </p>

<p>Sample data</p>

<pre><code>dfClose

    open      year  month   day    date
0   30.490000   2010    1   4   2010-01-04
1   30.657143   2010    1   5   2010-01-05
2   30.625713   2010    1   6   2010-01-06
3   30.250000   2010    1   7   2010-01-07
4   30.042856   2010    1   8   2010-01-08
.
.
2551    297.260010  2020    2   24  2020-02-24
2552    300.950012  2020    2   25  2020-02-25
2553    286.529999  2020    2   26  2020-02-26
2554    281.100006  2020    2   27  2020-02-27
2555    257.260010  2020    2   28  2020-02-28
</code></pre>

<p>Output</p>

<pre><code>tempOpenDF
Series([], Name: open, dtype: float64)
</code></pre>

<p>Data types</p>

<pre><code>tempYearDF.dtypes

open     float64
year       int64
month      int64
day        int64
date      object
dtype: object
</code></pre>

<p>All the data for ""year"" is correctly separating, just having trouble grabbing month data now. </p>

<pre><code>tempYearDF

    open    year    month   day date
2516    296.239990  2020    1   2   2020-01-02
2517    297.149994  2020    1   3   2020-01-03
2518    293.790009  2020    1   6   2020-01-06
2519    299.839996  2020    1   7   2020-01-07
2520    297.160004  2020    1   8   2020-01-08
2521    307.239990  2020    1   9   2020-01-09
2522    310.600006  2020    1   10  2020-01-10
2523    311.640015  2020    1   13  2020-01-13
2524    316.700012  2020    1   14  2020-01-14
2525    311.850006  2020    1   15  2020-01-15
2526    313.589996  2020    1   16  2020-01-16
2527    316.269989  2020    1   17  2020-01-17
2528    317.190002  2020    1   21  2020-01-21
2529    318.579987  2020    1   22  2020-01-22
2530    317.920013  2020    1   23  2020-01-23
2531    320.250000  2020    1   24  2020-01-24
2532    310.059998  2020    1   27  2020-01-27
2533    312.600006  2020    1   28  2020-01-28
2534    324.450012  2020    1   29  2020-01-29
2535    320.540009  2020    1   30  2020-01-30
2536    320.929993  2020    1   31  2020-01-31
2537    304.299988  2020    2   3   2020-02-03
2538    315.309998  2020    2   4   2020-02-04
2539    323.519989  2020    2   5   2020-02-05
2540    322.570007  2020    2   6   2020-02-06
2541    322.369995  2020    2   7   2020-02-07
2542    314.179993  2020    2   10  2020-02-10
2543    323.600006  2020    2   11  2020-02-11
2544    321.470001  2020    2   12  2020-02-12
2545    324.190002  2020    2   13  2020-02-13
2546    324.739990  2020    2   14  2020-02-14
2547    315.359985  2020    2   18  2020-02-18
2548    320.000000  2020    2   19  2020-02-19
2549    322.630005  2020    2   20  2020-02-20
2550    318.619995  2020    2   21  2020-02-21
2551    297.260010  2020    2   24  2020-02-24
2552    300.950012  2020    2   25  2020-02-25
2553    286.529999  2020    2   26  2020-02-26
2554    281.100006  2020    2   27  2020-02-27
2555    257.260010  2020    2   28  2020-02-28
</code></pre>

<p>If I use an actual value for the equals too, I get the results I want. 
But when I try use that value based on the range loop value, it breaks. </p>

<p>Good</p>

<pre><code>tempYearDF.loc[tempYearDF['month'] == 1, 'open']

2516    296.239990
2517    297.149994
2518    293.790009
2519    299.839996
2520    297.160004
2521    307.239990
2522    310.600006
2523    311.640015
</code></pre>
"
"60479253","<p>regex101.com finds the match <code>21.0*2</code> in the string <code>2+21.0*2*2</code>. <code>re.match</code> doesn't because <code>match</code> always has to include the start of the string. Using <code>re.search</code> instead works.</p>
","0","","0","31087","446","113","2216","60479178","60479253","<p>I created a regex to parse two floating point numbers and a <code>*</code> symbol between them using Python. As I am completely new to both I've tried basic online guides on using <code>re</code> library and regex itself. I came up with <code>((\d+)?(\.?)\d+)\*((\d+)?(\.?)\d+)</code> which works fine <a href=""https://regex101.com/"" rel=""nofollow noreferrer"">here</a> even for the string in question, <code>2+21.0*2*2</code>.</p>

<p>But if I use this expression and string in Python like so
<code>m = re.match(r""((\d+)?(\.?)\d+)\*((\d+)?(\.?)\d+)"", ""2+21.0*2*2"")</code>
it gives me ""None"" object. I do not see any obvious problems, any ideas why it does not work?</p>
"
"60479255","<p>As <a href=""https://docs.python.org/3/library/re.html"" rel=""nofollow noreferrer"">docs</a> says regarding <code>re.match</code>:</p>

<blockquote>
  <p>If zero or more characters at the beginning of string match the
  regular expression pattern, return a corresponding match object.
  Return None if the string does not match the pattern</p>
</blockquote>

<p>regex101 show that there is match starting at first digit of 21. You should use <code>re.search</code> instead:</p>

<pre><code>import re
m = re.search(r""((\d+)?(\.?)\d+)\*((\d+)?(\.?)\d+)"", ""2+21.0*2*2"")
print(m is None)  # False
</code></pre>
","0","","0","8910","0","0","376","60479178","60479253","<p>I created a regex to parse two floating point numbers and a <code>*</code> symbol between them using Python. As I am completely new to both I've tried basic online guides on using <code>re</code> library and regex itself. I came up with <code>((\d+)?(\.?)\d+)\*((\d+)?(\.?)\d+)</code> which works fine <a href=""https://regex101.com/"" rel=""nofollow noreferrer"">here</a> even for the string in question, <code>2+21.0*2*2</code>.</p>

<p>But if I use this expression and string in Python like so
<code>m = re.match(r""((\d+)?(\.?)\d+)\*((\d+)?(\.?)\d+)"", ""2+21.0*2*2"")</code>
it gives me ""None"" object. I do not see any obvious problems, any ideas why it does not work?</p>
"
"60479281","<p>It seems like you want to get the gradient of the loss function with respect to the input (not the weights, as is usually the case). You can use <code>tf.GradientTape()</code> to achieve this particular task. Here is a sample implementation I referenced from a <a href=""https://www.tensorflow.org/tutorials/generative/adversarial_fgsm"" rel=""nofollow noreferrer"">TensorFlow tutorial</a>, with minimal edits to code to suit your situation:</p>

<pre class=""lang-py prettyprint-override""><code>loss_object = tf.keras.losses.CategoricalCrossentropy() # Can be any loss function

model = tf. keras.applications.MobileNetV2(include_top=True, weights='imagenet') # Can be any model

def compute_gradient(input, input_label):
  with tf.GradientTape() as tape:
    tape.watch(input)
    prediction = model(input)
    loss = loss_object(input_label, prediction)
  gradient = tape.gradient(loss, input)
  return gradient
</code></pre>

<p>For more information on how to use <code>tf.GradientTape()</code>, refer to the <a href=""https://www.tensorflow.org/api_docs/python/tf/GradientTape"" rel=""nofollow noreferrer"">official documentation</a>.</p>
","0","2020-03-01 20:26:04","0","1396","8","14","79","60479230","60479281","<p>I'm building a custom neural network implementation. I use Keras for testing to make sure that gradients computed by my implementation match Keras gradients. Thanks to this answer <a href=""https://stackoverflow.com/questions/51140950/how-to-obtain-the-gradients-in-keras"">How to obtain the gradients in keras?</a> I was able to compare weights and outputs gradients. However I would also like to compare gradients for INPUTS. My Keras model is just one dense layer.</p>

<pre><code>model = Sequential()
model.add(Dense(output_size,
                use_bias=bias,
                input_shape=(input_size,),
                activation=activation_name))
model.compile(optimizer=""sgd"", loss=loss_function_name)

...

model.evaluate(x, y)
</code></pre>

<p>How can I get gradients in respect to <code>x</code>?</p>
"
"60479493","<p>I was not exactly sure what you wanted to do, but I modified your function to determine if num entry is ''.  If not then convert value fetched to int and compare to 56.  If larger, then insert entry ""Excellent"" in remark entry, otherwise put ""Done"" in remark entry.</p>

<p>As you enter each digit, the comparison to 56 will take place so the first digit will always result in ""Done"" appearing.  Once you exceed 56 (which will require a minimum of 2 digits) it will continue to remain ""Excellent"".</p>

<p>Again, I did the best I could with the logic provided.  Here's the full code:</p>

<pre><code>from tkinter import *

root = Tk()

num = StringVar()
entry1 = Entry(root, textvariable=num).pack()

remark = StringVar()
entry2 = Entry(root, textvariable=remark).pack()

def set_label(name, index, mode):
    result = num.get()
    if result == '':
        pass # not sure what rule should be here
    else:
        result = int(result)
        if result &gt; 56:
            remark.set(""Excellent"")
        else:
            remark.set(""Done"")

num.trace('w', set_label)
num.set('')

root.mainloop
</code></pre>
","2","","0","337","5","0","111","60479237","60479493","<p>Good evening, I am struggling to return an output without creating a button in Tkinker. I want to return either ""Excellent"" or ""Done"" based on the input but only the input is showing.</p>

<p>Below is the code I'm struggling with</p>

<pre><code>from tkinter import *

root = Tk()

num = StringVar()
entry1 = Entry(root, textvariable=num).pack()

remark = StringVar()
entry2 = Entry(root, textvariable=remark).pack()

def set_label(name, index, mode):
    return remark.set(num.get())
    if result &gt; 56:
        return ""Excellent""
    else:
        return ""Done""

num.trace('w', set_label)
num.set('')

root.mainloop
</code></pre>
"
"60479829","<p>Welcome to StackOverflow.</p>

<p>There could be two causes for your problem. </p>

<p>1) It could be that you modified the dataset. For this, I would check the dataset and see if you made any changes to the data itself. Because your code works on other examples and will not change from day to day because there are no random elements to it. </p>

<p>2) The second issue could be your use of <code>df.description</code> when you call a dataframe column in this line:</p>

<pre><code>sent = nltk.word_tokenize(str(df.description))
</code></pre>

<p>you get a truncated output. Look at the type of <code>df.description</code> and it is a <code>Series</code> object.</p>

<p>I created another example and it is as follows:</p>

<pre><code>from nltk.tokenize import word_tokenize
import pandas as pd

df = pd.DataFrame({'description' : ['The OP is asking a question and I referred him to the Minimum Verifible Example page which states: When asking a question, people will be better able to provide help if you provide code that they can easily understand and use to reproduce the problem. This is referred to by community members as creating a minimal, reproducible example (reprex), a minimal, complete and verifiable example (mcve), or a minimal, workable example (mwe). Regardless of how it\'s communicated to you, it boils down to ensuring your code that reproduces the problem follows the following guidelines:']})


print(df.description)

0    The OP is asking a question and I referred him...
Name: description, dtype: object
</code></pre>

<p>As you see above, it is truncated and it is not the full text in the <code>description</code> column.</p>

<p>My recommendation to your code is to look into this line of code and find a different way of doing it:</p>

<pre><code>sent = nltk.word_tokenize(str(df.description))
</code></pre>

<p>Note that the method that you used in your code will include the index number (which I understand you filtered by <code>isalpha</code>) and also this <code>Name: description, dtype: object</code> in the data that you are processing.</p>

<p>One way would be to use <code>map</code> to process your data. An example is:</p>

<pre><code>pd.set_option('display.max_colwidth', -1)
df['tokenized'] = df['description'].map(str).map(nltk.word_tokenize)
</code></pre>

<p>Proceed to do this for other operations as well. An easy way to do it would be to build a preprocessing function that applies all the pre-processing operations (that you want to use) on your dataframe.</p>

<p>I hope this helps.</p>
","2","2020-03-01 21:23:37","0","1710","112","5","196","60479331","60479829","<p>Last month, I tried to tokenize text and create a of words to see which word shows up frequently. Today, I want do it again in the same dataset with the same code. It still works but the result is different and obviously today's outcome is wrong because the frequency of appearing words decrease significantly. </p>

<p>Here is my code:</p>

<pre><code>from nltk.tokenize import sent_tokenize, word_tokenize
from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS
from nltk.stem import WordNetLemmatizer
import nltk
from collections import Counter

sent = nltk.word_tokenize(str(df.description))
lower_token = [t.lower() for t in sent]
alpha = [t for t in lower_token if t.isalpha()]
stop_word =  [t for t in alpha if t not in ENGLISH_STOP_WORDS]
k = WordNetLemmatizer()
lemma = [k.lemmatize(t) for t in stop_word]
bow = Counter(lemma)
print(bow.most_common(20))
</code></pre>

<p><a href=""https://i.stack.imgur.com/08fkb.png"" rel=""nofollow noreferrer"">Here is a sample of my dataset</a></p>

<p>This dataset is from Kaggle and the name of it is ""Wine Reviews"".</p>
"
"60479363","<p>No, that gets evaluated like this:</p>

<p><code>a[1:3][1]</code> -> <code>[[8, 3], [22, 80]][1]</code> -> <code>[22, 80]</code></p>

<p>Note that <code>:3</code> means <em>up to</em> index 3 (not including it), so really your slice should be <code>a[1:4]</code>, but where you want the <em>last three</em> sublists, and not the <em>second to fourth</em> sublists, you should use a negative slice: <code>a[-3:]</code>. Even if the list can only ever be 4-long, this is clearer.</p>

<p>So you want <code>[x[1] for x in a[-3:]]</code></p>

<p>If you want to print them like in your example output:</p>

<pre><code>&gt;&gt;&gt; for x in a[-3:]:
...     print(x[1])
... 
3
80
9
</code></pre>
","1","2020-03-01 20:38:25","0","15300","3115","1510","3211","60479341","60479396","<p>I'm wondering if I have a list of the list like this:</p>

<pre><code>a = [[43,76],[8,3],[22,80],[71,9]]
</code></pre>

<p>If I want to retrieve the second value in the last 3 sub-lists, i.e the second value from index 1 to 3 would be like that:</p>

<pre><code>a[1:3][1]:

3
80
9
</code></pre>
"
"60479373","<p>You can use <em>negative slicing</em> here.</p>

<pre><code>print(*[x[1] for x in a[-3:]],sep='\n') #a[-3:] gives last 3 elements
</code></pre>
","0","","1","14733","1831","61","1931","60479341","60479396","<p>I'm wondering if I have a list of the list like this:</p>

<pre><code>a = [[43,76],[8,3],[22,80],[71,9]]
</code></pre>

<p>If I want to retrieve the second value in the last 3 sub-lists, i.e the second value from index 1 to 3 would be like that:</p>

<pre><code>a[1:3][1]:

3
80
9
</code></pre>
"
"60479396","<p>My 2c:</p>

<pre><code>[x[1] for x in a[-3:]]
</code></pre>

<hr>

<pre><code>[3, 80, 9]
</code></pre>

<p><a href=""https://trinket.io/python3/d1dc7e25e6"" rel=""nofollow noreferrer"">Demo</a></p>
","0","2020-03-01 20:33:40","3","74108","5063","858","7248","60479341","60479396","<p>I'm wondering if I have a list of the list like this:</p>

<pre><code>a = [[43,76],[8,3],[22,80],[71,9]]
</code></pre>

<p>If I want to retrieve the second value in the last 3 sub-lists, i.e the second value from index 1 to 3 would be like that:</p>

<pre><code>a[1:3][1]:

3
80
9
</code></pre>
"
"60479504","<p>Possibly the easiest way to do this as most of the other answers have suggested is:</p>

<pre><code>[x[1] for x in a[-3:]]
</code></pre>

<p>However, for practice and for getting used to other ways of solving problems involving lists (and others), it is good to read up on what <code>map</code>, <code>filter</code> and <code>reduce</code> do (assuming that it is not known already). A small description is <a href=""https://book.pythontips.com/en/latest/map_filter.html"" rel=""nofollow noreferrer"">here</a>. </p>

<p>I thought I'd leave this answer here to add to the other answers. This is another way to do it using <code>map</code>. </p>

<pre><code>[*map(lambda x: x[1], a[-3:])]

Output: [3, 80, 9]
</code></pre>

<p>Hope this helps.</p>
","1","2020-03-01 20:39:39","0","1710","112","5","196","60479341","60479396","<p>I'm wondering if I have a list of the list like this:</p>

<pre><code>a = [[43,76],[8,3],[22,80],[71,9]]
</code></pre>

<p>If I want to retrieve the second value in the last 3 sub-lists, i.e the second value from index 1 to 3 would be like that:</p>

<pre><code>a[1:3][1]:

3
80
9
</code></pre>
"
"60479490","<p>By default, kafka python start from last offset, ie will only read new mesages.
One approach is to read from beginning or the alternative approach is to keep polling topic in an infinite loop as shown in below code:</p>

<pre><code>while True:
    try:
        records = consumer.poll(60 * 1000) # timeout in millis , here set to 1 min

        record_list = []
        for tp, consumer_records in records.items():
            for consumer_record in consumer_records:
                record_list.append(consumer_record.value)
        print(record_list) # record_list will be list of dictionaries
</code></pre>

<h2>Edit</h2>

<p>To read from the beginning, we need to add <code>auto_offset_reset=earliest</code> earlies while making consumer object</p>

<pre><code>consumer = KafkaConsumer(
    ""my-topic"",
    bootstrap_servers=""localhost:9092""),
    value_deserializer=lambda v: json.dumps(v).encode(""utf-8""),
    auto_offset_reset='earliest')
</code></pre>

<p>Let me know if this helps!!</p>
","2","2020-03-01 20:55:03","1","1444","3","8","195","60479348","60479490","<p>I have written a python script using <code>kafka-python</code> library which writes and reads messages into <code>kafka</code>. I write messages without any problem; I can retrieve them using <code>kafka</code> console tools. But I can't read them using my python script. I have a for on my consumer which freezes on the first line of the iteration and never returns. Here's my code:</p>

<pre><code>from kafka import KafkaConsumer

consumer = KafkaConsumer(
    ""my-topic"",
    bootstrap_servers=""localhost:9092""),
    value_deserializer=lambda v: json.dumps(v).encode(""utf-8"")
)

for msg in consumer:
    print(type(msg))
</code></pre>

<p>The consumer is created and subscribed completely; I can see that <code>my-topic</code> is listed on the topic list of its <code>_client</code> property.</p>

<p>Any idea?</p>
"
"60479999","<p>Why <code>+=</code> works and <code>+</code> doesn't work is ""that's how its coded"". But I haven't figured out any good reason for it. Lets focus simply on list addition</p>

<pre><code>operator         magic method   list equiv
--------         ------------   ----------
+= (inplace add) __iadd__       list_inplace_concat
+  (add)         __add__        list_concat
</code></pre>

<p>Inplace Add / list_inplace_concat works on any sequence. Under the covers, python simply calls <code>list.extend</code> which turns the right hand side into an iterator and so works with all sequences</p>

<pre><code>&gt;&gt;&gt; test = []
&gt;&gt;&gt; test += 'abc'
&gt;&gt;&gt; test
['a', 'b', 'c']
</code></pre>

<p>Add / list_concat is hardcoded to work only with other lists. The underlying C code uses the internal data structure of the list to copy its elements.</p>

<pre><code>&gt;&gt;&gt; test + 'abc'
Traceback (most recent call last):
  File ""&lt;stdin&gt;"", line 1, in &lt;module&gt;
TypeError: can only concatenate list (not ""str"") to list
</code></pre>

<p>Change the right hand side to a list and it works</p>

<pre><code>&gt;&gt;&gt; test + list('abc')
['a', 'b', 'c', 'a', 'b', 'c']
&gt;&gt;&gt; 
</code></pre>

<p><code>list_concat</code> is optimized to use the size of the two lists to know exactly how large the new list needs to be. Then it does member copy at the C structure level. What puzzles me is why there isn't a fallback when the ""not a list"" condition is detected. The list could be copied and extended.</p>
","0","","1","55035","2176","130","4224","60479354","60479999","<pre><code>&gt;&gt;&gt; r = [[]]
&gt;&gt;&gt; r[0] = r[0] + 'abc'
Traceback (most recent call last):
  File ""&lt;stdin&gt;"", line 1, in &lt;module&gt;
TypeError: can only concatenate list (not ""str"") to list
&gt;&gt;&gt; r[0] += 'abc'
&gt;&gt;&gt; r
[['a', 'b', 'c']]
</code></pre>

<p>Could somebody explain why second assignment works but not the first one ?</p>
"
"60480411","<p>Django is framework designed to build web applicattions. So it means that when the web-browser sends a request to a server, server processes the request and produces a response with adequate data, data gets send and displayed in the browser. This also means that most of processing that is done in Django happens in request context, while the applications is running.</p>

<p>Now if Django is not running and you try to use it scripts it crashes because it does not have its configuration loaded. So what you are really trying to do is using Django database layer outside of Django. To achieve this you load the settings and setup Django before you use its models.</p>

<p>Question how to use Django ORM outside of Django has already been answered here 
<a href=""https://stackoverflow.com/questions/2180415/using-django-database-layer-outside-of-django"">Using Django database layer outside of Django?</a>
and here 
<a href=""https://stackoverflow.com/questions/55247878/how-to-use-django-models-outside-of-django"">How to use Django models outside of Django?</a></p>

<p>For the sake of making your code work, if we supposedly if we have application 'football' and an app called 'list' in it with model 'Player' in its models module, and your script is in folder with manage.py. Than your code could look like the following:</p>

<pre><code>import requests
import urllib3
from bs4 import BeautifulSoup
import os
import django

os.environ['DJANGO_SETTINGS_MODULE'] = 'football.settings'
django.setup()

from list.models import Player

urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)
session = requests.Session()
session.headers = {""User-Agent"": ""Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/79.0.3945.117 Safari/537.36""}
url = 'https://www.smitegame.com/'
content = session.get(url, verify=False).content
soup = BeautifulSoup(content, 'html.parser')
allgods = soup.find_all('div', {'class': 'god'})

allitem = []

for god in allgods:
    godName = god.find('p')
    godFoto = god.find('img').get('src')
    allitem.append((godName, godFoto))
    Player.objects.create(name=godName.text)
</code></pre>

<p>Now what the bit of code that was added tells Django where its settings module, and then imports the models. </p>

<blockquote>
  <p>When you use Django, you have to tell it which settings youâ€™re using. Do this by using an environment variable, </p>
</blockquote>

<p>Check the documentation
<a href=""https://docs.djangoproject.com/en/3.0/topics/settings/#designating-the-settings"" rel=""nofollow noreferrer"">https://docs.djangoproject.com/en/3.0/topics/settings/#designating-the-settings</a></p>
","1","","1","86","22","0","6","60479411","60480411","<p>I have a python file in my Django project which scrapes 10 names from a website.
I want to store these 10 names in a postgresql database.</p>

<p>Below is the python file.</p>

<pre><code>import requests
import urllib3
from bs4 import BeautifulSoup
import psycopg2


urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)
session = requests.Session()
session.headers = {
    ""User-Agent"": ""Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/79.0.3945.117 Safari/537.36""}
url = 'https://www.smitegame.com/'
content = session.get(url, verify=False).content
soup = BeautifulSoup(content, ""html.parser"")
allgods = soup.find_all('div', {'class': 'god'})

allitem = []

for god in allgods:
    godName = god.find('p')
    godFoto = god.find('img').get('src')
    allitem.append((godName, godFoto))
    print(godName.text)
</code></pre>

<p>How do I need to approach this, I've made a class in models.py named GodList. But as soon as I try to import it I cannot run the scrape script anymore. </p>

<p>Am I aproaching this wrong?</p>

<p>I have the postgresql database connected to Django and it works. I can add models and I see it gets saved in the data base.</p>
"
"60479735","<p>I recommend you scan the text as a whole and not the individual lines. Also you can use groups in your pattern to capture and contain data. I would read the data as follows:</p>

<pre class=""lang-py prettyprint-override""><code>with open('test_subtitle.srt', 'r') as f:
    subtitles = f.read()
</code></pre>

<p>Then using the following code I would match the single sections and extract the data:</p>

<pre class=""lang-py prettyprint-override""><code>import re

num_pat = r'(\d+)'
time_pat = r'(\d{2,}:\d{2}:\d{2},\d{3}) --&gt; (\d{2,}:\d{2}:\d{2},\d{3})'
sentence_pat = r'([^\n]*)\n'

data_pattern = re.compile(r'\n'.join([num_pat, time_pat, sentence_pat]))
print('data_pattern:', data_pattern)

for i in re.finditer(data_pattern, subtitles):
    print('-'*20)
    print(i.group(1))
    print(f'time: {i.group(2)} --&gt; {i.group(3)}')
    print('text:', repr(i.group(4)))
    print()
</code></pre>

<p>A problem I also noticed in your code is that when defining your patterns you were using normal strings instead of raw strings and you weren't escaping your backslashes. If you want to use backslashes without escaping you should use a raw string. Hope this helped.</p>
","5","","0","266","7","4","21","60479444","60479735","<p>I'm trying to get the captions text to analyze it but I'm stuck trying to get the subtitles text in a readable way. I'm using regular expressions to get the captions numbers, captions time and captions speech. When it gets to the speech I get a lot of blank lines because the subtitles are set up like the image. So <strong>I just want to create a list that only contains the speech and not no the blank lines</strong>. The list that I'm getting is in an image too.</p>

<p>Here's a sample from the captions too:</p>

<pre><code>1
00:00:00,030 --&gt; 00:00:05,370
so here we are at the offices of my

2
00:00:02,240 --&gt; 00:00:05,370



3
00:00:02,250 --&gt; 00:00:07,319
accountants of your Eric Biddle mr.

4
00:00:05,360 --&gt; 00:00:07,319



5
</code></pre>

<p><a href=""https://i.stack.imgur.com/35coj.png"" rel=""nofollow noreferrer"">MY LIST</a></p>

<p><a href=""https://i.stack.imgur.com/lslLZ.png"" rel=""nofollow noreferrer"">CAPTIONS</a>:</p>

<pre><code>import re

filename = r'test_subtitle.srt'
pattern_number = re.compile('^\d+$')
pattern_time = re.compile('^[\d]+:[\d]+:[\d]+,[\d]+ --&gt; [\d]+:[\d]+:[\d]+,[\d]+$')
pattern_speech = re.compile(""^[A-Za-z,;'\""\\s]+[.?!]*$"")

for i, line in enumerate(open(filename)):
    for match in re.findall(pattern_number, line):
        print(match)

for i, line in enumerate(open(filename)):
    for match in re.findall(pattern_time, line):
        print(match)

speech = []

for i, line in enumerate(open(filename)):
    for match in re.findall(pattern_speech, line):
        speech.append(match)

print(speech)
</code></pre>
"
"60479573","<p>Since you have multiple levels of grouping here, I'd recommend just using a for loop to iterate over your data.</p>

<pre><code>from collections import defaultdict  

def make_nested(df): 
    f = lambda: defaultdict(f)   
    data = f()  

    for row in df.to_numpy().tolist():
        t = data
        for r in row[:-1]:
            t = t[r]
        t[row[-1]] = {}

    return data
</code></pre>

<p></p>

<pre><code>print(json.dumps(make_nested(df), indent=2))
{
  ""src1"": {
    ""table1"": {
      ""col1"": {},
      ""col2"": {}
    },
    ""table2"": {
      ""col1"": {}
    }
  },
  ""src2"": {
    ""table1"": {
      ""col1"": {},
      ""col2"": {}
    }
  }
}
</code></pre>

<p></p>

<p>This assumes your columns are arranged from left to right: outermost keys to innermost key.</p>
","3","","2","266035","10142","8528","64481","60479452","60479573","<p>Assume that I have a pandas DataFrame called <code>df</code> that looks something like:</p>

<pre><code>source      tables      columns      
src1        table1      col1       
src1        table1      col2
src1        table2      col1 
src2        table1      col1
src2        table1      col2
</code></pre>

<p>My current code below can iterate through the list of sources and nest the list of tables within each source as an object:</p>

<pre><code>data = [
    {k: v} 

    for k, v in df.groupby('source')['tables'].agg(
        lambda x: {v: {} for v in x}).items()
    ]

    with open('data.json', 'w') as f:
        json.dump(data, f, indent = 2)
</code></pre>

<p>The output I'm receiving with this code is as follows:</p>

<pre><code>[
  {
    ""src1"": {
      ""table1"": {},
      ""table2"": {}
    }
  },
  {
    ""src2"": {
      ""table1"": {},
    }
  }
]
</code></pre>

<p>My desired output:</p>

<pre><code>[
  {
    ""src1"": {
      ""table1"": {
         ""col1"": {},
         ""col2"": {}
     },
      ""table2"": {
         ""col1"": {}
     }
    }
  },
  {
    ""src2"": {
      ""table1"": {
         ""col1"": {}
      }
    }
  }
]
</code></pre>

<p>Any assistance in converting my 2-layer nested JSON file to 3 layers as shown above would be greatly appreciated. Thank you in advance.</p>
"
"60486167","<p>I guess you only need the <code>review</code> part of the data? If so, and <code>dt</code> is that part of the json, you can use </p>

<pre><code>data=dt.to_dict('records'),
</code></pre>

<p>because your structure is <code>[{column -&gt; value}, â€¦ , {column -&gt; value}]</code>, see <a href=""https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.to_dict.html"" rel=""nofollow noreferrer"">pandas reference</a></p>
","0","","1","1920","33","39","141","60479516","60486167","<p>I'm trying to display my data into a Dash DataTable but i've got this error:</p>

<p><code>Invalid argument `data` passed into DataTable.
Expected an array.
Was supplied type `object`.</code></p>

<p>My data (amazon comments) :</p>

<pre><code>[
{
    ""ratings"": {
        ""\n            5 star\n          "": ""\n          "",
        ""\n            4 star\n          "": ""\n          "",
        ""\n            3 star\n          "": ""\n          "",
        ""\n            2 star\n          "": ""\n          "",
        ""\n            1 star\n          "": ""\n          ""
    },
    ""reviews"": [
        {
            ""review_text"": ""The \""MPD Digital (TM) USA Made Ham CB Radio GMRS Repeater Transmission MILSPEC M17/ 163A RG-213/U (RG8/U) Coaxial Cable with UHF PL259 Connectors, 12 inches \"", I having two products of like nature from MPD, the older of the two being lightly used between transmitter and SWR meter,... to being placed in storage when not in use, is a disappointing, if not marginal product given the high level of promoting by MPD (Times Microwave) relative to product component selection, product design, to manufacturing processes and procedures. i) The advertised description for this coax cable is a contradiction. This RF related product is either an RG-213/U or RG-8/U and not both types of RF transmission cable simultaneously. When measured at 50MHz, the Velocity of Propagation (VP) for Foam High Density Polyethylene (FHDPE) dielectric RG-213/U is 66% with 1.5dB loss/100ft where as FHDPE dielectric RG-8/U, the VP is 85% with 1.2dB loss/100ft. ii) The cable ends do not use high grade Amphenol, PL-259 connectors as they did in the past for this product line, the MPD cable received most recently from Kimberly Distribution, being produced with cheap and short (function of cost reducing engineering to basic disrespect, presuming the end user will not know the difference), Chinese made PL-259 connectors (see photo) and per such, have a smaller mating surface with the coax cable, thus less robust attachment. iii) The cable markings for product type, e.g. RG-213/U, are not of a permanent nature, the printing being neither molded into the cable outer jacket or laser burned, the label wearing off with ease from cleaning or use (see photo). Because of such low persistent printing method, less I check the purchase order or some other user is tasked, cannot properly determine with any great assurance, cable type (RF properties), thus VP (velocity of propagation), signal loss, SWR,... As a side note, since the printing on the outer jacket of the coax cable is easy to remove (not permanent), leaving no other identifiers present (mystery cable), that this electrical product maybe considered contraband per contract, code and insurance underwriters for applications in which UL standards compliant electrical components e.g. DoD, Hospitals, Schools, Civil Defense, Fire and Police,... are required or mandated. iv) The 12\"" inch (1' ft) coax cables by MPD (Times Microwave) from current to past are not consistent in overall length as seen from simple side by side compassion (see photo and arrogantly rotated by disrespectful Amazon). There seeming to be some manufacturing (procedural and process controls) confusion at MPD relative to how to make consistent measurements (cuts) of the product e.g. is the coax conductor measured to 12\"" or the entire path length (connector end point to connector end point) is measured to 12\"". The MPD (Time Microwave) cable with contradicting advertising along with low end build quality is an indication that the leadership at MPD has prioritized cutting corners on raw component selection and manufacturing methods for the sake of cost reduction and or higher margins and earnings, as appose to being driven to manufacture a high end and excellent analytical product for discriminating customers. Remember: \""do a job, big or small, do it right, or not at all\"". Less processes and procedures are adjusted and rigorously adhered to by Times Microwave (MPD), do not recommend this coax cable, from contradicting description thus EE (Electrical Engineering) properties, to raw component selection thus ultimately integrated build quality to product assurance and type, for demanding and disciplined RF applications. Minus 0.25 for inconsistent process and procedure for measuring total cable path length. Minus 0.25 for contradicting product description, thus electrical (RF) properties of the coax cable. Minus 0.50 for using Chinese made PL-259 connectors rather than high grade Amphenol connectors like in the past. Minus 1.0 for having easy to remove, non permanent type markings (printing) on the transmission coax cable jacket. Park McGraw JPL, Spacecraft Soldering Course Certified Experimental Physicist, Former US Navy, NASA Fellow Former CEO Class C Electrical Contracting Firm, Life Safety Industry Former Instructor, Basic Electricity and Electronics, University of Hawai`i Hilo Former Member Technical Staff and Process Engineering Mgr, Laser and Sensor Products Center, Northrop Grumman (Space Park)"",
            ""review_posted_date"": None,
            ""review_header"": ""Uses Chinese Made PL-259 Connectors, Cable Type Printing Wears Off Easily, Contradicting Description"",
            ""review_rating"": ""3.0 "",
            ""review_author"": ""Directed Energy""
        },
        {
            ""review_text"": ""I ordered this coax for Amateur Radio use. RG-213 is rugged coax, much better than many of the air dielectric cables which are actually somewhat fragile. It is double shielded. The connectors are first quality and their installation appears first class. The price is very competitive. I have no connection with browning but I have come to respect their quality products and the value they provide. I have several of their antenna mounts and they are by far the best I have ever seen. In my 40+ years as a ham I learned long ago you buy the best because it lasts. I will confirm the specs on the cable and post any issues here when I get a chance, but I can tell from the packaging, connected quality, weight, and feel the manufacturer intended to deliver a first class product and spared no expense in doing so. I have bought other coax on Amazon but this was the most impressive so far re packaging. I never buy coax on ebay, been burned too often. This piece is intended to allow me to run my qrp cw rig by the pool but I may someday want to run higher power or use it for another antenna run to the shack. I probably own 3000 feet of coax installed at various sites but had none to spare nearby, so it was either gas or coax. The coax arrived in a sturdy box, it was sealed in moisture proof plastic bagging, and uniformly coiled and bound with quality cable ties. It's obvious the manufacturer takes good care of their inventory and this assembly is not made in someone's garage! W7CCE"",
            ""review_posted_date"": None,
            ""review_header"": ""Excellent quality coax, connectors"",
            ""review_rating"": ""5.0 "",
            ""review_author"": ""Merciless""
        },
        {
            ""review_text"": ""The coax was working well for six months or so. When I recently unscrewed the PL-259 from my radio, the entire connector came off the coax. The crimp sleeve slid off and the center conductor came completely out of the connector. There was solder on the inner pin of the connector, but it never reached the wire itself, so only the crimp sleeve was holding the wire in, and apparently the crimp sleeve wasn't crimped very well."",
            ""review_posted_date"": None,
            ""review_header"": ""Connector Failed"",
            ""review_rating"": ""1.0 "",
            ""review_author"": ""RichG""
        }
    ],
    ""url"": ""http://www.amazon.com/dp/product-reviews/B00Y7H39IW/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&amp;reviewerType=all_reviews&amp;pageNumber=14"",
    ""name"": ""MPD Digital USA Made Ham CB Radio GMRS Repeater Transmission MILSPEC M17/ 163A RG-213/U (RG8/U) Coaxial Cable with Soldered Silver UHF PL-259 Connectors, 12 inches"",
    ""price"": ""$14.99""
}]
</code></pre>

<p>My code :</p>

<pre><code>external_stylesheets = ['https://codepen.io/chriddyp/pen/bWLwgP.css']

app = dash.Dash(__name__, external_stylesheets=external_stylesheets)

app.layout = html.Div([
    dcc.Upload(
        id='upload-data',
        children=html.Div([
            'Drag and Drop or ',
            html.A('Select Files')
        ]),
        style={
            'width': '20%',
            'height': '40px',
            'lineHeight': '60px',
            'borderWidth': '1px',
            'borderStyle': 'dashed',
            'borderRadius': '5px',
            'textAlign': 'center',
            'margin': '10px'
        },
        # Allow multiple files to be uploaded
        multiple=True
    ),
    html.Div(id='output-data-upload'),
])
def update_output(contents, filename):
        .
        .
        .
dt = pd.DataFrame(data_extract)
    return html.Div([
        html.H5(filename),
        dash_table.DataTable(
            style_data={
                'whiteSpace': 'normal',
                'height': 'auto'
            },
            data=dt.to_dict('list'),
            columns=[{'name': i, 'id': i} for i in dt.columns]
        )
    ])

@app.callback(Output('output-data-upload', 'children'),
          [Input('upload-data', 'contents')],
          [State('upload-data', 'filename')])
def parse_contents(list_of_contents, list_of_names):
    if list_of_contents is not None:
        children = [
            update_output(c, n) for c, n in
            zip(list_of_contents, list_of_names)]
        return children


if __name__ == '__main__':
    app.run_server(debug=True)
</code></pre>

<p>I upload a csv file to generate the <code>data_extract</code> in the update_output() function which i want to display in my DataTable. 
I convert my data_extract into a pandas DataFrame, then i try to submit my data with data=dt.to_dict('list'). I also tried with different argument. </p>
"
"60480022","<p>Decorator is a function that takes as input the function (or class) to decorate, and makes some changes to it. I would go for a two method option, in which if the first method is true then they're genuine teacher, else they're not and in such case give them a valid output.</p>

<pre><code>def teacher_required(function=None, redirect_field_name=REDIRECT_FIELD_NAME, login_url='login'):
    '''
    Decorator for views that checks that the logged in user is a teacher,
    redirects to the log-in page if necessary.
    '''
    actual_decorator = user_passes_test(
        lambda u: u.is_active and u.is_teacher,
        login_url=login_url,
        redirect_field_name=redirect_field_name
    )
</code></pre>

<p>We can simply make a use case for the decorator <code>user_passes_test</code> </p>

<pre><code>from django.contrib.auth.decorators import user_passes_test

def teacher_required(function=None):
    def is_teacher(u):
        return Shopkeeper.objects.filter(user=u).exists()
    actual_decorator = user_passes_test(is_teacher)
    if function:
        return actual_decorator(function)
    else:
        return actual_decorator

</code></pre>

<p>You can then for example implement it as:</p>

<pre><code>@login_required
@teacher_required
def teacher_view(request):
    # ...
    pass

@login_required
def not_teacher_view(request):
    # ...
    pass

</code></pre>

<p>I hope you get the idea, for clarity see <a href=""https://stackoverflow.com/a/51127599/6505847"">this</a></p>
","0","","1","5568","358","9","686","60479527","60480657","<p>I wrote my own decorator, which checks if the currently logged in user is a teacher. If not, the decorator redirects the user to the login page, but for the user it is a bit confusing, so I want to pass a message why the user was redirected to the login page, but I have no idea how to do it.</p>

<pre class=""lang-py prettyprint-override""><code># here is my decorator:
def teacher_required(function=None, redirect_field_name=REDIRECT_FIELD_NAME, login_url='login'):
    '''
    Decorator for views that checks that the logged in user is a teacher,
    redirects to the log-in page if necessary.
    '''
    actual_decorator = user_passes_test(
        lambda u: u.is_active and u.is_teacher,
        login_url=login_url,
        redirect_field_name=redirect_field_name
    )
    if function:
        return actual_decorator(function)
    return actual_decorator
</code></pre>
"
"60480543","<p>Django comes with build in messages framework. <a href=""https://docs.djangoproject.com/en/3.0/ref/contrib/messages/"" rel=""nofollow noreferrer"">https://docs.djangoproject.com/en/3.0/ref/contrib/messages/</a></p>

<p>To use if you have to follow the steps:</p>

<p>Make sure you have django messages added in installed apps in your settings.py.</p>

<pre><code>INSTALLED_APPS = [
    ...

    'django.contrib.messages',

    ...
]
</code></pre>

<p>Configure the messages storage by adding the following line into your settings.py:</p>

<pre><code>MESSAGE_STORAGE = 'django.contrib.messages.storage.session.SessionStorage'
</code></pre>

<p>Add message in your decorator before returning the actual_decorator:</p>

<pre><code>messages.warning(request, 'Access restricted, for teachers only')
</code></pre>

<p>and than if you use bootstrap you could display alters in your template in following way:</p>

<pre><code>{% if messages %}
    {% for message in messages %}
    &lt;div class=""alert alert-warning""&gt;
    {{ message }}
    &lt;/div&gt;
    {% endfor %}
{% endif %}
</code></pre>

<p>the documentation for bootstrap alerts can be found here: <a href=""https://getbootstrap.com/docs/4.0/components/alerts/"" rel=""nofollow noreferrer"">https://getbootstrap.com/docs/4.0/components/alerts/</a></p>
","0","","0","86","22","0","6","60479527","60480657","<p>I wrote my own decorator, which checks if the currently logged in user is a teacher. If not, the decorator redirects the user to the login page, but for the user it is a bit confusing, so I want to pass a message why the user was redirected to the login page, but I have no idea how to do it.</p>

<pre class=""lang-py prettyprint-override""><code># here is my decorator:
def teacher_required(function=None, redirect_field_name=REDIRECT_FIELD_NAME, login_url='login'):
    '''
    Decorator for views that checks that the logged in user is a teacher,
    redirects to the log-in page if necessary.
    '''
    actual_decorator = user_passes_test(
        lambda u: u.is_active and u.is_teacher,
        login_url=login_url,
        redirect_field_name=redirect_field_name
    )
    if function:
        return actual_decorator(function)
    return actual_decorator
</code></pre>
"
"60480657","<p>You can use the build-in <a href=""https://docs.djangoproject.com/en/3.0/ref/contrib/messages/"" rel=""nofollow noreferrer"">messages</a> from Django with a custom decorator.</p>

<p>For this, Django provides full support for cookie- and session-based messaging, for both anonymous and authenticated users.</p>

<p>In your case, an example would be the following:</p>

<p>decorators.py</p>

<pre><code># Import Django messages
from django.contrib import messages

# Custom Decorator
def teacher_required(function):
    def _function(request, *args, **kwargs):
        if not request.user.is_teacher:
            messages.info(request, 'Custom message to user')
            return HttpResponseRedirect(reverse('app:url_name'))
        return function(request, *args, **kwargs)

    return _function
</code></pre>

<p>views.py</p>

<pre><code>from django.utils.decorators import method_decorator
from django.contrib.auth.decorators import login_required
from foo.decorators import teacher_required

@method_decorator([login_required, teacher_required], name='dispatch')
class MyView(TemplateView):
    template_name = 'template.html'
</code></pre>

<p>In this case you have to call the decorator with <code>@method_decorator()</code>, and pass the <code>login_required</code> first, to ensure that the user is logged in before checking if he is a teacher.</p>

<p>If you want to implement a more elegant system, I have found an example on <a href=""https://gist.github.com/edwinlunando/3af8f1eae9bbd67cb647"" rel=""nofollow noreferrer"">github</a>.</p>
","0","","1","675","143","17","71","60479527","60480657","<p>I wrote my own decorator, which checks if the currently logged in user is a teacher. If not, the decorator redirects the user to the login page, but for the user it is a bit confusing, so I want to pass a message why the user was redirected to the login page, but I have no idea how to do it.</p>

<pre class=""lang-py prettyprint-override""><code># here is my decorator:
def teacher_required(function=None, redirect_field_name=REDIRECT_FIELD_NAME, login_url='login'):
    '''
    Decorator for views that checks that the logged in user is a teacher,
    redirects to the log-in page if necessary.
    '''
    actual_decorator = user_passes_test(
        lambda u: u.is_active and u.is_teacher,
        login_url=login_url,
        redirect_field_name=redirect_field_name
    )
    if function:
        return actual_decorator(function)
    return actual_decorator
</code></pre>
"
"60479584","<p>You can do for example:</p>

<pre><code>matching_shakes = list(filter(lambda line: re.match(regex, line), shakes))
</code></pre>
","3","","0","701","18","5","37","60479529","60479584","<pre><code>import re
shakes = open(""output.txt"", ""r"")
for line in shakes:
    if re.match(r'.*(\w*Daemon\w*).*', line):
        print(line)
        break
    else:
        print(""none"")
</code></pre>

<p>output:</p>

<pre class=""lang-none prettyprint-override""><code>none
none
none
none
none
none
none
none
none
none
none
none
none
none
none
none
none
none
none
none
none
none
none
none
local1.crit: Aug 23 09:08:42 abvlab_ confd[860]: - Daemon n_7 died
</code></pre>
"
"60479634","<p>You've opened <code>out</code> twice: once for the <code>f</code> variable and a second time for the <code>for line in open(out):</code> loop. Each <code>file</code> object has its own position, and you've only been reading from the second one (which hasn't been assigned to a variable so you can't get the position). The position of <code>f</code> is still at the beginning, since you never read from it.</p>

<p>You should use</p>

<pre><code>for line in f:
</code></pre>

<p>and not call <code>open(out)</code> a second time. You can then call <code>f.readline()</code> inside the loop to read more lines of the file.</p>
","0","","1","586865","7069","3864","89361","60479599","60481686","<p>I'm trying to read xyz coordinates from a long file using python.
within the file there is a block which indicates that the xyz coordinates are within the next lines.</p>

<pre><code>CARTESIAN COORDINATES (ANGSTROEM)
---------------------------------
  C     -0.283576   -0.776740   -0.312605
  H     -0.177080   -0.046256   -1.140653
  Cl    -0.166557    0.025928    1.189976

----------------------------
</code></pre>

<p>I'm using the following code to find the line which mentions the ""CARTESIAN COORDINATES (ANGSTROEM)"" and then try to iterate until finding an empty line to read the coordinates. However, f.tell() points that I'm at line 0! Therefore, I can not do either next(f) or f.readline() to go through the next lines (just goes to line 1 from line 0). I don't know how this can be done with python.</p>

<pre><code>def read_xyz_out(self,out):
    atoms = []
    x = []
    y = []
    z = []
    f = open(out, ""r"")
    for line in open(out):
        if re.match(r'{}'.format(r'CARTESIAN COORDINATES \(ANGSTROEM\)'), line):
            print(f.tell())
             #    data = line.split()
             #    atoms.append(data[0])
             #    x.append(float(data[1]))
             #    y.append(float(data[2]))
             #    z.append(float(data[3]))
</code></pre>
"
"60479673","<p>How about this (note: untested so there's bound to be bugs - think of this as a sketch of a solution):</p>

<pre><code>def read_xyz_out(self,out):
    atoms = []
    x = []
    y = []
    z = []
    f = open(out, ""r"")

    # Read until you get to the data
    for line in f:
        if re.match(r'{}'.format(r'CARTESIAN COORDINATES \(ANGSTROEM\)'), line):
            # skip the next line too
            f.readline()
            break

     # Now you're into the data - the loop here picks up where the previous
     # one left off
     for line in f:
             data = line.split()
             atoms.append(data[0])
             x.append(float(data[1]))
             y.append(float(data[2]))
             z.append(float(data[3]))
    f.close()
</code></pre>
","0","","1","8115","76","8","296","60479599","60481686","<p>I'm trying to read xyz coordinates from a long file using python.
within the file there is a block which indicates that the xyz coordinates are within the next lines.</p>

<pre><code>CARTESIAN COORDINATES (ANGSTROEM)
---------------------------------
  C     -0.283576   -0.776740   -0.312605
  H     -0.177080   -0.046256   -1.140653
  Cl    -0.166557    0.025928    1.189976

----------------------------
</code></pre>

<p>I'm using the following code to find the line which mentions the ""CARTESIAN COORDINATES (ANGSTROEM)"" and then try to iterate until finding an empty line to read the coordinates. However, f.tell() points that I'm at line 0! Therefore, I can not do either next(f) or f.readline() to go through the next lines (just goes to line 1 from line 0). I don't know how this can be done with python.</p>

<pre><code>def read_xyz_out(self,out):
    atoms = []
    x = []
    y = []
    z = []
    f = open(out, ""r"")
    for line in open(out):
        if re.match(r'{}'.format(r'CARTESIAN COORDINATES \(ANGSTROEM\)'), line):
            print(f.tell())
             #    data = line.split()
             #    atoms.append(data[0])
             #    x.append(float(data[1]))
             #    y.append(float(data[2]))
             #    z.append(float(data[3]))
</code></pre>
"
"60481686","<p>Suppose you read your file into this string:</p>

<pre><code>My dog has fleas.
CARTESIAN COORDINATES (ANGSTROEM)
---------------------------------
  C     -0.283576   -0.776740   -0.312605
  H     -0.177080   -0.046256   -1.140653
  Cl    -0.166557    0.025928    1.189976

----------------------------

My cat too.
</code></pre>

<p>You can then extract lines 4, 5 and 6 with the regular expression</p>

<pre><code>/CARTESIAN COORDINATES \(ANGSTROEM\)\r?\n---------------------------------\r?\n(.+?)(?=\r?\n\r?\n)/s
</code></pre>

<p><a href=""https://regex101.com/r/gOwkCf/3/"" rel=""nofollow noreferrer"">demo</a></p>

<p>This expression reads, ""match the string 'CARTENSION...---\r?\n' followed by matching 1+ chars, greedily, in capture group 1, followed by an empty line, with the flag '/s' to enable '.' to match the ends of lines"".</p>

<p>The desired information can then be extracted with the regular expression</p>

<pre><code>/ *([A-Z][a-z]*) +(-?\d+.\d{6}) +(-?\d+.\d{6}) +(-?\d+.\d{6})\r?\n/
</code></pre>

<p><a href=""https://regex101.com/r/AU4WTR/3/"" rel=""nofollow noreferrer"">demo</a></p>

<p>The first step can be skipped if it is sufficient to look for a line that look like this:</p>

<pre><code>C     -0.283576   -0.776740   -0.312605
</code></pre>

<p>without having to confirm it is preceded by ""CARTESIAN...---"".</p>

<p><a href=""https://regex101.com/r/AU4WTR/5/"" rel=""nofollow noreferrer"">demo</a></p>
","0","2020-03-02 02:18:07","1","93421","7912","102","9185","60479599","60481686","<p>I'm trying to read xyz coordinates from a long file using python.
within the file there is a block which indicates that the xyz coordinates are within the next lines.</p>

<pre><code>CARTESIAN COORDINATES (ANGSTROEM)
---------------------------------
  C     -0.283576   -0.776740   -0.312605
  H     -0.177080   -0.046256   -1.140653
  Cl    -0.166557    0.025928    1.189976

----------------------------
</code></pre>

<p>I'm using the following code to find the line which mentions the ""CARTESIAN COORDINATES (ANGSTROEM)"" and then try to iterate until finding an empty line to read the coordinates. However, f.tell() points that I'm at line 0! Therefore, I can not do either next(f) or f.readline() to go through the next lines (just goes to line 1 from line 0). I don't know how this can be done with python.</p>

<pre><code>def read_xyz_out(self,out):
    atoms = []
    x = []
    y = []
    z = []
    f = open(out, ""r"")
    for line in open(out):
        if re.match(r'{}'.format(r'CARTESIAN COORDINATES \(ANGSTROEM\)'), line):
            print(f.tell())
             #    data = line.split()
             #    atoms.append(data[0])
             #    x.append(float(data[1]))
             #    y.append(float(data[2]))
             #    z.append(float(data[3]))
</code></pre>
"
"60479760","<p>The solution is provided below:</p>

<pre><code>NPVDict = sum([cash_flow/(1.1**year) for year,cash_flow in
cash_flow_dictionary.items()]) # Note items function to iterate over dictionary
print(""Present Value = "" , (f""{NPVDict:9,.2f}""))
</code></pre>

<p>Let me know if it helps!!</p>
","2","","1","1444","3","8","195","60479657","60479760","<p>For Lists and tuples I've been able to do the same thing to find NPV</p>

<pre><code>cash_flow_list_of_lists = [[1, 200], [4, 500], [7, 1600]]
</code></pre>

<h1>Compute and print the present value as per above</h1>

<pre><code>NPV=sum([cash_flow/(1.1**year) for year,cash_flow in 
cash_flow_list_of_lists])
print(""Present Value = "" , (f""{NPV:9,.2f}""))
</code></pre>

<p>How do I do this with a dictionary list</p>

<pre><code>cash_flow_dictionary = {1: 200, 4: 500, 7: 1600}
</code></pre>

<h1>Compute and print the present value as per above</h1>

<p>I tried 
    NPV=sum([cash_flow_dictionary.values()]/(1.1**cash_flow_dictionary.keys()) in cash_flow_dictionary)</p>

<p>But I have no idea how to do this</p>
"
"60524489","<blockquote>
  <p>Each image has one object that I want to classify. But in total I have images of 10 different objects. I am confused, how can I prepare my mask input? Is it considered as multi-label segmentation or only for one class?</p>
</blockquote>

<p>If your dataset has N different labels (i.e: 0 - background, 1 - dogs, 2 -cats...), you have a multi class problem, even if your images contain only kind of object.</p>

<blockquote>
  <p>Should I convert my input to one hot encoded? Should I use to_categorical?</p>
</blockquote>

<p>Yes, you should one-hot encode your labels. Using to_categorical boils down to the source format of your labels. Say you have N classes and your labels are (height, width, 1), where each pixel has a value in range [0,N). In that case <strong>keras.utils.to_categorical(label, N)</strong> will provide a float (height,width,N) label, where each pixel is 0 or 1. And you don't have to divide by 255.</p>

<p>if your source format is different, you may have to use a custom function to get the same output format.</p>

<p>Check out this repo (not my work): <a href=""https://github.com/karolzak/keras-unet"" rel=""nofollow noreferrer"">keras-unet</a>. The notebooks folder contain two examples to train a u-net on small datasets. They are not multiclass, but it is easy to go step by step to use your own dataset. Star by loading your labels as:</p>

<pre><code>im = Image.open(mask).resize((512,512))
im = to_categorical(im,NCLASSES)
</code></pre>

<p>reshape and normalize like this:</p>

<pre><code>x = np.asarray(imgs_np, dtype=np.float32)/255
y = np.asarray(masks_np, dtype=np.float32)
y = y.reshape(y.shape[0], y.shape[1], y.shape[2], NCLASSES)
x = x.reshape(x.shape[0], x.shape[1], x.shape[2], 3)
</code></pre>

<p>adapt your model to NCLASSES</p>

<pre><code>model = custom_unet(
input_shape,
use_batch_norm=False,
num_classes=NCLASSES,
filters=64,
dropout=0.2,
output_activation='softmax')
</code></pre>

<p>select the correct loss:</p>

<pre><code>from keras.losses import categorical_crossentropy
model.compile(    
   optimizer=SGD(lr=0.01, momentum=0.99),
   loss='categorical_crossentropy',    
   metrics=[iou, iou_thresholded])
</code></pre>

<p>Hope it helps</p>
","1","","1","327","13","0","27","60479659","60524489","<p>I am new to tensorflow and Semantic segmentation. </p>

<p>I am designing a U-Net for semantic segmentaion. Each image has one object that I want to classify. But in total I have images of 10 different objects. I am confused, how can I prepare my mask input? Is it considered as multi-label segmentation or only for one class?</p>

<p>Should I convert my input to one hot encoded? Should I use to_categorical? I find exaples for multi-class segmentation, but I don't know, If that's the case here. Because in one image I only have one object to detect/classify. </p>

<p>I tried using this as my code for input. But I am not sure, what I am doing is right or not.</p>

<pre><code>#Generation of batches of image and mask
class DataGen(keras.utils.Sequence):
    def __init__(self, image_names, path, batch_size, image_size=128):
        self.image_names = image_names
        self.path = path
        self.batch_size = batch_size
        self.image_size = image_size

    def __load__(self, image_name):
        # Path
        image_path = os.path.join(self.path, ""images/aug_test"", image_name) + "".png""
        mask_path = os.path.join(self.path, ""masks/aug_test"",image_name) +  "".png""

        # Reading Image
        image = cv2.imread(image_path, 1)
        image = cv2.resize(image, (self.image_size, self.image_size))


        # Reading Mask
        mask = cv2.imread(mask_path, -1)
        mask = cv2.resize(mask, (self.image_size, self.image_size))

        ## Normalizaing 
        image = image/255.0
        mask = mask/255.0

        return image, mask

    def __getitem__(self, index):
        if(index+1)*self.batch_size &gt; len(self.image_names):
            self.batch_size = len(self.image_names) - index*self.batch_size

        image_batch = self.image_names[index*self.batch_size : (index+1)*self.batch_size]

        image = []
        mask  = []

        for image_name in image_batch:
            _img, _mask = self.__load__(image_name)
            image.append(_img)
            mask.append(_mask)

        #This is where I am defining my input
        image = np.array(image)
        mask  = np.array(mask)
        mask = tf.keras.utils.to_categorical(mask, num_classes=10, dtype='float32') #Is this true?


        return image, mask

    def __len__(self):
        return int(np.ceil(len(self.image_names)/float(self.batch_size)))

</code></pre>

<p>Is this true? If it is, then, to get the label/class as output what should I change in my input? Should I change the value of pixel of my mask according to my class? </p>

<p>Here is my U-Net architecture.</p>

<pre><code># Convolution and deconvolution Blocks

def down_scaling_block(x, filters, kernel_size=(3, 3), padding=""same"", strides=1):
    conv = keras.layers.Conv2D(filters, kernel_size, padding=padding, strides=strides, activation=""relu"")(x)
    conv = keras.layers.Conv2D(filters, kernel_size, padding=padding, strides=strides, activation=""relu"")(conv)
    pool = keras.layers.MaxPool2D((2, 2), (2, 2))(conv)
    return conv, pool

def up_scaling_block(x, skip, filters, kernel_size=(3, 3), padding=""same"", strides=1):
    conv_t = keras.layers.UpSampling2D((2, 2))(x)
    concat = keras.layers.Concatenate()([conv_t, skip])
    conv = keras.layers.Conv2D(filters, kernel_size, padding=padding, strides=strides, activation=""relu"")(concat)
    conv = keras.layers.Conv2D(filters, kernel_size, padding=padding, strides=strides, activation=""relu"")(conv)
    return conv

def bottleneck(x, filters, kernel_size=(3, 3), padding=""same"", strides=1):
    conv = keras.layers.Conv2D(filters, kernel_size, padding=padding, strides=strides, activation=""relu"")(x)
    conv = keras.layers.Conv2D(filters, kernel_size, padding=padding, strides=strides, activation=""relu"")(conv)
    return conv

</code></pre>

<pre><code>def UNet():
    filters = [16, 32, 64, 128, 256]
    inputs = keras.layers.Input((image_size, image_size, 3))

    '''inputs2 = keras.layers.Input((image_size, image_size, 1))
       conv1_2, pool1_2 = down_scaling_block(inputs2, filters[0])'''

    Input = inputs
    conv1, pool1 = down_scaling_block(Input, filters[0])
    conv2, pool2 = down_scaling_block(pool1, filters[1])
    conv3, pool3 = down_scaling_block(pool2, filters[2])
    '''conv3 = keras.layers.Conv2D(filters[2], kernel_size=(3,3), padding=""same"", strides=1, activation=""relu"")(pool2)
    conv3 = keras.layers.Conv2D(filters[2], kernel_size=(3,3), padding=""same"", strides=1, activation=""relu"")(conv3)
    drop3 = keras.layers.Dropout(0.5)(conv3)
    pool3 = keras.layers.MaxPooling2D((2,2), (2,2))(drop3)'''
    conv4, pool4 = down_scaling_block(pool3, filters[3])

    bn = bottleneck(pool4, filters[4])

    deConv1 = up_scaling_block(bn, conv4, filters[3]) #8 -&gt; 16
    deConv2 = up_scaling_block(deConv1, conv3, filters[2]) #16 -&gt; 32
    deConv3 = up_scaling_block(deConv2, conv2, filters[1]) #32 -&gt; 64
    deConv4 = up_scaling_block(deConv3, conv1, filters[0]) #64 -&gt; 128

    outputs = keras.layers.Conv2D(10, (1, 1), padding=""same"", activation=""softmax"")(deConv4)
    model = keras.models.Model(inputs, outputs)
    return model

model = UNet()
model.compile(optimizer='adam', loss=""categorical_crossentropy"", metrics=[""acc""])

train_gen = DataGen(train_img, train_path, image_size=image_size, batch_size=batch_size)
valid_gen = DataGen(valid_img, train_path, image_size=image_size, batch_size=batch_size)
test_gen = DataGen(test_img, test_path, image_size=image_size, batch_size=batch_size)

train_steps = len(train_img)//batch_size
valid_steps = len(valid_img)//batch_size

model.fit_generator(train_gen, validation_data=valid_gen, steps_per_epoch=train_steps, validation_steps=valid_steps, 
                    epochs=epochs)
</code></pre>

<p>I hope that I explained my question properly. Any help appriciated!</p>

<p>UPDATE: I changed the value of each pixel in mask as per object class. (If the image contains object which I want to classify as object no. 2, then I changed the value of mask pixel to 2. the whole array of mask will contain 0(bg) and 2(object). Accordingly for each object, the mask will contain 0 and 3, 0 and 10 etc.) </p>

<p>Here I first changed the mask to binary and then if the value of pixel is greater than 1, I changed it to 1 or 2 or 3. (according to object/class no.) </p>

<p>Then I converted them to one_hot with to_categorical as shown in my code. training runs but the network doesnt learn anything. Accuracy and loss keep swinging between two values. What is my mistake here? Am I making a mistake at generating mask (changing the value of pixels?) Or at the function to_categorical?</p>

<p>PROBLEM FOUND:
I was making an error while creating mask.. I was reading image with cv2, which reads image as heightxwidth.. I was creating mask with pixel values according to class, after considering my image dimention as widthxheight.. Which was causing problem and making network not to learn anything.. It is working now..</p>
"
"60479855","<blockquote>
  <p>I'm relying on the fact that <code>./</code> is (in effect) on the PYTHONPATH.</p>
</blockquote>

<p>It's not. It's not on <code>PYTHONPATH</code>, and it's not on <code>sys.path</code>. When you run a script by file path, it's the <em>script's</em> directory that gets added to <code>sys.path</code>. You can see what gets added to <code>sys.path</code> for each way of specifying a program to run in the <a href=""https://docs.python.org/3/using/cmdline.html"" rel=""nofollow noreferrer"">Python command line docs</a>.</p>
","0","","1","212283","3259","18958","29736","60479777","60479855","<p>When I try to <code>$&gt; python ./tools/test.py</code>  I get an import error that I cannot import a module that exists in the directory from which I am invoking python.  However, I can import this module, <code>$&gt; python -c ""import mod""</code> works.</p>

<p>I'm relying on the fact that <code>./</code> is (in effect) on the PYTHONPATH.</p>

<p>What is python doing to the python path when I run the interpreter on a script that exists in a different directory?  Is there a way to ""lock"" the current working directory so that I can get the import to work?</p>

<p>My setup:</p>

<p><code>./mod.py</code>  :</p>

<pre><code>x = 5     # just for demonstration purposes
</code></pre>

<p><code>./tools/test.py</code> :</p>

<pre><code>from mod import x
# ... snip ... actual content
</code></pre>

<p>I am invoking python from the directory that contains <code>mod.py</code> and <code>tools/</code>:</p>

<pre><code>$&gt; python -c ""from mod import x""      # works fine
$&gt; python tools/test.py

Traceback (most recent call last):

File ""tools/test.py"", line 1, in &lt;module&gt;
from mod import x
ModuleNotFoundError: No module named 'mod'
</code></pre>

<p>Note that the current directory, which contains <code>mod.py</code> and <code>tools</code> is <strong>not</strong> on my PYTHONPATH.</p>
"
"60484475","<p>I have not used pandas dataframes before. I'm sure you could also use those, but I find it easier to use the builtin structures.<br>
What I recommended in the comments was using a list of characters. That could look like this:  </p>

<pre class=""lang-py prettyprint-override""><code>mylist = [ 'a', 'b', 'c' ]
print(mylist[1])
# outputs 'b', because that's at position 1 in the list
</code></pre>

<p>However, since you already have a dict of the numbers and characters in your code, we can just as well use that <code>code</code> dict:</p>

<pre class=""lang-py prettyprint-override""><code>import string, random

def make_a_guess(solution):
    print(""Make a guess..."")
    letter = input(""What letter: "").lower()
    number = int(input(""What number: ""))

    # the -1 is a default value to be returned if no valid number was provided. None would work just as well, if not better.
    if solution.get(number, -1) == letter:
        print(""Correct, {} = {}"".format(letter, number))
    else:
        print(""Wrong, {} != {}"".format(letter, number))

#User Input
title = input(""Please Enter A Title For This Puzzle: "")
if len(title) == 0:
    print(""String is empty"")
    quit()

phrase = input(""Please Enter A Phrase To Be Encoded: "")
if len(phrase) == 0:
    print(""String is empty"")
    quit()


if not  phrase.islower():
    print(""Please use lowercase for the phrase"")
    quit()

#Numbers get assigned to the letters
nums = random.sample(range(1, 27), 26)
code = dict(zip(nums, string.ascii_lowercase))

print('')

while True:
    make_a_guess(code)

</code></pre>

<p>Of course, you'll still have to add a stopping condition and a way to allow the user to enter the correct phrase as numbers. But the <code>make_a_guess</code> function should be what I think you were looking for.</p>

<hr>

<h3>Bonus Question</h3>

<p>As you asked in a comment if I have an idea why the numbers from my code are off by one compared to the pandas indexing.
That is likely simply due to this line here, which samples from a minimum of <code>1</code> instead of <code>0</code> up to but exclusive <code>27</code>.</p>

<pre class=""lang-py prettyprint-override""><code>nums = random.sample(range(1, 27), 26)
</code></pre>

<p>If you change that to the following, it will also start at 0.</p>

<pre class=""lang-py prettyprint-override""><code>nums = random.sample(range(0, 26), 26)
</code></pre>

<p>Normally, arrays count from <code>0</code>, not from <code>1</code>, and it seems pandas keeps to this convention.</p>
","3","2020-03-02 20:02:38","2","3674","7445","142","610","60479809","60484475","<p>I have a working program that:</p>

<p>Takes a phrase and encodes it with randomized numbers from 1-26
Allows user to get 3 letters, of their choice, and their computer assigned number
But what I would like to do is allow the user to be able to guess a letter and what they think the correct letter is, if their guess is correct allow them to carry on but if it's wrong, to say so and let them try again.Eventually allowing them to guess the whole phrase as well.</p>

<p>Hopefully that makes sense :)</p>

<p>Here's the Code:</p>

<pre><code>import string, random
import pandas as pd
#User Input
title = input(""Please Enter A Title For This Puzzle: "")
if len(title) == 0:
    print(""String is empty"")
    quit()

phrase = input(""Please Enter A Phrase To Be Encoded: "")
if len(phrase) == 0:
    print(""String is empty"")
    quit()


if not  phrase.islower():
    print(""Please use lowercase for the phrase"")
    quit()

#Numbers get assigned to the letters
nums = random.sample(range(1, 27), 26)
code = dict(zip(nums, string.ascii_lowercase))

print(    )
#Giveaway letters
num1 = int(input(""Enter the first giveaway letter you would like (Note:a=0, b=1 ect): ""))
num2 = int(input(""Enter the second giveaway letter you would like (Note:a=0, b=1 ect): ""))
#Code for Grid
code2 = {'Number': [[nums[num1]],[nums[num2]]],
        'Letter': (string.ascii_lowercase[num1],string.ascii_lowercase[num2]),
        }
#'Start' of Puzzle for the user  
print (  )
print (""The Title Of This Puzzle Is"", title)
print(    )

df = pd.DataFrame(code2, columns = ['Number', 'Letter'])
code = dict(zip(string.ascii_lowercase, nums))
code.update({"" "":100})
encoded = [code[item] for item in phrase]



print (df)
print(    )
print (""Hint: 100 is always a space"")
print (encoded)
</code></pre>

<p>Note: I have asked this question before however the link provided wasn't that helpful, in this particular situation. An example or slight snippet of code would be appreciated. </p>

<p>I have been trying on my own but it looks like a mess and wouldn't work with this program. Regardless here it is:</p>

<pre><code>def make_a_guess():

          print(""A is "" + str(a))
          print(""Make a guess..."")
          Article_Guess = input(""What letter: "").lower()
          Numerical_Guess = int(input(""What number: ""))

          if Article_Guess == 'a' and Numerical_Guess == a:
               print_letters()
               print(""Correct, A: "" + str(a))

          elif Article_Guess == 'b' and Numerical_Guess == b:
               print_letters()
               print(""Correct, B: "" + str(b))

          elif Article_Guess == 'C' and Numerical_Guess == c:
               print_letters()
               print(""Correct, C: "" + str(c))

          elif Article_Guess == 'D' and Numerical_Guess == d:
               print_letters()
               print(""Correct, D: "" + str(d))

          elif Article_Guess == 'E' and Numerical_Guess == e:
               print_letters()
               print(""Correct, E: "" + str(e))

          elif Article_Guess == 'F' and Numerical_Guess == f:
               print_letters()
               print(""Correct, F: "" + str(f))

          elif Article_Guess == 'G' and Numerical_Guess == g:
               print_letters()
               print(""Correct, G: "" + str(g))

          elif Article_Guess == 'H' and Numerical_Guess == h:
               print_letters()
               print(""Correct, H: "" + str(h))

          elif Article_Guess == 'I' and Numerical_Guess == i:
               print_letters()
               print(""Correct, I: "" + str(i))

          elif Article_Guess == 'J' and Numerical_Guess == j:
               print_letters()
               print(""Correct, J: "" + str(j))

          elif Article_Guess == 'K' and Numerical_Guess == k:
               print_letters()
               print(""Correct, K: "" + str(k))

          elif Article_Guess == 'L' and Numerical_Guess == l:
               print_letters()
               print(""Correct, L: "" + str(l))

          elif Article_Guess == 'M' and Numerical_Guess == m:
               print_letters()
               print(""Correct, M: "" + str(m))

          elif Article_Guess == 'N' and Numerical_Guess == n:
               print_letters()
               print(""Correct, N: "" + str(n))

          elif Article_Guess == 'O' and Numerical_Guess == o:
               print_letters()
               print(""Correct, O: "" + str(o))

          elif Article_Guess == 'P' and Numerical_Guess == p:
               print_letters()
               print(""Correct, P: "" + str(p))

          elif Article_Guess == 'Q' and Numerical_Guess == q:
               print_letters()
               print(""Correct, Q: "" + str(q))

          elif Article_Guess == 'R' and Numerical_Guess == r:
               print_letters()
               print(""Correct, R: "" + str(r))

          elif Article_Guess == 'S' and Numerical_Guess == s:
               print_letters()
               print(""Correct, S: "" + str(s))

          elif Article_Guess == 'T' and Numerical_Guess == t:
               print_letters()
               print(""Correct, T: "" + str(t))

          elif Article_Guess == 'U' and Numerical_Guess == u:
               print_letters()
               print(""Correct, U: "" + str(u))

          elif Article_Guess == 'V' and Numerical_Guess == v:
               print_letters()
               print(""Correct, V: "" + str(v))

          elif Article_Guess == 'W' and Numerical_Guess == w:
               print_letters()
               print(""Correct, W: "" + str(w))

          elif Article_Guess == 'X' and Numerical_Guess == x:
               print_letters()
               print(""Correct, X: "" + str(x))

          elif Article_Guess == 'Y' and Numerical_Guess == y:
               print_letters()
               print(""Correct, Y: "" + str(y))

          elif Article_Guess == 'Z' and Numerical_Guess == z:
               print_letters()
               print(""Correct, Z: "" + str(z))
</code></pre>
"
"60479900","<p>We can split the y before the <code>rolling</code> and <code>reindex</code> fill the value with 0 </p>

<pre><code>y1 = y[df.COL3 == 'A']
y1 = y1.rolling(window).apply(lambda x: np.max(x) if len(x)&gt;0 else 0).fillna('drop')
y = y1.reindex(y.index, fill_value = 0).loc[lambda x : x!='drop']
</code></pre>
","2","","0","252249","5881","962","22297","60479828","60479900","<p>I have the following pandas data frame <code>df</code>:</p>

<pre><code>COL1   COL2   COL3   Y
10     2      A      1
20     5      A      3
30     2      B      1
20     7      B      4
15     2      A      2
25     1      B      1
10     3      A      1
25     1      A      1
</code></pre>

<p>I  apply rolling to <code>y</code> as follows:</p>

<pre><code>window = 2
y = df[""Y""]
y = y.rolling(window).apply(lambda x: np.max(x) if len(x)&gt;0 else 0).dropna()
</code></pre>

<p>But now I need to add a restriction to <code>y</code>: the <code>max</code> should be calculated only over rows where <code>COL3</code> is equal to <code>A</code>.
If there is no <code>A</code> value in rows, then <code>y</code> should be equal to 0. For example, rows 3 and 4 (if we use the <code>window</code> of 2)</p>

<p>I tried:</p>

<pre><code>y = df.rolling(window).apply(lambda row: np.max(row[row[""COL3""==""A""]][""Y""]) if len(row[""Y""])&gt;0 else 0).dropna()[""Y""]
</code></pre>

<p>But got the error:</p>

<pre><code>IndexError: only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices
</code></pre>
"
"60486172","<p>You can merge every two contours that applies the following condition:  </p>

<ul>
<li>Area of <strong>convex hull</strong> of the merged contours is close to the sum of areas of the two contours.  </li>
</ul>

<p>The following solution uses a kind of ""brute force"" approach that tries merging every contour with all other contours (not very efficient).  </p>

<p>Here is a working code sample (please read the comments):  </p>

<pre><code>from skimage.feature import peak_local_max
from skimage.segmentation import watershed
import matplotlib.pyplot as plt
from scipy import ndimage
import cv2 as cv
import imutils
import numpy as np

img = cv.imread(""image.jpg"");
blur = cv.GaussianBlur(img,(7,7),0)


#color space change
mSource_Hsv = cv.cvtColor(blur,cv.COLOR_BGR2HSV);
mMask = cv.inRange(mSource_Hsv,np.array([0,0,0]),np.array([80,255,255]));
output = cv.bitwise_and(img, img, mask=mMask)

#grayscale
img_grey = cv.cvtColor(output, cv.COLOR_BGR2GRAY)

#thresholding
ret,th1 = cv.threshold(img_grey,0,255,cv.THRESH_BINARY + cv.THRESH_OTSU)

#dist transform
D = ndimage.distance_transform_edt(th1)

#markers
localMax = peak_local_max(D, indices=False, min_distance=20, labels=th1)
markers = ndimage.label(localMax, structure=np.ones((3, 3)))[0]

#apply watershed
labels = watershed(-D, markers, mask=th1)
print(""[INFO] {} unique segments found"".format(len(np.unique(labels)) - 1))


contours = []

# loop over the unique labels, and append contours to all_cnts
for label in np.unique(labels):
    if label == 0:
        continue

    # draw label on the mask
    mask = np.zeros(img_grey.shape, dtype=""uint8"")
    mask[labels == label] = 255

    # detect contours in the mask and grab the largest one
    cnts = cv.findContours(mask.copy(), cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)
    cnts = imutils.grab_contours(cnts)
    c = max(cnts, key=cv.contourArea)

    ## Ignore small contours
    #if c.shape[0] &lt; 20:
    #    continue

    # Get convex hull of contour - it' going to help when merging contours
    hull = cv.convexHull(c)

    #cv.drawContours(img, c, -1, (0, 255, 0), 2)
    cv.drawContours(img, [hull], -1, (0, 255, 0), 2, 1)

    # Append hull to contours list
    contours.append(hull)


# Merge the contours that does not increase the convex hull by much.
# Note: The solution is kind of ""brute force"" solution, and can be better.
################################################################################
for i in range(len(contours)):
    c = contours[i]

    area = cv.contourArea(c)

    # Iterate all contours from i+1 to end of list
    for j in range(i+1, len(contours)):
        c2 = contours[j]

        area2 = cv.contourArea(c2)

        area_sum = area + area2

        # Merge contours together
        tmp = np.vstack((c, c2))
        merged_c = cv.convexHull(tmp)

        merged_area = cv.contourArea(merged_c)

        # Replace contours c and c2 by the convex hull of merged c and c2, if total area is increased by no more then 10%
        if merged_area &lt; area_sum*1.1:
            # Replace contour with merged one.
            contours[i] = merged_c
            contours[j] = merged_c
            c = merged_c
            area = merged_area
################################################################################


# Draw new contours in red color
for c in contours:
    #Ignore small contours
    if cv.contourArea(c) &gt; 100:
        cv.drawContours(img, [c], -1, (0, 0, 255), 2, 1)


cv.imshow(""segmented"",img)
cv.waitKey(0)
cv.destroyAllWindows()
</code></pre>

<hr>

<p>Result:<br>
<a href=""https://i.stack.imgur.com/sOZhT.jpg"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/sOZhT.jpg"" alt=""enter image description here""></a></p>
","0","","1","11911","1803","123","963","60479830","60486172","<p>I need to segment the seeds in the image below and crop them. </p>

<p><a href=""https://i.stack.imgur.com/ndOkX.jpg"" rel=""nofollow noreferrer"">https://i.stack.imgur.com/ndOkX.jpg</a></p>

<p>They can be pretty close to each other and sometimes overlap, so I chose to use the watershed algorithm for this task.</p>

<p>My results are in the image below, after drawing the contours of the markers that are returned, and as you can see I'm having problems defining good markers for applying it. The individual seeds are outlined but there are many inner lines that I do not want.</p>

<p><a href=""https://i.stack.imgur.com/BtOfj.jpg"" rel=""nofollow noreferrer"">https://i.stack.imgur.com/BtOfj.jpg</a></p>

<p><strong>How would I go about removing them or defining better markers?</strong> </p>

<p>The code I'm running:</p>

<pre><code>from skimage.feature import peak_local_max
from skimage.segmentation import watershed
import matplotlib.pyplot as plt
from scipy import ndimage
import cv2 as cv
import imutils
import numpy as np

img = cv.imread(""image.jpg"");
blur = cv.GaussianBlur(img,(7,7),0)


#color space change
mSource_Hsv = cv.cvtColor(blur,cv.COLOR_BGR2HSV);
mMask = cv.inRange(mSource_Hsv,np.array([0,0,0]),np.array([80,255,255]));
output = cv.bitwise_and(img, img, mask=mMask)

#grayscale
img_grey = cv.cvtColor(output, cv.COLOR_BGR2GRAY)

#thresholding
ret,th1 = cv.threshold(img_grey,0,255,cv.THRESH_BINARY + cv.THRESH_OTSU)

#dist transform
D = ndimage.distance_transform_edt(th1)

#markers
localMax = peak_local_max(D, indices=False, min_distance=20, labels=th1)
markers = ndimage.label(localMax, structure=np.ones((3, 3)))[0]

#apply watershed
labels = watershed(-D, markers, mask=th1)
print(""[INFO] {} unique segments found"".format(len(np.unique(labels)) - 1))

# loop over the unique labels

for label in np.unique(labels):
    if label == 0:
        continue

    # draw label on the mask
    mask = np.zeros(img_grey.shape, dtype=""uint8"")
    mask[labels == label] = 255

    # detect contours in the mask and grab the largest one
    cnts = cv.findContours(mask.copy(), cv.RETR_EXTERNAL,
        cv.CHAIN_APPROX_SIMPLE)
    cnts = imutils.grab_contours(cnts)
    c = max(cnts, key=cv.contourArea)

    cv.drawContours(img, cnts, -1, (0, 255, 0), 2)


cv.imshow(""segmented"",img)
cv.waitKey(0)
</code></pre>
"
"60479998","<p>The error might be that <code>json_data</code> is a string and not a dict type as <code>json.dumps(str(soup))</code> returns a string.Since <code>json_data</code> is string, we cannot do <code>json_data['Results']</code> and to access any element of string, we need to pass the index and hence the error.</p>

<h2>EDIT</h2>

<p>To get <code>Results</code> from the response, the code is shown below:</p>

<pre><code>json_data = json.loads(str(soup.text))
print(json_data['Results'])
</code></pre>

<p>Let me know if this helps!!</p>
","2","2020-03-01 22:32:27","2","1444","3","8","195","60479854","60479998","<p><strong>Background</strong></p>

<p>I am attempting to scrape this <a href=""https://shop.guess.com/en/catalog/browse/men/tanks-t-shirts/view-all/"" rel=""nofollow noreferrer"">page</a>. Basically get the name of each product, it's price and image. I was expecting to see the div's that contain the product in the soup but i did not. So what i did is i opened up the url in my chrome browser and upon doing inspect element in my networks tab i found the GET call it's making is directly to this <a href=""https://shop.guess.com/en/catalog/browse/men/tanks-t-shirts/view-all/?filter=true&amp;page=1"" rel=""nofollow noreferrer"">page</a> to get all the product related information. If you open that url you will see basically a JSON object and there is html string in there with the divs for the product and prices. The question for me is how would I parse this?</p>

<p><strong>Attempted Solution</strong>
I thought one obvious way is to convert the soup in to a JSON and so in order to do that soup needs to be a string and that's exactly what i did. The issue now is that my <code>json_data</code> variable basically has a string. So when i attempt to do something like this <code>json_data['Results']</code> it gives me and error saying i can only pass ints. I am unsure how to proceed further. </p>

<p>I would love suggestions and any pointers if i am doing something wrong.</p>

<p>Following is My code</p>

<pre><code>from bs4 import BeautifulSoup
from random_user_agent.user_agent import UserAgent
from random_user_agent.params import SoftwareName, OperatingSystem
import requests
import json
import sys


sys.stdout = open('output.html', 'wt')
page_to_scrape = 'https://shop.guess.com/en/catalog/browse/men/tanks-t-shirts/view-all/?filter=true&amp;page=1'
software_names = [SoftwareName.CHROME.value]
operating_systems = [OperatingSystem.WINDOWS.value, OperatingSystem.LINUX.value]
user_agent_rotator = UserAgent(software_names=software_names, operating_systems=operating_systems, limit=100)
page = requests.get(page_to_scrape, headers={'User-Agent': user_agent_rotator.get_random_user_agent()})
soup = BeautifulSoup(page.content, ""html.parser"")
json_data = json.dumps(str(soup))
print(json_data)
</code></pre>
"
"60479993","<p>Use a <a href=""https://docs.python.org/3/glossary.html#term-generator-expression"" rel=""nofollow noreferrer"">generator expression</a> instead of a <code>map</code>.</p>

<pre><code>(fun(x, **kwargs) for x in elements)
</code></pre>

<p>e.g.</p>

<pre><code>reduce(fun(x, **kwargs) for x in elements)
</code></pre>

<p>Or if you're going straight to a list, use a <a href=""https://docs.python.org/3/glossary.html#term-list-comprehension"" rel=""nofollow noreferrer"">list comprehension</a> instead:</p>

<pre><code>[fun(x, **kwargs) for x in elements]
</code></pre>
","0","2020-03-01 21:41:51","4","15300","3115","1510","3211","60479968","60479993","<p>As above, I want to use map function to apply a function to a bunch of things and collect results in a list. However, I don't see how can I pass kwargs to that function.</p>

<p>For concreteness:</p>

<pre><code>map(fun, elements)
</code></pre>

<p>What about kwargs?</p>
"
"60480014","<p>The question is already answered at <a href=""https://stackoverflow.com/questions/16874244/python-map-and-arguments-unpacking"">Python `map` and arguments unpacking</a></p>

<p>The map does not exactly support named variable, though can handle multiple variable based on position. </p>

<p>Since Python 3 the standard map can list arguments of multi-argument separately</p>

<pre><code>map(fun, listx, listy, listz)
</code></pre>

<p>It is though less convenient for variable length list of named variables, especially in presence of <code>**kwargs</code> in the function signature. You can, though,
introduce some intermediate function to pack separately positional and named arguments. For one line solution with lambda see <a href=""https://stackoverflow.com/questions/16874244/python-map-and-arguments-unpacking"">Python `map` and arguments unpacking</a>
If you are not proficient with lambda, you can go as below</p>

<pre><code>def foldarg(param): 
    return f(param[0], **param[1])
list(map(foldarg, elements))
</code></pre>

<p>where <code>elements</code> is something like</p>

<pre><code>[[[1,2], dict(x=3, y=4)],
[[-2,-2], dict(w=3, z=4)]]
</code></pre>

<p>For unnamed variables list you can also use itertools.starmap </p>
","1","2020-03-02 01:41:01","2","2617","151","9","275","60479968","60479993","<p>As above, I want to use map function to apply a function to a bunch of things and collect results in a list. However, I don't see how can I pass kwargs to that function.</p>

<p>For concreteness:</p>

<pre><code>map(fun, elements)
</code></pre>

<p>What about kwargs?</p>
"
"60480123","<p>Looks like the problem is that you want the program to remember the player's health between screens?</p>

<p>If so, I think you'll need some kind of variable outside of the function to store the player's health in between attacks. Since right now it looks like the function resets the health to 10 every time.</p>

<p>Also, I'd recommend using another argument to the function to pass in your current health, and a return value to calculate what your new health should be after the attack.</p>

<p>If that's the approach you're going for, I think your top level function would look kind of like this --</p>

<pre class=""lang-py prettyprint-override""><code># Starting Health
my_health = 10
...
# Main loop
while(not_quit):
    ...
    # Update health
    my_health = healthSystem(enemy_attack, my_health)
    ...
</code></pre>
","0","","3","731","442","15","39","60480049","60480123","<p>Let me preface by saying that I am very very new to programming in general. I've been doing it for about a week and have successfully made things like calculators and all that beginner jazz and have been working on my first real ""project"", which is a text-based adventure game. My problem right now is that I cannot put together a very simple health system for the life of me and would like to get any pointers any of you might have.</p>

<p>I've rewritten the code for it many times but here is the basic framework of what I've been working with:</p>

<pre><code>def healthSystem(enemy_atk = 0):   # Called at the beginning of every game screen.
    watermark()   # A function that prints the game title and other things at the top of every screen

    max_health = 10       # Player max health
    no_health = 0         # Player dies at this threshold
    modifier = enemy_atk  # An enemy attack roll is taken from another function and stored here
    current_health = max_health - modifier   # Calculating the new health

    print(""+"" * current_health)   # Prints the new health to the screen, every 1 health is represented with a ""+""
    print()
</code></pre>

<p>It's very barebones and it works on the first game screen. However, when you progress to the next game screen, everything is recalculated and the health is redrawn to the screen every time, so you get a different amount of health every screen.</p>

<p>Would this call for a class? I have yet to use classes and have seen some examples using them, but I was hoping I could stick to functions for this first project. Thanks for any help everyone.</p>
"
"60480124","<p>The root problem is that you're not tracking health at all. <code>current_health</code> is defined in the function but not returned or saved to a global or anything. Ultimately a class is going to be the best solution (probably - I've never built a game myself), but the bare minimum fix would be to take <code>current_health</code> as a parameter, modify it in the function, <code>return current_health</code> at the end, and track it outside the function until the next loop.</p>
","0","2020-03-02 13:26:57","0","15300","3115","1510","3211","60480049","60480123","<p>Let me preface by saying that I am very very new to programming in general. I've been doing it for about a week and have successfully made things like calculators and all that beginner jazz and have been working on my first real ""project"", which is a text-based adventure game. My problem right now is that I cannot put together a very simple health system for the life of me and would like to get any pointers any of you might have.</p>

<p>I've rewritten the code for it many times but here is the basic framework of what I've been working with:</p>

<pre><code>def healthSystem(enemy_atk = 0):   # Called at the beginning of every game screen.
    watermark()   # A function that prints the game title and other things at the top of every screen

    max_health = 10       # Player max health
    no_health = 0         # Player dies at this threshold
    modifier = enemy_atk  # An enemy attack roll is taken from another function and stored here
    current_health = max_health - modifier   # Calculating the new health

    print(""+"" * current_health)   # Prints the new health to the screen, every 1 health is represented with a ""+""
    print()
</code></pre>

<p>It's very barebones and it works on the first game screen. However, when you progress to the next game screen, everything is recalculated and the health is redrawn to the screen every time, so you get a different amount of health every screen.</p>

<p>Would this call for a class? I have yet to use classes and have seen some examples using them, but I was hoping I could stick to functions for this first project. Thanks for any help everyone.</p>
"
"60480189","<p>The return type is an instance of <code>sympy.core.add.Add</code>. You can convert it to float by doing:</p>

<pre><code>&gt;&gt;&gt; integral
1/8 - exp(-4)/8
&gt;&gt;&gt; float(integral)
0.12271054513890822
</code></pre>
","0","","0","10203","195","80","596","60480054","60480189","<p>I want to integrate xe^(-4(x^2)) from x=0 to x=1. When i get integral result, result seems not numerical.</p>

<p>My code is:</p>

<pre><code>import sympy as sp
def f(x):
     return x * sp.exp(-4 * (x ** 2))
x = sp.symbols('x')
integral = sp.integrate(f(x), (x, 0, 1))
print(f'Result of analytic integration = {integral}')
</code></pre>

<p>Output is:</p>

<pre><code>Result of analytic integration = 1/8 - exp(-4)/8
</code></pre>
"
"60482765","<p>Just so you know, I don't know much about the transip api.</p>

<p>I took a look at their code where the error is being thrown in <a href=""https://github.com/benkonrath/transip-api/blob/master/transip/service/objects.py#L52"" rel=""nofollow noreferrer"">transip/service/objects.py</a>, and it looks like they have a bug:</p>

<pre class=""lang-py prettyprint-override""><code>def __eq__(self, other): 
    # other can be a list. This check ensures that other is a DnsEntry. 
    if not hasattr(self, 'name') or not hasattr(self, 'type') or not hasattr(self, 'content'): 
        return False 

    # expire is intentionally not used for equality. 
    return self.name == other.name and self.type == other.type and self.content == other.content

</code></pre>

<p>The comment says that <code>other</code> can be a list so they're ensuring that it's a DNSEntry, but they're actually not checking that at all. If <code>self</code> has the attributes <code>name</code>, <code>type</code>, and <code>content</code>, and <code>other</code> does not, this will break. In your case, <code>other</code> is a list so it doesn't have the <code>name</code> attribute.</p>

<p>Something like changing the first if statement to check <code>other</code> instead of <code>self</code> may solve it:</p>

<pre class=""lang-py prettyprint-override""><code>if not hasattr(other, 'name') or not hasattr(other, 'type') or not hasattr(other, 'content'): 
        return False 
</code></pre>

<p>It would actually probably be better to just check if <code>other</code> is a list:</p>

<pre class=""lang-py prettyprint-override""><code>if isinstance(other, list):
   return False
</code></pre>

<p>If I were you, I'd either open an issue in transip API GitHub repo, or do a quick fix yourself and submit a pull request.</p>
","0","","1","1337","2625","1","61","60480069","60482765","<p>I try to get a script to work for checking / editing my dns at transip. It works partly until I realy want to do something.</p>

<p>Current code:</p>

<pre><code>#!/usr/bin/env python3

from transip.service.domain import DomainService

basedomain='gemert.net'
key='MY_KEY_IS_SECRET'

dnsservice = DomainService('MY_USERNAME', private_key=key)
print(dnsservice.get_domain_names())
print(dnsservice.check_availability(basedomain))
print(dnsservice.get_info(basedomain))
</code></pre>

<p>The result when running is al follows:</p>

<pre><code>./setdns.py 
[mydomain1.com, mydomain2.org, mydomain3.net]
inyouraccount
Traceback (most recent call last):
  File ""./setdns.py"", line 49, in &lt;module&gt;
    print(dnsservice.get_info(basedomain))
  File ""/usr/local/lib/python3.7/dist-packages/suds/__init__.py"", line 166, in &lt;lambda&gt;
    __str__ = lambda x: x.__unicode__()
  File ""/usr/local/lib/python3.7/dist-packages/suds/sudsobject.py"", line 172, in __unicode__
    return self.__printer__.tostr(self)
  File ""/usr/local/lib/python3.7/dist-packages/suds/sudsobject.py"", line 256, in tostr
    return self.process(object, history, indent)
  File ""/usr/local/lib/python3.7/dist-packages/suds/sudsobject.py"", line 265, in process
    return self.print_object(object, h, n+2, nl)
  File ""/usr/local/lib/python3.7/dist-packages/suds/sudsobject.py"", line 312, in print_object
    s.append(self.process(item[1], h, n, True))
  File ""/usr/local/lib/python3.7/dist-packages/suds/sudsobject.py"", line 273, in process
    return self.print_collection(object, h, n+2)
  File ""/usr/local/lib/python3.7/dist-packages/suds/sudsobject.py"", line 352, in print_collection
    s.append(self.process(item, h, n-2))
  File ""/usr/local/lib/python3.7/dist-packages/suds/sudsobject.py"", line 265, in process
    return self.print_object(object, h, n+2, nl)
  File ""/usr/local/lib/python3.7/dist-packages/suds/sudsobject.py"", line 282, in print_object
    if d in h:
  File ""/usr/local/lib/python3.7/dist-packages/transip/service/objects.py"", line 57, in __eq__
    return self.name == other.name and self.type == other.type and self.content == other.content
AttributeError: 'list' object has no attribute 'name'
</code></pre>

<p>What am I doing wrong? The first 2 commands seem to work but the <code>dnsservice.get_info(basedomain)</code> isn't working</p>

<p>Version of <em>transip</em> module</p>

<pre><code>pip3 show transip
Name: transip
Version: 2.0.0
Summary: TransIP API Connector
Home-page: https://github.com/benkonrath/transip-api
Author: Go About B.V.
Author-email: tech@goabout.com
License: MIT
Location: /usr/local/lib/python3.7/dist-packages
Requires: cryptography, suds-jurko, requests
Required-by: 
</code></pre>
"
"60480182","<p>For example:</p>

<pre><code>while all((row[2] != 2 for row in list)):
</code></pre>

<p>or:</p>

<pre><code>while any((row[2] != 2 for row in list)):
</code></pre>

<p>depending on what you really want.</p>
","0","","2","701","18","5","37","60480149","60480182","<p><strong>[Python 3.7]</strong></p>

<hr>

<p>I want to run a <code>while()</code> condition which looks at the <code>3rd</code> position of all lists in a nested list:</p>

<p><em>example:</em> </p>

<p><code>list = [[0,2,3,4], [4,3,2,5], [3,4,3,2]]</code></p>

<pre><code>while list[:][2] != 2:    # ':' denoting all (I know its not correct)
    pass                  # AKA do something
</code></pre>

<p>I want to do this because in the code I am working on I have parts of a list that require deletion and I need to know when only a specific element is left.</p>
"
"60480831","<p>I wrote a function that could get the job done, depending on the size of the file. Explanation in code comments.</p>

<pre><code>def split_file(file_name, lines_per_file=100000):
    # Open large file to be read in UTF-8
    with open(file_name, 'r', encoding='utf-8') as rf:
        # Read all lines in file
        lines = rf.readlines()
        print ( str(len(lines)) + ' LINES READ.')
        # Set variables to count file number and count of lines written
        file_no = 0
        wlines_count = 0
        # For x from 0 to length of lines read stepping by number of lines that will be written in each file
        for x in range(0, len(lines), lines_per_file):
            # Open new ""split"" file for writing in UTF-8
            with open( 'data' + '-' + str(file_no) + '.txt', 'w', encoding='utf-8') as wf:
                # Write lines
                wf.writelines(lines[x:x+lines_per_file])
                # Update the written lines count
                wlines_count += (len(lines[x:x + lines_per_file]))
                # Update new ""split"" file count mainly for naming
                file_no+=1
        print(str(wlines_count) + "" LINES WRITTEN IN "" + str(file_no) + "" FILES."")

# Split data.txt into files containing 100000 lines
split_file('data.txt',100000)
</code></pre>
","0","","0","1541","222","23","129","60480172","60480831","<p>I have a data txt file formatted in a way to be loaded into a database (MySQL) in the following format (somewhat exaggerated):</p>

<p>data.txt</p>

<pre><code>name   age profession datestamp
John   23  engineer   2020-03-01
Amy    17  doctor     2020-02-27
Gordon 19  artist     2020-02-27
Kevin  25  chef       2020-03-01
</code></pre>

<p>The above was generated by the following command executed through python:</p>

<pre><code>LOAD DATA LOCAL INFILE '/home/sample_data/data.txt' REPLACE INTO TABLE person_professions 
FIELDS TERMINATED BY 0x01 OPTIONALLY ENCLOSED BY '\""' LINES TERMINATED BY '\n'
 (name,age,profession,datestamp)
</code></pre>

<p>which creates data.txt; however, data.txt is really huge for this database to be inserted all at once (~200 MB insertion limit set), I want to slice the data up into several chunks (data_1.txt, data_2.txt, data_3.txt, etc.) and insert them one by one to avoiding hitting the insertion size limit. I know that you can go line by line and look for a condition to slice out the data for such as </p>

<pre><code>with open('data.txt', 'w') as f:
    data = f.read().split('\n')
    if some condition:
       with open('data_1.txt', 'w') as f2:
            insert data 
</code></pre>

<p>But I'm not too sure on how I could come up with a condition breakpoint to make it start inserting into a new txt file unless there's a better way of doing it. </p>
"
"60480247","<p>If you're looking for how to use a builtin Python module (the <code>csv</code> module, for example), I would recommend looking at the official Python documentation.</p>

<p>You can find the documentation for the csv module <a href=""https://docs.python.org/3/library/csv.html"" rel=""nofollow noreferrer"">here</a>.</p>

<p>Here's the first example they give of reading a csv file (see <a href=""https://docs.python.org/3/library/csv.html#examples"" rel=""nofollow noreferrer"">https://docs.python.org/3/library/csv.html#examples</a>):</p>

<pre class=""lang-py prettyprint-override""><code>with open('some.csv', newline='') as f:
    reader = csv.reader(f)
    for row in reader:
        print(row)
</code></pre>

<p>In the loop, you can access <code>row</code> to store it in whatever data structure you prefer.</p>

<p>For example, to put it in all in a list:</p>

<pre class=""lang-py prettyprint-override""><code>with open('some.csv', newline='') as f:
    reader = csv.reader(f)
    data = [row for row in reader]
print(data)
</code></pre>
","0","","1","1337","2625","1","61","60480197","60480251","<p>I'm trying to open a CSV file on Python 3.7/Spyder/Anaconda IDE. </p>

<p>I want to learn how to import csv files either by using pandas and by using the csv libraries. </p>

<p>The following code worked well and a <em>csvfile</em> variable containing the data frame was created:</p>

<pre><code>import pandas as pd
csvfile = pd.read_csv(r'C:\Users\Documents\PyLearning\data_file.csv', sep=',')
</code></pre>

<p>However I didn't get the same result with the csv module. After running the following code, nothing happend. </p>

<pre><code>import csv
csvfile = open('data_file.csv', 'rb')
reader = csv.reader(csvfile)
</code></pre>

<p>I got no error message but no variable was created.  </p>

<p>I would like to some help to understand why this is happening.  </p>

<p>EDIT: It seems csv module was replaced by unicodecsv module at more recent python versions
<a href=""https://pypi.org/project/unicodecsv/"" rel=""nofollow noreferrer"">https://pypi.org/project/unicodecsv/</a></p>
"
"60480251","<p>The beauty of using pandas' read_csv is that it automatically and most importantly <strong>quickly</strong> converts said csv into a usable dataframe.</p>

<p>using csv.reader simply refers to the csv in question but you would have to call an iterator to get a result.</p>

<p>i.e.: (from <a href=""https://docs.python.org/3/library/csv.html"" rel=""nofollow noreferrer"">https://docs.python.org/3/library/csv.html</a>)</p>

<pre><code>&gt;&gt;&gt; import csv
&gt;&gt;&gt; with open('eggs.csv', newline='') as csvfile:
...     spamreader = csv.reader(csvfile, delimiter=' ', quotechar='|')
...     for row in spamreader:
...         print(', '.join(row))
Spam, Spam, Spam, Spam, Spam, Baked Beans
Spam, Lovely Spam, Wonderful Spam
</code></pre>
","1","","0","505","25","7","54","60480197","60480251","<p>I'm trying to open a CSV file on Python 3.7/Spyder/Anaconda IDE. </p>

<p>I want to learn how to import csv files either by using pandas and by using the csv libraries. </p>

<p>The following code worked well and a <em>csvfile</em> variable containing the data frame was created:</p>

<pre><code>import pandas as pd
csvfile = pd.read_csv(r'C:\Users\Documents\PyLearning\data_file.csv', sep=',')
</code></pre>

<p>However I didn't get the same result with the csv module. After running the following code, nothing happend. </p>

<pre><code>import csv
csvfile = open('data_file.csv', 'rb')
reader = csv.reader(csvfile)
</code></pre>

<p>I got no error message but no variable was created.  </p>

<p>I would like to some help to understand why this is happening.  </p>

<p>EDIT: It seems csv module was replaced by unicodecsv module at more recent python versions
<a href=""https://pypi.org/project/unicodecsv/"" rel=""nofollow noreferrer"">https://pypi.org/project/unicodecsv/</a></p>
"
"60480389","<p>As you can see from the <code>insert(self, data)</code> method's content, the <code>right</code> and <code>left</code> instance attributes are meant to hold objects of type <code>Node</code>, which are references to the two child nodes of the <code>self</code> node. The lines you quoted call the methods defined in this very class, but instead of calling them on the <code>self</code> instance, they call them on the child nodes, so they'll be working with different data.</p>
","1","","1","88","29","0","22","60480265","60480389","<p>I was reading this simple approach of a Binary Search tree insertion, below is the solution :</p>

<pre><code>class Node:

    def __init__(self, data):
        self.left = None
        self.right = None
        self.data = data

    def insert(self, data):
        if self.data:


            if data &lt; self.data:
                if self.left is None:
                    self.left = Node(data)
                else:
                    self.left.insert(data)
            elif data &gt; self.data:
                if self.right is None:
                    self.right = Node(data)
                else:
                    self.right.insert(data)
            else:
                self.data = data

    def PrintTree(self):
        if self.left:
            self.left.PrintTree()
        print(self.data),
        if self.right:
            self.right.PrintTree()


if __name__ == ""__main__"":
    root = Node(12)
    root.insert(6)
    root.insert(14)
    root.insert(3)

    root.PrintTree()
</code></pre>

<p>But am still wondering on the following lines where they called a function through a variable :</p>

<pre><code>self.left.insert(data)
</code></pre>

<p>then  :</p>

<pre><code>self.right.insert(data)
</code></pre>

<p>and :</p>

<pre><code>self.left.PrintTree()
</code></pre>

<p>What is this called ? I need a recap on this.</p>
"
"60480460","<p>You can get a specified version of a file without checking out the corresponding commit using <code>git show</code>. For example:</p>

<pre><code>git show git_hash:./file.py
</code></pre>

<p>will print the contents of <code>file.py</code> as of the specified commit to standard output. (Presumably the Git Python interface, which I haven't used, provides similar functionality.) The leading <code>./</code> avoids path resolution problems in some cases (I don't remember the details).</p>

<p>I've written a Perl script that does this kind of thing for several different version control systems (most of which I no longer use): <a href=""https://github.com/Keith-S-Thompson/get-versions"" rel=""nofollow noreferrer"">https://github.com/Keith-S-Thompson/get-versions</a> (no warranties).</p>

<p>As requested, here's an example of running <code>get-versions</code> on a copy of its own repo:</p>

<pre><code>$ ls -l
total 56
-rw-r--r-- 1 kst kst 18092 Aug  9  2015 COPYING
-rw-r--r-- 1 kst kst  6234 Apr 16  2018 README.md
-rw-r--r-- 1 kst kst   940 Apr 25  2018 TODO.md
-rwxr-xr-x 1 kst kst 20977 Apr 16  2018 get-versions
$ get-versions -pad 3 -last 3 get-versions 
$ ls -l
total 128
-rw-r--r-- 1 kst kst 18092 Aug  9  2015 COPYING
-rw-r--r-- 1 kst kst  6234 Apr 16  2018 README.md
-rw-r--r-- 1 kst kst   940 Apr 25  2018 TODO.md
-rwxr-xr-x 1 kst kst 20977 Apr 16  2018 get-versions
-r--r--r-- 1 kst kst 20752 Mar  2 10:54 get-versions,012
-r--r--r-- 1 kst kst 20766 Mar  2 10:54 get-versions,013
-r--r--r-- 1 kst kst 20977 Mar  2 10:54 get-versions,014
$ 
</code></pre>

<p><code>get-versions -help</code> prints an entirely too verbose usage message. (Adding a man page is on my TODO list, as is preserving execute permissions.)</p>
","1","2020-03-02 18:56:24","0","228253","1538","626","50273","60480287","60480966","<p>Having a <code>file.py</code> which has three versions in git with three unique commit hashes. </p>

<p>So how can I programmatically restore all of the versions into specific files, such as:</p>

<pre class=""lang-sh prettyprint-override""><code>0_&lt;git_hash&gt;_file.py
1_&lt;git_hash&gt;_file.py
2_&lt;git_hash&gt;_file.py
</code></pre>

<p>Solution does not have to be Python, but looking into the Python <code>git</code> package currently.</p>
"
"60480960","<p>Use git rev-list to get the list of commits, and git show to output the file:</p>

<pre><code>i=0; git rev-list --abbrev-commit HEAD | 
while read sha; do
    git show $sha:./file.py &gt; $((i++))_${sha}_file.py
done
</code></pre>

<p>This version might avoid problems with <code>i++</code> being executed in a subshell and not affecting the parent:</p>

<pre><code>i=0; git rev-list --abbrev-commit HEAD |
while read sha; do
    git show $sha:./file.py &gt; ${i}_${sha}_file.py
    ((i++))
done
</code></pre>
","13","2020-03-03 19:08:10","0","171867","3675","1562","10640","60480287","60480966","<p>Having a <code>file.py</code> which has three versions in git with three unique commit hashes. </p>

<p>So how can I programmatically restore all of the versions into specific files, such as:</p>

<pre class=""lang-sh prettyprint-override""><code>0_&lt;git_hash&gt;_file.py
1_&lt;git_hash&gt;_file.py
2_&lt;git_hash&gt;_file.py
</code></pre>

<p>Solution does not have to be Python, but looking into the Python <code>git</code> package currently.</p>
"
"60480966","<pre><code>n=0
git log --pretty= --diff-filter=d --raw -- $file | 
while read m1 m2 h1 h2 rest; do
        eval git show $h2 &gt; $((n++))_${h2}.$file
done
</code></pre>

<p>or</p>

<pre><code>n=0
git log --pretty=%h --diff-filter=d -- $file |
while read; do
        eval git show $REPLY:$file &gt; $((n++))_$REPLY.$file
done
</code></pre>

<p>depending on whether you want the blob's or the commit's hash in the resulting file name.</p>
","4","","2","42001","1728","671","1888","60480287","60480966","<p>Having a <code>file.py</code> which has three versions in git with three unique commit hashes. </p>

<p>So how can I programmatically restore all of the versions into specific files, such as:</p>

<pre class=""lang-sh prettyprint-override""><code>0_&lt;git_hash&gt;_file.py
1_&lt;git_hash&gt;_file.py
2_&lt;git_hash&gt;_file.py
</code></pre>

<p>Solution does not have to be Python, but looking into the Python <code>git</code> package currently.</p>
"
"60481244","<p>You: I wanted to apply k-mean to remove any anomalies. </p>

<p>Actually, KMeas will detect anomalies and include them in the nearest cluster.  The loss function is the minimum sum of squared distances from each point to its assigned cluster centroid.  If you want to kick out outliers, consider using a z-score methodology.  </p>

<pre><code>import numpy as np
import pandas as pd

# import your data
df = pd.read_csv('C:\\Users\\your_file.csv)

# get only numerics
numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']
newdf = df.select_dtypes(include=numerics)

df = newdf

# count rows in DF before kicking out records with z-score over 3
df.shape

# handle NANs
df = df.fillna(0)


from scipy import stats
df = df[(np.abs(stats.zscore(df)) &lt; 3).all(axis=1)]
df.shape


df = pd.DataFrame(np.random.randn(100, 3))
from scipy import stats
df[(np.abs(stats.zscore(df)) &lt; 3).all(axis=1)]

# count rows in DF before kicking out records with z-score over 3
df.shape
</code></pre>

<p>In addition, take a look at these links when you have some free time.</p>

<p><a href=""https://medium.com/analytics-vidhya/effect-of-outliers-on-k-means-algorithm-using-python-7ba85821ea23"" rel=""nofollow noreferrer"">https://medium.com/analytics-vidhya/effect-of-outliers-on-k-means-algorithm-using-python-7ba85821ea23</a></p>

<p><a href=""https://statisticsbyjim.com/basics/outliers/"" rel=""nofollow noreferrer"">https://statisticsbyjim.com/basics/outliers/</a></p>
","3","","1","14971","13653","10","2256","60480314","60482019","<p>I have a database which has 13 features and 10million rows. I wanted to apply k-mean to remove any anomalies. My though was to apply k-mean, create a new column with the distance between the data points and the cluster centroids, and a new column with the mean distance,and if the distance is larger than the mean distance I remove the whole row. But it seems the code I wrote is not working.</p>

<p>Dataset sample:
<a href=""https://drive.google.com/open?id=1iB1qjnWQyvoKuN_Pa8Xk4BySzXVTwtUk"" rel=""nofollow noreferrer"">https://drive.google.com/open?id=1iB1qjnWQyvoKuN_Pa8Xk4BySzXVTwtUk</a></p>

<pre><code>df = pd.read_csv('Final After Simple Filtering.csv',index_col=None,low_memory=True)


# Dropping columns with low feature importance
del df['AmbTemp_DegC']
del df['NacelleOrientation_Deg']
del df['MeasuredYawError']



#applying kmeans
#applying kmeans
kmeans = KMeans( n_clusters=8)


clusters= kmeans.fit_predict(df)

centroids = kmeans.cluster_centers_

distance1 = kmeans.fit_transform(df)

distance2 = distance1.mean()

df['distances']=distance1-distance2

df = df[df['distances'] &gt;=0]


del df['distances']

df.to_csv('/content//drive/My Drive/K TEST.csv', index=False)
</code></pre>

<p>Error:</p>

<pre><code>KeyError                                  Traceback (most recent call last)
/usr/local/lib/python3.6/dist-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance)
   2896             try:
-&gt; 2897                 return self._engine.get_loc(key)
   2898             except KeyError:

pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc()

pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc()

pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item()

pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item()

KeyError: 'distances'

During handling of the above exception, another exception occurred:

KeyError                                  Traceback (most recent call last)
9 frames
pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc()

pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc()

pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item()

pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item()

KeyError: 'distances'

During handling of the above exception, another exception occurred:

ValueError                                Traceback (most recent call last)
/usr/local/lib/python3.6/dist-packages/pandas/core/internals/blocks.py in __init__(self, values, placement, ndim)
    126             raise ValueError(
    127                 ""Wrong number of items passed {val}, placement implies ""
--&gt; 128                 ""{mgr}"".format(val=len(self.values), mgr=len(self.mgr_locs))
    129             )
    130 

ValueError: Wrong number of items passed 8, placement implies 1
</code></pre>

<p>Thank you</p>
"
"60482019","<p>Here is a follow up answer for your last question.</p>

<pre><code>import seaborn as sns
import pandas as pd
titanic = sns.load_dataset('titanic')
titanic = titanic.copy()
titanic = titanic.dropna()
titanic['age'].plot.hist(
  bins = 50,
  title = ""Histogram of the age variable""
)


from scipy.stats import zscore
titanic[""age_zscore""] = zscore(titanic[""age""])
titanic[""is_outlier""] = titanic[""age_zscore""].apply(
  lambda x: x &lt;= -2.5 or x &gt;= 2.5
)
titanic[titanic[""is_outlier""]]


ageAndFare = titanic[[""age"", ""fare""]]
ageAndFare.plot.scatter(x = ""age"", y = ""fare"")


from sklearn.preprocessing import MinMaxScaler
scaler = MinMaxScaler()
ageAndFare = scaler.fit_transform(ageAndFare)
ageAndFare = pd.DataFrame(ageAndFare, columns = [""age"", ""fare""])
ageAndFare.plot.scatter(x = ""age"", y = ""fare"")


from sklearn.cluster import DBSCAN
outlier_detection = DBSCAN(
  eps = 0.5,
  metric=""euclidean"",
  min_samples = 3,
  n_jobs = -1)
clusters = outlier_detection.fit_predict(ageAndFare)

clusters


from matplotlib import cm
cmap = cm.get_cmap('Accent')
ageAndFare.plot.scatter(
  x = ""age"",
  y = ""fare"",
  c = clusters,
  cmap = cmap,
  colorbar = False
)
</code></pre>

<p><a href=""https://i.stack.imgur.com/iuhct.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/iuhct.png"" alt=""enter image description here""></a></p>

<p>See this link for all details.</p>

<p><a href=""https://www.mikulskibartosz.name/outlier-detection-with-scikit-learn/"" rel=""nofollow noreferrer"">https://www.mikulskibartosz.name/outlier-detection-with-scikit-learn/</a></p>

<p>I have never heard of 'Local Outlier Factor' before today.  When I Googled it, I got some information that seems to indicate that it is a derivative of DBSCAN.  Finally, I think my first answer is actually the best way to detect outliers.  DBSCAN is clustering algo that happens to find outliers, which are really considered 'noise'.  I don't think the primary purpose of DBSCAN is anomaly detection, but rather clustering.  In conclusion, it takes a bit of skill to choose hyper-parameters correctly.  Also, DBSCAN can be slow on very large datasets, as it implicitly needs to compute the empirical density for each sample point, leading  to  a  quadratic  worst-case  time  complexity, which is quite slow on large datasets. </p>
","0","2020-03-02 03:17:50","1","14971","13653","10","2256","60480314","60482019","<p>I have a database which has 13 features and 10million rows. I wanted to apply k-mean to remove any anomalies. My though was to apply k-mean, create a new column with the distance between the data points and the cluster centroids, and a new column with the mean distance,and if the distance is larger than the mean distance I remove the whole row. But it seems the code I wrote is not working.</p>

<p>Dataset sample:
<a href=""https://drive.google.com/open?id=1iB1qjnWQyvoKuN_Pa8Xk4BySzXVTwtUk"" rel=""nofollow noreferrer"">https://drive.google.com/open?id=1iB1qjnWQyvoKuN_Pa8Xk4BySzXVTwtUk</a></p>

<pre><code>df = pd.read_csv('Final After Simple Filtering.csv',index_col=None,low_memory=True)


# Dropping columns with low feature importance
del df['AmbTemp_DegC']
del df['NacelleOrientation_Deg']
del df['MeasuredYawError']



#applying kmeans
#applying kmeans
kmeans = KMeans( n_clusters=8)


clusters= kmeans.fit_predict(df)

centroids = kmeans.cluster_centers_

distance1 = kmeans.fit_transform(df)

distance2 = distance1.mean()

df['distances']=distance1-distance2

df = df[df['distances'] &gt;=0]


del df['distances']

df.to_csv('/content//drive/My Drive/K TEST.csv', index=False)
</code></pre>

<p>Error:</p>

<pre><code>KeyError                                  Traceback (most recent call last)
/usr/local/lib/python3.6/dist-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance)
   2896             try:
-&gt; 2897                 return self._engine.get_loc(key)
   2898             except KeyError:

pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc()

pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc()

pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item()

pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item()

KeyError: 'distances'

During handling of the above exception, another exception occurred:

KeyError                                  Traceback (most recent call last)
9 frames
pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc()

pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc()

pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item()

pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item()

KeyError: 'distances'

During handling of the above exception, another exception occurred:

ValueError                                Traceback (most recent call last)
/usr/local/lib/python3.6/dist-packages/pandas/core/internals/blocks.py in __init__(self, values, placement, ndim)
    126             raise ValueError(
    127                 ""Wrong number of items passed {val}, placement implies ""
--&gt; 128                 ""{mgr}"".format(val=len(self.values), mgr=len(self.mgr_locs))
    129             )
    130 

ValueError: Wrong number of items passed 8, placement implies 1
</code></pre>

<p>Thank you</p>
"
"60480344","<p>From <a href=""https://stackoverflow.com/a/7397195/1675501"">https://stackoverflow.com/a/7397195/1675501</a></p>

<p>First, you need to strip the 0b prefix, and left-zero-pad the string so it's length is divisible by 8, to make dividing the bitstring up into characters easy:</p>

<pre><code>bitstring = bitstring[2:]
bitstring = -len(bitstring) % 8 * '0' + bitstring
</code></pre>

<p>Then you divide the string up into blocks of eight binary digits, convert them to ASCII characters, and join them back into a string:</p>

<pre><code>string_blocks = (bitstring[i:i+8] for i in range(0, len(bitstring), 8))
string = ''.join(chr(int(char, 2)) for char in string_blocks)
</code></pre>

<p>If you actually want to treat it as a number, you still have to account for the fact that the leftmost character will be at most seven digits long if you want to go left-to-right instead of right-to-left.</p>
","0","","0","1082","116","16","81","60480316","60480344","<p>I'm looking for a loop similar to this for converting ASCII to decimal then decimal to binary string:
string = input(""Enter message: "")</p>

<pre><code>#Convert string from ASCII to Decimal
A_string = [ord(c) for c in string]
print(A_string)

# add 1 to ASCII value 
B_string = A_string
for i in range(len(B_string)):
    B_string[i] = B_string[i] + 1 
print(B_string)


#Decimal to Binary
decimal = B_string
remainder = decimal
Binary_string = decimal

for i in range(len(decimal)):
    remainder[i] = int(decimal[i])
    remainder[i] %= 2
    decimal[i] = decimal[i] // 2
    Binary_string[i] = str(remainder[i] + Binary_string[i])
print(Binary_string)
</code></pre>

<p>What I'm NOT looking for are things like this:</p>

<p>res = """".join(f""{ord(shiftedChar):08b}"")</p>

<p>shiftedChar </p>

<p>I'm looking for BASIC OLD SCHOOL techniques... programming what's actually happening using basic division, multiplication, powers, etc</p>
"
"60480448","<p>You have two issues:</p>

<ul>
<li>You are not sending JSON data, you forgot to encode your data to JSON. Encoding the string value <code>test connection</code> to JSON becomes <code>""test connection""</code>, but <em>quotes have meaning in your shell too</em>, so you need to add <em>extra</em> quoting or escapes.</li>
<li>You can't set multiple headers with a single <code>-H</code> entry. Use multiple, one per header set. Headers don't need quotes, only the shell needs quoting to prevent argument splitting on spaces.</li>
</ul>

<p>This would be equivalent:</p>

<pre class=""lang-sh prettyprint-override""><code>curl -X POST \
  --data '""test connection""' \
  -H 'Content-type: application/json' \
  -H 'Authorization: Basic asdfasdf' \
  dns.com/end
</code></pre>

<p>Demo using <a href=""https://httpbin.org"" rel=""nofollow noreferrer"">https://httpbin.org</a>:</p>

<pre class=""lang-sh prettyprint-override""><code>$ curl -X POST \
&gt;   --data '""test connection""' \
&gt;   -H 'Content-type: application/json' \
&gt;   -H 'Authorization: Basic asdfasdf' \
&gt;   https://httpbin.org/post

{
  ""args"": {},
  ""data"": ""\""test connection\"""",
  ""files"": {},
  ""form"": {},
  ""headers"": {
    ""Accept"": ""*/*"",
    ""Authorization"": ""Basic asdfasdf"",
    ""Content-Length"": ""17"",
    ""Content-Type"": ""application/json"",
    ""Host"": ""httpbin.org"",
    ""User-Agent"": ""curl/7.54.0"",
    ""X-Amzn-Trace-Id"": ""Root=1-5e5c399c-201cc8007165873084d4cf38""
  },
  ""json"": ""test connection"",
  ""origin"": ""&lt;ip address&gt;"",
  ""url"": ""https://httpbin.org/post""
}
</code></pre>

<p>which matches the Python equivalent:</p>

<pre class=""lang-py prettyprint-override""><code>&gt;&gt;&gt; import requests
&gt;&gt;&gt; url = 'https://httpbin.org/post'
&gt;&gt;&gt; msg = ""test connection""
&gt;&gt;&gt; headers = {""Content-type"": ""application/json"",
...             ""Authorization"": ""Basic asdfasdf""}
&gt;&gt;&gt; response = requests.post(url, json=msg, headers=headers)
&gt;&gt;&gt; print(response.text)
{
  ""args"": {},
  ""data"": ""\""test connection\"""",
  ""files"": {},
  ""form"": {},
  ""headers"": {
    ""Accept"": ""*/*"",
    ""Accept-Encoding"": ""gzip, deflate"",
    ""Authorization"": ""Basic asdfasdf"",
    ""Content-Length"": ""17"",
    ""Content-Type"": ""application/json"",
    ""Host"": ""httpbin.org"",
    ""User-Agent"": ""python-requests/2.22.0"",
    ""X-Amzn-Trace-Id"": ""Root=1-5e5c3a25-50c9db19a78512606a42b6ec""
  },
  ""json"": ""test connection"",
  ""origin"": ""&lt;ip address&gt;"",
  ""url"": ""https://httpbin.org/post""
}
</code></pre>
","0","","1","879075","5816","21692","293021","60480388","60480448","<p>Sample python code which send sample message.</p>

<pre><code>import requests

url = ""dns.com/end""
msg = ""test connection""
headers = {""Content-type"": ""application/json"",
            ""Authorization"": ""Basic asdfasdf""}

requests.post(url, json=msg, headers=headers)
</code></pre>

<p>Now, I'd like to send exactly the same message using curl request.</p>

<pre><code>curl -X POST --data ""test connection"" -H '""Content-type"": ""application/json"", ""Authorization"": ""Basic asdfasdf""' dns.com/end
</code></pre>

<p>I'm getting an error:
""status"":404,""message"":""No message available""</p>
"
"60498093","<p>You can remove some of the noise using contour area filtering with <a href=""https://docs.opencv.org/2.4/modules/imgproc/doc/structural_analysis_and_shape_descriptors.html#contourarea"" rel=""nofollow noreferrer""><code>cv2.contourArea</code></a>. The idea is to filter using some threshold area. If a contour passes this filter then we can remove the noise by filling in the contour with <a href=""https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_imgproc/py_contours/py_contours_begin/py_contours_begin.html#how-to-draw-the-contours"" rel=""nofollow noreferrer""><code>cv2.drawContours</code></a>. Using your binary image as input:</p>

<p><a href=""https://i.stack.imgur.com/BL55h.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/BL55h.png"" alt=""enter image description here""></a></p>

<p>Detected contours to remove highlighted in green</p>

<p><a href=""https://i.stack.imgur.com/4IR5n.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/4IR5n.png"" alt=""enter image description here""></a></p>

<p>Result</p>

<p><a href=""https://i.stack.imgur.com/xkGlL.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/xkGlL.png"" alt=""enter image description here""></a></p>

<p>Depending on how much noise you want to remove, you can adjust the threshold area value</p>

<p>Code</p>

<pre><code>import numpy as np
import cv2

# Load image, grayscale, Otsu's threshold
image = cv2.imread(""1.png"")
gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]

# Find contours and filter using contour area
cnts = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)
cnts = cnts[0] if len(cnts) == 2 else cnts[1]
for c in cnts:
    area = cv2.contourArea(c)
    if area &lt; 50:
        cv2.drawContours(thresh, [c], -1, 0, -1)
        cv2.drawContours(image, [c], -1, (36,255,12), -1)

result = 255 - thresh
cv2.imshow(""image"", image) 
cv2.imshow(""thresh"", thresh) 
cv2.imshow(""result"", result) 
cv2.waitKey()
</code></pre>
","0","","2","25600","1364","21","7558","60480473","60498093","<p>I would like to be able to analyze the following image, get the lines and find the average width.(My copy is much larger ~5K by ~4K) Cannot move to the next step due to all the noise after thresholding.</p>

<p><a href=""https://i.stack.imgur.com/etxt3.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/etxt3.png"" alt=""enter image description here""></a></p>

<p>Using my code I was able to get to this point...</p>

<p><a href=""https://i.stack.imgur.com/XMMHx.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/XMMHx.png"" alt=""enter image description here""></a></p>

<p>My issue is that it has a lot of noise in-between lines, which looks like noise that got condensed.</p>

<p>Here is my code...</p>

<pre><code>image = np.copy(origImg)
newImage = np.empty_like(image)

scale = 64

height = image.shape[0]
width = image.shape[1]

dH = int(height / scale)
dW = int(width / scale)

xi = int(dH)
yi = int(dW)

fragments = []
image = cv2.bilateralFilter(image,9,75,75)
image = cv2.medianBlur(image, 21)

for i in range(0,height,dH):
    for j in range(0,width,dW):
        fragment = image[i:i + int(dH), j:j + int(dW)]

        fragment = cv2.adaptiveThreshold(fragment, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 31, 0)

        fragments.append(fragment)

analyzed = com.stackArrayToImage(fragments)

nlabels, labels, stats, centroids = cv2.connectedComponentsWithStats(analyzed, None, None, None, 8, cv2.CV_32S)
sizes = stats[1:, -1] 
img2 = np.zeros((labels.shape), np.uint8)

for i in range(0, nlabels - 1):
    if sizes[i] &gt;= 100:  
        img2[labels == i + 1] = 255

analyzed = cv2.bitwise_not(img2)

analyzed = cv2.erode(analyzed, np.ones((5, 5)), iterations=2)
analyzed = cv2.dilate(analyzed, np.ones((5, 5), np.uint8))

dis.plotImages([origImg], ""Origional"")
dis.plotImages([analyzed], ""Analyzed"")
dis.displayStart() 
</code></pre>

<p>Is there anyway I can remove that noise?</p>

<p>Thank you very much!</p>
"
"60482931","<p>You can compare text of revision directly, or look for the revisions that have the same sha1 hash:</p>

<pre><code>&gt;&gt;&gt; rev = next(revs)
&gt;&gt;&gt; rev.sha1
'1b02fc4cbcfd1298770b16f85afe0224fad4b3ca'
</code></pre>

<p>If two revision have the same text/hash it means that the newer one is a revert to the older one. Of-course there are some special cases like <a href=""https://www.mediawiki.org/wiki/API:Revisions"" rel=""nofollow noreferrer""><code>sha1hidden</code></a>, or how to handle multiple reverts to the same revision that one needs to consider.</p>
","1","","3","5471","4461","28","216","60480535","60483214","<p>I am using <code>pywikibot</code> in python to get all revisions of a Wikipedia page.</p>

<p><code>import pywikibot as pw
wikiPage='Narthaki'
page = pw.Page(pw.Site('en'), wikiPage)
revs = page.revisions(content=True)</code></p>

<p>How do I know which of the revisions were reverts? I see from <a href=""https://xtools.wmflabs.org/articleinfo/en.wikipedia.org/Narthaki"" rel=""nofollow noreferrer"">https://xtools.wmflabs.org/articleinfo/en.wikipedia.org/Narthaki</a> that the page has one revert edit. Not sure how to get more information about this from the revision object.</p>

<p>Request your help. Many thanks!</p>
"
"60483214","<p>""Revert"" is not a well-defined concept so it depends on how you define it. (See <a href=""https://phabricator.wikimedia.org/T152434"" rel=""nofollow noreferrer"">https://phabricator.wikimedia.org/T152434</a> for some relevant discussion.) The most capable revert detection tool today is probably <a href=""https://pythonhosted.org/mwreverts/"" rel=""nofollow noreferrer"">mwrevert</a>.</p>
","0","","4","25311","465","58","1995","60480535","60483214","<p>I am using <code>pywikibot</code> in python to get all revisions of a Wikipedia page.</p>

<p><code>import pywikibot as pw
wikiPage='Narthaki'
page = pw.Page(pw.Site('en'), wikiPage)
revs = page.revisions(content=True)</code></p>

<p>How do I know which of the revisions were reverts? I see from <a href=""https://xtools.wmflabs.org/articleinfo/en.wikipedia.org/Narthaki"" rel=""nofollow noreferrer"">https://xtools.wmflabs.org/articleinfo/en.wikipedia.org/Narthaki</a> that the page has one revert edit. Not sure how to get more information about this from the revision object.</p>

<p>Request your help. Many thanks!</p>
"
"60480819","<p>With the most recent versions of Matplotlib, this is pretty straightforward.</p>

<pre><code>def add_twin(ax, **kwargs):
    twin = ax.twinx()
    twin.yaxis.tick_left()
    twin.tick_params(axis='y', direction='in', **kwargs)
    for tick in twin.get_yticklabels():
        tick.set_horizontalalignment('right')
    return twin


fig, ax = plt.subplots()
twin = add_twin(ax)
twin.set_yticks((0.1, 0.5, 0.9))
</code></pre>

<p>The horizontal alignment part is key, and you'll probably need to tweak the pad for your purposes, using the <code>kwargs</code>. But you should get something like this:</p>

<p><a href=""https://i.stack.imgur.com/G0alw.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/G0alw.png"" alt=""enter image description here""></a></p>
","0","","1","5064","271","12","584","60480567","60480819","<p>Say I create a secondary y-axis with twinx() similar to this <a href=""https://matplotlib.org/gallery/api/two_scales.html"" rel=""nofollow noreferrer"">demo</a></p>

<p>Is there a way I can place the tick marks and values of the secondary y-axis on the left side immediately next to the existing y-axis such as below ?</p>

<p><a href=""https://i.stack.imgur.com/89dIw.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/89dIw.png"" alt=""enter image description here""></a></p>
"
"60480732","<p>Each line of data you read from the file already has a newline character at the end of it. If you append something to the line, it will go after the newline, and therefore appear on the next line.</p>

<p><a href=""https://stackoverflow.com/questions/60480613/mysterious-new-line-character-when-writing-to-a-text-file#comment106994109_60480613"">Source</a></p>
","0","","0","10360","1639","11617","4786","60480613","60480732","<pre><code>def addCourse(studentId,courseAdd): #Registers the student's id to a class they input
    infile = open('student_database.txt','r')
    data = infile.readlines()
    outfile = open('student_database.txt','w')
    for line in data:
        if studentId+"" "" in line:
            line = line+"" ""+courseAdd
        outfile.write(line) #We rewrite all lines to the file whether they where modified or not
    infile.close()
    outfile.close()
</code></pre>

<p>This is a function that should add something like ""course4"" to the end of the first line of a text file. It should look something like this if the studentId in this instance is studentID</p>

<pre><code>studentID course course2 course3 course4
studentID2 course course2 course3
</code></pre>

<p>however after the code runs it ends up looking like this</p>

<pre><code>studentID course course2 course3
 course4studentID2 course course2 course3
</code></pre>

<p>Why is <code>course4</code> added to the wrong line?</p>
"
"60537191","<p>Here's a temporary hack that I found:<br>
I changed line 753 in djongo/sql2mongo/query.py from this:</p>

<pre class=""lang-py prettyprint-override""><code>        self.parse()
</code></pre>

<p>to this:</p>

<pre class=""lang-py prettyprint-override""><code>        try:
            self.parse()
        except:
            if (self._sql.strip().endswith(""subquery"")):
                self._sql = self._sql.strip()[:-8]
</code></pre>
","1","","1","147","5","0","14","60480692","60537191","<p>An sql decode error is raised whenever I filter the groups in the admin module. I have made no modification to the admin interface or models regarding users or groups, except for a few one-to-one relationships with the user model. The error is only raised when filtering groups.<br>
Is there any way to prevent this error from being raised?  </p>

<p>The error is as is:</p>

<pre><code>Environment:


Request Method: GET
Request URL: http://127.0.0.1:8000/admin/auth/user/?groups__id__exact=1

Django Version: 2.2.10
Python Version: 3.8.1
Installed Applications:
['game.apps.GameConfig',
 'user.apps.UserConfig',
 'django.contrib.admin',
 'django.contrib.auth',
 'django.contrib.contenttypes',
 'django.contrib.sessions',
 'django.contrib.messages',
 'django.contrib.staticfiles']
Installed Middleware:
['django.middleware.security.SecurityMiddleware',
 'django.contrib.sessions.middleware.SessionMiddleware',
 'django.middleware.common.CommonMiddleware',
 'django.middleware.csrf.CsrfViewMiddleware',
 'django.contrib.auth.middleware.AuthenticationMiddleware',
 'django.contrib.messages.middleware.MessageMiddleware',
 'django.middleware.clickjacking.XFrameOptionsMiddleware']



Traceback:

File ""/Users/jayjay/anaconda3/envs/djongo/lib/python3.8/site-packages/djongo/sql2mongo/query.py"" in parse
  824.                 return handler(self, statement)

File ""/Users/jayjay/anaconda3/envs/djongo/lib/python3.8/site-packages/djongo/sql2mongo/query.py"" in _select
  963.         self._query = SelectQuery(self.db, self.connection_properties, sm, self._params)

File ""/Users/jayjay/anaconda3/envs/djongo/lib/python3.8/site-packages/djongo/sql2mongo/query.py"" in __init__
  111.         super().__init__(*args)

File ""/Users/jayjay/anaconda3/envs/djongo/lib/python3.8/site-packages/djongo/sql2mongo/query.py"" in __init__
  72.         self.parse()

File ""/Users/jayjay/anaconda3/envs/djongo/lib/python3.8/site-packages/djongo/sql2mongo/query.py"" in parse
  119.                 c = self.selected_columns = ColumnSelectConverter(self, tok_id)

File ""/Users/jayjay/anaconda3/envs/djongo/lib/python3.8/site-packages/djongo/sql2mongo/converters.py"" in __init__
  44.         super().__init__(query_ref, begin_id)

File ""/Users/jayjay/anaconda3/envs/djongo/lib/python3.8/site-packages/djongo/sql2mongo/converters.py"" in __init__
  24.         self.parse()

File ""/Users/jayjay/anaconda3/envs/djongo/lib/python3.8/site-packages/djongo/sql2mongo/converters.py"" in parse
  63.             raise SQLDecodeError

The above exception () was the direct cause of the following exception:

File ""/Users/jayjay/anaconda3/envs/djongo/lib/python3.8/site-packages/django/core/handlers/exception.py"" in inner
  34.             response = get_response(request)

File ""/Users/jayjay/anaconda3/envs/djongo/lib/python3.8/site-packages/django/core/handlers/base.py"" in _get_response
  115.                 response = self.process_exception_by_middleware(e, request)

File ""/Users/jayjay/anaconda3/envs/djongo/lib/python3.8/site-packages/django/core/handlers/base.py"" in _get_response
  113.                 response = wrapped_callback(request, *callback_args, **callback_kwargs)

File ""/Users/jayjay/anaconda3/envs/djongo/lib/python3.8/site-packages/django/contrib/admin/options.py"" in wrapper
  606.                 return self.admin_site.admin_view(view)(*args, **kwargs)

File ""/Users/jayjay/anaconda3/envs/djongo/lib/python3.8/site-packages/django/utils/decorators.py"" in _wrapped_view
  142.                     response = view_func(request, *args, **kwargs)

File ""/Users/jayjay/anaconda3/envs/djongo/lib/python3.8/site-packages/django/views/decorators/cache.py"" in _wrapped_view_func
  44.         response = view_func(request, *args, **kwargs)

File ""/Users/jayjay/anaconda3/envs/djongo/lib/python3.8/site-packages/django/contrib/admin/sites.py"" in inner
  223.             return view(request, *args, **kwargs)

File ""/Users/jayjay/anaconda3/envs/djongo/lib/python3.8/site-packages/django/utils/decorators.py"" in _wrapper
  45.         return bound_method(*args, **kwargs)

File ""/Users/jayjay/anaconda3/envs/djongo/lib/python3.8/site-packages/django/utils/decorators.py"" in _wrapped_view
  142.                     response = view_func(request, *args, **kwargs)

File ""/Users/jayjay/anaconda3/envs/djongo/lib/python3.8/site-packages/django/contrib/admin/options.py"" in changelist_view
  1685.             cl = self.get_changelist_instance(request)

File ""/Users/jayjay/anaconda3/envs/djongo/lib/python3.8/site-packages/django/contrib/admin/options.py"" in get_changelist_instance
  731.         return ChangeList(

File ""/Users/jayjay/anaconda3/envs/djongo/lib/python3.8/site-packages/django/contrib/admin/views/main.py"" in __init__
  82.         self.get_results(request)

File ""/Users/jayjay/anaconda3/envs/djongo/lib/python3.8/site-packages/django/contrib/admin/views/main.py"" in get_results
  210.         result_count = paginator.count

File ""/Users/jayjay/anaconda3/envs/djongo/lib/python3.8/site-packages/django/utils/functional.py"" in __get__
  80.         res = instance.__dict__[self.name] = self.func(instance)

File ""/Users/jayjay/anaconda3/envs/djongo/lib/python3.8/site-packages/django/core/paginator.py"" in count
  91.             return c()

File ""/Users/jayjay/anaconda3/envs/djongo/lib/python3.8/site-packages/django/db/models/query.py"" in count
  392.         return self.query.get_count(using=self.db)

File ""/Users/jayjay/anaconda3/envs/djongo/lib/python3.8/site-packages/django/db/models/sql/query.py"" in get_count
  504.         number = obj.get_aggregation(using, ['__count'])['__count']

File ""/Users/jayjay/anaconda3/envs/djongo/lib/python3.8/site-packages/django/db/models/sql/query.py"" in get_aggregation
  489.         result = compiler.execute_sql(SINGLE)

File ""/Users/jayjay/anaconda3/envs/djongo/lib/python3.8/site-packages/django/db/models/sql/compiler.py"" in execute_sql
  1133.             cursor.execute(sql, params)

File ""/Users/jayjay/anaconda3/envs/djongo/lib/python3.8/site-packages/django/db/backends/utils.py"" in execute
  99.             return super().execute(sql, params)

File ""/Users/jayjay/anaconda3/envs/djongo/lib/python3.8/site-packages/django/db/backends/utils.py"" in execute
  67.         return self._execute_with_wrappers(sql, params, many=False, executor=self._execute)

File ""/Users/jayjay/anaconda3/envs/djongo/lib/python3.8/site-packages/django/db/backends/utils.py"" in _execute_with_wrappers
  76.         return executor(sql, params, many, context)

File ""/Users/jayjay/anaconda3/envs/djongo/lib/python3.8/site-packages/django/db/backends/utils.py"" in _execute
  84.                 return self.cursor.execute(sql, params)

File ""/Users/jayjay/anaconda3/envs/djongo/lib/python3.8/site-packages/djongo/cursor.py"" in execute
  48.         self.result = Result(

File ""/Users/jayjay/anaconda3/envs/djongo/lib/python3.8/site-packages/djongo/sql2mongo/query.py"" in __init__
  753.         self.parse()

File ""/Users/jayjay/anaconda3/envs/djongo/lib/python3.8/site-packages/djongo/sql2mongo/query.py"" in parse
  846.                 raise exe from e

Exception Type: SQLDecodeError at /admin/auth/user/
Exception Value: FAILED SQL: SELECT COUNT(*) FROM (SELECT DISTINCT ""auth_user"".""id"" AS Col1, ""auth_user"".""password"" AS Col2, ""auth_user"".""last_login"" AS Col3, ""auth_user"".""is_superuser"" AS Col4, ""auth_user"".""username"" AS Col5, ""auth_user"".""first_name"" AS Col6, ""auth_user"".""last_name"" AS Col7, ""auth_user"".""email"" AS Col8, ""auth_user"".""is_staff"" AS Col9, ""auth_user"".""is_active"" AS Col10, ""auth_user"".""date_joined"" AS Col11 FROM ""auth_user"" INNER JOIN ""auth_user_groups"" ON (""auth_user"".""id"" = ""auth_user_groups"".""user_id"") WHERE ""auth_user_groups"".""group_id"" = %(0)s) subquery
Params: (1,)
Version: 1.3.1

</code></pre>

<p>Here is the output of pip freeze:</p>

<pre><code>certifi==2019.11.28
dataclasses==0.6
Django==2.2.10
django-jsoneditor==0.1.5
djongo==1.3.1
jsonfield==3.1.0
packaging==20.1
pymongo==3.10.1
pyparsing==2.4.6
python-dateutil==2.8.1
pytz==2019.3
six==1.14.0
sqlparse==0.2.4
</code></pre>
"
"60481078","<p>Easiest way is to use ImageDataGenerator.flow from directory. Documentation is 
at <a href=""https://keras.io/preprocessing/image/"" rel=""nofollow noreferrer"">https://keras.io/preprocessing/image/</a>. images will be an array of shape (batch_size, 200, 200, 3)
Note: each time you run this it will put batch_size more images in the 
save_to_dir so you may not want to include that parameter.
You can access the individual images as img1=images[0], img2=images[1] etc
Set up your generator as follows    </p>

<pre><code>datagen = ImageDataGenerator(rotation_range = 30, width_shift_range = 0.2,
                             height_shift_range = 0.2,
                             shear_range = 0.2, 
                             zoom_range = 0.2,
                             rescale=1/255,
                             horizontal_flip = True,
                             fill_mode = ""nearest"")
data=datagen.flow_from_directory(your_dir, target_size=(200, 200),
                                 batch_size=your_file_count, shuffle=False,
                                 save_to_dir=your_save_dir,save_format='png',
                                 interpolation='nearest')
images,labels=data.next()

</code></pre>
","4","2020-03-02 03:52:34","0","3888","52","11","321","60480693","60481078","<p>How do I apply Keras Image Augmentation for multiple images stored in a folder ?</p>

<p>P.S: I tried the below code for a single image and it worked fine.</p>

<p>Could someone help me to solve for multiple images ??</p>

<pre><code>enter code here

from keras.preprocessing import image

import matplotlib.pyplot as plt
import cv2

from keras.preprocessing.image import ImageDataGenerator

datagen = ImageDataGenerator(
            rotation_range = 30, 
            width_shift_range = 0.2,
            height_shift_range = 0.2, 
            shear_range = 0.2, 
            zoom_range = 0.2,
            horizontal_flip = 0.2,
            fill_mode = ""nearest"")

for img in glob.glob(""Images/*/*.jpg""):
    cv_img = cv2.imread(img)
    cv_resize = cv2.resize(cv_img,(200,200))
    cv_norm_img = cv_resize/255.0
    break


cv_norm_img = np.array(cv_norm_img)

input_batch = cv_norm_img.reshape((1,*cv_norm_img.shape))

i = 0

for output_batch in datagen.flow(input_batch,batch_size=1):
    plt.figure()
    imgplot = plt.imshow(image.img_to_array(output_batch[0]))
    i+=1
    if i==10:
        break
    plt.axis('off')
    plt.show
</code></pre>
"
"60481033","<p>If you check the <a href=""https://github.com/scikit-learn/scikit-learn/blob/b194674c4/sklearn/metrics/_plot/confusion_matrix.py#L119"" rel=""nofollow noreferrer"">source</a> for <code>sklearn.metrics.plot_confusion_matrix</code>, you can see how the data is processed to create the plot. Then you can reuse the constructor <code>ConfusionMatrixDisplay</code> and plot your own confusion matrix.</p>

<pre><code>import matplotlib.pyplot as plt
from sklearn.metrics import ConfusionMatrixDisplay

cm = [0.612, 0.388, 0.228, 0.772] # your confusion matrix
ls = [0, 1] # your y labels
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=ls)
disp.plot(include_values=include_values, cmap=cmap, ax=ax, xticks_rotation=xticks_rotation)
plt.show()
</code></pre>
","0","","3","2342","130","56","174","60480777","60481033","<p>How can I plot in Python a Confusion Matrix similar do the one shown <a href=""https://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html"" rel=""nofollow noreferrer"">here</a> for already given values of the Confusion Matrix?</p>
<p>In the code they use the method <code>sklearn.metrics.plot_confusion_matrix</code> which computes the Confusion Matrix based on the ground truth and the predictions.</p>
<p>But in my case, I already have calculated my Confusion Matrix. So for example, my Confusion Matrix is (values in percentages):</p>
<pre><code>[[0.612, 0.388]
 [0.228, 0.772]]
</code></pre>
"
"65865549","<p>I saw that someone already answered this question, but I'm adding a new one that can be useful for the author or even for other users.</p>
<p>It is possible to <strong>plot</strong> in <strong>Python</strong> an already <strong>Confusion Matrix</strong> computed through <code>mlxtend</code> package:</p>
<blockquote>
<p>Mlxtend (machine learning extensions) is a Python library of useful
tools for the day-to-day data science tasks.</p>
</blockquote>
<p><strong>Snippet code:</strong></p>
<pre><code># Imports
from mlxtend.plotting import plot_confusion_matrix
import matplotlib.pyplot as plt
import numpy as np

# Your Confusion Matrix
cm = np.array([[0.612, 0.388],
               [0.228, 0.772]])

# Classes
classes = ['class A', 'class B']

figure, ax = plot_confusion_matrix(conf_mat = cm,
                                   class_names = classes,
                                   show_absolute = False,
                                   show_normed = True,
                                   colorbar = True)

plt.show()
</code></pre>
<p><strong>The output will be:</strong></p>
<p><a href=""https://i.stack.imgur.com/b2HL4.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/b2HL4.png"" alt=""enter image description here"" /></a></p>
","0","","1","540","907","1","230","60480777","60481033","<p>How can I plot in Python a Confusion Matrix similar do the one shown <a href=""https://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html"" rel=""nofollow noreferrer"">here</a> for already given values of the Confusion Matrix?</p>
<p>In the code they use the method <code>sklearn.metrics.plot_confusion_matrix</code> which computes the Confusion Matrix based on the ground truth and the predictions.</p>
<p>But in my case, I already have calculated my Confusion Matrix. So for example, my Confusion Matrix is (values in percentages):</p>
<pre><code>[[0.612, 0.388]
 [0.228, 0.772]]
</code></pre>
"
"60481442","<p><a href=""https://matplotlib.org/tutorials/introductory/customizing.html#matplotlibrc-sample"" rel=""nofollow noreferrer""><code>matplotlib.rcParams</code></a> contains the plot parameters for <code>matplotlib</code>, stored in <em>matplotlibrc</em> file. You can change the parameters either directly in the matplotlibrc file (as explained <a href=""https://matplotlib.org/tutorials/introductory/customizing.html#the-matplotlibrc-file"" rel=""nofollow noreferrer"">here</a>), or in your code, just before plotting. Here is an example to change the figure background color as you requested:</p>

<pre><code>import matplotlib as mpl
import matplotlib.plot as plt

plt.plot(play_num_2019[g], home_prob_2019[g], color = getColor(home_teams_2019[g]))
plt.plot(play_num_2019[g], away_prob_2019[g], color = getColor(away_teams_2019[g]))
plt.xlabel(""Play Number"")
plt.ylabel(""Win Probability"")
mpl.rcParams['figure.facecolor'] = 'r' # &lt;--- here is the line for changing the background to red
plt.legend([home_teams_2019[g], away_teams_2019[g]])
fig = plt.figure()
fig.patch.set_facecolor('xkcd:white')
</code></pre>

<p>If you want to change it only when the figure is saved, change the following parameter instead.</p>

<pre><code>mpl.rcParams['savefig.facecolor'] = 'r'
</code></pre>
","0","","1","2342","130","56","174","60480832","60481442","<p>I'm trying to make some plots in python 3 for a data science project, and I'm having an issue where there is no color behind the text on my axes when I save it. Here's my code with an example plot:</p>

<pre><code>plt.plot(play_num_2019[g], home_prob_2019[g], color = getColor(home_teams_2019[g]))
plt.plot(play_num_2019[g], away_prob_2019[g], color = getColor(away_teams_2019[g]))
plt.xlabel(""Play Number"")
plt.ylabel(""Win Probability"")
plt.legend([home_teams_2019[g], away_teams_2019[g]])
fig = plt.figure()
fig.patch.set_facecolor('xkcd:white')
</code></pre>

<p><a href=""https://i.stack.imgur.com/mbOIQ.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/mbOIQ.png"" alt=""Plot""></a></p>
"
"60485077","<p>If you want to set the facecolor for a figure you can either use <code>matplotlib.rcParams</code> to set the a facecolcolor globally - for all figures - or for a single figure you can specify the facecolor in calling <code>plt.savefig()</code>. If you want to set the facecolor using <code>fig.patch.set_facecolor()</code> you can then simply use <code>fig.get_facecolor()</code> in <code>savefig()</code>. For example:</p>

<pre class=""lang-py prettyprint-override""><code>import matplotlib.pyplot as plt
import numpy as np

x = np.linspace(0, np.pi*4, 100)

fig = plt.figure()
plt.plot(x, np.sin(x))
plt.plot(x, np.cos(np.sin(x)))
fig.patch.set_facecolor((0.68, 0.78, 0.91))

plt.savefig('/path/to/output.png', facecolor = fig.get_facecolor())
</code></pre>

<p>Output</p>

<p><a href=""https://i.stack.imgur.com/8pKZP.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/8pKZP.png"" alt=""enter image description here""></a></p>

<p>If you want this color applied behind the plot area as well then you must pass <code>transparent=True</code> in <code>plt.savefig()</code> which will give you</p>

<p><a href=""https://i.stack.imgur.com/hpCUr.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/hpCUr.png"" alt=""enter image description here""></a></p>

<p>Or - as I prefer - you can set the alpha of the axes patch like so</p>

<pre class=""lang-py prettyprint-override""><code>plt.gca().patch.set_alpha(0.7)
</code></pre>

<p>or the like. This will produce</p>

<p><a href=""https://i.stack.imgur.com/otAcb.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/otAcb.png"" alt=""enter image description here""></a></p>

<hr>

<p><strong>Note</strong> &ensp; - &ensp;  Setting the facecolor to <code>'xkcd:white'</code> won't have any effect because the corresponding RGB values are <code>(1.0, 1.0, 1.0)</code> - identical to the default facecolor.</p>
","0","2020-03-02 08:48:41","0","8010","2376","172","1219","60480832","60481442","<p>I'm trying to make some plots in python 3 for a data science project, and I'm having an issue where there is no color behind the text on my axes when I save it. Here's my code with an example plot:</p>

<pre><code>plt.plot(play_num_2019[g], home_prob_2019[g], color = getColor(home_teams_2019[g]))
plt.plot(play_num_2019[g], away_prob_2019[g], color = getColor(away_teams_2019[g]))
plt.xlabel(""Play Number"")
plt.ylabel(""Win Probability"")
plt.legend([home_teams_2019[g], away_teams_2019[g]])
fig = plt.figure()
fig.patch.set_facecolor('xkcd:white')
</code></pre>

<p><a href=""https://i.stack.imgur.com/mbOIQ.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/mbOIQ.png"" alt=""Plot""></a></p>
"
"60491341","<p>In Python 2.7 (which has been deprecated since 2015 and has officially reached End of Life per Januari 1, 2020), <a href=""https://docs.python.org/2.7/reference/simple_stmts.html#print"" rel=""nofollow noreferrer""><code>print</code> used to be a statement</a>, just like a couple of other keywords such as <code>break</code> and <code>continue</code>. In newer versions of Python since 3.0 onwards, <a href=""https://docs.python.org/3/whatsnew/3.0.html#print-is-a-function"" rel=""nofollow noreferrer""><code>print</code> is a function</a>, and that is why you may see examples of your callback that use <code>print</code> itself.</p>

<p>So you get a SyntaxError because you are applying a modern construction (post-2015 v.3) to an old and officially obsolete version of Python.</p>

<p>If you want to keep on using 2.7, you can work around it by creating a wrapper <em>function</em> for just the <code>print</code> statement:</p>

<pre class=""lang-py prettyprint-override""><code>def my_print (text):
  print text

def event_loop (handle_key):
  handle_key('hello!')

event_loop(my_print)
</code></pre>

<p>where replacing the last line with your original line</p>

<pre class=""lang-py prettyprint-override""><code>event_loop(print)
</code></pre>

<p>will show that SyntaxError again. But it would be better to upgrade.</p>
","1","2020-03-02 18:51:30","0","20908","7958","28090","11460","60480901","60491341","<p>I'm having a trouble with running script, where <em>print</em> is a callback function to event loop</p>

<pre><code>from pygame.locals import KEYDOWN
import pygame


def event_loop(handle_key, delay=10):
        """"""Processes events and updates callbacks.""""""
        while True:
            pygame.event.pump()
            event = pygame.event.poll()
            if event.type == KEYDOWN:
                handle_key(event.key)
            pygame.time.delay(delay)


if __name__ == '__main__':
        pygame.init()
        pygame.display.set_mode((640, 400))
        event_loop(print)
</code></pre>

<p>I get syntax error:</p>

<pre><code>event_loop(print)
               ^
 SyntaxError: invalid syntax
Wirman:04_scientific_method mac$ python event_loop.py
 File ""event_loop.py"", line 23
   event_loop(print)
                  ^
SyntaxError: invalid syntax
</code></pre>

<p>Any help would much appreciatedðŸ™ŒðŸ½</p>
"
"60480994","<p>The source of your problem is that the path variable you are adding to ROUTES is a reference to the same object that you are using to control the traversal.  This same object is added every time you find a destination so, when the process is over (and path is empty again), your ROUTE list contains multiple references to the (now empty) path object.</p>

<p>Your correction <code>ROUTES.append([i for i in path])</code> creates a new instance of the path variable to store in the ROUTES list.  That's why it works.</p>

<p>It is a common mistake in Python to store lists in variables assuming that you are holding a copy when in fact it is only a reference and the content may be modified by other parts of the program that change the original.</p>

<p>Note that you could also use <code>ROUTES.append(path.copy())</code> or <code>ROUTES.append(list(path))</code> or <code>ROUTES.append([*path])</code></p>
","0","2020-03-02 00:16:57","1","24359","14","17","1310","60480903","60480994","<p>I have the following recursive function - The function works well to print out all the paths of a tree/graph. But trying to add <code>ROUTES</code> as a global variable and appending to it results in a bunch of empty nested lists:
<code>[[], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [],</code>...etc</p>

<p>A better solution to using a global variable and a better solution to storing the paths is what I'm looking for and this is my function:</p>

<pre><code> def printAllPathsUtil(self, u, d, visited, path):
        # Mark the current node as visited and store in path
        visited[u] = True
        path.append(u)
        # If current vertex is same as destination, then print
        # current path[]
        if u == d:
            print(path)
            ROUTES.append(path)
        else:
            # If current vertex is not destination
            # Recur for all the vertices adjacent to this vertex
            for i in self.graph[u]:
                if visited[i] == False:
                    self.printAllPathsUtil(i, d, visited, path)
                    # Remove current vertex from path[] and mark it as unvisited

        path.pop()
        visited[u] = False
</code></pre>
"
"60499012","<p>Of the unsupported operations, itâ€™s only interrupt that you <em>should</em> want; Java has long deprecated the others as being <a href=""https://stackoverflow.com/q/16504140/8586227"">impossible to use safely in general</a>.  Since Python lacks even the generic interrupt interface (except that an interrupt produces a <code>KeyboardInterrupt</code> on the <em>main</em> thread only, which is not very useful), you have to avoid basic functions like <a href=""https://stackoverflow.com/a/49877671/8586227""><code>time.sleep</code></a> in favor of versions that also detect an inter-thread signal.  (In general, successful methods of <em>killing</em> a thread are also able to <em>control</em> it, since they involve getting the threadâ€™s attention and then having <em>it</em> exit.)</p>

<p>Details:</p>

<ul>
<li>Dropping references to a <code>Thread</code> object canâ€™t kill it: threads are the <strong>roots</strong> for garbage collection.</li>
<li><strong>All</strong> objects are shared between threads: thatâ€™s what distinguishes them from processes.  (Thatâ€™s not to say that threads typically <em>use</em> their theoretical access to a large number of objects, nor to say that they shouldnâ€™t <em>minimize</em> the number of shared objects for simplicity.)</li>
<li>Libraries that you call may or may not provide an interface to interrupt their long-running operations; for example, some will gracefully return control to you upon receipt of an â€œignoredâ€ signal like <code>SIGPIPE</code>.</li>
</ul>
","2","","0","22977","1407","171","2296","60480944","60499012","<p>In Python's documentation (v3.8.2) on threading, there is this text (ch. 17): ""Pythonâ€™s Thread class supports a subset of the behavior of Javaâ€™s Thread class; currently, there are no priorities, no thread groups, and threads cannot be destroyed, stopped, suspended, resumed, or interrupted."" I haven't been hampered by no means of prioritizing, or grouping threads, but that last bit, ""cannot be destroyed, stopped, suspended, resumed, or interrupted"" is an issue. </p>

<p>I have an application that starts one thread to post sensor-data to a queue, and another one to pull sensor data from that queue, then post it to a curses window. The trouble is, there are instances where thread pairs (they're always pairs in this case) get over-written with new threads, owing to configuration changes, etc. Until now, I have been deleting the thread objects under the foolish assumption that this action will result in the destruction of said threads. I have noticed some weird behaviour in the app, which now makes sense, as several threads are attempting to post data to the same curses window object.</p>

<p>Changing my approach, I will create several thread pairs, treat them as indestructible, update their configurations as needed... but how do I control their execution from the main thread? Is there a best practice? I'm thinking, create several pairs of template threads, start them, and use the threading.Condition() or the threading.Event() class to start/stop the code inside each thread running, but how do I pass information about what to do to each running thread? Since I have not done this, I'm learning mostly by the time-honoured tradition of rtfm; but, examples and a little guidance will help. Do I use threading.Event.is_set()? If so, how do I set/clear the internal flag from outside the thread? Are threading.Event() objects global, and hence visible to the threads, or do I need to make the Event() object one of the arguments of the function executed by the thread, then let the thread function evaluate the Event() and set/clear it in the main thread?</p>
"