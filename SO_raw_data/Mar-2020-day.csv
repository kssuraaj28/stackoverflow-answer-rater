Id,Body,CommentCount,Score,Reputation,UpVotes,DownVotes,Views,QId,QAcceptedAnswerId
"60473588","<blockquote>
  <p>[...] after dealing with all mobs in level 2 it won't load level 3. instead it restarts in level 2. I think my mistake is in the update section of the code, [...]</p>
</blockquote>

<p>Of course. See the following liens of code:</p>

<blockquote>
  <pre class=""lang-py prettyprint-override""><code>class Game:
   # [...]

   def update(self):
       # Game over?
       if len(self.mobs) == 0:
           self.new_2()
           if len(self.mobs) == 0:
               self.new_3()
</code></pre>
</blockquote>

<p><code>self.new_3()</code> will never be invoked. If <code>len(self.mobs) == 0</code> is fulfilled, the <code>self.new_2()</code> is executed and <code>self.mobs</code> is initialized.</p>

<p>Add the number of the level (<code>self.current_level</code>) to the class <code>Game</code>. Increment the  level in <code>update</code> and invoke either <code>new_2</code> or <code>new_3</code> dependent on <code>self.current_level</code>. e.g.:</p>

<pre class=""lang-py prettyprint-override""><code>class Game:
    def __init__(self):
        # [...]
        self.current_level = 1

    # [...]

    def update(self):
        # Game over?
        if len(self.mobs) == 0:
            self.current_level += 1
            if self.current_level == 2:
                self.new_2()
            else:
                self.new_3()
</code></pre>

<p>With this approach it is easy to add and load further levels.</p>
","3","0","136140","16645","626","8521","60470790","60473588"
"60470950","<p>You have to use <code>self.number</code> to have access to numbers in <code>update</code>. And you should use <code>self</code> instead of <code>number</code> in <code>def update(number)</code></p>

<p>Also to create new list you have to create empty list before <code>for</code>-loop and <code>append(newnum)</code> to this list. And later you can <code>return</code> this list to get it as  <code>b = ...</code></p>

<pre><code>class Fraction():

    def __init__(self):
        shape = int(input(""How many sides does the shape have? : ""))

        if shape &lt;= 0: #doesnt work with negatives?
            print(""Please make a valid choice (positive integers only)"")
            shape = int(input(""How many sides does the shape have? : ""))

        self.numbers = []
        for i in range(shape):
            n = random.randint(1, 100)
            self.numbers.append(n)
        print(""Your numbers are:"", self.numbers)

    def update(self):
        newlist = []

        long = len(self.numbers)
        for i in range(long-1): # it has to be long-1 because later `long-1+1`will give `long` 
            newnum = self.numbers[i] - self.numbers[i+1]
            newlist.append(newnum)

        return newlist

import random

def main():
    a = Fraction()
    b = a.update()
    print(b)
main()
</code></pre>

<hr>

<p><strong>BTW:</strong> it could be good to use <code>input()</code> outside class and run it as <code>Fraction(shape)</code> so it could run with values from <code>input()</code> or file or hardcoded varaible. It is helps to test code again and again with the same values.</p>
","2","0","91473","3793","3687","13493","60470809","60470950"
"60470978","<p>You can run a subprocess to source the results and print the <code>os.environ</code>  back to the current python process. For example:</p>

<pre><code>os.environ=ast.literal_eval(subprocess.check_output(
  'source credentials.txt &amp;&amp; python -c ""import os;print os.environ""', shell=True)
)
</code></pre>

<p>Answer inspired by <a href=""https://stackoverflow.com/a/7198338/651174"">this answer</a>.</p>
","0","-1","95528","2897","13","6872","60470924","60471160"
"60471160","<p>Take a look at this library:  <a href=""https://pypi.org/project/python-dotenv/"" rel=""nofollow noreferrer"">https://pypi.org/project/python-dotenv/</a> </p>

<p>I've used it before and it's simple and does the job.Instead of 'credentials.txt' you put the key-value pairs in '.env' file and load it during program start using a single 'load' call.</p>

<p>Here is somple code:</p>

<pre><code>import os
from pathlib import Path
from dotenv import load_dotenv, find_dotenv

# write some sample contents in the current dir
Path.cwd().joinpath("".env"").write_text(""USERNAME=My user name\nPASSWORD=MyCust0mS3cr3tPAsw00d"")

# loads from .env file in CWD
load_dotenv(find_dotenv())  

# here is the magic:
print(os.environ[""PASSWORD""])
</code></pre>
","1","0","427","13","0","32","60470924","60471160"
"60477028","<p>The correct answer turned out to be that the name (master) node of the cluster had firewall access to the MongoDB instance, but the other nodes in the cluster did not.  So apparently MongoDB queries are distributed on the cluster as well.  Once I added the slave nodes to the Security Group for the MongoDB server as allowed incoming connections, the cluster mode processing began working.</p>
","0","0","23","48","0","10","60470949","60477028"
"60473043","<p>You can use <code>panda.DataFrame.merge</code> to merge them.</p>

<p>If you just want to merge two lists:</p>

<pre class=""lang-py prettyprint-override""><code>def merge_probability(f3, f4):
    df0 = pd.DataFrame(f3[0], columns=f3[1] + [""probability0""])
    df1 = pd.DataFrame(f4[0], columns=f4[1] + [""probability1""])

    df = df0.merge(df1)

    df[""probability""] = df[""probability0""] * df[""probability1""]
    df = df.drop([""probability0"", ""probability1""], axis=1)
    return [df.values.tolist(), f4[1]]
</code></pre>

<p>Or if more lists need to be merged together:</p>

<pre><code>def merge_probabilitys(*fs):
    size = len(fs)
    dfs = [
        pd.DataFrame(fs[i][0], columns=fs[i][1] + [""probability"" + str(i)])
        for i in range(size)
    ]

    df_res = dfs[0]
    for df in dfs[1:]:
        df_res = df_res.merge(df)

    df_res[""probability""] = 1
    for i in range(size):
        df_res[""probability""] *= df_res[""probability"" + str(i)]

    df_res = df_res.drop([""probability"" + str(i) for i in range(size)], axis=1)
    return [df_res.values.tolist(), list(df_res.columns)[:-1]]
</code></pre>
","0","1","331","9","0","13","60470963","60473043"
"60471097","<p>In the first image, you don't have your virtual environment activated. Because you only have <code>python-nmap</code> installed in your virtual environment python, your system-wide python installation can't find it.</p>

<p>In the second image, you do have the virtual environment activated, which is why it says python-nmap is installed.</p>

<p>To activate your virtual environment on Windows, you need to execute <code>\path\to\your\venv\bin\activate.exe</code>. Then run your command and it should work.</p>

<p>Alternatively, you could just run <code>pip install python-nmap</code> to install it on your system level python installation.</p>
","0","2","1337","2625","1","61","60470971","60471097"
"60471100","<p>Use <a href=""https://docs.scipy.org/doc/numpy/reference/generated/numpy.where.html"" rel=""nofollow noreferrer""><code>numpy.where</code></a> with <a href=""http://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.fillna.html"" rel=""nofollow noreferrer""><code>Series.fillna</code></a>:</p>

<pre><code>enr['gender'] = np.where(enr['home_work'] &gt; 9,  
                         enr['gender'].fillna('m'),
                         enr['gender'].fillna('f'))
</code></pre>

<p>Or filter separately by 2 masks:</p>

<pre><code>m = enr['gender'].isna()
enr.loc[m, 'gender'] = np.where(enr['home_work'] &gt; 9,  'm',  'f')[m]
</code></pre>

<hr>

<pre><code>print (enr)
   name_id enrollment_term  gpa_term  dog_owner    salary  home_work gender
0     1254     spring 2018      2.93          0   50657.0         34      m
1     1359     spring 2018       NaN          1   90658.0         42      f
2     1254       fall 2018      1.65          1       NaN         12      f
3     1296     spring 2018      4.00          1  104352.0          9      f
4     1353     spring 2018      3.95          1       NaN          8      f
5     2656       fall 2020      2.92          0  102043.0         27      m
</code></pre>

<p>EDIT:</p>

<pre><code>m = enr['gender'].isna() &amp; enr['home_work'].notna()
enr.loc[m, 'gender'] = np.where(enr['home_work'] &gt;= 0.5, 0, 1)[m]
print (enr)
   name_id enrollment_term  gpa_term  dog_owner    salary  home_work  gender
0     1254     spring 2018      2.93          0   50657.0        NaN     0.0
1     1359     spring 2018       NaN          1   90658.0        NaN     1.0
2     1254       fall 2018      1.65          1       NaN       0.70     1.0
3     1296     spring 2018      4.00          1  104352.0       0.30     1.0
4     1353     spring 2018      3.95          1       NaN       0.64     0.0
5     2656       fall 2020      2.92          0  102043.0       0.49     1.0
</code></pre>
","13","3","615041","23439","1483","126104","60471025","60471100"
"60471550","<p>Let us try <code>map</code> the value and <code>where</code> </p>

<pre><code>df.gender=df.gender.where(df.gender.notna(),df.home_work.gt(9).map({True:'m',False:'f'})) 


df
   name_id enrollment_term  gpa_term  dog_owner    salary  home_work gender
0     1254     spring 2018      2.93          0   50657.0       34.0      m
1     1359     spring 2018       NaN          1   90658.0        NaN      f
2     1254       fall 2018      1.65          1       NaN       12.0      f
3     1296     spring 2018      4.00          1  104352.0        9.0      f
4     1353     spring 2018      3.95          1       NaN        8.0      f
5     2656       fall 2020      2.92          0  102043.0       27.0      m
</code></pre>
","0","3","252249","5881","962","22297","60471025","60471100"
"60476029","<p>The response is in that format because you are explicitly wrapping it in a JSON object with a <code>body</code> property. Change <code>return {'body' : data}</code> to <code>return data</code>.</p>
","0","2","137251","10558","9025","8564","60471046","60476029"
"60471088","<p>Inside your for loop put in a line to <code>print(item)</code>
You’ll see it is the value in wrongMark, not the index. 
You probably want</p>

<pre><code>For index in range(len(wrongMark)):
</code></pre>
","0","2","1323","92","59","106","60471060","60471088"
"60471093","<p>The error is that you are using <code>for item in wrongMark</code>. In the first iteration, the loop will assign item with value 75 and the list <code>adFactor</code> doesn't have 75 items ;)</p>

<p>One way to solve this is just changing the loop to:</p>

<pre><code>for item in range(len(wrongMark)):
    results = wrongMark[item]*adFactor[item]
    newMark.append(results)
</code></pre>
","0","0","125","730","0","16","60471060","60471088"
"60471128","<p>The problem is at this row:</p>

<pre><code>   results = item*adFactor[item]
</code></pre>

<p>For the first iteration of the for loop, you are trying to access the 72th cell in the list adFactor.</p>

<p>That is why you get ""list index out of range""</p>
","0","0","101","7","0","1","60471060","60471088"
"60471141","<p>you need to use index while iterating. You are using value which is 72 for first iteration. That is why it out of range error. Use something like :        for idx in range(len(wrongMark)):
    results = wrongMark[idx]*adFactor[idx]
    newMark.append(results)</p>
","0","0","386","10","2","32","60471060","60471088"
"60471182","<p>The error is In the code: results = item*adFactor[item]
It is easier to note the error when you imagine the first iteration of your loop to be : result = 72 * adFactor[72]
You get an  out of index  error because the list adFactor doesnt have a  72nd term.</p>
","0","0","23","5","0","8","60471060","60471088"
"60472369","<p>In <code>BaggingClassifier</code> you can only use base estimators that support sample weights because it relies on <a href=""https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.BaggingClassifier.html#sklearn.ensemble.BaggingClassifier.score"" rel=""nofollow noreferrer"">score</a> method, which takes in <code>sample_weight</code>param.</p>

<p>You can list all the available classifiers like:</p>

<pre><code>import inspect 
from sklearn.utils.testing import all_estimators 
for name, clf in all_estimators(type_filter='classifier'): 
    if 'sample_weight' in inspect.getargspec(clf.fit)[0]: 
        print(name) 
</code></pre>
","0","0","15516","968","609","1473","60471192","60472369"
"60471488","<p>Python logged <code>str(stdout)</code>, but <code>stdout</code> is a byte stream so you got the whole <code>bytes</code> representation starting with <code>b'</code> and backslash escaped newlines. You need to decode it first. Using the default encoding on your system should work</p>

<pre><code>&gt;&gt;&gt; import logging
&gt;&gt;&gt; logging.basicConfig()
&gt;&gt;&gt; import subprocess as subp
&gt;&gt;&gt; cmd = subp.Popen([""ls""], stdout=subp.PIPE, stderr=subp.STDOUT)
&gt;&gt;&gt; stdout, stderr = cmd.communicate()
&gt;&gt;&gt; logging.warning(stdout)
</code></pre>

<p>WARNING:root:b'a.py\nb.py\nc.py\ne.py\nf.py\ng.py\nh.py\ni.py\nj.py\nl.py\n__pycache__\n'</p>

<pre><code>&gt;&gt;&gt; logging.warning(stdout.decode())
WARNING:root:a.py
b.py
c.py
e.py
f.py
g.py
h.py
i.py
j.py
l.py
__pycache__
</code></pre>
","0","2","55035","2176","130","4224","60471200","60471488"
"60471326","<p>Is this what you're looking for?</p>

<pre><code>from random import shuffle

my_list = [1,2,3,4,5]
print (my_list)
shuffle (my_list)
print (my_list)
</code></pre>
","2","1","1349","59","3","86","60471250","60471336"
"60471336","<p>You can do that by merging the list with its reverse:</p>

<pre><code>lst = [1,2,3,4,5]

b = [c for a,b in zip(lst,reversed(lst)) for c in (a,b)][:len(lst)]

print(b) # [1, 5, 2, 4, 3]
</code></pre>
","0","2","24359","14","17","1310","60471250","60471336"
"60471370","<p>The following code gives you the expected output.</p>

<pre class=""lang-py prettyprint-override""><code>l = [1,2,3,4,5]

r = []
for i in range(len(l)):
    if i % 2 == 0:
        r.append(l[i // 2])
    else:
        r.append(l[-1 - i // 2])

print(r)  # prints [1, 5, 2, 4, 3]
</code></pre>
","1","1","590","106","10","40","60471250","60471336"
"60471385","<p><a href=""https://docs.scipy.org/doc/numpy/reference/generated/numpy.loadtxt.html"" rel=""nofollow noreferrer""><code>np.loadtxt</code></a> has supported an <code>encoding</code> argument since version 1.14.0. It allows you to manually set the encoding. Something like UTF-16 comes to mind as a possibility when the first byte is 0xFF. However the actual determination of the encoding is best made by investigating the program that created your file.</p>
","2","1","73982","12512","5089","14868","60471251","60471385"
"60478140","<ol>
<li><p>When you use <code>create_task</code> with an <code>async def</code> function, call the function normally and then pass the result to <code>create_task</code>. </p>

<pre><code>await asyncio.create_task(start_tornado())
await asyncio.create_task(display_date())
</code></pre></li>
<li><p>You don't need to use <code>create_task</code> if you're going to <code>await</code> it immediately. Use <code>create_task</code> without <code>await</code> to start tasks in the background, like <code>display_date()</code>. <code>start_tornado</code> is not a background task in this sense because it doesn't have an infinite loop, it just starts a server that is put into the background by Tornado. So I'd write it like this:</p>

<pre><code>await start_tornado()
asyncio.create_task(display_date())
</code></pre></li>
<li><p>Since Tornado 5.0, the Tornado IOLoop and asyncio event loop are integrated by default, so you only need to start one, not both. So just remove the <code>IOLoop.start()</code> call in <code>start_tornado</code>. </p></li>
<li><p><code>start_tornado</code> isn't currently doing anything asynchronous, so it could just be a normal function. But it would also be a reasonable place to add asynchronous startup logic like establishing database connections, so you can keep it as a coroutine. </p></li>
</ol>

<p>Working version of the code with my edits: <a href=""https://repl.it/@bdarnell/FarawayAdmiredConversions"" rel=""nofollow noreferrer"">https://repl.it/@bdarnell/FarawayAdmiredConversions</a></p>
","2","2","20673","55","11","2489","60471268","60478140"
"60495807","<p>Tornado might already have everything you need.</p>

<ol>
<li>Instead of using <code>await asyncio.create_task</code> you can use <code>tornado.ioloop.IOLoop.current().add_callback</code></li>
<li>Instead of <code>await asyncio.sleep(1)</code> you can use <code>yield gen.sleep(1)</code></li>
</ol>

<p>So in the end the whole code from your example could look like this:</p>

<pre><code>import datetime
import tornado.ioloop
import tornado.web
import tornado.gen as gen


class MainHandler(tornado.web.RequestHandler):
    def get(self):
        self.write(""Hello, world"")


def make_app():
    return tornado.web.Application([
        (r""/"", MainHandler),
    ])


@gen.coroutine
def display_date():
    while True:
        print(datetime.datetime.now())
        yield gen.sleep(1)


def start_tornado():
    app = make_app()
    app.listen(8888)
    tornado.ioloop.IOLoop.current().add_callback(display_date)
    tornado.ioloop.IOLoop.current().start()


start_tornado()
</code></pre>
","0","-1","1250","210","8","169","60471268","60478140"
"60471360","<p>Because python 2 is no longer supported,
Pip2(invoked by either <code>pip</code> or <code>python -m pip</code>) is complaining that you should use python 3. The package manager for python 3 is called pip3(invoked by <code>pip3</code> or <code>python3 -m pip</code>).</p>

<p>Your pip3 is currently the latest version and you dont need to take any action to upgrade pip3.</p>

<p>If you want to use PIL in python then i recommend you <a href=""https://pillow.readthedocs.io/en/stable/installation.html"" rel=""nofollow noreferrer"">install pillow</a>. Pillow is the PIL of python 3.
You should be able to install pillow with <code>pip3 install Pillow</code>. Pillow supercedes PIL. (unless you specifically want to use PIL with python 2)</p>

<p>Perhaps you want to configure your terminal to alias pip to pip3 so you wont call pip2 by mistake.</p>
","0","2","1024","81","14","64","60471280","60471360"
"60471415","<p>It actually catches it, but your 'except' block generates anoter one.</p>
","4","2","427","13","0","32","60471366","60471415"
"60471574","<p>I haven't used BeatifulSoup before, but try using urlopen instead. This will store the webpage as a string, which you can use to find the email.</p>

<pre class=""lang-py prettyprint-override""><code>from urllib.request import urlopen

try:
    response = urlopen(""http://www.traiteurcheminfaisant.com"")
    html = response.read().decode(encoding = ""UTF8"", errors='ignore')
    print(html.find(""traiteurcheminfaisant@hotmail.com""))
except:
    print(""Cannot open webpage"")


</code></pre>
","0","0","68","2","0","9","60471420","60471709"
"60471709","<p>A quick glance at the website that you're attempting to scrape from makes me suspect that not all content is loaded when sending a simple get request via the requests module. In other words, it seems likely that some components on the site, such as the footer you mentioned, are being loaded asynchronously with Javascript.</p>

<p>If that is the case, you'll probably want to use some sort of automation tool to navigate to the page, wait for it to load and then parse the fully loaded source code. For this, the most common tool would be Selenium. It can be a bit tricky to set up the first time since you'll also need to install a separate webdriver for whatever browser you'd like to use. That said, the last time I set this up it was pretty easy. Here's a rough example of what this might look like for you (once you've got Selenium properly set up):</p>

<pre><code>from bs4 import BeautifulSoup
from selenium import webdriver

import time

driver = webdriver.Firefox(executable_path='/your/path/to/geckodriver')
driver.get('http://www.traiteurcheminfaisant.com')
time.sleep(2)

source = driver.page_source
soup = BeautifulSoup(source, 'html.parser')

full_text = soup.find_all()

print(full_text)
</code></pre>
","0","3","138","45","0","13","60471420","60471709"
"60513800","<p>Most likely, the key is not wrapped correctly. Can you please try the following commands to see that the decryption of the wrapped key generates the right output?</p>

<pre><code>cat wrapped_key.txt | base64 -d &gt; ciphertext.txt
</code></pre>

<pre><code>gcloud kms decrypt --location global --keyring &lt;key-ring-name&gt; --key &lt;key-name&gt; --plaintext-file unwrapped_secret.txt --ciphertext-file ciphertext.txt
</code></pre>

<pre><code>stat --printf=""%s\n"" unwrapped_secret.txt
</code></pre>

<p>Here are the steps to generate the KMS wrapped key for use with Google Cloud DLP API.</p>

<p><strong>Basic Terminology:</strong></p>

<p>DEK: Key to be wrapped.</p>

<p>KEK: Key with which DEK would be wrapped. This key does not leave Google Cloud KMS. </p>

<p>Go to your Google cloud console project > cryptographic keys and create a keyring and a KEK (if not already done so).</p>

<p><strong>Commands</strong></p>

<p>In order to execute the following commands, Google Cloud Shell might be the best option as it takes care of gcloud credential setup for you.</p>

<p>Step 1. Generate a 32 Byte random value. This would be your DEK.</p>

<pre><code>openssl rand 32 &gt; secret.txt
</code></pre>

<p>Step 2. Encrypt using Cloud KMS</p>

<pre><code>gcloud kms encrypt --location global --keyring &lt;key-ring-name&gt; --key \
&lt;key-name&gt; --plaintext-file secret.txt --ciphertext-file \
mysecret.txt.encrypted
</code></pre>

<p>Step 3: Convert to base64</p>

<pre><code>base64 mysecret.txt.encrypted
</code></pre>

<p>Step 4: Use this generated value in your request to Google Cloud DLP API.</p>

<p>Let me know if this doesn't help. If you could provide details on how you are wrapping the key, we could triage this further.</p>
","1","5","66","0","0","6","60471428","60513800"
"60482141","<p>In the CArchive step PyInstaller tries to bundle the Python DLLs. These names are set dependent on the version, and PyInstaller will return an empty string if it's an unsupported version of python. That is what is causing the error. Please use python 3.5-3.7</p>
","0","3","2289","1152","280","424","60471485","60482141"
"60471529","<p>We can try using a list comprehension along with <code>re.sub</code>:</p>

<pre><code>output = [re.sub(r'^&lt;a ', '&lt;a target=""_blank"" ', i) for i in list]
print(output)

['&lt;a target=""_blank"" href=""url_1""&gt;Title_1&lt;/a&gt;',
 '&lt;a target=""_blank"" href=""url_2""&gt;Title_2&lt;/a&gt;',
 '&lt;a target=""_blank"" href=""url_3""&gt;Title_3&lt;/a&gt;',
 '&lt;a target=""_blank"" href=""url_4""&gt;Title_4&lt;/a&gt;']
</code></pre>
","0","1","379372","14513","4457","41845","60471506","60471529"
"60471568","<p>This is how to do it without regex. An alternative to @Tim Biegeleisen solution. Explanation in code comments:</p>

<pre><code>list = [""&lt;a href=\""url_1\""&gt;Title_1&lt;/a&gt;"",
    ""&lt;a href=\""url_2\""&gt;Title_2&lt;/a&gt;"",
    ""&lt;a href=\""url_3\""&gt;Title_3&lt;/a&gt;"",
    ""&lt;a href=\""url_4\""&gt;Title_4&lt;/a&gt;""]

new_list = []
# for each html string in the list
for html in list:
    # Create a new string concatenating the first 4 characters of html with  target=""_blank""  and the remainder of html string
    s = html[:3] + 'target=""_blank"" ' + html[3:]
    new_list.append(s)

print(new_list)
</code></pre>
","0","0","1541","222","23","129","60471506","60471529"
"60476710","<p>Another option is to use the <a href=""https://book.pythontips.com/en/latest/map_filter.html#map"" rel=""nofollow noreferrer""><code>map</code></a> function to perform the <code>target</code> addition:</p>

<pre><code>inlist = [""&lt;a href=\""url_1\""&gt;Title_1&lt;/a&gt;"", 
    ""&lt;a href=\""url_2\""&gt;Title_2&lt;/a&gt;"", 
    ""&lt;a href=\""url_3\""&gt;Title_3&lt;/a&gt;"", 
    ""&lt;a href=\""url_4\""&gt;Title_4&lt;/a&gt;""]

newList = list(map(lambda elem: elem.replace('&lt;a', '&lt;a target=""blank""'), inlist))
print(newList)
</code></pre>

<p>Output:</p>

<pre><code>['&lt;a target=""blank"" href=""url_1""&gt;Title_1&lt;/a&gt;', '&lt;a target=""blank"" href=""url_2""&gt;Title_2&lt;/a&gt;', '&lt;a target=""blank"" href=""url_3""&gt;Title_3&lt;/a&gt;', '&lt;a target=""blank"" href=""url_4""&gt;Title_4&lt;/a&gt;']
</code></pre>

<p><strong>Note</strong>: Do not use <code>list</code> as variable name because it's a reserved Python keyword.</p>
","0","0","6360","377","3","5416","60471506","60471529"
"60473364","<p>This is because the callback instance is recreated every time you run the script; it isn't saved with the model. As such, the first epoch will always begin from the default value which is either <code>np.Inf</code> or <code>-np.Inf</code> as per <a href=""https://github.com/keras-team/keras/blob/7a39b6c62d43c25472b2c2476bd2a8983ae4f682/keras/callbacks/callbacks.py#L683"" rel=""nofollow noreferrer"">this right here.</a></p>
","0","2","1012","172","5","229","60471533","60473364"
"60471589","<p>Is very easy, in your example you can simply use the models.ForeingKey() method, this will work because that classroom can be linked to many students. But in the case where you have one model linked only to one other model you will use the models.OneToOne().</p>

<p>You will also have to enter the ""on_delete"" argument, this is telling django what to do with this attribute if the other model gets deleted from the database. The most common used is ""models.CASCADE"" which will delete the model as well but you can use others like (PROTECT, SET_NULL, SET_DEFAULT, etc)</p>

<p><a href=""https://docs.djangoproject.com/en/3.0/ref/models/fields/#module-django.db.models.fields.related"" rel=""nofollow noreferrer"">LINK</a> to official documentation just in case.</p>

<pre><code>class Student(models.Model):
    name = models.CharField(max_length=255)
    surname = models.CharField(max_length=255)
    age = models.IntegerField()
    classroom = models.ForeignKey(Item, on_delete=models.CASCADE)

    def __str__(self):
        return str(self.name) + "" - "" + str(self.surname)
</code></pre>
","2","2","633","42","33","146","60471585","60471589"
"60471714","<p><a href=""https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.filter.html"" rel=""nofollow noreferrer"">filter</a> out the columns to be merged; add ', ' and convert relevant columns from int to string. finally concat back to df.ID on the columns axis</p>

<pre><code>Merged_Dfs = (df.filter(like='Cat').astype(str)
             .add(', ')
             .add(df1.filter(like='Cat').astype(str)))

pd.concat([df.ID,
           Merged_Dfs
           ],axis=1)

    ID  Cat1    Cat2    Cat3
0   1   1, text 1, text 0, text
1   2   0, text 2, text 1, text
2   3   0, text 0, text 5, text
</code></pre>

<p>Alternatively, you can use pandas insert to hook back df.ID to Merged Dfs as the first column</p>

<pre><code>Merged_Dfs.insert(0,'ID',df.ID)

print(Merged_Dfs)
</code></pre>
","0","2","13958","3315","15","1304","60471614","60471714"
"60471759","<p>You can use <code>combine</code> to join the two dataframes using <code>pd.Series.str.cat</code> to join the elements of each dataframe:</p>

<pre><code>df1.set_index('ID').astype(str).combine(df2.set_index('ID'), lambda x,y: x.str.cat(y, sep=', '))
</code></pre>

<p>This requires setting the index as <code>ID</code> and having the numerics as strings.</p>

<p>Output:</p>

<pre><code>       Cat1     Cat2     Cat3
ID                           
1   1, text  1, text  0, text
2   0, text  2, text  1, text
3   0, text  0, text  5, text
</code></pre>
","0","1","8332","312","225","547","60471614","60471714"
"60471848","<p>You can use <code>pandas.DataFrame.conbine</code> to merge two data frames. However, you need to pass the correct function to attribute <code>func</code>. </p>

<hr>

<pre><code>merge = lambda x,y: [x,y]
df1.combine(df2, func = lambda s1,s2: s1.combine(s2, func = merge))
</code></pre>

<p>Note that the variable of this function is <code>pandas.Series</code>. Thus, <code>pandas.Series.combine</code> is called to get the correct result.</p>
","1","1","46","0","0","2","60471614","60471714"
"60471787","<p>My solution might be complicated, and I haven't worked with Django, nor REST api before. However, I was thinking along the lines of using Pathlib, and it loops through all of the apps, finding the location of the ViewSet. Then, using regex, finds the names of the ViewSets and writes them to a file with a list of all the things. Then, the routers.py reads the file, and loops through each ViewSet in the file.</p>
","0","0","11","0","0","14","60471704","60471985"
"60471985","<p>I just found out that the best way is to import the router from the app and use the router.registry.extend method.</p>

<p>First in the routers.py I will name the router something unique to avoid name collisions when merging them</p>

<pre><code>router_store = DefaultRouter()
router_store.register('items', ItemViewSet)
router_store.register('purchases', PurchaseViewSet)
router_store.register('receipts', ReceiptViewSet)
</code></pre>

<p>Then the main routers.py, I will import all my routers, then create a new router and extend it using them routers.py:</p>

<pre><code>from store.routers import router_store
from accounts.routers import router_accounts

router = DefaultRouter()
router.registry.extend(router_store.registry)
router.registry.extend(router_accounts.registry)
</code></pre>
","0","0","633","42","33","146","60471704","60471985"
"60471850","<p>Create your <code>Counter</code> as</p>

<pre><code>c = Counter(item['country']for item in item_data)
</code></pre>

<p>and it’s now counted your countries up.</p>
","0","1","18408","116","505","903","60471819","60471850"
"60471851","<p>One way would be to pass a generator of the countries to the <code>Counter</code>, as that takes an iterable. For example:</p>

<pre><code>&gt;&gt;&gt; countries = (item['country'] for item in item_data)
&gt;&gt;&gt; totals_per_country = Counter(countries) # not a generator, evaluates immediately
&gt;&gt;&gt; totals_per_country.most_common(5)
[('US', 299072), ('CA', 183927), ('GB', 150242), ('AU', 131295), ('DE', 100611)]
</code></pre>
","0","0","95528","2897","13","6872","60471819","60471850"
"60471899","<p>Using the new Walrus operator in Python 3.8</p>

<pre class=""lang-py prettyprint-override""><code>(c[item['country']]:=c[item['country']]+1 for item in item_data)
</code></pre>

<p>This allows you to do assignments an expression, making it syntactically legal in places it otherwise is not, such as a comprehension</p>
","0","0","1588","262","65","275","60471819","60471850"
"60471912","<p>You can use <code>extractall</code>: </p>

<pre><code>df2 = df.pop('Dimension').str.extractall('(\d+)')[0].unstack().astype(int) 
df2.columns = ['Amount', 'L', 'W', 'H']
</code></pre>

<p>Assuming you only have the one ""Dimension"" column, you are finished. Otherwise, concatenate this back to <code>df</code>: </p>

<pre><code>pd.concat([df, df2], axis=1)

   Index  Amount    L   W   H
0      0       1   43  32  34
1      1       1  120  80  74
2      2       2   26  26  32
3      3       1  120  80  81
</code></pre>
","0","4","266035","10142","8528","64481","60471885","60471950"
"60471950","<p>You can use <a href=""https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.str.split.html"" rel=""nofollow noreferrer"">pandas str split</a> with expand=True, the delimiters are @ and X, so passing them in will ensure appropriate splits. You can then insert Index as the first column and rewrite the column names:</p>

<pre><code>M = df.Dimension.str.split('[@X]',expand=True)
M.insert(0,'Index',df.Index)
M.columns = ['Index','Amount','Length','Width','Height']


   Index    Amount  Length  Width   Height
0   0       1         43    32      34
1   1       1        120    80      74
2   2       2         26    26      32
3   3       1        120    80      81
</code></pre>
","0","4","13958","3315","15","1304","60471885","60471950"
"60471974","<p>Information in your variables is stored during the execution of your script. It is not automatically carried across to <em>different</em> executions of your script. Each one is a blank slate. Even if it weren't, the first line of your program sets <code>list</code> to an empty dictionary.</p>

<p>At the moment, you're putting salt on your broccoli, eating it, then expecting the broccoli you eat tomorrow to <em>also</em> have salt on it.</p>

<p>You could serialise the dictionary to a file, that can be read back in on next execution, rather than starting with an empty dictionary each time.</p>
","3","0","16086","826","623","2362","60471967","60471974"
"60472247","<p>You will need recursion in order to support an undefined number of levels.</p>

<p>Assuming your levels always have 2 or 3 items in the lists at each level, the recursive function could look like this:</p>

<pre><code>a = ['foo', 'bar', ['can', 'haz']]

def f(a):
    k,v,b,*_ = a+[None]
    result = [{""key"":k,""val"":v}]
    if b: result.append(f(b))
    return result
</code></pre>

<p>output:</p>

<pre><code>print(f(a))

# [{'key': 'foo', 'val': 'bar'}, [{'key': 'can', 'val': 'haz'}]]


b = ['foo', 'bar', ['can', 'haz', ['boo','yah',['dino','dog']]]]
print(f(b))
[
  {'key': 'foo', 'val': 'bar'},
  [
     {'key': 'can', 'val': 'haz'},
     [
        {'key': 'boo', 'val': 'yah'},
        [
          {'key': 'dino', 'val': 'dog'}
        ]
     ]
  ]
]
</code></pre>
","3","0","24359","14","17","1310","60471996","60500273"
"60472555","<p>Assuming consecutive content of every each one of the lists is always either key-val pair or a list:</p>

<pre><code>a = ['foo', 'bar', ['can', 'haz']]

def f(a):
  itr = iter(a)
  return [f(a) if isinstance(x, list) else {'key': x, 'val': next(itr)} for x in itr]

# &gt;&gt;&gt; f(a)
# [{'key': 'foo', 'val': 'bar'}, [{'key': 'can', 'val': 'haz'}]]
</code></pre>

<hr>

<p><strong>Update:</strong></p>

<p>Ok, I must say this gave me a bit of a headache but since it's an interesting problem and great opportunity to learn something new, here it is.<br>A function that does <strong>exactly</strong><sup>1</sup> what you wanted and since you have some issues with recursive operations:</p>

<blockquote>
  <p>With your precise function and input I get <code>RecursionError: maximum recursion depth exceeded while calling a Python object</code></p>
</blockquote>

<p>It does it <strong>without recursion</strong>. I'm sure this is not the <em>ultimate</em> solution but it works:</p>

<pre><code>from functools import reduce
import operator

def traverse(lst):
  stack = [lst]
  res = [[]]

  substack = stack[0]
  subres = res[0]

  depth = 0

  while stack:
    if substack:
      if isinstance(substack[0], list):
        substack = substack[0]
        subres.append([])
        subres = subres[-1]
        depth += 1
      else:
        if len(substack) &gt; 1 and not isinstance(substack[1], list):
            subres.append({'key': substack.pop(0), 'val': substack.pop(0)})
        else:
          subres.append(substack.pop(0))
    else:
        substack = reduce(operator.getitem, [0] * depth, stack)
        subres = reduce(operator.getitem, [-1] * depth, res)
        depth -= 1
        substack.pop(0)

  return res[0]
</code></pre>

<p><a href=""http://pythontutor.com/live.html?fbclid=IwAR2jZeYE0C2kgQ72rMOXdLLKySXyHRn2PY-MUM8B6Ua67JcvXm5rlTybq9k#code=from%20random%20import%20random,%20randint%0Afrom%20string%20import%20ascii_lowercase%0Afrom%20functools%20import%20reduce%0Aimport%20operator%0A%0Aa,%20b,%20c,%20d,%20e,%20f,%20g,%20h,%20i,%20j,%20k,%20l,%20m,%20n,%20o,%20p,%20q,%20r,%20s,%20t,%20u,%20v,%20w,%20x,%20y,%20z%20%3D%20tuple%28%0A%20%20%20%20%28round%28abs%28random%28%29%29%20**%2010,%204%29%0A%20%20%20%20%20if%20randint%280,%201%29%20%25%202%20%3D%3D%200%0A%20%20%20%20%20else%20randint%2820,%2050%29%0A%20%20%20%20%20if%20randint%280,%201%29%20%25%202%20%3D%3D%200%0A%20%20%20%20%20else%20%28&#39;foo&#39;,%20&#39;bar&#39;,%20&#39;can&#39;,%20&#39;haz&#39;,%20&#39;bzr&#39;%29%5Brandint%280,%204%29%5D%29%0A%20%20%20%20%20%20%20%20%20%20%20for%20c%20in%20ascii_lowercase%29%0A%0Al1%20%3D%20%5Ba,%20b,%20c,%20d,%20e,%20f,%20g,%20%5Bh,%20i,%20j,%20k%5D,%0A%20%20%20%20%20%20l,%20m,%20n,%20%5Bo,%20p,%20q,%20r,%20%5Bs,%20t,%20u,%20v,%20w,%20x,%20y,%20z%5D,%20a,%20b%5D,%20c,%20d,%20e%5D%0A%20%20%20%20%20%20%0Adef%20traverse%28lst%29%3A%0A%20%20stack%20%3D%20%5Blst%5D%0A%20%20res%20%3D%20%5B%5B%5D%5D%0A%20%20%0A%20%20substack%20%3D%20stack%5B0%5D%0A%20%20subres%20%3D%20res%5B0%5D%0A%20%20%0A%20%20depth%20%3D%200%0A%0A%20%20while%20stack%3A%0A%20%20%20%20if%20substack%3A%0A%20%20%20%20%20%20if%20isinstance%28substack%5B0%5D,%20list%29%3A%0A%20%20%20%20%20%20%20%20substack%20%3D%20substack%5B0%5D%0A%20%20%20%20%20%20%20%20subres.append%28%5B%5D%29%0A%20%20%20%20%20%20%20%20subres%20%3D%20subres%5B-1%5D%0A%20%20%20%20%20%20%20%20depth%20%2B%3D%201%0A%20%20%20%20%20%20else%3A%0A%20%20%20%20%20%20%20%20if%20len%28substack%29%20%3E%201%20and%20not%20isinstance%28substack%5B1%5D,%20list%29%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20subres.append%28%7B&#39;key&#39;%3A%20substack.pop%280%29,%20&#39;val&#39;%3A%20substack.pop%280%29%7D%29%0A%20%20%20%20%20%20%20%20else%3A%0A%20%20%20%20%20%20%20%20%20%20subres.append%28substack.pop%280%29%29%0A%20%20%20%20else%3A%0A%20%20%20%20%20%20%20%20substack%20%3D%20reduce%28operator.getitem,%20%5B0%5D%20*%20depth,%20stack%29%0A%20%20%20%20%20%20%20%20subres%20%3D%20reduce%28operator.getitem,%20%5B-1%5D%20*%20depth,%20res%29%0A%20%20%20%20%20%20%20%20depth%20-%3D%201%0A%20%20%20%20%20%20%20%20substack.pop%280%29%0A%0A%20%20return%20res%5B0%5D%0A%0Aprint%28l1%29%20%20%0Aprint%28traverse%28l1%29%29&amp;cumulative=false&amp;curInstr=258&amp;heapPrimitives=nevernest&amp;mode=display&amp;origin=opt-live.js&amp;py=3&amp;rawInputLstJSON=%5B%5D&amp;textReferences=false"" rel=""nofollow noreferrer"">Live Demo</a></p>

<p><sub><em>1. I'm not exactly sure how you're supposed to know the exact pre-names for dict keys in your output example if you're passing just lists of list to the function so I'll leave it up to you.</em></sub></p>
","3","0","387","77","3","26","60471996","60500273"
"60500273","<p>There's a pile of mess down below but the core algorithm in <code>solution()</code> doesn't seem so bad.  I can't say I like the <code>sentinel</code> there but...  it made everything else tidy.</p>

<p><a href=""https://repl.it/@altendky/ChartreuseWeightyRoot-10"" rel=""nofollow noreferrer"">https://repl.it/@altendky/ChartreuseWeightyRoot-10</a></p>

<pre class=""lang-py prettyprint-override""><code>import functools
import itertools
import random
import string

import attr
import toolz


@attr.s(frozen=True)
class Example:
    source = attr.ib()
    target = attr.ib()
    group_handler = attr.ib()


def random_example():
    a, b, c, d, e, f, g, h, i, j, k, l, m, n, o, p, q, r, s, t, u, v, w, x, y, z = tuple(
        (round(abs(random.random()) ** 10, 4)
        if random.randint(0, 1) % 2 == 0
        else random.randint(20, 50)
        if random.randint(0, 1) % 2 == 0
        else ('foo', 'bar', 'can', 'haz', 'bzr')[random.randint(0, 4)])
            for c in string.ascii_lowercase)

    l1 = [a, b, c, d, e, f, g, [h, i, j, k],
        l, m, n, [o, p, q, r, [s, t, u, v, w, x, y, z], a, b], c, d, e]

    auauughhghhhh = [
        {f'{a}_key': a, f'{a}_val': b,
        f'{c}_key': c, f'{c}_val': d,
        f'{e}_key': e, f'{e}_val': f},
        g,
        [
            {f'{h}_key': h, f'{h}_val': i,
            f'{j}_key': j, f'{j}_val': k}
        ],
        {f'{l}_key': l, f'{l}_val': m},
        n,
        [
            {f'{o}_key': o, f'{o}_val': p,
            f'{q}_key': q, f'{q}_val': r},
            [
                {f'{s}_key': s, f'{s}_val': t,
                f'{u}_key': u, f'{u}_val': v,
                f'{w}_key': w, f'{w}_val': x,
                f'{y}_key': y, f'{y}_val': z}
            ],
            {f'{a}_key': a, f'{a}_val': b}
        ],
        {f'{c}_key': c, f'{c}_val': d},
        e
    ]

    g = lambda k,v: {'{}_key'.format(k): k, '{}_val'.format(k): v}

    return Example(
        source=l1,
        target=auauughhghhhh,
        group_handler=functools.partial(process_group, paired_sequence_handler=lambda s: build_dict_by_update(s, g)),
    )


def process_group(group, paired_sequence_handler):
    processed_group = []

    if len(group) == 0:
        return processed_group

    odd = (len(group) % 2) != 0
    raw_pairs = group[:-1] if odd else group
    pairs = toolz.partition_all(2, raw_pairs)
    result = paired_sequence_handler(pairs)

    processed_group.append(result)

    if odd:
        processed_group.append(group[-1])

    return processed_group


def build_dict_by_update(sequence, pair_handler):
    result = {}
    for pair in sequence:
        result.update(pair_handler(*pair))

    return result


examples = [
    Example(
        source=['foo', 'bar', ['can', 'haz']],
        target=[{'key': 'foo', 'val': 'bar'}, [{'key': 'can', 'val': 'haz'}]],
        group_handler=functools.partial(process_group, paired_sequence_handler=lambda s: build_dict_by_update(s, lambda k,v: {'key': k, 'val': v})),
    ),
    random_example(),
]


def solution(source, group_handler):
    built = []
    group = []

    sentinel = object()

    for value in itertools.chain(source, [sentinel]):
        if not isinstance(value, list) and value is not sentinel:
            group.append(value)
            continue

        built.extend(group_handler(group))
        group = []

        if value is sentinel:
            break

        result = solution(
            source=value,
            group_handler=group_handler,
        )
        built.append(result)

    return built



for example in examples:
    result = solution(
        source=example.source,
        group_handler=example.group_handler,
    )

    succeeded = result == example.target

    print('?', succeeded)

    if not succeeded:
        print('?  ', example.target)
        print('?  ', result)
</code></pre>
","0","1","3745","220","7","271","60471996","60500273"
"60472032","<p>Use <a href=""https://pandas.pydata.org/docs/user_guide/io.html#csv-text-files"" rel=""nofollow noreferrer"">Pandas</a> for better manipulation of data</p>

<pre><code>import pandas as pd
df = pd.read_csv(filename, sep=' ', header=None)
</code></pre>
","2","0","7612","912","171","1052","60472015","60472280"
"60472047","<p>You can simply use split that will split based on space and will return you a list with all the fields</p>

<pre><code>fields = text.split()
print (fields)
</code></pre>

<p>The output will be &amp; you can use it as you want</p>

<pre><code>['28/11/2019', '05:26', 'PM', '2,074,273,364', 'jdev_suite_122130_win64.exe']     
</code></pre>
","1","1","802","15","1","31","60472015","60472280"
"60472280","<p>You can do it by regex like this:</p>

<pre><code>import re

text = ""28/11/2019  05:26 PM     2,074,273,364 jdev_suite_122130_win64.exe""

m = re.match(r'(\d+/\d+/\d+) +(\d{2}:\d{2} (?:AM|PM)) +([0-9,]+) ([\w.]+)', text)
if m:
    print(m.groups())
</code></pre>

<p>Output:</p>

<pre><code>('28/11/2019', '05:26 PM', '2,074,273,364', 'jdev_suite_122130_win64.exe')
</code></pre>
","3","1","5541","802","41","331","60472015","60472280"
"60472126","<p>Look for week_number where holiday == 1. Then convert the remaining 0s to 1 by assigning Holiday to 1 for that particular week number. Last part is to remove duplicates based on subset = ['Week_number','Description']</p>

<pre><code>df['Qty'] = df.groupby(['Description','Week_number']).Qty.transform('sum')

cond = df.query('Holiday ==1').Week_number.unique()

df['Holiday'] = np.where(df.Week_number.isin(cond),1,df.Holiday)

df = df.drop_duplicates(['Week_number','Description'])

    Week_number Holiday Description  Qty
0       38          1       A        11
2       38          1       B         1
3       38          1       C         1
4       40          0       A         1
</code></pre>
","4","1","13958","3315","15","1304","60472025","60472126"
"60472235","<p>The exact real number arithmetic product of 10 and 0.1000000000000000055511151231257827021181583404541015625, the IEEE 754 64-bit binary representation of 0.1, is 1.000000000000000055511151231257827021181583404541015625.</p>

<p>It is not exactly representable. It is bracketed by 1.0 and 1.0000000000000002220446049250313080847263336181640625</p>

<p>It is closer to 1.0, so that is the round-to-nearest result of the multiplication.</p>

<p>I calculated the numbers using a short Java program:</p>

<pre><code>import java.math.BigDecimal;

public strictfp class Test {
    public static void main(String[] args) {
        BigDecimal rawTenth = new BigDecimal(0.1);
        BigDecimal realProduct = rawTenth.multiply(BigDecimal.TEN);
        System.out.println(realProduct);
        System.out.println(new BigDecimal(Math.nextUp(1.0)));
    }
}
</code></pre>

<p>Output:</p>

<pre><code>1.0000000000000000555111512312578270211815834045410156250
1.0000000000000002220446049250313080847263336181640625
</code></pre>
","4","4","24773","2187","18","5088","60472069","60472235"
"60475395","<p>This answer shows how you can determine that converting 1/10 to floating-point and multiplying by 10 will produce exactly 1 using just a little arithmetic; there is no need to calculate large or precise numbers.</p>

<p>Your Python implementation uses the common IEEE-754 binary64 format. (Python is not strict about which floating-point format implementations should use.) In this format, numbers are represented, in effect, as a sign (+ or −) applied to some 53-bit integer multiplied by some power of two. Because 2<sup>−4</sup> ≤ 1/10 &lt; 2<sup>−3</sup>, the representable number nearest 1/10 is some integer M multiplied by 2<sup>−3−53</sup>. (The −53 scales the 53-bit integer to between ½ and 1, and the −3 scales that to between 2<sup>−4</sup> and 2<sup>−3</sup>.) Let’s call that representable number x.</p>

<p>Then we have x = M•2<sup>−56</sup> = 1/10 + e, where e is some rounding error that occurs when we round 1/10 to the nearest representable value. Since we round to the nearest representable value, |e| ≤ ½•2<sup>−56</sup> = 2<sup>−57</sup>.</p>

<p>To find exactly what e is, multiply 1/10 by 2<sup>56</sup>. <a href=""https://www.wolframalpha.com/input/?i=2**56%2F10"" rel=""nofollow noreferrer"">WolframAlpha</a> tells us it is 7205759403792793+3/5. To get the nearest representable value, we should round up, so M = 7205759403792794 and e = 2/5 • 2<sup>−56</sup>. Although I used WolframAlpha to illustrate this, we do not need M, and we can find e by observing the pattern in powers of two modulo 10: 2<sup>1</sup>→2, 2<sup>2</sup>→4, 2<sup>3</sup>→8, 2<sup>4</sup>→6, 2<sup>5</sup>→2, 2<sup>6</sup>→4, and so the pattern repeats with a cycle of 4, and 56 modulo 4 is 0, so 2<sup>56</sup> modulo 10 has the same remainder as 2<sup>4</sup>, 6, so the fraction is 6/10 = 3/5. We know that should round to the nearest integer, 1, so e = 2/5 • 2<sup>−56</sup>.</p>

<p>So x = M•2<sup>−56</sup> = 1/10 + 2/5•2<sup>−56</sup>.</p>

<p>Now we can figure out the result of computing 10•x with floating-point arithmetic. The result is as if we first compute 10•x with real-number arithmetic and then round to the nearest representable value. In real-number arithmetic, 10•x = 10•(1/10 + 2/5•2<sup>−56</sup>) = 1 + 10•2/5•2<sup>−56</sup> = 1 + 4•2<sup>−56</sup> = 1 + 2<sup>−54</sup>. The two neighboring representable values are 1 and 1 + 2<sup>−52</sup>, and 1 + 2<sup>−54</sup> is closer to 1 than it is to 1 + 2<sup>−52</sup>. So the result is 1.</p>
","3","2","138014","2844","4443","11797","60472069","60472235"
"60478634","<p>Through experimentation and further research I discovered that the fastest method of checking the Levenshtein ratio is through the <code>python-Levenshtein</code> library itself. The function <code>Levenshtein.ratio()</code> is <em>significantly faster</em> (for one game the entire search takes only 0.05 seconds on average) compared to using any function in fuzzywuzzy or difflib, likely because of its simplicity and C implementation. I used this function in a for loop iterating over every name in the master list to get the best answer:</p>

<pre class=""lang-py prettyprint-override""><code>from Levenshtein import ratio

metric = 0
for master_name in master_names:
    new_metric = ratio(name, master_name)
    if (new_metric &gt; metric):
        metric = new_metric
</code></pre>

<p>In conclusion I say that the fastest method of searching for the highest percent Levenshtein distance between a string and a list of strings is to iterate over the list of strings, use <code>Levenshtein.ratio()</code> to get the ratio of each string compared with the first string, and then check for the highest value ratio on each iteration.</p>
","0","2","156","22","1","11","60472100","60478634"
"60472214","<p>You can't do:</p>

<pre><code>split.endswith('ay','ey','iy')
</code></pre>

<p>The <code>endswith</code> method only accepts a single string argument, optionally followed by <code>start</code> and <code>end</code> indices.  Instead, you can test each suffix individually, or you can avoid <code>endswith</code> and instead do:</p>

<pre><code>split[-2:] in ('ay', 'ey', 'iy')
</code></pre>

<p>which will do what you want.</p>

<p>Update:  You <em>can</em> have <code>endswith</code> check for multiple suffixes at once if you pass a <code>tuple</code> for the first argument.  So a better way to do this is:</p>

<pre><code>split.endswith(('ay','ey','iy'))
</code></pre>

<p>The extra parentheses create a <code>tuple</code> that's passed as the first (and only) argument to <code>endswith</code>.  This is closer to what you wanted to do in the first place.</p>
","0","0","16811","333","672","2135","60472182","60472214"
"60472475","<h3>Firstly</h3>
<p>Your question is very ambiguous and I recommend reading this <a href=""https://stackoverflow.com/questions/20109391/how-to-make-good-reproducible-pandas-examples"">link</a> in @sammywemmy's comment. If I understand your problem correctly... we'll talk about this mask first:</p>
<pre><code>df.columns[      
    (df == 1)        # mask 
    .any(axis=0)     # mask
]
</code></pre>
<p>What's happening? Lets work our way outward starting from within <code>df.columns[**HERE**]</code> :</p>
<ol>
<li><code>(df == 1)</code> makes a boolean mask of the <code>df</code> with <code>True</code>/<code>False</code>(<code>1</code>/<code>0</code>)</li>
<li><code>.any()</code> as per the <a href=""https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.any.html"" rel=""nofollow noreferrer"">docs</a>:</li>
</ol>
<blockquote>
<p>&quot;Returns False unless there is at least one element within a series or along a Dataframe axis that is True or equivalent&quot;.</p>
</blockquote>
<p>This gives us a handy <code>Series</code> to mask the column names with.</p>
<p><strong>We will use this example to automate for your solution below</strong></p>
<hr />
<h3>Next:</h3>
<p>Automate to get an output of <code>(&lt;row index&gt; ,[&lt;col name&gt;, &lt;col name&gt;,..])</code> where there is <code>1</code> in the row values. Although this will be slower on large datasets, it should do the trick:</p>
<pre><code>import pandas as pd

data = {'foo':[0,0,0,0], 'bar':[0, 1, 0, 0], 'baz':[0,0,0,0], 'spam':[0,1,0,1]}
df = pd.DataFrame(data, index=['a','b','c','d'])

print(df)

   foo  bar  baz  spam
a    0    0    0     0
b    0    1    0     1
c    0    0    0     0
d    0    0    0     1
</code></pre>
<pre><code># group our df by index and creates a dict with lists of df's as values
df_dict = dict(
    list(
        df.groupby(df.index)
    )
)
</code></pre>
<p>Next step is a <code>for</code> loop that iterates the contents of each df in <code>df_dict</code>, checks them with the mask we created earlier, and prints the intended results:</p>
<pre><code>for k, v in df_dict.items():               # k: name of index, v: is a df
    check = v.columns[(v == 1).any()]
    if len(check) &gt; 0:
        print((k, check.to_list()))
</code></pre>
<pre><code>('b', ['bar', 'spam'])
('d', ['spam'])
</code></pre>
<h3>Side note:</h3>
<p>You see how I generated sample data that can be easily reproduced? In the future, please try to ask questions with posted sample data that can be reproduced. This way it helps you understand your problem better and it is easier for us to answer it for you.</p>
","1","4","769","215","34","82","60472196","60472475"
"60472541","<p>Use <a href=""http://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.dot.html"" rel=""nofollow noreferrer""><code>DataFrame.dot</code></a>:</p>

<pre><code>df1 = df.dot(df.columns)
</code></pre>

<p>If there is multiple <code>1</code> per row:</p>

<pre><code>df2 = df.dot(df.columns + ';').str.rstrip(';')
</code></pre>
","0","3","615041","23439","1483","126104","60472196","60472475"
"60472474","<p>You can do it with two <code>range</code> by iterating in 2 interval</p>

<pre><code>even_odd = [list(range(0, 19, 2)), list(range(1, 20, 2))]
# [[0, 2, 4, 6, 8, 10, 12, 14, 16, 18], [1, 3, 5, 7, 9, 11, 13, 15, 17, 19]]
</code></pre>
","2","1","33900","639","3108","4197","60472333","60472474"
"60476610","<p>The code is trying to write text encoded as ISO-8859-1 to tables set to expect UTF-8.</p>

<p>There are two solutions:</p>

<ul>
<li><p>Set the <code>charset</code> argument on the connection to <code>latin1</code> (this is the same as ISO-8859-1) and let the connection handle re-encoding the bytes to UTF-8  </p>

<pre><code>db = MySQLdb.connect(host=cred.host, user=cred.user, password=cred.password, 
                     db=cred.db, port=cred.port, charset='latin1')
</code></pre></li>
<li><p>decode the encoded bytes to <code>str</code> and let the connection perform the encoding.</p>

<pre><code>report_as_dict = report.parsed.decode('ISO-8859-1')
</code></pre></li>
</ul>

<p>If the code is doing nothing apart from writing the bytes directly to the database then the first option is fine; if the bytes are undergoing further manipulations then decoding to <code>str</code> will keep things simple.  </p>
","2","1","27066","4430","2273","3147","60472411","60476610"
"60496413","<p>The client is working with latin1 encoding (92, etc).  The table would like to have the utf8 encoding (E28099) for that ""right single quotation mark"".  You can achieve that by telling MySQL that the client is using latin1 in the connection parameters, and having the column be utf8 (or utf8mb4).</p>

<p>The former is something like</p>

<pre><code>db = MySQLdb.connect(host=DB_HOST, user=DB_USER, passwd=DB_PASS, db=DB_NAME,
              charset=""utf8"", use_unicode=True)
</code></pre>

<p>Also check whether or not you should change the beginning of your source to</p>

<pre><code># -*- coding: utf-8 -*-
</code></pre>

<p>But... I am worried.  Are you really using right quote, registered sign (AE), I-acute, and a-double-dot?  Or is this merely the beginning of some other mess?  Sometimes multiple bytes in a row are 'bad'.  To further analyze your situation, please get the hex for more than just one byte, and/or provide what characters you think the text <em>should</em> include.</p>
","0","0","104249","1335","142","9251","60472411","60476610"
"60472766","<p>you could use ajax and bootstrap modal,
crate a general modal somewhere in your html page(I usually have it in my base.html so it will be included in all pages) then submit your from by using ajax then ajax will provide success or error function regarding the response will receive from server-side. put that message in the modal. an example is:</p>

<h1>somewhere inside base.html</h1>

<pre><code>    &lt;!-- Info General modal --&gt;
    &lt;div id=""general_modal"" class=""modal fade "" &gt;
      &lt;div class=""modal-dialog ""&gt;
        &lt;div class=""modal-content ""&gt;
          &lt;div class=""modal-header bg-info""&gt;
            &lt;h6 class=""modal-title""&gt;Info header&lt;/h6&gt;
            &lt;button type=""button"" class=""close"" data-dismiss=""modal""&gt;&amp;times;&lt;/button&gt;
          &lt;/div&gt;
          &lt;div class=""modal-body""&gt;
          &lt;!-- Empty will be field by Js --&gt;
          &lt;/div&gt;
        &lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
    &lt;!-- /info General modal --&gt;
</code></pre>

<h1>js and ajax function</h1>

<pre><code>$(""#your-form"").on('submit',function(e){
    e.preventDefault();
var ajax_link = this.getAttribute(""data-ajax-link"");
var target = this.getAttribute(""data-target"");
var title = this.getAttribute(""data-modal-title"");
var size = this.getAttribute(""data-modal-size"");
var bg = this.getAttribute(""data-modal-content-bg"");
// $(target+"" .modal-body"").load(ajax_link);
$.ajax({
    url:ajax_link,
    type:'POST',
    // data: $(""#your-form-feilds"").serialize(),

    success: function (response){
        $(target+"" .modal-body"").html(response);
    },
    /*
    error:function (response){
        new PNotify({
            title: 'oops',
            text:' Unable to load',
            type: 'error'
        });
    }
   */
});

$(target+"" .modal-content"").addClass(bg);
$(target+"" .modal-title"").html(title);
$(target+"" .modal-dialog"").removeClass().addClass(""modal-dialog"");
$(target+"" .modal-dialog"").addClass(size);
</code></pre>

<p>});</p>

<h1>html form</h1>

<pre><code>&lt;form action=""."" method=""post"" id=""your-form"" class=""btn btn-info  modal-ajax-load""
                        data-ajax-link=""url""
                        data-toggle=""modal""
                        data-modal-title=""tilte""
                        data-target=""#general_modal""&gt;
</code></pre>

<p>ofcurse you need to modify this answer to create the functions you need</p>
","0","0","635","65","18","78","60472413","60472766"
"60472550","<p>You can append the user input to the same list every time. The while loop would accept input, if it's an empty string then break and print the list. Otherwise add the input to the list and print the value. The trickiest thing in your question is actually getting the ordinal number representation (1st, 2nd, 3rd, etc), which there is an answer to <a href=""https://stackoverflow.com/questions/9647202/ordinal-numbers-replacement"">here</a>.</p>

<pre><code>shoeCat = {1: 'Adidas', 2: 'Alexander McQueen', 3: 'Converse', 4: 'Fila', 5: 'Kids/Teens', 6: 'Men’s Kicks', 7: 'New Balance', 8: 'Nike', 9: 'OFF-White', 10: 'Puma', 11: 'Select Brands', 12: 'Slides', 13: 'Under Armour', 14: 'Women’s Kicks'}
ordinal = lambda n: ""%d%s"" % (n, ""tsnrhtdd""[(n // 10 % 10 != 1) * (n % 10 &lt; 4) * n % 10::4])
i = 1
final = []
while True:
    mycat1 = input(f""Enter {ordinal(i)} category: "")
    if mycat1:
        final.append(shoeCat[int(mycat1)])
        print(final[-1:])
        i += 1
    else:
        print(' | '.join(final))
        break
</code></pre>
","0","2","4481","30","42","339","60472446","60472569"
"60472569","<p>Keep a list to store the values that you have printed:</p>

<pre><code>shoeCat = {1: 'Adidas', 2: 'Alexander McQueen', 3: 'Converse', 4: 'Fila', 5: 'Kids/Teens', 6: 'Men’s Kicks', 7: 'New Balance', 8: 'Nike', 9: 'OFF-White', 10: 'Puma', 11: 'Select Brands', 12: 'Slides', 13: 'Under Armour', 14: 'Women’s Kicks'}
lst = []
while True:
    mycat1 = input(""Enter Category: (Press enter to generate.)"")
    if mycat1 == '':
        break
    lst.append(shoeCat[int(mycat1)])
    print(shoeCat[int(mycat1)])
print(*lst, sep="" | "")
</code></pre>

<p><code>lst</code> stores the values that you have printed out. You can then just plainly print out the list with the required separator.</p>

<p>Note that this assumes the user always enters a valid integer input that is in <code>shoeCat</code>. Additional checks need to be in place to make sure it handles edge cases.</p>
","0","1","690","750","43","125","60472446","60472569"
"60517680","<p>By passing the result of EnvInterpolation to another configparser, I'm able to get the required output. Sharing the results so that it could benefit others.</p>

<pre><code>import configparser
import os

class EnvInterpolation(configparser.BasicInterpolation):
    """"""Interpolation which expands environment variables in values.""""""

    def before_get(self, parser, section, option, value, defaults):
        return os.path.expandvars(value)

cfg = """"""
[Default]
key = world
my_path = ${PYSPARK_PYTHON}
path2 = /user/${Default:key} 
[Main]
path_main = Hello.${Default:key}
""""""

config = configparser.ConfigParser(interpolation=EnvInterpolation())
config.read_string(cfg)

config2 = configparser.ConfigParser(interpolation=configparser.ExtendedInterpolation())
config2.read_dict(config)

print(""====1====="")
print(config['Default']['my_path'])
print(config['Default']['path2'])
print(config['Main']['path_main'])

print(""====2====="")
print(config2['Default']['path2'])
print(config2['Default']['my_path'])
print(config2['Main']['path_main'])
</code></pre>

<p>Results:</p>

<pre><code>====1=====
C:\install\anaconda\Anaconda3\python.exe
/user/${Default:key}
Hello.${Default:key}
====2=====
/user/world
C:\install\anaconda\Anaconda3\python.exe
Hello.world
</code></pre>
","0","1","7626","379","2","947","60472455","60517680"
"60472480","<p>Use <code>in</code> in <a href=""http://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.apply.html"" rel=""nofollow noreferrer""><code>Series.apply</code></a> with lambda function:</p>

<pre><code>df['Monday'] = df.DaysOfWeek.str.split("","").apply(lambda x: 'Monday' in x)
</code></pre>

<p>Or create <code>DataFrame</code> and test with <a href=""http://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.isin.html"" rel=""nofollow noreferrer""><code>DataFrame.isin</code></a> and <a href=""http://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.any.html"" rel=""nofollow noreferrer""><code>DataFrame.any</code></a>:</p>

<pre><code>df['Monday'] = df.DaysOfWeek.str.split("","", expand=True).eq('Monday').any(axis=1)

print(df)
   UniqueID                                         DaysOfWeek  \
0         1                                     Monday,Tuesday   
1         2  Wednesday,Thursday,Can work Monday if given ad...   
2         3                                             Friday   

                                            DaysList  Monday  
0                                  [Monday, Tuesday]    True  
1  [Wednesday, Thursday, Can work Monday if given...   False  
2                                           [Friday]   False  
</code></pre>

<p>If need matches also in substrings use generator with <code>any</code>:</p>

<pre><code>df['Monday'] = df.DaysOfWeek.str.split("","").apply(lambda x: any('Monday' in y for y in x))
</code></pre>

<p>Or add <a href=""http://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.str.contains.html"" rel=""nofollow noreferrer""><code>Series.str.contains</code></a>:</p>

<pre><code>df['Monday'] = df.DaysOfWeek.str.split("","", expand=True).apply(lambda x: x.str.contains('Monday')).any(axis=1)
print (df)
   UniqueID                                         DaysOfWeek  \
0         1                                     Monday,Tuesday   
1         2  Wednesday,Thursday,Can work Monday if given ad...   
2         3                                             Friday   

                                            DaysList  Monday  
0                                  [Monday, Tuesday]    True  
1  [Wednesday, Thursday, Can work Monday if given...    True  
2                                           [Friday]   False  
</code></pre>
","3","0","615041","23439","1483","126104","60472463","60472480"
"60472603","<p>Add parameter <code>expand=True</code> for <code>DataFrame</code> and then add <code>[]</code> for new columns:</p>

<pre><code>df[['date','time']] = df.Time.str.split("":"", 1, expand=True)
print (df)
           IP                   Time                        URL  Staus  \
0  10.128.2.1  [29/Nov/2017:06:58:55     GET/login.php HTTP/1.1    200   
1  10.128.2.1  [29/Nov/2017:06:59:02  POST/process.php HTTP/1.1    302   

           date      time  
0  [29/Nov/2017  06:58:55  
1  [29/Nov/2017  06:59:02  
</code></pre>

<p>Or also add <a href=""http://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.str.strip.html"" rel=""nofollow noreferrer""><code>Series.str.strip</code></a> for remove trailing <code>[]</code>:</p>

<pre><code>df[['date','time']] = df.Time.str.strip('[]').str.split("":"", 1, expand=True)
print (df)
           IP                   Time                        URL  Staus  \
0  10.128.2.1  [29/Nov/2017:06:58:55     GET/login.php HTTP/1.1    200   
1  10.128.2.1  [29/Nov/2017:06:59:02  POST/process.php HTTP/1.1    302   

          date      time  
0  29/Nov/2017  06:58:55  
1  29/Nov/2017  06:59:02  
</code></pre>
","0","1","615041","23439","1483","126104","60472483","60472603"
"60634520","<p>I have used phase unwrapping module in C++. For Python, I have seen that this module is available in cv2 namespace in Ubuntu 20.04 and Fedora 31. </p>

<p>Which distribution are you using?</p>
","3","1","51","1","0","6","60472492","62402057"
"62402057","<p>I discovered that if I <code>pip install opencv-contrib-python</code>, then I have the following functions available, which were not available before I installed opencv contrib</p>

<p><code>cv2.phase_unwrapping_HistogramPhaseUnwrapping()</code></p>

<p>and </p>

<p><code>cv2.phase_unwrapping_PhaseUnwrapping()</code></p>

<p>I believe these were the ones I was looking for, so the reason I couldn't find them before is that they were/are still contrib modules. Note that I'm using version 4.2.0 of OpenCV.</p>
","0","1","193","125","0","13","60472492","62402057"
"60472568","<p>You can use the zip function in python to do pair 2 lists.</p>

<pre><code>list_a=[1,2,3]
list_b=[4,5,6]
multiplied_ab=[]
for i,j in zip(list_a,list_b):
    multiplied_ab.append(i,j)
print(multiplied_ab)
</code></pre>

<p>Your result will be multiplication of the 2 lists like this:
[4,10,18]</p>

<p>You'll have to make sure that the length of the 2 lists match.</p>

<p>Then you can simply calculate the sum of the list by using the <code>sum()</code> function</p>
","1","-1","123","11","0","27","60472526","60472673"
"60472673","<p>You want to do this.</p>

<p><code>m=sum((x<sub>i</sub>-mean(x))*y<sub>i</sub>)</code></p>

<p>You can try this.</p>

<pre><code>from statistics import mean
x=[1,2,3,4,5]
y=[6,7,8,9,10]

mean_x=mean(x)

m=(1/D)*sum((i-mean_x)*j for i,j in zip(x,y))
c=mean(y)-(m*mean_x)
</code></pre>
","5","1","14733","1831","61","1931","60472526","60472673"
"60472759","<p>Is the image type float from 0.0 to 1.0? Is it one channel grayscale? You are assigning text color with 3 channels and 255 valued... Probably you're having trouble because of one of those.</p>
","0","0","891","507","43","130","60472551","60472759"
"60472745","<p>You don't need them in the first place - as you wrote, you can just use instance variables:</p>
<pre><code>def __init__(self):
    self.the_answer = 42
</code></pre>
<p>But if you later change the implementation to use a function instead of a variable, you can change that to:</p>
<pre><code>def __init__(self):
    self._the_answer = None

@property
def the_answer(self):
    if self._the_answer is None:
         self._the answer = self.calculate_answer() 
    return self._the_answer
</code></pre>
<p>without changing the API. In this example, it is using lazy evaluation to make the calculation only on access, but there are a lot of other cases where this can be helpful:</p>
<ul>
<li>calculate the property value from several variables, so no single variable is needed</li>
<li>add constraints to the setter to only allow setting certain values</li>
<li>do not add a setter to have read-only attributes</li>
<li>invalidate the value on certain events and re-calculate them only in this case</li>
<li>overwrite the behavior of attributes in subclasses</li>
</ul>
","3","4","7188","468","333","872","60472614","60472745"
"60472770","<p><code>r</code> is actually an instance of class:<a href=""https://2.python-requests.org/en/master/api/#requests.Response"" rel=""nofollow noreferrer""><code>request.Response</code></a>. You can read documentation of <a href=""https://2.python-requests.org/en/master/api/#requests.get"" rel=""nofollow noreferrer""><code>requests.get</code></a> for more information.</p>
","0","0","331","9","0","13","60472659","60472785"
"60472785","<p>According to <a href=""https://2.python-requests.org/en/v1.1.0/user/quickstart/#make-a-request"" rel=""nofollow noreferrer"">Python Requests quickstart guide</a>   <code>requests.get(url)</code> simply returns a <code>Response</code> object, thus in your example, <code>r</code> is assigned to that object, which enables you to access its attributes such as <code>status_code</code>, <code>text</code>, etc.</p>
","0","0","36","6","0","3","60472659","60472785"
"60472677","<p>Apparently you should install pip separately in CentOS.
Try this <a href=""https://www.liquidweb.com/kb/how-to-install-pip-on-centos-7/"" rel=""nofollow noreferrer"">Link</a>.</p>
","0","1","354","9","1","41","60472660","60472683"
"60472683","<p>Pip is not available in CentOS 7 core repositories. To install pip we need to enable the EPEL repository:</p>

<pre><code>sudo yum install epel-release
</code></pre>

<p>Once the EPEL repository is enabled we can install pip and all of its dependencies with the following command:</p>

<pre><code>sudo yum install python-pip
</code></pre>

<p>To verify that the pip is installed correctly run the following command which will print the pip version:</p>

<pre><code>pip --version
</code></pre>

<p>Enjoy! :)</p>
","4","2","595","8","3","84","60472660","60472683"
"60480823","<p>I think this should do it:</p>

<pre><code>elms = []
for elem in soup.find_all('font'):
    if elem not in elms:
        elms.append(elem)
    else:
        target =elem.findParent().findParent()
        target.decompose()
print(soup.html)
</code></pre>

<p>This should get you your the desired output.</p>

<p>Edit:</p>

<p>To remove only for those paragraphs that have don't size 4 or 5, change the <code>else</code> block to</p>

<pre><code> else:
    if elem.attrs['size'] != ""4"" and elem.attrs['size'] !=""5"":
        target =elem.findParent().findParent()
        target.decompose()
</code></pre>
","4","1","15499","2905","1040","1214","60472800","60480823"
"60472886","<p>If you use Pandas, you may refer to this question <a href=""https://stackoverflow.com/questions/16476924/how-to-iterate-over-rows-in-a-dataframe-in-pandas"">How to iterate over rows in a DataFrame in Pandas?</a></p>

<p>the index is where the row is, probably the row slice you referred to? and the row is obviously the row. You can select the data field in the row you're interested in.</p>

<p>for 'Edit' data field, when you loop through the dataset, you may write something like:</p>

<pre><code>for index, row in df.iterrows():
    if row['Edit'] == 'False'
        print(index) #where the row is
</code></pre>
","0","0","1","0","0","3","60472837","60473864"
"60472968","<p>Using <code>dplyr</code> : </p>

<pre><code>library(dplyr)

df %&gt;%
  mutate(Date = lubridate::mdy_hms(Date),
         gr = lag(cumsum(!Edit), default = TRUE)) %&gt;%
  slice(-c(1, n())) %&gt;%
  group_by(gr) %&gt;%
  summarise(Start = min(Date),
            End = max(Date),
            Duration = as.integer(End - Start), 
            RowNum = n(), 
            Length = Length[n()]) %&gt;%
  mutate(RowNum = cumsum(RowNum)) %&gt;%
  slice(n():1) %&gt;%
  select(-gr)

#  Start               End                 Duration RowNum Length
#  &lt;dttm&gt;              &lt;dttm&gt;                 &lt;int&gt;  &lt;int&gt;  &lt;int&gt;
#1 2020-01-02 01:00:05 2020-01-02 01:00:15       10      8     90
#2 2020-01-02 01:00:01 2020-01-02 01:00:04        3      4     90
</code></pre>
","15","0","269285","5403","4754","49182","60472837","60473864"
"60473864","<p>True + False should give 1 (True ==1, False == 0).  Basically, one end should be True + False, the other end should be False + True. So you have a window. <br>
Next step is to get rid of the nulls
Then look for values in going_forward equal to 1.
<br></p>

<pre><code>df['grouping_forward'] = df.Edit.add(df.Edit.shift(1))
df['grouping_backward'] = df.Edit.add(df.Edit.shift(-1))


(df.dropna()
 .query('grouping_forward==1')
 .assign(Row = lambda x: np.where(x.Edit.eq(0),
                                  x.index,
                                  np.nan),
        Start = lambda x: np.where(x.Edit.eq(1), 
                                   x.Date,
                                   np.datetime64('NaT')),
        End = lambda x: np.where(x.Edit.eq(0),
                                 x.Date,
                                 np.datetime64('NaT'))
    )
 .ffill()
 .query('Edit == 0')
 .drop(['grouping_forward','grouping_backward','Date','Edit'],axis=1)
 .assign(Duration = lambda x: x.End.sub(x.Start).dt.seconds)
  )

    Length  Row     Start                End             Duration
4   90      4.0 2020-01-02 01:00:01 2020-01-02 01:00:04     3
8   90      8.0 2020-01-02 01:00:05 2020-01-02 01:00:15     10
</code></pre>
","19","2","13958","3315","15","1304","60472837","60473864"
"60472909","<p>If the length of the string <code>x</code> is 1 (you can also just ask if the length is greater than 1 for the while loop), the code skips straight to returning <code>r</code>. However, it may not know what <code>r</code> refers to because it only gets assigned inside the while loop.</p>
","0","1","87","3","0","16","60472873","60472960"
"60472944","<p>I would approach this with recursion</p>

<pre><code>def root_sum(n):
    x = sum(int(i) for i in str(n))
    if x &gt; 9:
       return root_sum(x)
    return x
</code></pre>

<p>that is the easiest solution imho</p>
","1","1","92651","4411","1247","10760","60472873","60472960"
"60472960","<p>It looks like r is out of scope when you reach the return statement. It only applies locally within the while statement, which ends before the return statement.</p>

<p>It's good that you only have one return statement and that it is at the broadest scope for the function, and at the end. So, try declaring r outside of the while loop, in the same scope as the return statement. That scope includes everything inside the while loop as well.</p>

<pre><code>def digital_root(n):
    x = str(n)
    r = 0
    while len(x) &gt; 1:
        r = 0
        for i in range(len(x)):
            r = r + int(x[i])
        x = str(r)
    return r
</code></pre>
","2","3","169","112","3","50","60472873","60472960"
"60473142","<p>The function <code>calculateDate</code> doesn't have a return statement and hence <code>result</code> variable in function <code>calculate</code> (in routes.py) is always <strong>None</strong>.</p>

<p>Modify <code>calculateDate</code> in calc_ttv.py to return your calculated result:</p>

<pre class=""lang-py prettyprint-override""><code>return cttvcl.calculateTime()
</code></pre>
","4","1","368","10","4","32","60472898","60473142"
"60473009","<p>Following the <a href=""https://woocommerce.github.io/woocommerce-rest-api-docs/?python#list-all-products"" rel=""nofollow noreferrer"">docs</a>, I see that you can pass a <strong>page</strong> parameter also.</p>

<p>That makes it pretty straightforward to iterate all pages:</p>

<pre><code>page = 0
While True:
  products = wcapi.get('products', params={'per_page': 100, 'stock_status': 'instock', 'tag': '1111', 'page': page}).json()
  # retrieve ids from **products**
  if len(products) == 0: # no more products
    break
  page = page + 1
</code></pre>

<p>Edit: Bear in mind that this is going to process <strong>per page</strong> (in this case 100) products per loop.</p>
","0","0","106","2","0","9","60472917","60473009"
"60478438","<p>There can be several approaches for solving this problem
You can fetch all products in a single call or in multiple calls according to your use-case </p>

<p>for example, you want to fetch 2k records in a single call</p>

<pre><code>products = wcapi.get('products', params={'per_page': 2000, 'stock_status': 'instock', 'tag': '1111', 'page': page}).json()
</code></pre>

<p>But the above approach is not good enough as the number of products may vary from time to time, therefore limiting products to be fetched is not a good solution for the long run.</p>

<p>Hence the better solution is to fetch the product details by multiple calls </p>

<pre><code>page = 1 #The first page number to loop is page 1 
products = []
while True:
    prods = wcapi.get('products', params={'per_page': 100, 'stock_status': 'instock', 'tag': '1111', 'page': page}).json()
    page += 1
    if not prods:
        break
    products.append(prods)
</code></pre>

<p>After fetching all the product list you can fetch the product_ids like</p>

<pre><code>product_ids = [product['id'] for product in products]
</code></pre>
","1","-1","1","0","0","3","60472917","60473009"
"60473074","<p>You can put the credentials in a <code>dict</code> and check if the user name exists and matches the password</p>

<pre><code>credentials = {'zaphod': 'helloworld42',
           'mozzie': 'mozzietheaussie'}

user_name = input('Hello, what is your username?\n')
password = input(f'Hello {user_name}, what is your password?\n')

pas = credentials.get(user_name) # returns None if the user name doesn't exists
if not pas:
    print('Wrong Username')
elif pas != password:
    print('Wrong Password')
else:
    print(f'Hello {user_name}, welcome home')
</code></pre>

<p>The <code>print(""Are you gonna trick me pal xd"")</code> seems to be unnecessary, however you can add it by modifying the <code>elif</code></p>

<pre><code>elif pas != password:
    if password in credentials.values():
        print('Are you gonna trick me pal xd')
    else:
        print('Wrong Password')
</code></pre>
","0","0","33900","639","3108","4197","60472959","60473074"
"60473083","<p>according to @khelwood comment, the word 'async' is one of the reserved words.go to your .py document and change all of 'async' to something else.</p>
","0","0","305","178","4","74","60472986","60473083"
"60487073","<p>What you can do is to mask the data with the where function: </p>

<pre><code>ds = ds.where(np.logical_and(ds.latitude &gt; lat_bounds_min, ds.latitude &lt; lat_bounds_max))
ds = ds.where(np.logical_and(ds.longitude &gt; lon_bounds_min, ds.longitude &lt; lon_bounds_max))
</code></pre>

<p>To get only germany you need shapefiles to check whether a coordinates is in the german polygon or not. But this is not very clear if you need such a solution. </p>
","0","1","1126","76","8","145","60473025","60487073"
"60473088","<p>Use list comprehension:</p>

<pre><code>df = pd.concat([df] * 10000, ignore_index=True)

In [123]: %timeit [[*x, (x[1], x[2])] for x in df.values.tolist()]
27.8 ms ± 404 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)

In [124]: %timeit [x + [(x[1], x[2])] for x in df.values.tolist()]
26.6 ms ± 441 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)

In [125]: %timeit (test_get_value(df))
41.2 s ± 1.97 s per loop (mean ± std. dev. of 7 runs, 1 loop each)
</code></pre>
","0","1","615041","23439","1483","126104","60473032","60473088"
"60473160","<p>This behavior of <code>_</code> is only available in REPL. <code>_</code> holds the output of that the last expression evaluated to. It should be noted, if the previous expression produced a TRACEBACK, <code>_</code> will hold the last valid output. You could also chain <code>_</code> upto three times (in IPython), to go fetch the 3rd last output:</p>

<pre><code>&gt;&gt;&gt; 5
5
&gt;&gt;&gt; 6
6
&gt;&gt;&gt; 7
7
&gt;&gt;&gt; ___
5
&gt;&gt;&gt; __
7
&gt;&gt;&gt; _
7
</code></pre>

<p>If you use it in actual scripts, you can treat it <code>_</code> as a variable name (not recommended, if you plan to use the variable), for example:</p>

<pre><code>_ = 10
print(_)

# will print 10
</code></pre>

<p>But the behavior you get at <code>REPL</code> can't be emulated in an actual script.</p>
","0","3","12268","1175","288","837","60473102","60473160"
"60473179","<p>From a quick glance at it. <code>#gold = int(100)</code> is commented out on line 1.
This causes a issue because it doesn't know what gold is. it isn't defined. remove the # before it.</p>
","0","2","48","10","0","8","60473147","60473179"
"60473224","<h1>Reason</h1>

<p>You are overwriting to <code>failure_details_dict[test]</code> for every each loop.</p>

<hr>

<h1>Solution</h1>

<p>You should set list to it only once.
<br>You have several options to do it.</p>

<ul>
<li>Non-pythonic way(<strong>NOT RECOMMENDED</strong>)</li>
</ul>

<pre class=""lang-py prettyprint-override""><code>if test not in failure_details_dict:
    failure_details_dict[test] = []
</code></pre>

<ul>
<li>Replace assignment to <code>dict.setdefault</code> call. This way doesn't affect other interactions with <code>failure_details_dict</code></li>
</ul>

<pre class=""lang-py prettyprint-override""><code>failure_details_dict.setdefault(test, [])  # instead of failure_details_dict[test] = []
</code></pre>

<ul>
<li>Use <code>collections.defaultdict</code> instead of <code>dict</code>. This way will <strong>AFFECT</strong> other interactions with <code>failure_detilas_dict</code>.</li>
</ul>

<pre class=""lang-py prettyprint-override""><code>from collections import defaultdict

failure_details_dict = defaultdict(list)  # instead of {}
</code></pre>

<hr>

<h1>Example</h1>

<p>And I have refactored your code:</p>

<pre class=""lang-py prettyprint-override""><code>all_failures = [
    'test1/path/to/test1/log/failure_reason1',
    'test1/path/to/test1/log/failure_reason2',
    'test2/path/to/test2/log/failure_reason1',
    'test2/path/to/test2/log/failure_reason2',
    'test3/path/to/test3/log/failure_reason1',
    'test4/path/to/test4/log/failure_reason1',
]

failure_details_dict = {}

for failure in all_failures:
    key, *paths, reason = failure.split('/')
    failure_details_dict.setdefault(key, []).append({
        'path': f""/{'/'.join(paths)}/"",
        'reason': reason,
    })

for key, value in failure_details_dict.items():
    print(key)
    print(value)
    print()
</code></pre>

<hr>

<h1>Conclusion</h1>

<ul>
<li>If you want a simple change, use <code>dict.setdefault</code> method.</li>
<li>If you have multiple accesses to <code>failure_details_dict</code> and you want default value for each access, use <code>collection.defaultdict</code> class.</li>
</ul>

<hr>

<h1>Extra</h1>

<blockquote>
  <p>How can we modify the code so that 'path' key is copied only once and only multiple dictionaries with 'reason' key is created? In general, what would be the best way to store the data in JSON format?</p>
</blockquote>

<p>You can reformat your JSON like:</p>

<pre><code>{
  ""test1"": {
    ""path"": ""/path/to/test1/log/"",
    ""reason"": [
      ""failure_reason1"",
      ""failure_reason2""
    ]
  },
  ""test2"": {
    ""path"": ""/path/to/test2/log/"",
    ""reason"": [
      ""failure_reason1"",
      ""failure_reason2""
    ]
  },
  ""test3"": {
    ""path"": ""/path/to/test3/log/"",
    ""reason"": [
      ""failure_reason1""
    ]
  },
  ""test4"": {
    ""path"": ""/path/to/test4/log/"",
    ""reason"": [
      ""reason1""
    ]
  }
}
</code></pre>

<p>From code:</p>

<pre class=""lang-py prettyprint-override""><code>all_failures = [
    'test1/path/to/test1/log/failure_reason1',
    'test1/path/to/test1/log/failure_reason2',
    'test2/path/to/test2/log/failure_reason1',
    'test2/path/to/test2/log/failure_reason2',
    'test3/path/to/test3/log/failure_reason1',
    'test4/path/to/test4/log/failure_reason1',
]

failure_details_dict = {}

for failure in all_failures:
    key, *paths, reason = failure.split('/')
    failure_details_dict.setdefault(key, {
        'path': f""/{'/'.join(paths)}/"",
        'reason': [],
    })['reason'].append(reason)

for key, value in failure_details_dict.items():
    print(key)
    print(value)
    print()
</code></pre>
","1","4","2217","279","150","156","60473163","60473224"
"60473261","<p>You can use <strong>regular expressions</strong> to extract the information from your failure log file names. This can be simply achieved in the following way:</p>

<pre><code>import re
import json

all_failures = [
            'test1/path/to/test1/log/failure_reason1',
            'test1/path/to/test1/log/failure_reason2',
            'test2/path/to/test2/log/failure_reason1',
            'test2/path/to/test2/log/failure_reason2',
            'test3/path/to/test3/log/failure_reason1',
            'test4/path/to/test4/log/failure_reason1',
        ]


info = dict()
for failure in all_failures:
    match = re.search(r""^(.*?)(/.*/)(.*)$"", failure)

    details = dict()
    details[""path""] = match.group(2)
    details[""reason""] = match.group(3)

    if match.group(1) in info:
        info[match.group(1)].append(details)
    else:
        info[match.group(1)] = []
        info[match.group(1)].append(details)

print(json.dumps(info, indent=4))
</code></pre>

<p><strong>OUTPUT:</strong></p>

<pre><code>{
    ""test1"": [
        {
            ""path"": ""/path/to/test1/log/"",
            ""reason"": ""failure_reason1""
        },
        {
            ""path"": ""/path/to/test1/log/"",
            ""reason"": ""failure_reason2""
        }
    ],
    ""test2"": [
        {
            ""path"": ""/path/to/test2/log/"",
            ""reason"": ""failure_reason1""
        },
        {
            ""path"": ""/path/to/test2/log/"",
            ""reason"": ""failure_reason2""
        }
    ],
    ""test3"": [
        {
            ""path"": ""/path/to/test3/log/"",
            ""reason"": ""failure_reason1""
        }
    ],
    ""test4"": [
        {
            ""path"": ""/path/to/test4/log/"",
            ""reason"": ""failure_reason1""
        }
    ]
}
</code></pre>
","2","1","31794","2954","64","2384","60473163","60473224"
"60485767","<p>Try:</p>

<pre><code>  body = {
  ""size"": 0,
  ""aggs"": {
    ""sold"": {
      ""terms"": {
        ""field"": ""product.sold.keyword"",
        ""size"": 40000
      },
      ""aggs"": {
        ""bought"": {
          ""terms"": {
            ""field"": ""product.bought.keyword"",
            ""size"": 40000
          }
        }
      }
    }
  }
}
</code></pre>
","2","1","2677","27","50","452","60473218","60485767"
"60473353","<p>When you specify a list by range, the first boundary is included and the second boundary is not.  So here you are including <code>{}-01-01</code> and not including <code>{}-12-31</code>.  But you are including the midnight value.  </p>

<p>So, you need to include the last day of the year, but omit the ""celebratory"" New Year Hour:</p>

<pre><code>&gt;&gt;&gt; year = 2018
&gt;&gt;&gt; times = list(pd.date_range('{}-01-01'.format(year), '{}-01-01'.format(year+1), freq='H'))
&gt;&gt;&gt; times = times[:-1]
&gt;&gt;&gt; len(times)
8760
</code></pre>

<p>You need to include the New Year's Day, <code>{}-01-01</code>, so that you get New Year's Eve, <code>{}-12-31</code>.  But then you get the midnight hour since that's what starts the day.  Hence the need to eliminate the last entry in the list: <code>times = times[:-1]</code>, so that you're ending at 11:00pm on 12-31.</p>
","0","0","724","360","26","91","60473262","60473353"
"60486170","<p>The problem is likely to come from the way you have written you csv file. I would bet a coin that when read as text (with a simple text editor like notepad, notepad++, or vi) is actually contains:</p>

<pre><code>1228280254256623616,…,b'RT @MinisteroDifesa: #14febbraio Il Ministro...'
1228257366841405441,…,b'\xe2\x80\x9cNon t\xe2\x80\x99ama chi amor ti...'
...
</code></pre>

<p>or:</p>

<pre><code>1228280254256623616,…,""b'RT @MinisteroDifesa: #14febbraio Il Ministro...'""
1228257366841405441,…,""b'\xe2\x80\x9cNon t\xe2\x80\x99ama chi amor ti...'""
...
</code></pre>

<p>Pandas read_csv then correctly reads <em>the text representation of a byte string</em>.</p>

<p>The correct fix would be to write true UTF-8 encoded strings, but as I do not know the code, I cannot propose a fix.</p>

<p>A possible workaround is to use <code>ast.literal_eval</code> to convert the text representation into a byte string and decode it:</p>

<pre><code>df['text'] = df['text'].apply(lambda x: ast.literal_eval(x).decode('utf8'))
</code></pre>

<p>It should give:</p>

<pre><code>                    id ... text
0  1228280254256623616 ... RT @MinisteroDifesa: #14febbraio Il Ministro...
1  1228257366841405441 ... “Non t’ama chi amor ti...
...
</code></pre>
","1","1","119467","1546","546","7383","60473284","60486170"
"60473609","<p>Your submodule should just be:</p>

<pre><code>import logging

logger = logging.getLogger(__name__)

logger.info(""This is an info message from submodule, should be recorded in main.log!"")
logger.debug(""This is a debug message from submodule, also should be recorded in main.log!!"")
</code></pre>

<p>Then your main module should be:</p>

<pre><code># main.py importing a submodule
import logging

logger = logging.getLogger(__name__)

# log to console
c_handler = logging.StreamHandler()

console_format = logging.Formatter(""[%(levelname)s] %(message)s"")
c_handler.setFormatter(console_format)
c_handler.setLevel(logging.INFO)

logging.getLogger().addHandler(c_handler)

# log to file from main
logfile = ""./logging/main.log""

f_handler = logging.FileHandler(filename=logfile)

f_format = logging.Formatter(""%(asctime)s: %(name)-18s [%(levelname)-8s] %(message)s"")
f_handler.setFormatter(f_format)
f_handler.setLevel(logging.DEBUG)

logging.getLogger().addHandler(f_handler)
logging.getLogger().setLevel(logging.DEBUG)

import submodule

logger.error(""This is an error!!! Logged to console"")
logger.debug(""This is a debug error. Not logged to console, but should log to file"")
</code></pre>

<p>Edit: The handlers have to be added before the code in the submodule runs. To effect this the <code>import submodule</code> was moved after the code that sets up the handlers. </p>

<p>Normally modules shouldn't have any top level logging calls so all the imports can be done at the top and then callables that use logging are called indirectly by the code in the <code>if __name__==""__main__"":</code> after it sets up logging.</p>
","3","1","66828","4060","31","4293","60473336","60473609"
"60536984","<p>This answer is scoped to the question's title and content: Providing getters and setters for frequency and channel of a packet.</p>

<p>For this solution, use the <a href=""https://wiki.wireshark.org/SampleCaptures?action=AttachFile&amp;do=get&amp;target=wpa-Induction.pcap"" rel=""nofollow noreferrer"">wpa-Induction.pcap</a> file in Wireshark's <a href=""https://wiki.wireshark.org/SampleCaptures"" rel=""nofollow noreferrer"">Sample Captures</a>.</p>

<h2>Poking around</h2>

<p>It's useful to poke around one packet to see what fields Scapy has access to in the Scapy interpreter.</p>

<pre class=""lang-py prettyprint-override""><code>&gt;&gt;&gt; pkts = rdpcap('wpa-Induction.pcap')
&gt;&gt;&gt; pkts[0].summary()
""RadioTap / Dot11FCS / Dot11Beacon / Dot11Elt / Dot11EltRates / Dot11Elt / Dot11Elt / Dot11Elt / Dot11Elt / Dot11EltRSN / Dot11Elt / Dot11EltVendorSpecific / Dot11EltMicrosoftWPA / SSID=''""
&gt;&gt;&gt; pkts[0].show()
###[ RadioTap dummy ]###
  version= 0
  pad= 0
  len= 24
  present= Flags+Rate+Channel+Lock_Quality+Antenna+dB_AntSignal+RXFlags
  Flags= FCS
  Rate= 2
  Channel= 2412
  ChannelFlags= CCK+2GHz
  Antenna= 84
  notdecoded= '\x00\x00+\x00\x00\x9fa\xc9\\'

... &lt;output truncated&gt; ...
</code></pre>

<p>While 2412 is a frequency and <strong>NOT a channel</strong>, this is the data we want. RadioTap is the layer per <code>pkts[0].summary()</code>. Putting it together, </p>

<pre class=""lang-py prettyprint-override""><code>&gt;&gt;&gt; frequency = pkts[0][RadioTap].Channel
&gt;&gt;&gt; print(frequency)
2412
</code></pre>

<p>Scapy <a href=""https://github.com/secdev/scapy/issues/1979"" rel=""nofollow noreferrer"">does not provide access</a> to the channel, but it's trivial to convert frequency to channel.</p>

<h2>Putting it Together</h2>

<h3>Getting the Frequency</h3>

<p>Given a file and packet number, we can now get the channel and frequency for a packet.</p>

<pre class=""lang-py prettyprint-override""><code>from scapy.all import RadioTap, rdpcap

def getChannel(frequency):
    base = 2407              # 2.4Ghz
    if frequency//1000 == 5: 
        base = 5000          # 5Ghz
    # 2.4 and 5Ghz channels increment by 5
    return (frequency-base)//5

def getFrequency(file, packet_number):
  pkts = rdpcap(file)
  # Scapy mixes up Channel/Frequency here
  frequency = pkts[packet_number][RadioTap].Channel
  return frequency

freq = getFrequency('wpa-Induction.pcap', 0)
chan = getChannel(freq)
print(""Channel: {0} \nFrequency: {1}"".format(freq, chan))
</code></pre>

<h3>Setting the Frequency</h3>

<p>Let's say we wanted to change the frequency to 5300 and save it. This would only require iterating over the packet list, change the frequency for every packet, and saving the result. In the scapy interpreter:</p>

<pre class=""lang-py prettyprint-override""><code>&gt;&gt;&gt; for i in range(len(pkts)):
...     pkts[i][RadioTap].Channel = 5300
&gt;&gt;&gt; wrpcap('temp.pcap', pkts)
&gt;&gt;&gt; pkts2 = rdpcap('temp.pcap')
&gt;&gt;&gt; pkts[0].Channel
5300
</code></pre>
","1","2","2441","250","104","360","60473359","60609951"
"60609951","<p>I <a href=""https://wifinigel.blogspot.com/2013/11/what-are-radiotap-headers.html"" rel=""noreferrer"">found out</a> that RadioTab headers are not part of any Dot11 protocol but are merely added by the network interface. And the reason I got the RadioTab headers on sample packets from <a href=""https://wiki.wireshark.org/SampleCaptures"" rel=""noreferrer"">Wireshark.org</a> and not from my live wireshark capture is because some network adapters do not add RadioTap while others do and the network adapter of my laptop does not add RadioTab headers. I checked this with a new external WiFi adapter and it did add the RadioTap headers.</p>

<blockquote>
  <p>If the adapter does not inject the additional information as it captures frames, then no radiotap headers will be added.</p>
</blockquote>

<p>So to my main question, how to get/set frequency of a packet.
I expected Scapy to have this option but it doesn't, and it shouldn't. The reason is that the frequency depends on what is set on the network adapter. So what I did was to set the frequency/channel of my WiFi adapter to a different one. My external WiFi adapter can work in various channels so I changed each and confirmed with the RadioTap header. There are a simple <a href=""https://unix.stackexchange.com/questions/77965/force-a-specific-frequency-from-my-wireless-card"">linux commands/tools</a> that helped me check the supported channels of my WiFi interface, and switch to a particular channel.</p>

<blockquote>
  <p>To capture/send packets at a certain frequency or channel, you need to change the working channel of your interface and set the sniffer/sender interface in scapy to that interface.</p>
</blockquote>

<p>EDIT - Other problems I faced and solutions:</p>

<p>If you are on linux, and you want to change the working channel of your interface you need to disable network-manager for that interface and to do this
First
Add the following snippet to <code>/etc/network/interfaces</code></p>

<pre><code>auto $iface
iface $iface inet dhcp
wpa-conf /etc/wpa_supplicant/wpa_supplicant.conf
</code></pre>

<p>replace <code>$iface</code> with your interface name. This will let you control the interface by yourself. And then add the following lines to <code>/etc/wpa_supplicant/wpa_supplicant.conf</code></p>

<pre><code>ctrl_interface=/var/run/wpa_supplicant

network={
    ssid=""Your_AP_SSID""
    psk=""Your_Passphrase""
    freq_list=2412 2437 2462
}
</code></pre>

<p>Note that <code>2412 2437 2462</code> are the frequencies (channel 1, 6, 11 in this case) for your interface to choose from. You can edit them to desired frequency. <a href=""https://askubuntu.com/questions/1058622/how-to-force-to-linux-to-connect-only-5ghz-channel"">Source</a>. But first you have to check that your interface supports these frequencies. To check that</p>

<pre><code>iwlist channel
</code></pre>

<p>Finally after everything is done. </p>

<pre><code>sendp(Ether()/IP(dst=""1.2.3.4"",ttl=(1,4)), iface=""wlp3s0"")
</code></pre>

<p>This will send you packets at the frequency that <code>wlp3s0</code> is set.</p>
","1","6","1586","123","24","259","60473359","60609951"
"60473738","<p>IIUC you have an equal amount of columns for each category, and you want to compress this into numeric columns which are shape agnostic. If so this will work:</p>

<pre><code>dfs = []
for var in ['S', 'D', 'C']:
        # filter  columns with a regex
        res = df[df.iloc[:, 2:].filter(regex= var + '\d{1,2}').columns].dropna()
        # rename coumns with just numbers to enable concatenation
        res.columns = range(3)
        dfs.append(res)

df = pd.concat([df.iloc[:, :2], pd.concat(dfs)], 1)
print(df)
</code></pre>

<p>Output:</p>

<pre><code>   SC0  Shape        0      1       2
2   1   Circle      1.0     1.0     1.0
3   13  Square      2.0     1.0     2.0
4   13  Diamond     2.0     1.0     2.0
5   16  Diamond     2.0     2.0     2.0
6   16  Square      2.0     2.0     2.0
</code></pre>
","0","1","6477","2042","245","830","60473458","60473749"
"60473749","<p>Try:</p>

<pre class=""lang-py prettyprint-override""><code>n=3
cols_prefixes=[""C"", ""S"", ""D""]
for i in range(n):
    cols=[f""{l}{i+1}"" for l in cols_prefixes]
    df[f""res{i+1}""]=df[cols].bfill(axis=1).iloc[:,0]
    df=df.drop(columns=cols)
</code></pre>

<p>Outputs:</p>

<pre class=""lang-py prettyprint-override""><code>   SC0    Shape  res1  res2  res3
2    1   Circle   1.0   1.0   1.0
3   13   Square   2.0   1.0   2.0
4   13  Diamond   2.0   1.0   2.0
5   16  Diamond   2.0   2.0   2.0
6   16   Square   2.0   2.0   2.0
</code></pre>
","0","1","11365","152","50","745","60473458","60473749"
"60473602","<pre><code>for sertag in soup.findAll('span', {'class': 'font-weight-medium text-jet'})[1]:
    print(sertag, sertag.next_element.strip())
</code></pre>
","3","0","8986","62","313","1419","60473480","60473602"
"60473539","<p>Definitely store your results in a variable, and then save the whole thing into a file afterwards. Saving during the loop is ""messy"" and less efficient because of I/O calls constantly. </p>

<p>Note that this is not true if you are dealing with millions of entries, in which case you'd have to spare memory a bit and write to file in ""batches"". But it doesn't feel like this should be a problem in your case.</p>
","0","0","938","98","29","140","60473489","60473539"
"60473658","<p>Checking which statemets are triggered:</p>

<pre><code>import numpy as np

def scalar_function(x, y):
    """""" A function that returns x*y if x&lt;y and x/y otherwise
    """"""
    if x &lt; y :
        print('if x: ',x)
        print('if y: ',y)
        out = x * y 
        print('if out', out)
    else:
        print('else x: ',x)
        print('else y: ',y)
        out = x/y
        print('else out', out)

    return out

def vector_function(x, y):
    """"""
    Make it possible to accept vectors as input
    """"""
    v_scalar_function = np.vectorize(scalar_function)
    return v_scalar_function(x, y)


vector_function(np.array([3,4]), np.array([4,3]))

if x:  3
if y:  4
if out 12
if x:  3
if y:  4
if out 12
else x:  4
else y:  3
else out 1.3333333333333333 # &lt;-- seems that the value is calculated correctly, but the wrong dtype is returned
</code></pre>

<p>So, you can rewrite the scalar function:</p>

<pre><code>def scalar_function(x, y):
    """""" A function that returns x*y if x&lt;y and x/y otherwise
    """"""
    if x &lt; y :
        out = x * y 
    else:
        out = x/y
    return float(out)


vector_function(np.array([3,4]), np.array([4,3]))
array([12.        ,  1.33333333])
</code></pre>
","0","2","6026","765","678","483","60473567","60473737"
"60473737","<p>The docs for <a href=""https://docs.scipy.org/doc/numpy/reference/generated/numpy.vectorize.html"" rel=""nofollow noreferrer""><code>numpy.vectorize</code></a> state:</p>

<blockquote>
  <p>The output type is determined by evaluating the first element of the
  input, unless it is specified</p>
</blockquote>

<p>Since you did not specify a return data type, and the first example is integer multiplication, the first array is also of integer type and rounds the values. Conversely, when the first operation is division, the datatype is automatically upcasted to float. You can fix your code by specifying a dtype in <code>vector_function</code> (which doesn't necessarily have to be as big as 64-bit for this problem):</p>

<pre><code>def vector_function(x, y):
    """"""
    Make it possible to accept vectors as input
    """"""
    v_scalar_function = np.vectorize(scalar_function, otypes=[np.float64])
    return v_scalar_function(x, y)
</code></pre>

<p>Separately, you should also make note from that very same documentation that <code>numpy.vectorize</code> is a convenience function and basically just wraps a Python <code>for</code> loop so is not vectorized in the sense that it provides any real performance gains.</p>

<p>For a binary choice like this, a better overall approach would be:</p>

<pre><code>def vectorized_scalar_function(arr_1, arr_2):
    return np.where(arr_1 &lt; arr_2, arr_1 * arr_2, arr_1 / arr_2)

print(vectorized_scalar_function(np.array([4,4]), np.array([4,3])))
print(vectorized_scalar_function(np.array([3,4]), np.array([4,3])))
</code></pre>

<p>The above should be orders of magnitude faster and (possibly coincidentally rather than a hard-and-fast rule to rely on) doesn't suffer the type casting issue for the result.</p>
","2","3","10837","1326","3819","7193","60473567","60473737"
"60473624","<pre class=""lang-py prettyprint-override""><code>&gt;&gt;&gt; [[str(element) + '.jpg' for element in sublist] for sublist in a]
[['0.jpg', '1.jpg', '5.jpg'], ['3.jpg', '4.jpg', '6.jpg', '7.jpg'], ['2.jpg']]
</code></pre>
","1","0","2466","181","38","203","60473592","60473624"
"60473670","<p>Use <code>requests</code> module to get the data as dictionary, from there you can get the values by the key</p>

<pre><code>import requests

data = requests.get('http://110.93.230.117:1403/api/order/5e439b7052fcf2189ccb5207').json()
print(data)

""""""
{'date': '2020-02-12T06:30:08.106Z',
 '_id': '5e439b7052fcf2189ccb5207',
 'fitoName': 'Chinasor 01 - Bu Yang Huan Wu Wan',
 'fitoCode': 'Chinasor 01',
 'providerName': 'Soria - Chinasor',
 'providerCode': 'Chinasor 01',
 'valueItem': '01',
 'Email': 'helder@gmail.com',
 '__v': 0}
""""""
</code></pre>
","4","2","33900","639","3108","4197","60473611","60473670"
"60473680","<p>Regarding the code:</p>

<pre><code>for row in csv_reader:
    if row[0] == idNum:
        print(""matching barcode found"")
        return True
    else:
        print(""barcode not on file. Adding..."")
        return False
</code></pre>

<p>This <code>for</code> loop does indeed process every row if you let it, but you are <em>not</em> letting it because both your true and false parts of the <code>if</code> statement return after reading the first row, effectively ignoring all the others.</p>

<hr>

<p>What you probably need is this scheme: if you don't find it in the first row, don't immediately return false - you need to check all the <em>other</em> rows and return false only if it's in <em>none</em> of them.</p>

<p>In other words, something like this:</p>

<pre><code># Check ALL rows.

for row in csv_reader:
    # If found in THIS row, notify success.

    if row[0] == idNum:
        print(""matching barcode found"")
        return True

# If found in NO rows, notify failure.

print(""barcode not on file. Adding..."")
return False
</code></pre>
","0","3","765968","4508","1542","87167","60473651","60473680"
"60473759","<p>You can use Pandas. Pandas is very excellent in dealing with csv files. </p>

<pre><code>import Pandas as pd

file = pd.read_csv('csv_file')
df = pd.DataFrame(file)

# Check if Dataframe is empty using empty attribute
if df['Columnname'].empty == True:
    print('Barcode is empty')
else:
    print('Barcode is not empty')
</code></pre>
","3","0","111","26","0","18","60473651","60473680"
"60482890","<p>I decided to just rerun the scripts and compare the outputs. Seems it's not promising -- I lost a lot of rows.</p>
","3","0","1400","265","2","240","60473704","60482890"
"60474315","<p>It really depends on exactly what you did. Without more information I'm going to assume that you have a text widget somewhere and that you want to disable tab from indenting there.  </p>

<p>Example:</p>

<pre><code>from tkinter import Tk, Text

def no_tab(event):
    return 'break'

root = Tk()
text_widget = Text()
text_widget.pack()
text_widget.bind('&lt;Tab&gt;', no_tab)
root.mainloop()
</code></pre>

<p>In this example we bind the <code>&lt;Tab&gt;</code> key to the function <code>no_tab</code>. So everytime tab is pressed within the text widget the <code>no_tab</code> function is called. The <code>no_tab</code> function returns the magic string <code>'break'</code> which means that the action of the key won't be preformed and thus disabling the indentation that the tab key would have created otherwise.</p>
","0","1","2054","688","4","136","60473777","60474315"
"60473910","<p>Please check your code it's wrong.
You want somthing like this?</p>

<pre><code>class Parent:
    def __init__(self, var1, var2):
        self.var1 = var1
        self.var2 = var2
        print(var2)

    #more methods that to some stuff

class Child(Parent):
    a = 1 #a and b are class attributes
    b = 2

    def __init__(self, var1 = 1, var2 = 2, var3 = None):
        super().__init__(var1 = 1, var2 = 2) 
        self.var3 = var3

child_obj = Child(var3 = 3)
</code></pre>
","7","0","924","0","5","55","60473871","60473910"
"60474517","<p>The <a href=""https://docs.python.org/3/library/concurrent.futures.html"" rel=""nofollow noreferrer""><code>concurrent.futures</code></a> module provides a more high-level API for using threads or processes for individual operations.</p>

<pre><code>from concurrent.futures import ThreadPoolExecutor

executor = ThreadPoolExecutor()
executor.submit(np.savez_compressed, '/tmp/values.a', dict(a=a))
</code></pre>

<p>If you don't want the entire Executor API, you can define your own helper to run a function in a thread.</p>

<pre><code>def threaded(call, *args, **kwargs):
    """"""Execute ``call(*args, **kwargs)`` in a thread""""""
    thread = threading.Thread(target=call, args=args, kwargs=kwargs)
    thread.start()
    return thread

threaded(np.savez_compressed, '/tmp/values.a', dict(a=a))
</code></pre>
","0","4","25421","1898","3232","3219","60473911","60474517"
"60488483","<p>OP here:</p>

<p>Another solution I found was by using decorators with the decorators ""classic"" API:</p>

<pre><code>from threading import Thread

call_threaded(np.savez_compressed)('/tmp/values.a', dict(a=a))

# https://stackoverflow.com/a/19846691/2476373
def call_threaded(fn):        
    def wrapper(*args, **kwargs):
        thread = Thread(target=fn, args=args, kwargs=kwargs)
        thread.start()
        return thread
    return wrapper
</code></pre>
","0","0","4585","243","8","331","60473911","60474517"
"60476210","<p>No, as of Vega-Lite v4.4 there is no way to make interactions/selections work on mobile. The bug that tracks adding this feature is here: <a href=""https://github.com/vega/vega-lite/issues/4661"" rel=""nofollow noreferrer"">https://github.com/vega/vega-lite/issues/4661</a></p>
","0","3","51859","797","15","8125","60473973","60476210"
"60474050","<p>This should work.  You need to have the print statement outside the function definition, and also the assignment of <code>x</code>.  </p>

<pre><code>    def factorial(x):
      total = 1
      while x&gt;0:
        total *= x
        x -= 1
      return total

    n = input(""type here: "")
    print factorial(n)
</code></pre>
","1","0","27066","4430","2273","3147","60473975","60474050"
"60475631","<p>you adopted a recursive method to find a fictoral. Your code is erroneous following code will work.</p>

<p>def factorial(x):</p>

<pre><code>  total =1
  while x&gt;0:
        total =total * factorial (x-1)

  return total
</code></pre>

<p>n = input(""type here: "")</p>

<p>print factorial(n)</p>
","0","-1","63","10","0","37","60473975","60474050"
"60476271","<p>The fact that the tooltips stop working is probably a bug, and it would be worth filing a <a href=""https://github.com/vega/vega-lite/issues/new?labels=Bug+%3Abug%3A&amp;template=Bug_report.md"" rel=""noreferrer"">Vega-Lite bug report</a></p>

<p>It appears you can work around this by adding a second empty selection to the upper chart:</p>

<pre><code>upper = base.add_selection(alt.selection_single())
</code></pre>

<p>You can view the interactive result <a href=""https://vega.github.io/editor/#/url/vega-lite/N4KABGBEDGD2B2AzAlgc0gLjMSA3ZApgO6bYwIAuy8ArrDQM4DqyAJhQBakAsADLwBooceFVr0GACQJoOFUgGZ+AX2UDwUXCOgBDeVgDaGiKAhmoAWx0AnANalINgjsjrzESAXhxW1dFlN3DwpYWAAbKgAHUhwKAE9IggcARxodUWQKPWRcJKFIFAIw1gdI62RoJLVjd0gADxjIeMSHCgILSNhrHTDXKELih1Y9KrcgqDjG5qSsSFT0qiyqXL6CwkHZsoqqmohqoMgOGVQ5UgAmfjHzSAYigmgqBEbbsPuQ634FKYSZqAY-V6QVRXMyQIhsTikABs-Bq+zMgWuVjsDicLhBHi8Pj8MV2oJC4Si3xas3mGSWOTy-XWJU25UqQIxoIaASaP1a7U63V6+QGtKgwzajLxHkmrOmKTS5OyK15NNK9J2QXh1yOsn0YBhTJudweyCerJeby6-DOxN+kGobWsuB6qyxsF88FQDFIBnqkAAusC8WCIVwsDDeHCNJ6xpBBS5WTRrL1ZnIKJEGBgAPQp3KoHQAOlQmQ4NAARln9emCJmALSR24UBgpyMphiRACs-Cz0AYuGFHgAJAxoEcrA4E0nU6XMzm84Xi7AG-32joxzpy2FMgR09ws7ws2cswArBhPEDKIA"" rel=""noreferrer"">here</a>.</p>
","2","5","51859","797","15","8125","60474039","60476271"
"60474361","<p>The best way to approach is first saving the file and then reading it to get the text. As a convention, you set a <code>UPLOAD_FOLDER</code> variable with the path to save. Then, in flask use the following to save the file:</p>

<pre class=""lang-py prettyprint-override""><code>
file_path = os.path.join(app.config['UPLOAD_FOLDER'], secure_filename(f.filename))
f = request.files['file']
f.save(file_path)
# This would save the file. Now to read simply use the normal way to read files in Python

with open(file_path, 'r') as f:
    file_content = f.read()
# Rest of the processing logic
</code></pre>

<p>Note that the path is relative to your current working directory, which is usually the root of your project. Also, please be careful when storing and reading files from untrusted users.</p>

<p>A better place to store these files would be somewhere other than your project root. You could have a data directory somewhere through which you could configure Nginx (or any other front proxy) to serve the uploaded files</p>
","3","3","716","195","11","134","60474093","60474361"
"60475361","<p>This is my solution to my problem</p>

<pre><code>from werkzeug.utils import secure_filename
import os

class File():
def __init__(self,file):
    self.file = file

def read_file(self):
    file_name = secure_filename(self.file.filename)
    self.file.save(os.path.join(""app"", ""static"", file_name))
    with open(f""app/static/{file_name}"") as f:
        email_list = f.read().splitlines()
    return email_list
</code></pre>
","0","0","453","65","0","144","60474093","60474361"
"60474331","<p>There is an <code>files</code> parameter for <a href=""https://requests.readthedocs.io/en/master/user/quickstart/#post-a-multipart-encoded-file"" rel=""nofollow noreferrer"">requests.post</a> you can use it to send files like this:</p>

<pre class=""lang-py prettyprint-override""><code>import requests

url = ""http://localhost:8000/post_text_file""
fin = open('Hello World.txt', 'rb')
files = {'file': fin}
try:
    r = requests.post(url, files=files)
finally:
    fin.close()
</code></pre>

<p>And usually the file sent with your request is accessible with <code>request.files</code> as a dictionary of files uploaded.</p>
","0","3","680","178","6","67","60474097","60474331"
"62996203","<p>This can happen if you don't have <em>python-multipart</em> installed. So be sure you have done:</p>
<pre><code>pip install python-multipart
</code></pre>
","0","0","1","0","0","0","60474097","60474331"
"60474234","<p>You need to declare <code>total_transaction</code> as a property:</p>

<pre><code>class Transaction(models.Model):
    item = models.ForeignKey(Item,on_delete=models.PROTECT)
    coupon = models.ForeignKey(Coupon,on_delete=models.PROTECT)

    @property
    def total_transaction(self):
        return self.item.price * self.coupon.percentage // 100
</code></pre>

<p>Note: Properties do not get saved to DB</p>
","0","1","680","178","6","67","60474103","60474234"
"60474208","<p>First idea is use <a href=""http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#boolean-indexing"" rel=""nofollow noreferrer""><code>boolean indexing</code></a>:</p>

<pre><code>s = df.isnull().sum()
res = list(s[s &gt; 0].items())
print (res)
[('B', 1), ('D', 3)]
</code></pre>

<p>Or filter using <a href=""https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#selection-by-callable"" rel=""nofollow noreferrer""><code>callable</code></a>:</p>

<pre><code>res = list(df.isnull().sum()[lambda x: x &gt; 0].items())
</code></pre>

<p>Or filter in list comprehension:</p>

<pre><code>res = [(k, v) for k, v in df.isnull().sum().items() if v &gt; 0]
</code></pre>
","0","2","615041","23439","1483","126104","60474172","60474208"
"60474454","<p>Ok, figured it out. Just putting this out there just incase anyone has the same issue. If your project has a requirements.txt file (if it doesn't make one)  and add (If you want to use django-countries)</p>

<pre><code>django-countries==5.3.3 
</code></pre>

<p>To it, you can also use the latest version but I chose to use version 5.3.3 in this case. After that run the command</p>

<pre><code>pip install -r requirements.txt
</code></pre>
","0","1","15","1","0","7","60474286","60474454"
"60474405","<p>The position (<em>dest</em>) argument to <a href=""https://www.pygame.org/docs/ref/surface.html#pygame.Surface.blit"" rel=""nofollow noreferrer""><code>pygame.Surface.blit()</code></a> is ought to be a tuple of 2 integral numbers.<br />
In your case <code>self.pos[0]</code> and/or <code>self.pos[1]</code> seems to be a floating point number.</p>
<p>You can get rid of the warning by rounding the floating point coordinates to integral coordinates (<a href=""https://docs.python.org/3/library/functions.html#round"" rel=""nofollow noreferrer""><code>round</code></a>):</p>
<pre class=""lang-py prettyprint-override""><code>D.blit(self.player, (round(self.pos[0]), round(self.pos[1])))
</code></pre>
<p>For the sake of completeness it has to be mentioned that the argument can also be a rectangle. A tuple with the 4 components (left, top, width, height).</p>
<hr />
<p>Furthermore you have create a Surface with an integral length and you have to rotate the surface after it is (re)created:</p>
<pre class=""lang-py prettyprint-override""><code>class String:
    # [...]
   
    def draw(self):

        # compute INTEGRAL length        
        length = math.hypot(self.dx, self.dy)
        length = max(1, int(length))

        # create surface
        self.string = pygame.Surface((1, length)).convert_alpha()
        self.string.fill((0, 255, 0))

        # roatet surface
        angle = pygame.transform.rotate(self.string, player.orbital_angle)

        # blit rotated surface
        D.blit(angle, (round(self.pos[0]), round(self.pos[1])))
</code></pre>
","0","1","136140","16645","626","8521","60474292","60474405"
"60484343","<p>You can try with <code>compile = False</code> parameter in your load_model call. This will remove any metadata related to optimizers and loss function and since you have a reinitialize function and if you don't need to train it from where you stopped last time, that won't be a problem I guess. </p>

<p>As you said it works with compile = False, I think the problem might be in your custom functions for loss/optimizer etc, I can't pin point what exactly is the problem, you can try tf. instead of tf.keras.backend. if you want.</p>
","0","3","673","263","8","121","60474308","60484343"
"60474604","<p><strong>Instead of using <code>subprocess.call</code> you should use <code>subprocess.run</code> function it waits for the process to finish and returns the <code>CompletedProcess</code></strong></p>

<p><strong>Note:</strong></p>

<h2><code>subprocess.run(args)</code></h2>

<blockquote>
  <p>Run the command described by args. Wait for command to complete, then
  return a <code>CompletedProcess</code> instance.</p>
</blockquote>

<p>You can refer more at <a href=""https://docs.python.org/3/library/subprocess.html#subprocess.run"" rel=""nofollow noreferrer"">Python docs</a></p>
","2","2","31794","2954","64","2384","60474344","60474604"
"60474625","<p>Always use W (unicode) versions unless you really don't want to for some reason (some more recent APIs don't even have A versions). 
This is documented here: <a href=""https://docs.microsoft.com/en-us/windows/win32/intl/conventions-for-function-prototypes"" rel=""nofollow noreferrer"">Conventions for Function Prototypes</a>. I quote:</p>

<blockquote>
  <p>New Windows applications should use Unicode to avoid the
  inconsistencies of varied code pages and for ease of localization.
  They should be written with generic functions, and should define
  UNICODE to compile the functions into Unicode functions. In the few
  places where an application must work with 8-bit character data, it
  can make explicit use of the functions for Windows code pages.</p>
</blockquote>
","2","2","115910","827","209","10342","60474347","60474625"
"60474863","<p>Seems like your app executes this code each time</p>
<pre><code>if(name[0].files.length === 1){
        console.log(&quot;File name: &quot;, name[0].files[0].name)
        var temp = name[0].files[0].name;
        eel.getFileName(temp,moduleSelection); // passing file to python function getFileName
    }
</code></pre>
<h3>1. Index selection</h3>
<p>Is there a reason you're selecting the first index from <code>name[0]</code> each time? Maybe just checking for <code>name.files.length</code> would work?</p>
<h3>2. If/else algorithm</h3>
<p>If you structure your code a bit better, it might surprisingly work better. Try using the Javascript <a href=""https://developer.mozilla.org/nl/docs/Web/JavaScript/Reference/Global_Objects/Array/forEach"" rel=""nofollow noreferrer"">Array.forEach()</a> method instead of your loop. It would look something like this</p>
<pre><code>function showname(moduleSelection) {
    console.log(&quot;i am here&quot;);
    var files = document.getElementsByClassName('selectButton');
    
    var fileList = [];
    if (files.length &gt; 0) {
        files.forEach(file =&gt; {
            console.log(&quot;File name: &quot;, file.files[0].name);
            fileList.push(file.files[0].name);
        })
        eel.getFileName(fileList, moduleSelection);
    }
    return;
}
</code></pre>
<p>I hope this will <em>maybe</em> <strong><em>hopefully</em></strong> help!</p>
<p>EDIT:</p>
<p>If u want to remove previous files <strong>after</strong> calling the files, you will have to mark the currently selected files at <code>document.getElementsByClassName('selectButton')</code> as <strong>already called</strong>.</p>
<p>You can do this in various way, an example would be to change the <strong>class name</strong> from <code>selectButton</code> to <code>selectButtonDone</code> after the file name was pushed into the <code>fileList[]</code> array.</p>
<p>You can do this particularly by executing <code>file.className = 'selectButtonDone';</code> at the end of the <code>files.forEach()</code> function.</p>
","4","1","108","1","0","10","60474544","60474863"
"60474620","<p>From the <a href=""https://docs.python.org/3/library/stdtypes.html#dict.fromkeys"" rel=""nofollow noreferrer"">documentation</a>:</p>

<blockquote>
  <p><code>fromkeys()</code> is a class method that returns a new dictionary. <em>value</em> defaults to <code>None</code>. All of the values refer to just a single instance, so it generally doesn’t make sense for <em>value</em> to be a mutable object such as an empty list. To get distinct values, use a dict comprehension instead.</p>
</blockquote>

<p>So, both the keys point to the same dictionary that you are trying to change.</p>

<p>You can use this instead:</p>

<pre><code>comp = {key: {'dep': '', 'sal': ''} for key in ('emp1', 'emp2')}
</code></pre>
","0","0","6639","1993","1059","1424","60474564","60474620"
"60474800","<p>That is because the comp['emp1] and comp['emp2] actually refer to the same object.<br>
You can verify it by id() function which returns the unique identifier of the python object </p>

<pre class=""lang-py prettyprint-override""><code>a = ('emp1', 'emp2')
b = ({'dep': '', 'sal': ''})
comp = dict.fromkeys(a, b)
print(id(comp[""emp1""]))
print(id(comp[""emp2""]))
print(comp)
comp['emp1']['dep'] = 'IT'
comp['emp1']['sal'] = '300$'
print(comp)
</code></pre>

<p>it returns </p>

<pre><code>4467496912
4467496912
{'emp1': {'dep': '', 'sal': ''}, 'emp2': {'dep': '', 'sal': ''}}
{'emp1': {'dep': 'IT', 'sal': '300$'}, 'emp2': {'dep': 'IT', 'sal': '300$'}}
</code></pre>

<p>If u have to use fromkeys, The solution is </p>

<pre><code>from copy import deepcopy
a = ('emp1', 'emp2')
b = ({'dep': '', 'sal': ''})
comp = dict.fromkeys(a, b)
comp = {key: deepcopy(b) for key in comp}
print(id(comp[""emp1""]))
print(id(comp[""emp2""]))
print(comp)
comp['emp1']['dep'] = 'IT'
comp['emp1']['sal'] = '300$'
print(comp)
</code></pre>

<p>the output will be what u want</p>

<pre><code>4300371360
4301322592
{'emp1': {'dep': '', 'sal': ''}, 'emp2': {'dep': '', 'sal': ''}}
{'emp1': {'dep': 'IT', 'sal': '300$'}, 'emp2': {'dep': '', 'sal': ''}}
</code></pre>
","0","1","66","19","0","2","60474564","60474620"
"60474687","<p>You have definied ""dexterity"" as part of ""attributes"" so you need to refer to is as attributes['dexterity'].</p>
","4","1","71","4","0","43","60474576","60475230"
"60475230","<p>Your first problem is the input validation line:</p>

<pre><code>while choice != ""shop"" or ""tavern"" or ""forest"":
</code></pre>

<p>The expression is evaluated as:</p>

<pre><code>while (choice != ""shop"") or (""tavern"") or (""forest""):
</code></pre>

<p>So the condition will always be true because a non-empty string is truthy. You could write something like:</p>

<pre><code>while choice not in (""shop"", ""tavern"", ""forest""):
</code></pre>

<hr>

<p>Your second problem is that you keep all your code inside the input validation. You have a <code>while</code> loop to keep asking the user for input until a valid response is entered, which is good. But you need to remember that once a valid input was entered, the loop will terminate (because now <code>choice</code> is actually in <code>(""shop"", ""tavern"", ""forest"")</code>). So your code should be something like:</p>

<pre class=""lang-py prettyprint-override""><code>    choice = input(""Go to the shop, go to the tavern, go to the forest: "")
    while choice not in(""shop"", ""tavern"",""forest""):
        print(""Not accepted"")
        print(""What do you wish to do?"")
        print(""please input shop, tavern, forest."")
        choice = input(""Go to the shop, go to the tavern, go to the forest: "")

    if choice == ""tavern"":
        ....
</code></pre>

<hr>

<p>Regarding the <code>'dexterity'</code> error. It is not a variable, but a key in your dict so change to:</p>

<pre><code>if attributes['dexterity'] &gt;= 5:
</code></pre>
","0","1","11641","812","4462","4469","60474576","60475230"
"60474688","<p>You can create a list with your selection indices and use it to join what you want:</p>

<pre><code>list = [""0A"",""00"",""0C"",""20"",""10"",""AC""]
sel = [1,2]
print ("""".join(map(str, [list[i] for i in sel])))
</code></pre>
","0","0","16","0","0","1","60474606","60474688"
"60512492","<p>You may want to add <code>resizeMode=""contain""</code> at Image component - <a href=""https://github.com/GetStream/react-native-activity-feed/blob/master/src/components/Activity.js#L223"" rel=""nofollow noreferrer"">https://github.com/GetStream/react-native-activity-feed/blob/master/src/components/Activity.js#L223</a>.</p>

<p>But to add this prop, you will have to provide your own <code>Content</code> component to <code>Activity</code> component. So I suggest something like following (check the comments in code):</p>

<pre><code>&lt;StreamApp
    apiKey={apiKey}
    appId={appId}
    token={this.state.token}
&gt;
    &lt;FlatFeed
        notify
        feedGroup=""timeline""
        options={{
          limit: 10,
        }}
        notify
        navigation={this.props.navigation}
        Activity={(props) =&gt; (
            &lt;TouchableOpacity
                onPress={() =&gt; this._onPressActivity(props.activity)}
            &gt;
                &lt;Activity
                    {...props}
                    Footer={
                        &lt;View style={{ flexDirection: 'row', alignItems: 'center' }}&gt;
                        &lt;LikeButton reactionKind=""heart"" {...props} /&gt;
                        &lt;/View&gt;
                    }

                    // This is mostly copied from source of default `Content` component
                    // https://github.com/GetStream/react-native-activity-feed/blob/master/src/components/Activity.js#L193
                    Content={() =&gt; {
                        const width =
                        props.imageWidth != null
                            ? props.imageWidth
                            : Dimensions.get('window').width;
                        const { object, image, attachments } = props.activity;
                        let { text } = props.activity;
                        const { Card } = props;
                        if (text === undefined) {
                        if (typeof object === 'string') {
                            text = object;
                        } else {
                            text = '';
                        }
                        }
                        text = text.trim();

                        return (
                        &lt;View&gt;
                            {Boolean(text) &amp;&amp; (
                            &lt;View style={{
                                paddingBottom: 15,
                                paddingLeft: 15,
                                paddingRight: 15,
                            }}&gt;
                                &lt;Text&gt;{this.renderText(text, props.activity)}&lt;/Text&gt;
                            &lt;/View&gt;
                            )}

                            {Boolean(image) &amp;&amp; (
                                &lt;Image
                                    style={{ width, height: width }}
                                    source={{ uri: image }}
                                    // Either `contain` or `stretch`, depending on your requirement
                                    resizeMode=""contain""
                                /&gt;
                            )}

                            {attachments &amp;&amp;
                                attachments.images &amp;&amp;
                                attachments.images.length &gt; 0 &amp;&amp; (
                                    &lt;Image
                                        style={{ width, height: width }}
                                        source={{ uri: attachments.images[0] }}
                                        // Either `contain` or `stretch`, depending on your requirement
                                        resizeMode=""contain""
                                    /&gt;
                            )}
                            {attachments &amp;&amp;
                                attachments.og &amp;&amp;
                                Object.keys(attachments.og).length &gt; 0 &amp;&amp;
                                &lt;Card
                                    title={attachments.og.title}
                                    description={attachments.og.description}
                                    image={
                                        attachments.og.images &amp;&amp; attachments.og.images.length &gt; 0
                                            ? attachments.og.images[0].image
                                            : null
                                    }
                                    url={attachments.og.url}
                                    og={attachments.og} /&gt;
                            }
                        &lt;/View&gt;
                        );                        
                    }}
                /&gt;
            &lt;/TouchableOpacity&gt;
        )}
    /&gt;
&lt;/StreamApp&gt;
</code></pre>
","1","0","329","18","1","40","60474634","60512492"
"60474754","<p>You can add <code>header=0</code> parameter for first row of data to columns names, <code>thousands=' '</code> for remove spaces in <a href=""http://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_html.html"" rel=""nofollow noreferrer""><code>read_html</code></a> in first step.</p>

<p>Then remove first column by indexing with <a href=""http://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.iloc.html"" rel=""nofollow noreferrer""><code>DataFrame.iloc</code></a>, set new columns names and change values in <code>Text</code> column by <a href=""http://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.replace.html"" rel=""nofollow noreferrer""><code>Series.replace</code></a>:</p>

<pre><code>url = 'http://www.livepriceofgold.com/pakistan-gold-price.html'
df = pd.read_html(url, header=0, thousands=' ')[3].iloc[:, 1:]
df.columns= ['Text','Rates']

df['Text'] = df['Text'].replace('Gold Rate per ', '', regex=True)
print (df)
          Text       Rates
0  Gram in PKR     7889.65
1    Oz in PKR   245368.02
2    KG in PKR  7889646.96
3  Tola in PKR    92023.26
</code></pre>
","0","1","615041","23439","1483","126104","60474729","60474754"
"60475129","<p><strong>so far, I have used this to remove every thing and then split these strings and extract the values i need using split function</strong> </p>

<pre><code> fs=fs.replace(""Gold Rate per Gram in PKR"","""")
    fs=fs.replace(""Gold Rate per Oz in PKR"","""")
    fs=fs.replace(""Gold Rate per KG in PKR"","""")
    fs=fs.replace(""Gold Rate per Tola in PKR"","""")
    fs=fs.replace(""Gold Rate in PKR Pakistani rupee"","""")
    fs=fs.replace(""Rate"","""")
    fs=fs.replace(""0 NaN"","""")
    fs=fs.replace(""1 NaN"","""")
    fs=fs.replace(""2 NaN"","""")
    fs=fs.replace(""3 NaN"","""")
    fs=fs.replace(""4 NaN"","""")
    #print(fs.split())
    single= fs.split()
</code></pre>
","0","-1","33","13","0","10","60474729","60474754"
"60478221","<pre><code>Match = df.loc[df['ID'].isin(L),'Num']
</code></pre>
","0","0","3485","585","60","202","60474772","60478221"
"60474803","<p>They both have the same <em>values</em>, but they are two different lists.</p>

<p><code>table2D[:]</code> creates a copy of <code>table2D</code> and <code>[0]</code> takes the first index of that copy, so</p>

<pre><code>table2D[:][0]
</code></pre>

<p>is index 0 in a copy of <code>table2D</code>.</p>

<p><code>table2D[0]</code> takes the first index of <code>table2D</code> and <code>[:]</code> creates a copy of that list, so</p>

<pre><code>table2D[0][:]
</code></pre>

<p>is a copy of index 0 in <code>table2D</code>.</p>
","0","0","33900","639","3108","4197","60474785","60474803"
"60474879","<p>Actually, it's not <strong>exactly</strong> same.<br>
They looks like having same values.<br>
But they have different references.</p>

<pre class=""lang-py prettyprint-override""><code>table2D = [
    [1, 2, 3],
    [4, 5, 6],
    [7, 8, 9]
]

a = table2D[0][:]
b = table2D[:][0]

a[0] = 0
print(table2D[0])  # [1, 2, 3]
b[0] = 0
print(table2D[0])  # [0, 2, 3]
</code></pre>
","0","0","2217","279","150","156","60474785","60474803"
"60474933","<p>Your JSON data gets converted into a dictionary when using the <code>json.loads()</code> method, where the <em>keys</em> are 1, 2, 3 etc, and the <em>values</em> are dictionaries as well (e.g.: <code>{""home"":""001"",""street"":""Wolrd1"",""cap"":0}</code>).
The only modification you need is to use the <code>.values()</code> method in the for loop:</p>

<pre><code>import json
jsonData = '{""1"":{""home"":""001"",""street"":""Wolrd1"",""cap"":0},""2"":{""home"":""002"",""street"":""Wolrd2"",""cap"":0},""3"":{....}}'
jsonToPython = json.loads(jsonData)

jsonToPython = json.loads(jsonData)

for x in jsonToPython.values():
    print x
</code></pre>
","0","0","71","14","0","6","60474851","60474933"
"60476810","<p>The reason is that this part of <code>feasibleMove</code> has errors:</p>

<pre><code>row = coordinate[0] // 3
col = coordinate[1] // 3

for i in range(x * 3, x * 3 + 3):
    for j in range(y * 3, y * 3 + 3):
        if board[row][col] == number and (i, j) != coordinate:
            return False
</code></pre>

<p>The iteration should be based on <code>row</code> and <code>col</code>, not on <code>x</code> and <code>y</code>. And when you read out the value from <code>board</code>, you should use <code>i</code> and <code>j</code> as indexes. Right now, you are 9 times looking at the very same cell on your board.</p>

<pre><code>row = (x // 3) * 3
col = (y // 3) * 3

for i in range(row, row + 3):
    for j in range(col, col + 3):
        if board[i][j] == number and (i, j) != coordinate:
            return False
</code></pre>

<p>However, your algorithm is too slow to solve the puzzle in a reasonable time. You should improve your algorithm, with the following:</p>

<ul>
<li>Don't look for blank cells in real time. Instead, collect them into a queue, and pop them from there (and put them back when backtracking)</li>
<li>Instead of checking whether a value is valid for a cell, stay one step ahead, and keep track of which values are still valid (in a <code>set</code>), for each cell. Initialise this at the very start of the algorithm.</li>
<li>When placing a value update the sets of impacted cells</li>
</ul>

<p>These last two points may seem to give no gain as it just shifts the work of scanning rows, columns and boxes to another moment in the algorithm, but the benefit comes here:</p>

<ul>
<li>In order to keep your recursion tree narrow, give priority to cells that have the fewest possible values left, ideally only one. You can use python's <code>heapq</code> for this, and it should be applied to the queue that I mentioned in the first point.</li>
</ul>

<p>I leave the implementation for you, as it was not your question. There are lots of working examples on the net anyway.</p>
","2","0","204854","1897","2832","18633","60474867","60476810"
"60474942","<p><code>choice[1]</code> is doing <code>1[1]</code> which doesn't make sense. I think you want <code>li[choice][1]</code>. i.e.</p>

<pre><code>if li[choice][1] == ""t"":
</code></pre>
","1","1","2489","54","19","236","60474925","60474942"
"60475057","<p>You can not pass the list of URL.</p>

<pre><code>for url in urls:
   soup = BeautifulSoup(urllib.request.urlopen(url))
</code></pre>
","0","0","924","0","5","55","60474932","60475791"
"60475791","<p>@krishna has given you the answer. I'll give you another solution for reference only.</p>
<pre><code>from simplified_scrapy import Spider, SimplifiedDoc, SimplifiedMain, utils
class ImageSpider(Spider):
  name = 'archillect'
  start_urls = [&quot;https://archillect.com/1&quot;,&quot;https://archillect.com/2&quot;,&quot;https://archillect.com/3&quot;]
  def afterResponse(self, response, url, error=None, extra=None):
    try:
      # Create file name
      end = url.find('?') if url.find('?')&gt;0 else len(url)
      name = 'data'+url[url.rindex('/',0,end):end]
      # save image
      if utils.saveResponseAsFile(response,name,'image'):
        return None 
      else:
        return Spider.afterResponse(self, response, url, error)
    except Exception as err:
      print (err)
  def extract(self,url,html,models,modelNames):
    doc = SimplifiedDoc(html)
    urls = doc.listImg(url=url.url)
    return {'Urls':urls} 
SimplifiedMain.startThread(ImageSpider()) # Start
</code></pre>
<p>Here are more examples: <a href=""https://github.com/yiyedata/simplified-scrapy-demo/tree/master/spider_examples"" rel=""nofollow noreferrer"">https://github.com/yiyedata/simplified-scrapy-demo/tree/master/spider_examples</a></p>
","0","0","2231","56","0","189","60474932","60475791"
"60475006","<p>When you do this, you are just creating copies of list, n times. </p>

<p>So the inner lists here are actually the same list. When you modify the first one, you're also modifying the second. If you don't want that functionality, you can do this instead:</p>

<pre><code>a = [[1 for _ in range(2)] for _ in range(2)]
</code></pre>
","2","1","2489","54","19","236","60474939","60475039"
"60475039","<p>It's due to the fact, how Python handles objects in memory. When you are using the <code>* 2</code> to duplicate the list, Python does not create a separate list object in memory, it only copies the memory pointer for the second list position. Due to this behaviour when you mutate the first element, it affects the second too.
You can use the <code>id()</code> function to check the object ids within Python. You will see that <code>a[0]</code> and <code>a[1]</code> will have the same ids.</p>

<pre><code>&gt;&gt;&gt; a = [[1] * 2] * 2
&gt;&gt;&gt; a[0][0] = 2
&gt;&gt;&gt; a
[[2, 1], [2, 1]]
&gt;&gt;&gt; id(a[0])
140608840898432
&gt;&gt;&gt; id(a[1])
140608840898432
&gt;&gt;&gt; id(a[0]) == id(a[1])
True
</code></pre>
","0","1","71","14","0","6","60474939","60475039"
"60475001","<p>Use <a href=""http://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.core.groupby.GroupBy.transform.html"" rel=""nofollow noreferrer""><code>GroupBy.transform</code></a> for <code>max</code> values per groups compared by <code>Lenght</code> column by <a href=""http://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.eq.html"" rel=""nofollow noreferrer""><code>Series.eq</code></a> for equality and for map to <code>True-&gt;1</code> and <code>False-&gt;0</code> cast values to integers by <a href=""http://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.astype.html"" rel=""nofollow noreferrer""><code>Series.astype</code></a>:</p>

<pre><code>#added first row data by second row
df = pd.DataFrame({'Name': ['Karl', 'Karl', 'Billy', 'Abe', 'Karl', 'Billy', 'Abe', 'Karl', 'Billy'], 
               'Lenght': ['12.5', '12.5', '11', '12.5', '12', '11', '12.5', '10', '5'],
              'Try': [0,0,0,1,1,1,2,2,2],
              'Batch':[0,0,0,0,0,0,0,0,0]})
</code></pre>

<hr>

<pre><code>df['Lenght'] = df['Lenght'].astype(float)


m1 = df.groupby('Batch')['Lenght'].transform('max').eq(df['Lenght'])

df1 = df[m1]
m2 = df1.groupby('Name')['Try'].transform('nunique').eq(1)
m3 = ~df1.duplicated(['Name','Batch'])

df['new'] = ((m2 | m3) &amp; m1).astype(int)
print (df)
    Name  Lenght  Try  Batch  new
0   Karl    12.5    0      0    1
1   Karl    12.5    0      0    1
2  Billy    11.0    0      0    0
3    Abe    12.5    1      0    1
4   Karl    12.0    1      0    0
5  Billy    11.0    1      0    0
6    Abe    12.5    2      0    0
7   Karl    10.0    2      0    0
8  Billy     5.0    2      0    0
</code></pre>
","8","2","615041","23439","1483","126104","60474979","60475001"
"60475425","<p>You can rewrite your cycle like this:</p>

<pre><code>while counter &lt;= 71:
    plt.cla() # clean current axis
    plt.plot(t, packet(E0,t,w0,T,i),label = 't = %d' %(i))
    plt.ylim([-1.1, 1.1]) # establish limits for better visualization
    plt.savefig(""time%d.jpg"" %i)
    i += 1
    counter += 1
</code></pre>

<p>also you can create <a href=""https://matplotlib.org/3.1.3/gallery/animation/simple_anim.html"" rel=""nofollow noreferrer"">animation</a> according this example</p>
","0","0","26","0","0","2","60474987","60475425"
"60475370","<p>Change the line:</p>

<pre><code>X_train[:,8] = impC.fit_transform(X_train[:,8].reshape(-1,1))
</code></pre>

<p>to </p>

<pre><code>X_train[:,8] = impC.fit_transform(X_train[:,8].reshape(-1,1)).ravel()
</code></pre>

<p>and your error will disappear.</p>

<p>It's assigning imputed values back what causes issues on your code.</p>
","3","2","15516","968","609","1473","60475098","60475370"
"60475147","<p>The VGG16 architecture does not contain a dropout layer by default. You would need to insert a dropout layer in the model.</p>

<p>Here is a post I found useful to solve this:
<a href=""https://stackoverflow.com/questions/42475381/add-dropout-layers-between-pretrained-dense-layers-in-keras"">Add dropout layers between pretrained dense layers in keras</a></p>
","1","1","350","1196","4","32","60475122","60475147"
"60475681","<p>You <em>think</em> it exists, but when you call <code>message_widget()</code> it does not exist yet.</p>

<p>In fact, you are calling that function <em>before</em> this line:</p>

<pre><code>self.scrollAreaWidgetContents = QtWidgets.QWidget()
</code></pre>

<p>So, it <em>could</em> work if you put that function at least <em>after</em> creating that widget.</p>

<p><br/>
Unfortunately, there are other serious issues with your code.</p>

<p>The most important one is that you are modifying the output of pyuic to create your program, which is highly discouraged (and the <code>WARNING</code> message at the beginning should be a hint).</p>

<p>The python scripts generated from UI files should <strong>NEVER</strong> be edited, but used as an import in your actual program files. The most obvious reason is that as soon as you want to do some changes in the ui, you'll find yourself in the mess of trying to merge the new generated code with what you've written so far.</p>

<p>To know more about this, read the documentation about <a href=""https://www.riverbankcomputing.com/static/Docs/PyQt5/designer.html"" rel=""nofollow noreferrer"">using Designer</a>.</p>

<p>Other issues in your code:</p>

<ul>
<li>threading in Qt should be used with Qt's own QThread as much as possible;</li>
<li>UI objects should <em>never</em> be accessed nor modified by an external thread; to do that you have to use a QThread, and communicate with the main Qt thread using signals and slots;</li>
<li><code>QLabel.text()</code> does not accept parameters, as it is used to access the text property; to set the text of a label, use <code>setText()</code>;</li>
</ul>
","1","0","18223","101","602","1897","60475128","60475681"
"60475388","<blockquote>
  <p>No. But I think except Exception as e, catch all errors? Am I wrong?</p>
</blockquote>

<p>All built-in, <code>non-system-exiting</code> exceptions are derived from <code>Exception</code> class. All user-defined exceptions should also be derived from this class.</p>

<p>However, The <code>FileNotFoundError</code> exception is subclasses of <a href=""https://docs.python.org/3/library/exceptions.html#OSError"" rel=""nofollow noreferrer"">OSError</a>.</p>

<p>Try this:</p>

<pre><code>try:
    image = loadImage(filename)
except OSError as e:
   print(""Error"",e)
</code></pre>

<p>A small example code:</p>

<pre><code>try:
    image = open(""i_donot_exist"")
except OSError as e:
   print(""Exception Raised"", e)
</code></pre>

<p>Outputs:</p>

<pre><code>Exception Raised [Errno 2] No such file or directory: 'hehe'
</code></pre>

<blockquote>
  <p>Any way to catch all types of errors? Programmer defined, built-in defined and all types on earth?</p>
</blockquote>

<p>You need to put multiple <code>except</code> blocks to catch all type of exception. See an example below:</p>

<pre><code>try:
    f = open('myfile.txt')
    s = f.readline()
    i = int(s.strip())
except IOError as (errno, strerror):
    print ""I/O error({0}): {1}"".format(errno, strerror)
except ValueError:
    print ""Could not convert data to an integer.""
except:
    print ""Unexpected error:"", sys.exc_info()[0]
    raise
</code></pre>

<p>You can also catch multiple exceptions in one line. 
From <a href=""https://docs.python.org/3/tutorial/errors.html#handling-exceptions"" rel=""nofollow noreferrer"">Python Documentation</a>, An except clause may name multiple exceptions as a parenthesized tuple. See <a href=""https://stackoverflow.com/questions/6470428/catch-multiple-exceptions-in-one-line-except-block"">this</a> link for more information. For example,</p>

<pre><code>try:
    may_raise_specific_errors():
except (SpecificErrorOne, SpecificErrorTwo) as error:
    handle(error) # might log or have some other default behavior...
</code></pre>
","5","1","7385","7807","4","901","60475216","60475388"
"60475478","<p>You can just print the whole traceback error with importing <code>tracaback</code> like this : </p>

<pre><code>import traceback
try:
    #code that might produce error
except:
    traceback.print_exc()
    pass
</code></pre>

<p>This actually doesn't catch the raised exceptions - the errors are shown in cli likewise if there were no try except block.</p>
","0","0","6314","2100","843","1012","60475216","60475388"
"60485619","<p>I think you need to:</p>

<ul>
<li>Derive a class from <a href=""https://pyftpdlib.readthedocs.io/en/latest/api.html#pyftpdlib.filesystems.AbstractedFS"" rel=""nofollow noreferrer""><code>AbstractedFS</code></a>.</li>
<li>Reimplement its <a href=""https://pyftpdlib.readthedocs.io/en/latest/api.html#pyftpdlib.filesystems.AbstractedFS.listdir"" rel=""nofollow noreferrer""><code>listdir</code> method</a>.</li>
<li>Assign your implementation of <code>AbstractedFS</code> to <code>FTPHandler.abstracted_fs</code>.</li>
</ul>

<pre><code>class FilteredFS(AbstractedFS):
    def listdir(self, path):
        files = os.listdir(path)
        # filter as you need
        return files

handler = FTPHandler
# ...
handler.abstracted_fs = FilteredFS
server = FTPServer(('', 21), handler)
server.serve_forever()
</code></pre>
","0","0","144036","8283","6276","21385","60475241","60485619"
"60475330","<p>You can simply override the <code>get_context_data</code>. You can let the Django <code>ListView</code> handle one of the lists, and handle the other one yourself:</p>

<pre><code>class ChatOverView(ListView):
    model = Message
    <b>context_object_name = 'sent'</b>
    template_name = 'chat/home-chat.html'

    def <b>get_queryset</b>(self):
        return super().get_queryset().filter(
            sender=self.request.user
        )

    def <b>get_context_data</b>(self, *args, **kwargs):
        context = super().get_context_data(*args, **kwargs)
        context.update(
            received=Message.objects.filter(receiver=self.request.user)
        )
        return context</code></pre>
","4","1","312807","16628","2518","41861","60475247","60475330"
"60475292","<p><code>n in val</code> checks whether the value <code>n</code> is in the iterable <code>val</code>. The correct check here is <code>n == val</code></p>
","0","1","188","57","14","18","60475249","60475292"
"60475584","<p>You can use a GUI automation package like pyautogui. Explanation in code comments.</p>

<pre><code>import pyautogui
import time

# To simulate a Save As dialog. You can remove this since you'll be saving/downloading a file from a link
pyautogui.hotkey('ctrl', 's')
# Wait for the Save As dialog to load. Might need to increase the wait time on slower machines
time.sleep(1)
# File path + name
FILE_NAME = 'C:\\path\\to\\file\\file.ext'
# Type the file path and name is Save AS dialog
pyautogui.typewrite(FILE_NAME)
#Hit Enter to save
pyautogui.hotkey('enter')
</code></pre>
","3","4","1541","222","23","129","60475367","60475584"
"60544899","<p>Solved it by editing the .jason file and providing the right path to the environment executable.</p>
","0","1","168","43","2","28","60475373","60544899"
"60475432","<p>Try this:</p>

<pre><code>def outside_variable_show(status):
    global crrnt_nmbr
    if status == 1:
        crrnt_nmbr = crrnt_nmbr + 1
        print (crrnt_nmbr)

status = 1
crrnt_nmbr = 0
print (crrnt_nmbr)
outside_variable_show(1)
</code></pre>
","0","0","484","430","29","54","60475398","60475432"
"60497203","<p>1) RS232 is a combination of UART with certain voltage levels for the high and low (i.e. +3 to +15V and -3 to -15V afaik. Never ever connect a RS232 adapter to standard 3.3V  or 5V devices e.g. UART, TTL-UART etc. The Lattice Semiconductor document just plainly missuses the term RS232 - try not to fall for it (IMHO the performance of their products strongly anticorrelates with the quality of their documentation and support). </p>

<p>2) page 19 of the linked doc shows the sections: Ordering Information, Technical Support Assistance, Revision History. Shifted by one page?</p>

<p>3) The FT2232H can be used in multiple modes. This depends on the way how it is addressed and of the settings flashed to the EEPROM connected to it (on the dev board is one placed but the FT2232H can be used without as well). The dev board is in the standard configuration designed to be programmed via the JTAG pins and the FT2232H is opened via the D2XX driver by lattice diamond. For that reason they flashed the EEPROM with settings which prohibits the use as virtual com port. The FTDI flash software can be used to change that behavior - for each bank seperately.</p>

<p>4) The solder bridges can be used to rearrange the connections (e.g. if one wants to change from the JTAG interface to the SPI or I2C programming interface). In your case you most likely want to place bridges on R14 and R15 to make the proper connection for an UART link to the port B of the FT2232H. EDIT: <em>This way Port A can be used in JTAG mode to program the FT2232H and port B to communicate via e.g. UART or even other modes like the fast opto or the parallel bus/FIFO - if the correct bridges are soldered. Changing the EEPROM settings might be still required to make Port B visible as VCP if one want to avoid the usage of the D2XXX driver</em>.</p>
","4","1","578","7","2","76","60475411","60497203"
"60479016","<p>Two issues.</p>

<ul>
<li>The CommCtrl.h header uses a 1-byte packing.  Add <code>_pack_ = 1</code> before <code>_fields_</code> definition in all structures.</li>
<li>The two <code>_TASKDIALOG_BUTTON</code> fields should be type <code>ctypes.POINTER(_TASKDIALOG_BUTTON)</code>.</li>
</ul>

<p>I tracked these down by using a C program to print the size of the structure and the offsets of a few fields and printed the same info in Python:</p>

<pre><code>#include &lt;windows.h&gt;
#include &lt;commctrl.h&gt;
#include &lt;stdio.h&gt;
#include &lt;stdlib.h&gt;

int main()
{
    printf(""%zu\n"",sizeof(TASKDIALOGCONFIG));
    printf(""%zu\n"",offsetof(TASKDIALOGCONFIG,pszWindowTitle));
    printf(""%zu\n"",offsetof(TASKDIALOGCONFIG,pszMainInstruction));
    printf(""%zu\n"",offsetof(TASKDIALOGCONFIG,pszFooter));
}
</code></pre>

<pre><code>tdc = TaskDialogConfig()
print(tdc.cbSize)
print(TaskDialogConfig.pszWindowTitle)
print(TaskDialogConfig.pszMainInstruction)
print(TaskDialogConfig.pszFooter)
</code></pre>
","1","2","130384","1343","1379","5540","60475469","60479016"
"60475664","<p>You can use <code>requests</code> to download files and <code>apply</code> to apply a function to each row of the dataframe:</p>

<pre><code>import os
import requests


def download(row):
   filename = os.path.join(root_folder,
                           '_'.join([row['Color'],
                                     row['Gender'],
                                     row['Model']],
                           str(row.name) + im_extension)

   # create folder if it doesn't exist
   os.makedirs(os.path.dirname(filename), exist_ok=True)

   url = row.link
   print(f""Downloading {url} to {filename}"")
   r = requests.get(url, allow_redirects=True)
   with open(filename, 'wb') as f:
       f.write(r.content)

root_folder = '/path/to/download/folder'
im_extension = '.jpg'  # or whatever type of images you are downloading

df.apply(download, axis=1)
</code></pre>
","0","1","1630","315","21","115","60475568","60475664"
"60477554","<blockquote>
  <p><strong>Question</strong>: first I will select that rectangle with ""Button 1"" and then I will right-click and delete</p>
</blockquote>

<ol>
<li>Create the rectangles ...</li>
</ol>

<pre><code>        canvas.create_rectangle(75, 75, 100, 100, tags=""DnD"")
        canvas.create_rectangle(100, 100, 125, 125, tags=""DnD"")
</code></pre>

<ol start=""2"">
<li>Bind event <code>""&lt;ButtonPress-1&gt;""</code> to the <code>Canvas</code>  </li>
</ol>

<pre><code>        canvas.bind(""&lt;ButtonPress-1&gt;"", self.on_button_1)
</code></pre>

<ol start=""3"">
<li>Prepare the <code>popup</code>, to delete <code>items</code> with <code>tag='DELETE'</code></li>
</ol>

<pre><code>        self.popup.add_command(label=""delete"", 
                               command=lambda: canvas.delete(canvas.find_withtag('DELETE')))
</code></pre>

<ol start=""4"">
<li>Define the event <code>""&lt;ButtonPress-1&gt;""</code> callback.<br>
Here, the matching item get added <code>tags='DELETE'</code> and outlined <code>'red'</code>.</li>
</ol>

<pre><code>    def on_button_1(self, event):
        iid = canvas.find_enclosed(event.x - 26, event.y - 26, event.x + 26, event.y + 26)
        canvas.itemconfigure(iid, tags='DELETE', outline='red')
</code></pre>
","0","0","13198","207","7779","3141","60475640","60477554"
"60476002","<p>You can do this with <a href=""https://docs.python.org/3/library/re.html"" rel=""nofollow noreferrer""><code>re</code></a> regular expression module:</p>

<pre><code>import re

#assume that resp is response from API
resp = ""NetRange: 185.0.0.0 - 185.255.255.255 CIDR: 185.0.0.0/8 NetName: RIPE-185 NetHandle: NET-185-0-0-0-1 Parent: () NetType: Allocated to RIPE NCC OriginAS: Organization: RIPE Network Coordination Centre (RIPE) RegDate: 2011-01-04 Updated: 2011-02-08 Comment: These addresses have been further assigned to users in Comment: the RIPE NCC region. Contact information can be found in Comment: the RIPE database at http://www.ripe.net/whois Ref: https://rdap.arin.net/registry/ip/185.0.0.0 ResourceLink: https://apps.db.ripe.net/search/query.html ResourceLink: whois.ripe.net OrgName: RIPE Network Coordination Centre OrgId: RIPE Address: P.O. Box 10096 City: Amsterdam StateProv: PostalCode: 1001EB Country: NL RegDate: Updated: 2013-07-29 Ref: https://rdap.arin.net/registry/entity/RIPE ReferralServe ""

regex = r""OrgName:\s(.+?)\sOrgId""
orgName = re.findall(regex, resp)[0]
print(orgName) #RIPE Network Coordination Centre
</code></pre>
","0","0","618","176","3","64","60475655","60476002"
"60476379","<p>This is a simple parser of the data you are getting:</p>

<pre><code>def parse_reply(data):
    tmp = []
    result = {}
    kvdata = data.split()
    key = kvdata[0]
    for e in kvdata[1:]:
        if e.endswith(':'):
            result[key] = "" "".join(tmp)
            key = e[:-1]
            tmp.clear()
        else:
            tmp.append(e)
    return result


rep = parse_reply(data)
print(rep['OrgName'])

</code></pre>
","0","0","1174","59","8","101","60475655","60476002"
"60475733","<p>In the dockerfile add:</p>

<pre><code>ADD /path/to/local/file /path/inside/docker
</code></pre>

<p>or </p>

<pre><code>COPY /path/to/local/file /path/inside/docker
</code></pre>
","0","1","1630","315","21","115","60475682","60475733"
"60476147","<p>After some additional searching I found out that the logging level that is set for the handler is separate from the level that is set for the logger.</p>

<p>meaning, that adding:</p>

<pre><code>logger.setLevel(logging.INFO)
</code></pre>

<p>fixes the problem.</p>
","0","0","2672","151","11","191","60475707","60476147"
"60475862","<p>you can find the line that has 5 fields by doing:</p>

<pre><code>with open(csv_file, 'r') as f:
   for i, l in f.readlines():
       if len(l.split(',') &gt; 4:
           print(i)
</code></pre>

<p>then open the file with an editor and correct it</p>
","0","2","1630","315","21","115","60475772","60475862"
"60475982","<p>It's hard to say for sure without seeing the data, but it seems that the line 33 of your file has 5 fields instead of 4. If you think you can import the data without this line (and other lines that may have the same problem), you can try this:</p>

<pre><code> df = pd.read_csv('feedPreview.csv', error_bad_lines=False)
</code></pre>

<p>As said in pandas documentation <a href=""https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html"" rel=""nofollow noreferrer"">here</a>:</p>

<p>""Lines with too many fields (e.g. a csv line with too many commas) will by default cause an exception to be raised, and no DataFrame will be returned. If False, then these “bad lines” will dropped from the DataFrame that is returned.""</p>
","0","1","303","301","1","70","60475772","60475862"
"60475876","<p>Use <a href=""http://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.str.extract.html"" rel=""nofollow noreferrer""><code>Series.str.extract</code></a> with escape <code>\.</code> because special regex character, then remove possible missing values if no match by <a href=""http://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.dropna.html"" rel=""nofollow noreferrer""><code>Series.dropna</code></a> and last convert output to list:</p>

<pre><code>df = pd.DataFrame({'a':range(3)}, index=['point.subclase.optimum.R31.done',
                                         'point.subclase',
                                         'point.subclase.optimum.R98.done'])
print (df)
                                 a
point.subclase.optimum.R31.done  0
point.subclase                   1
point.subclase.optimum.R98.done  2

L = (df.index.str.extract(r'point\.subclase\.optimum\.(.*)\.done', expand=False)
             .dropna()
             .tolist())
print (L)
['R31', 'R98']
</code></pre>
","1","1","615041","23439","1483","126104","60475845","60475876"
"60476065","<p>25th percentile is ""bottom fourth out of those who took the thing"", and 75th percentile is ""top fourth"", regardless of the actual score. So what you need to do is sort the list, then take a slice out of the middle, based on the index.</p>

<p>Here's what I think you're trying to do:</p>

<pre><code>import math

students = ['student1','student2','student3','student4','student5','student6','student7','student8','student9','student10']
marks = [45, 78, 12, 14, 48, 43, 45, 98, 35, 80]

# zip() will bind together corresponding elements of students and marks
# e.g. [('student1', 45), ('student2', 78), ...]
grades = list(zip(students, marks))

# once that's all in one list of 2-tuples, sort it by calling .sort() or using sorted()
# give it a ""key"", which specifies what criteria it should sort on
# in this case, it should sort on the mark, so the second element (index 1) of the tuple
grades.sort(key=lambda e:e[1])
# [('student3', 12), ('student4', 14), ('student9', 35), ('student6', 43), ('student1', 45), ('student7', 45), ('student5', 48), ('student2', 78), ('student10', 80), ('student8', 98)]

# now, just slice out the 25th and 75th percentile based on the length of that list
twentyfifth = math.ceil(len(grades) / 4)
seventyfifth = math.floor(3 * len(grades) / 4)
middle = grades[twentyfifth : seventyfifth]

print(middle)
# [('student6', 43), ('student1', 45), ('student7', 45), ('student5', 48)]
</code></pre>

<p>You have 10 students here, so how you round <code>twentyfifth</code> and <code>seventyfifth</code> is up to you (I chose to include those strictly those within 25-75th percentile, by rounding 'inwards' - you could do the opposite by switching <code>ceil</code> and <code>floor</code>, and get your final list to have two more elements in this case - or you could round them both the same way).</p>
","1","0","18009","875","52","1348","60475885","60476151"
"60476151","<p>A small addition to your code can solve this issue, below is the solution</p>

<pre><code>Students = ['student1','student2','student3','student4','student5','student6','student7','student8','student9','student10']
Marks = [45, 78, 12, 14, 48, 43, 45, 98, 35, 80]

Students,Marks=zip(*sorted(zip(Students, Marks))) #addition to your code

for i in range(0,10):
    if Marks[i]&gt;25 and Marks[i]&lt;75: 
        print(Students[i],Marks[i])

</code></pre>
","0","1","673","9","55","92","60475885","60476151"
"60476223","<p>Looks like <a href=""https://stackoverflow.com/users/2648811/green-cloak-guy"">@Green Cloak Guy</a> answer is the correct. But anyway, if what you want is to get the data of students with marks between two ranges I'll do it like this:</p>

<pre><code># Get a dict of students with it's mark, filtered by those with mark between 25 and 75
students_mark = {s: m for s, m in zip(Students, Marks) if m &gt; 25 and m &lt; 75}
# Sort results
res = dict(sorted(students_mark.items(), key=lambda i: i[1])
# res: {'student9': 35, 'student6': 43, 'student1': 45, 'student7': 45, 'student5': 48}

# In one line
res = {s: m for s, m in sorted(zip(Students, Marks), key=lambda i: i[1]) if m &gt; 25 and m &lt; 75}
</code></pre>

<p>As a summary: first link each student with it's score, and then filter and sort. I stored the result as dictionary because it seems more convinient.</p>
","0","1","133","500","0","11","60475885","60476151"
"60476089","<p>A bit elaborated from my comment:
You could first merge all dataframes with <code>pd.concat()</code>, then select the matching rows and create new dataframes from them:</p>

<pre><code>merged_frame = pd.concat(df_countries)
country_dict = {}
for country in country_names:
    country_dict[country] = merged_frame[merged_frame['Country'] == country]
</code></pre>

<p>Optionally you can also call <code>country_dict[country].reset_index()</code> to fix the indices of the new frames.</p>
","0","1","515","63","7","46","60475987","60476089"
"60476592","<p>As @Vaishali commented, this is <code>groupby</code> and <code>cumsum</code>. You may want to do <code>sort_values</code> to make sure that the data is sorted in order, although it appears already so:</p>

<pre><code># sort by `c_id` and `a_date`
df = df.sort_values(['c_id','a_date'])

df['balance'] = df.groupby('c_id')['c_action'].cumsum()
</code></pre>

<p>Output:</p>

<pre><code>        a_date  c_id c_name  c_action  balance
0   2016-01-01     1   King      1000     1000
1   2016-01-02     1   King      -200      800
2   2016-01-03     1   King       100      900
3   2016-01-04     1   King      -400      500
4   2016-01-05     1   King       200      700
5   2016-01-06     1   King      -200      500
6   2016-01-01     2  Smith      1000     1000
7   2016-01-02     2  Smith      -300      700
8   2016-01-03     2  Smith      -600      100
9   2016-01-04     2  Smith       100      200
10  2016-01-05     2  Smith      -100      100
</code></pre>
","0","1","112902","3825","17","9360","60476010","60476592"
"60476086","<p>Try:</p>

<pre class=""lang-py prettyprint-override""><code>train[[""Minimum Temperature"", ""Maximum Temperature""]]=train[""Cellar Temperature""].str.split(""-"", expand=True, n=1)
</code></pre>

<p><code>str.split()</code> will split string by provided delimiter - <code>-</code> in this case. Then <code>expand</code> will explode splitted array, so every element will go into separate column. Then <code>n=1</code> will limit max splits to 1 (otherwise you would get an error, in case if you would have more than 1 hyphen in any cell).</p>
","0","1","11365","152","50","745","60476022","60476086"
"60476486","<p>You can use <code>extract</code> to get both:</p>

<pre><code>df['temp'].str.extract('(?P&lt;minimum&gt;\d+)-(?P&lt;maximum&gt;\d+)')
</code></pre>

<p>Output:</p>

<pre><code>   minimum maximum
0       35      40
1       35      40
2       40      45
3       40      45
4       45      50
5       40      45
6       40      45
7      NaN     NaN
8       40      45
9      NaN     NaN
10      40      45
11      40      45
12      35      40
</code></pre>
","0","1","112902","3825","17","9360","60476022","60476086"
"60484870","<p>To directly correct your code, try</p>

<pre><code>train[""Maximum Temperature""] = train[""Cellar Temperature""].apply(lambda x: np.nan if pd.isnull(x) else x.split(""-"")[1])
</code></pre>
","0","0","106","33","0","4","60476022","60476086"
"60476165","<p>Open your file in append mode:</p>

<pre><code>with open(""Output.txt"", ""ab"") as text_file:
</code></pre>
","0","3","885","79","6","101","60476093","60476165"
"60480634","<p>Matplotlib's plot can draw a curve over any existing plot. To plot the logistic function, just plot <code>1 / (1 + exp(-beta0 - beta1 * x))</code> where beta0 and beta1 are the result of fitting a logistic function to the given data. Scikit Learn's <code>LogisticRegression</code> is a function that can fit such a function and return the parameters:</p>

<pre><code>import matplotlib.pyplot as plt
from sklearn.linear_model import LogisticRegression
import seaborn as sns
import pandas as pd
import numpy as np

def draw_logistic_regression_curve(beta0, beta1, x, **kwargs):
    y = 1 / (1 + np.exp(-beta0 - beta1 * x))
    plt.plot(x, y, '-', **kwargs)


hours = np.array([0.50, 0.75, 1.00, 1.25, 1.50, 1.75, 1.75, 2.00, 2.25, 2.50, 2.75,
                  3.00, 3.25, 3.50, 4.00, 4.25, 4.50, 4.75, 5.00, 5.50])
passed = np.array([0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1])
df = pd.DataFrame({""hours_study"": hours, ""passed"": passed})
sns.scatterplot(df.hours_study, df.passed)

clf = LogisticRegression().fit(hours.reshape(-1, 1), passed)
beta0 = clf.intercept_ # -3.13952411
beta1 = clf.coef_[0] # 1.14860386
x = np.linspace(min(hours) - 0.5, max(hours) + 0.5, 500)
draw_logistic_regression_curve(beta0, beta1, x, color='crimson', label=""Sklearn's default estimate"")
draw_logistic_regression_curve(-4.0777, 1.5046, x, color='limegreen', label=""Wikipedia's estimate"")
plt.legend(loc='center right')
plt.show()
</code></pre>

<p><a href=""https://i.stack.imgur.com/d7QQL.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/d7QQL.png"" alt=""resulting plot""></a></p>
","2","1","34973","1481","136","1951","60476203","60480634"
"60477081","<p>As @Pedro Lobito noted, the data should be adjusted with stocks split times. So, after using <code>get_daily_adjusted</code> function and plotting <code>'5. adjusted close'</code> values, the result is as expected:
<a href=""https://i.stack.imgur.com/WTbJA.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/WTbJA.png"" alt=""enter image description here""></a></p>

<p>Code:</p>

<pre class=""lang-py prettyprint-override""><code>from alpha_vantage.timeseries import TimeSeries
import matplotlib.pyplot as plt
ts = TimeSeries(key='YOUR_API_KEY', output_format='pandas')

data, meta_data = ts.get_daily_adjusted(symbol='AAPL', outputsize='full')
plt.figure(figsize=(10,6))

data['5. adjusted close'].plot()

plt.grid(linestyle='-', linewidth=2)
plt.title('AAPL stock price daily')
plt.savefig('sample.png')
plt.show()
</code></pre>
","0","3","4549","1302","28","299","60476268","60477081"
"60476442","<p>Generally <code>matplotlib</code> do not show all labels, if there is a lof them, as it would look cluttered. If you want to show all dates nonetheless you might add following line:</p>

<pre><code>plt.xticks(your_full_list_of_dates)
</code></pre>

<p>above:</p>

<pre><code>plt.show()
</code></pre>

<p><a href=""https://matplotlib.org/api/pyplot_api.html#matplotlib.pyplot.xticks"" rel=""nofollow noreferrer"">xticks</a> might be also used for styling.</p>
","2","1","8910","0","0","376","60476274","60476442"
"60477417","<p>Yeah, you are right. We need to give the path to the file which needs to be uploaded. 
<code>request.files['file']</code> gives the file pointer and using that pointer, you can save the file into a location. The path where the file will be saved can be done using <code>os.path.join(UPLOAD_FOLDER, f.filename)</code> as shown below:</p>

<pre><code>@app.route(""/upload"", methods=['POST'])
def upload():
    if request.method == ""POST"":
        f = request.files['file']
        file_path=os.path.join(UPLOAD_FOLDER, f.filename) # path where file can be saved
        f.save(file_path)
        upload_file(file_path, BUCKET) # send the file path
        return redirect(""/storage"")
</code></pre>

<p>After that, as it can be seen, I called <code>upload_file</code> method which will write to s3 and the code for that function is given below:</p>

<pre><code>BUCKET = ""flaskdrive""
AWS_ACCESS_KEY=""aws_access_key""
AWS_SECERT_KEY=""aws_secret_key""

def upload_file(file_name, bucket):
    """"""
    Function to upload a file to an S3 bucket
    """"""
    object_name = file_name
    s3_client = boto3.client('s3',
                             aws_access_key_id=AWS_ACCESS_KEY,
                             aws_secret_access_key=AWS_SECERT_KEY)
    response = s3_client.upload_file(filename=file_name, bucket=bucket, key=object_name)

    return response
</code></pre>

<p>Let me know if this helps!</p>
","1","3","1444","3","8","195","60476326","60477417"
"60476530","<p>You have to get the value of data attribute from the link. You can try this code -</p>

<pre class=""lang-py prettyprint-override""><code>import requests
from bs4 import BeautifulSoup

raw = requests.get('https://www.iproperty.com.my/property/findanagent.aspx?ty=as&amp;ak=&amp;rk=&amp;pg=1&amp;rmp=10&amp;st=KL&amp;ct=&amp;st1=&amp;ct1=#40091').text
raw = raw.replace(""&lt;/br&gt;"", """")

soup = BeautifulSoup(raw, 'html.parser')

import re
#['data-content'])[0][1:][:-1] ## note sure what is this
# for d in soup.find_all('a',{'class':'csagentphonelead'}):
name = [x.text.strip().split(""\r\n"")[-1].strip() for x in soup.find_all(""p"", class_='box-listing_agentCS')]
phone = [x['data'].strip().split(""\r\n"")[-1].strip() for x in soup.find_all(""a"", class_='csagentphonelead')] 
website = [x['data'].strip().split(""\r\n"")[-1].strip() for x in soup.find_all(""a"", class_='csagentemaillead')] 

num_page_items = len(name)
with open('results180.csv', 'a') as f:
    for i in range(num_page_items):
        f.write(name[i] + "","" + phone[i] + "","" + website[i] + "","" + ""\n"")
</code></pre>
","0","1","536","22","2","61","60476361","60476530"
"60482516","<p>This gets you a list of dataframes that match the content of the dataframe <code>sub</code>, but for all results of the <code>.groupby()</code>:</p>

<pre><code>import numpy
import pandas

source = pandas.DataFrame(
    {'id_1': [1, 2, 1, 1, 1, 1, 1, 2, 2, 2, 2],
     'id_2': [1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2],
     'v_1': [2, 1, 1, 3, 2, 1, 2, 4, 1, 1, 2],
     'v_2': [1, 1, 1, 1, 2, 2, 2, 1, 1, 2, 2],
     'v_3': [3, 3, 3, 3, 4, 4, 4, 3, 3, 3, 3]})


def add_v4(df):
    df['v_4'] = numpy.where(df['v_1'] == df['v_2'].shift(), 'A', numpy.where(df['v_1'] == df['v_3'].shift(), 'B', 'C'))
    return df


dfs = [add_v4(pandas.DataFrame(slice)) for _, slice in source.groupby(by=['id_1', 'id_2'])]
print(dfs)
</code></pre>

<p>About this line:</p>

<pre><code>dfs = [add_v4(pandas.DataFrame(slice)) for _, slice in source.groupby(by=['id_1', 'id_2'])]
</code></pre>

<p>It's a list comprehension that gets all the slices from the <code>groupby</code> and turns them into actual new dataframes before passing them to <code>add_v4</code>, which returns the modified dataframe to be added to the list.</p>
","2","1","12065","76","218","1202","60476373","60482516"
"60476422","<p>Use <a href=""http://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.factorize.html"" rel=""nofollow noreferrer""><code>factorize</code></a> with both columns joined with <code>-</code> and converted to strings, because need combination values of both columns:</p>

<pre><code>df['group_num'] = pd.factorize(df['room'].astype(str) + '-' + df['box_num'].astype(str))[0]
</code></pre>

<p>Or convert both columns to <code>list of tuple</code>s by <code>map</code>:</p>

<pre><code>df['group_num'] = pd.factorize(list(map(tuple, df[['room','box_num']].values)))[0]
</code></pre>

<hr>

<pre><code>print (df)
      ml  room  box_num  group_num
0   1526   106       11          0
3   1608   106        9          1
9   1601   106        8          2
13  1603   106        8          2
17  1604   106        8          2
22  1558   106        5          3
24  1556   106        2          4
28  1557   106        2          4
32  1534     9       19          5
39  1552     9      104          6
43  1551     9      105          7
49  1550     9      102          8
57  1539     9       23          9
65  1546     9       23          9
73  1560     9       28         10
</code></pre>

<p><strong>Detail</strong>:</p>

<pre><code>print (df['room'].astype(str) + '-' + df['box_num'].astype(str))
0     106-11
3      106-9
9      106-8
13     106-8
17     106-8
22     106-5
24     106-2
28     106-2
32      9-19
39     9-104
43     9-105
49     9-102
57      9-23
65      9-23
73      9-28
dtype: object

print (list(map(tuple, df[['room','box_num']].values)))
[(106, 11), (106, 9), (106, 8), (106, 8), (106, 8), (106, 5), 
 (106, 2), (106, 2), (9, 19), (9, 104), (9, 105), (9, 102), (9, 23), (9, 23), (9, 28)]
</code></pre>
","0","1","615041","23439","1483","126104","60476390","60476422"
"60477015","<p>You are indexing the dataframe along columns. So when using lambda, specify the axis as 1:</p>

<pre><code>df['diffval'] = df.apply(lambda x: x['diffval'] * -1 if x['GL'].str[0] in ['4', '0'] else x['diffval'], axis=1)
</code></pre>

<p>Just noticed your comment,</p>

<p>You do not need to specify .str as it is already a string.</p>

<pre><code>df['diffval'] = df.apply(lambda x: x['diffval'] * -1 if x['GL'][0] in ['4', '0'] else x['diffval'], axis=1)
</code></pre>

<p>If it is required to convert to string, you may use, </p>

<pre><code>df['diffval'] = df.apply(lambda x: x['diffval'] * -1 if str(x['GL'])[0] in ['4', '0'] else x['diffval'], axis=1)
</code></pre>

<p>Does this work, or am I missing something?</p>
","1","1","482","16","2","43","60476396","60477015"
"60477245","<p>For your problem, you don't need to use the <code>apply</code> command (which is slow). You can solve this using <code>loc</code>. <br> 
Select rows where <strong>GL</strong> starts with '4' or '0' and then multiply to -1 the <strong>diffval</strong> column</p>

<pre><code>mask = df['GL'].str[0].isin(['4','0'])

df.loc[mask, 'diffval'] = df.loc[mask, 'diffval'] * -1
</code></pre>
","0","1","2311","369","31","122","60476396","60477015"
"60477123","<p>Found a possible solution with some playing around from the dictionary output from the original flatten_json() function. Not sure how efficient this is but it seems to work:</p>

<pre><code>dictionary = flatten_json(data2)
all_values = list(dictionary.values())

index_list = []
for key in dictionary:
    x = tuple(key.split(""-""))
    index_list.append(x)

index = pd.MultiIndex.from_tuples(index_list)

df = pd.Series(all_values, index=index).to_frame()
</code></pre>

<p>Any suggestions or comments welcome...</p>
","2","0","143","0","0","9","60476491","60477123"
"60477711","<p>You can also flatten out the dictionary into a list of lists, make a DataFrame out of it, and then set the index to get the required output:</p>

<pre><code>def flatten_json(dictionary):
    flattened = []

    def flatten(data, name=''):
        if type(data) is dict:
            for d in data:
                flatten(data[d], name + d + ',')
        elif type(data) is list:
            i = 0
            for l in data:
                flatten(l, name[:-1] + '_' + str(i) + ',')
                i += 1
        else:
            flattened.append((name[:-1] + ',' + data).split(','))

    flatten(dictionary)
    return flattened

list_obj=flatten_json(dict_obj)
pd.DataFrame(list_obj).set_index(list(range(len(list_obj[0])-1)))
</code></pre>

<p>Works fine for the example given and is less complicated even.</p>
","0","0","46","9","0","2","60476491","60477123"
"60502645","<p>The issue was resolved, in the Jenkins the full path is different than I thought it was.
Anyway, ran pwd and saw where I was - added the path where the file was and worked.</p>

<p>Thanks friends !</p>
","0","0","47","0","0","16","60476494","60502645"
"60485745","<p>It's probably more difficult for the network to find the matching class between 20 classes than between two classes. </p>

<p>For example if you give it a dog image and it need to classify it between cat, dog and horse it could send 60% cat, 30% dog 10% horse and then be wrong
while if it needs to classify it only between dog and horse it would give may be 75% dog, 25% horse and then be wright. </p>

<p>The finetunnig will also be longer so you could have better result if you train it longer with the 20 classes if you haven't stop it after convergence but after a fix number of epochs.</p>
","2","0","592","10","1","21","60476501","60485745"
"60477345","<p><strong>Assuming that you don't have any strange filenames:</strong></p>

<pre><code>find . \! -name '.' -type d -prune | 
     grep  -v -f ids.txt | 
     xargs echo rm -rf 
</code></pre>

<p>This should work with any POSIX <a href=""https://pubs.opengroup.org/onlinepubs/009695399/utilities/find.html"" rel=""nofollow noreferrer"">find</a>/<a href=""https://pubs.opengroup.org/onlinepubs/009695399/utilities/grep.html"" rel=""nofollow noreferrer"">grep</a>/<a href=""https://pubs.opengroup.org/onlinepubs/009695399/utilities/xargs.html"" rel=""nofollow noreferrer"">xargs</a>. Remove the <code>echo</code> when you are satisfied, remove <code>-v</code> to delete the matching directories.</p>

<ul>
<li><strong>find</strong> - search for files

<ul>
<li><code>\! -name '.'</code> - file is not named '.', so it doesn't include the root directory (you might need to adapt that if you run this from another directory)</li>
<li><code>-type d</code> - select only directories</li>
<li><code>-prune</code> - once found, don't enter a directory, just print it</li>
</ul></li>
<li><strong>grep</strong> - filter

<ul>
<li><code>-f ids.txt</code> - load patterns from file ids.txt</li>
<li><code>-v</code> - return lines that don't match</li>
</ul></li>
<li><strong>xargs</strong> - run a command with arguments from standard input</li>
</ul>

<p><strong>Note:</strong> if you run find from another directory, you will need to change <code>-name</code> to match the base directory where your directories are. Example:</p>

<pre><code>$ find ./60476598/ \! -name '.' -type d -prune
./60476598/
$ find ./60476598/ \! -name '60476598' -type d -prune
./60476598/chain_asd123
./60476598/hello?_1effaj
$ find /home/sorin/tmp/60476598/ \! -name '60476598' -type d -prune
/home/sorin/tmp/60476598/chain_asd123
/home/sorin/tmp/60476598/hello?_1effaj
</code></pre>

<p>In this case, I have my test setup in a directory named 60476598 (the question id). If you don't take that in account, the you can see that it will return only the base directory, but if you change the <code>-name '.'</code> to <code>-name '60476598'</code> it will work as expected. You have to use just the name of the directory, not the entire path.  </p>

<p><strong>A slightly better approach</strong>, if you have a set of utilities that support null separation of records:</p>

<pre><code>find . \! -name '.' -type d -prune -print0 | 
     grep -v -z -f ids.txt | 
     xargs --null echo rm -rf
</code></pre>

<p>In this case <a href=""https://www.gnu.org/software/findutils/manual/html_mono/find.html#Print-File-Name"" rel=""nofollow noreferrer""><code>-print0</code></a> tells <code>find</code> to output results separated by the null char, <a href=""https://www.gnu.org/software/grep/manual/grep.html#Other-Options"" rel=""nofollow noreferrer""><code>-z</code></a> tells <code>grep</code> that lines are separated by the null char, and <code>--null</code> tells <a href=""https://www.gnu.org/software/findutils/manual/html_mono/find.html#xargs-options"" rel=""nofollow noreferrer""><code>xargs</code></a> that input lines are separated by null. These options are not required by POSIX compatibility however they are available for GNU variants of these tools.</p>

<p><strong>What is the difference ?</strong></p>

<p>Suppose you have a directory that has a new line in its name:</p>

<pre><code>ls -1la
total 28
drwxr-xr-x  6 sorin pi 4096 Mar  1 18:18 .
drwxr-xr-x 31 sorin pi 4096 Mar  1 17:26 ..
drwxr-xr-x  2 sorin pi 4096 Mar  1 17:26 chain_asd123
drwxr-xr-x  2 sorin pi 4096 Mar  1 17:26 hello_1afadf
drwxr-xr-x  2 sorin pi 4096 Mar  1 18:18 hello_1effaj
drwxr-xr-x  2 sorin pi 4096 Mar  1 18:17 hello?_1effaj
-rw-r--r--  1 sorin pi   29 Mar  1 17:28 ids.txt
</code></pre>

<p>In this case hello?_1effaj has a newline embedded in the name.</p>

<p>For the first command the output would be:</p>

<pre><code>$ find . \! -name '.' -type d -prune | grep  -f ids.txt | xargs echo rm -rf
rm -rf _1effaj ./hello_1effaj
</code></pre>

<p>(it would try to delete a directory named <code>_1effaj</code> but <code>hello?_1effaj</code> would be untouched)</p>

<pre><code>$ find . \! -name '.' -type d -prune -print0 | grep  -z -f ids.txt | xargs --null echo rm -rf
rm -rf ./hello
_1effaj ./hello_1effaj
</code></pre>

<p>This would successfully delete the directory <code>hello?_1effaj</code>.</p>

<p><strong>How do I check if I have such a filename ?</strong>:</p>

<pre><code>find -name '*
*'
</code></pre>

<p>this should work in any POSIX shell.</p>

<p>Or in bash you can use: <code>find -name \*$'\n'\*</code></p>
","2","1","4560","238","568","597","60476598","60477345"
"60476677","<p>The <a href=""https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html"" rel=""nofollow noreferrer"">LabelEncoder</a> don't need to extract information from the data to work, this program just run on the series and transform the target values in numbers. </p>

<p>The <a href=""https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html"" rel=""nofollow noreferrer"">StandardScale</a> compute mean and variance of the column to scale them. </p>

<p>Seen this, the x and y column may have 2 different mean and standard deviation, needing to be computed separately and that is why they created 2 objects. </p>
","1","1","332","24","5","34","60476605","60476677"
"60476736","<p>You can use <code>np.polyfit</code> for linear regression:</p>

<pre><code>pd.DataFrame(np.polyfit(df['Base'], df.filter(like='Thing'), deg=1)).T
</code></pre>

<p>Output:</p>

<pre><code>           0            1
0   3.002379    -0.714256
1   6.002379    -0.714256
2   12.002379   -0.714256
3   4.002379    -0.714256
4   2.672379    -0.714256
</code></pre>
","0","1","112902","3825","17","9360","60476704","60476736"
"60479612","<p>@Quang-Hoang 's idea of using df.filter solves the problem. If you really want to use sklearn, this also works:</p>

<pre><code>reg = linear_model.LinearRegression()
X = df['Base'].values.reshape(-1,1)
y = df.filter(items=things).values
reg.fit(X, y)
result_df['Betas'] = reg.coef_
y_predict = reg.predict(X)
result_df['Rsq'] = r2_score(y, y_predict)
</code></pre>
","0","1","709","225","0","87","60476704","60476736"
"60478035","<p>If the only objective of the use of QGraphicsItemGroup is to enable the movement of a group of items then the procedure is to select the items, add them to the group, move the items and before any action remove the items from the group. Thus, it will not be necessary for the items to permanently belong to the group but only when necessary avoiding side effects such as the non-transmission of events.</p>
","1","2","184341","3940","32065","41961","60476803","60478035"
"60720234","<p>I did not get exactly what you are looking for, lm mean linear model, you could try linear regression in sklearn as follows:</p>

<pre><code>    import numpy as np
    from sklearn.linear_model import LinearRegression
    import matplotlib.pyplot as plt

    year        = np.arange(0, 100, 1)
    year = np.reshape(year, (1, -1))
    year_predict        = np.arange(100, 200, 1)
    year_predict        = np.reshape(year_predict, (1, -1))

    y   = np.sin(2*np.pi*year/15)+np.cos(2*np.pi*year/15)
    lm = LinearRegression()
    lm.fit(year, y)

    y_pred = lm.predict(year_predict)

    plt.plot(year[0,:], y[0,:])
    plt.plot(year_predict[0,:], y_pred[0,:])
    plt.ylabel('np.sin(2*pi*year/15)+np.cos(2*pi*year/15)')
    plt.show()
</code></pre>

<p>More info you can find here: <a href=""https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html"" rel=""nofollow noreferrer"">https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html</a> </p>

<p>If you have something unclear, write here. We could help you</p>
","0","0","5626","1528","0","427","60476920","60720234"
"60621952","<p>I suspect your issue has to do with your outputs / <code>data[1]</code> (it would help if you show examples of your train_set). Running the following piece of code gives no nan, but I forced shape of output by hand before calling the <code>loss_fn(pred, outputs)</code> :</p>

<pre><code>class BaselineModel(nn.Module):
    def __init__(self, feature_dim=5, hidden_size=5, num_layers=2, batch_size=32):
        super(BaselineModel, self).__init__()
        self.num_layers = num_layers
        self.hidden_size = hidden_size

        self.lstm = nn.LSTM(input_size=feature_dim,
                            hidden_size=hidden_size, num_layers=num_layers)

    def forward(self, x, hidden):
        lstm_out, hidden = self.lstm(x, hidden)
        return lstm_out, hidden

    def init_hidden(self, batch_size):
        hidden = Variable(next(self.parameters()).data.new(
            self.num_layers, batch_size, self.hidden_size))
        cell = Variable(next(self.parameters()).data.new(
            self.num_layers, batch_size, self.hidden_size))
        return (hidden, cell)

model = BaselineModel(batch_size=32)
optimizer = optim.Adam(model.parameters(), lr=0.01, weight_decay=0.0001)
loss_fn = torch.nn.MSELoss(reduction='sum')

hidden = model.init_hidden(10)
model.zero_grad()
pred, hidden = model(torch.randn(2,10,5), hidden)
pred.size() #torch.Size([2, 10, 5])
outputs = torch.zeros(2,10,5)

loss = loss_fn(pred, outputs)
loss

loss.backward()
torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)
optimizer.step()
print(loss)
</code></pre>

<p>Please note a common reason for nan values can be related to numerical stability of your learning phase, but usually you have values for the first steps before you see the divergence happening, which is apparently not the case here.</p>
","0","2","1195","248","2","81","60476943","60621952"
"60477205","<p>Remove <code>l=sorted(l)</code> step because it changes the order of indices of numbers since one of the constraints say <code>i &lt; j &lt; k</code>.</p>

<p>Consider below case:</p>

<p><code>4 2 1</code></p>

<p>Answer should be <code>0</code> but your code will return <code>1</code>. </p>

<hr>

<p>Regarding efficiency, you can count how many numbers each number divides from the right. For <code>1,2,3,4,5,6</code> the counts for each would look like:</p>

<pre><code>1 2 3 4 5 6
5 2 1 0 0 0 
</code></pre>

<p>For <code>1</code>, when you come to <code>2</code>, <code>2</code> already has <code>2</code> in the cached array, so now you got 2 triplets to add to the final answer. You get <code>1</code> triplet when you come to <code>3</code>, So <code>2+1</code> = <code>3</code>.</p>

<p><strong>Time Complexity:</strong> O(n^2)</p>

<p><strong>Space Complexity:</strong> O(n)</p>

<hr>

<p>Since, the question says <code>The elements of l are between 1 and 999999 inclusive</code>, I think you can just go the factorial way. </p>

<p>First collect all value counts in a map.</p>

<p>Now, go every multiple for every number and add the triplets from last to first. Like below:</p>

<pre><code>triplet_map = {}
map = {}
for every number in array: # from last to first
   if number in triplet_map:
       triplets += triplet_map(number)
       continue
   cnt = 0
   for(i = number; i &lt; 1000000; i *= number) 
     if i in map:
         if map(i) &gt; 0: 
           cnt += map(i)
     map(number,map(number) + 1)
   triplets += cnt
   triplet_map(number,cnt)
</code></pre>

<p>This way, it's like logarithmic time for each number. Didn't test this much but seems to work.</p>
","4","2","11694","807","83","2040","60477022","60477205"
"64255097","<pre><code>def answer(l):
    triples_count=0

    p=len(l)
    print l
    for i in xrange(p-2):
        for j in xrange(i+1, p-1):
            if l[j] % l[i] == 0:
                for k in xrange(j+1, p):
                    if l[k] % l[j] == 0:
                        #print l[i], l[j], l[k]
                        triples_count=triples_count+1
    return(triples_count)
</code></pre>
","0","1","615","171","1","77","60477022","60477205"
"60484910","<p>You can shuffle siteid parameter.
But much more robust approach is to create currencies rates on Your own, lets say:</p>

<pre><code>import numpy as np
eur_rate=4.3008 #EUR to PLN rate
usd_rate=3.9047 #USD to PLN rate
gbp_rate=5.0411 #GBP to PLN rate
a = np.array([[""EUR"",eur_rate]], dtype=object)
b = [[""USD"", usd_rate]]
c = [[""GBP"", gbp_rate]]
curr_rates = np.vstack((a,np.asarray(b,object)))
curr_rates = np.vstack((curr_rates,np.asarray(c,object)))
</code></pre>

<p>Here is my python repository: <a href=""https://github.com/Brat-Pit/eBay"" rel=""nofollow noreferrer"">https://github.com/Brat-Pit/eBay</a></p>
","2","0","364","8","0","49","60477052","60484910"
"60494484","<p>The issue was occurring due to folder permissions issue.
This was resolved by giving the proper permissions to the folder containing the .db file (in this case the application only had read permissions, that is why this issue was only occurring when trying to change or create content in it) these permissions being read and write.</p>

<p>So in my case I used chmod to change the permissions of my /var/www/FlaskApp/FlaskApp folder (which contains all my flask files and my .db file) and this resolved the issue</p>
","0","1","50","7","0","17","60477091","60494484"
"60477240","<p>Here is a way to do it. First create the countup flag, and then perform a cumsum. Then correct it with the NaN values.</p>

<pre><code>import pandas as pd
import numpy as np

df = pd.DataFrame({'Signal_1' : [0,0,0,1,1,0,0,1,1,1,1,0,0,0,1,1,1,1,1]})

# Only count up when the previous sample = 0, and the current sample = 1
df[""shift""] = df[""Signal_1""].shift(1)
df[""countup""] = np.where((df[""Signal_1""] == 1) &amp; (df[""shift""] == 0),1,0)

# Cumsum the countup flag and set to NaN when sample = 0
df[""result""] = df[""countup""].cumsum()
df[""result""] = np.where(df[""Signal_1""] == 0, np.NaN, df[""result""] )

</code></pre>
","0","0","206","1","0","39","60477143","60477240"
"60477289","<pre><code>^(?:#(.*?)#)?\s*\{?(.*?)\}?\s*(?:\((#.*?)\))*\s*(?:&lt;(\d.*?)&gt;)*$
</code></pre>

<p><a href=""https://regex101.com/r/ETbK93/1"" rel=""nofollow noreferrer"">Demo here</a></p>
","2","1","3019","170","38","254","60477188","60477289"
"60479405","<p>You can use the following regular expression:</p>

<pre><code>/^(?:#(\d+(?:,\d+)*)#)? *([^&lt;]+?) *(?:\(([^()]*)\))? *(?:&lt;(\d+(?:,\d+)*)&gt;)?$/
</code></pre>

<p><a href=""https://regex101.com/r/ifR7I8/5/"" rel=""nofollow noreferrer"">demo</a></p>

<p>We can write it in <em>free spacing mode</em> to make it self-documenting:</p>

<pre><code>/
^             # match beginning of line
(?:           # begin non-capture group
  #           # match '#'
  (           # begin capture group 1
    \d+       # match 1+ digits  
    (?:,\d+)* # match a comma then 1+ digits in non-capture
              # group, executed 0+ times (*)
  )           # end capture group #1
  #           # match '#'
)?            # end non-capture group and make it optional

\ *           # match 0+ spaces
(.+?)         # match any char 1+ times (+), non-greedily
              # in capture group 2 (not optional)

\ *           # match 0+ spaces
(?:           # begin non-capture group
  \(          # match '('
  ([^()]*)    # match 0+ (*) chars other than '(' and
              # ')' in capture group 3 
  \)          # match ')'       
)?            # end non-capture group and make it optional

\ *           # match 0+ spaces
(?:           # begin non-capture group
  &lt;           # match '&lt;'
  (           # begin capture group 4 
    \d+       # match 1+ digits
    (?:,\d+)* # match a comma then 1+ digits in non-
              # capture group, 0+ times
  )           # end capture group 4
  &gt;           # match '&gt;'
)?            # end non-capture group and make it optional
$             # match end of line
/x            # free-spacing regex definition mode
</code></pre>
","4","2","93421","7912","102","9185","60477188","60477289"
"60477275","<p>nums and nums[:] have indeed the same value (that you check using ==), but the are different objects (that you can check using the 'is' keyword). Sequences are mutable, therefore you can change the values they contain without changing the object itself.
The [:] simply creates a copy of an existing sequence. This way you have a different object with all the values of the previous one</p>

<p>EDIT:
the reason is that, when you append nums to results, nums can still be changed even if it's inside results. Therefore the elements inside results will be changed everytime you change the original nums (in fact in the result all the values are identical). If you create a copy for each element you put in results, instead, the elements will all have different values.</p>
","5","3","326","32","3","54","60477206","60477275"
"60477910","<p>Flask needs to know that it is receiving ""json"". In your PHP script you need to add additional ""Content-Type"" header.</p>

<pre><code>&lt;?php
$url = 'http://127.0.0.1:34000/reg';
$data = array(""collection"" =&gt; ""RapidAPI"");
$curl = curl_init($url);
curl_setopt($curl, CURLOPT_RETURNTRANSFER, true);
curl_setopt($curl, CURLOPT_POST, true);
curl_setopt($curl, CURLOPT_POSTFIELDS,  json_encode($data));
curl_setopt($curl, CURLOPT_HTTPHEADER, [
   'Content-Type: application/json'
]);
$response = curl_exec($curl);
echo $response;
curl_close($curl);
</code></pre>
","0","1","324","23","0","8","60477235","60477910"
"60477491","<p><code>easygui.enterbox</code> returns the text that the user entered, or None if he cancels the operation. You will have to convert the text returned to byte array. <a href=""http://easygui.sourceforge.net/api.html"" rel=""nofollow noreferrer"">Docs</a></p>

<pre><code>if l is not None:
    f = hashlib.sha256(l.encode()).hexdigest()
</code></pre>
","1","2","12487","27","13","826","60477353","60477491"
"60477536","<p>You have to encode your given string bevor you can hash it. The easiest way would, to just use the for strings implemented encode() method.</p>

<p><code>f = hashlib.sha256(l.encode()).hexdigest()
print(f)</code></p>

<p>with return your sha256 hash.</p>
","0","1","108","9","0","11","60477353","60477491"
"60477770","<p>Discarding the imaginary part of the FFT (and also the sign of the real part) is exactly what the problem is leading to the 'backfolding' of the inverted image into itself. The FFT of a function that is symmetric about its origin is real (i.e. imaginary part 0). By discarding the imaginary part, the image has thus been somehow 'symmetrized'.</p>

<p>After performing operations on the complex FFT result in Fourier space, one can take the inverse FFT, and then only plot the real part <code>np.fft.ifft2((imgRadius(amp,43))).real</code> of it.</p>
","4","3","431","25","0","106","60477377","60481431"
"60480549","<p>The following works for me in Python/OpenCV/Numpy and shows the difference between using a sharp boundary circle and one that has been smoothed by Gaussian blurring in order to mitigate ringing artifacts</p>

<p>Input:</p>

<p><a href=""https://i.stack.imgur.com/6et6q.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/6et6q.png"" alt=""enter image description here""></a></p>

<pre><code>import numpy as np
import cv2

# read input and convert to grayscale
img = cv2.imread('lena_gray.png', cv2.IMREAD_GRAYSCALE)

# do dft saving as complex output
dft = np.fft.fft2(img)

# apply shift of origin to center of image
dft_shift = np.fft.fftshift(dft)

# generate spectrum from magnitude image (for viewing only)
mag = np.abs(dft_shift)
spec = np.log(mag) / 20

# create circle mask
radius = 32
mask = np.zeros_like(img)
cy = mask.shape[0] // 2
cx = mask.shape[1] // 2
cv2.circle(mask, (cx,cy), radius, (255,255,255), -1)[0]

# blur the mask
mask2 = cv2.GaussianBlur(mask, (19,19), 0)

# apply mask to dft_shift
dft_shift_masked = np.multiply(dft_shift,mask) / 255
dft_shift_masked2 = np.multiply(dft_shift,mask2) / 255


# shift origin from center to upper left corner
back_ishift = np.fft.ifftshift(dft_shift)
back_ishift_masked = np.fft.ifftshift(dft_shift_masked)
back_ishift_masked2 = np.fft.ifftshift(dft_shift_masked2)


# do idft saving as complex output
img_back = np.fft.ifft2(back_ishift)
img_filtered = np.fft.ifft2(back_ishift_masked)
img_filtered2 = np.fft.ifft2(back_ishift_masked2)

# combine complex components to form original image again
img_back = np.abs(img_back).clip(0,255).astype(np.uint8)
img_filtered = np.abs(img_filtered).clip(0,255).astype(np.uint8)
img_filtered2 = np.abs(img_filtered2).clip(0,255).astype(np.uint8)


cv2.imshow(""ORIGINAL"", img)
cv2.imshow(""SPECTRUM"", spec)
cv2.imshow(""MASK"", mask)
cv2.imshow(""MASK2"", mask2)
cv2.imshow(""ORIGINAL DFT/IFT ROUND TRIP"", img_back)
cv2.imshow(""FILTERED DFT/IFT ROUND TRIP"", img_filtered)
cv2.imshow(""FILTERED2 DFT/IFT ROUND TRIP"", img_filtered2)
cv2.waitKey(0)
cv2.destroyAllWindows()

# write result to disk
cv2.imwrite(""lena_dft_numpy_mask.png"", mask)
cv2.imwrite(""lena_dft_numpy_mask_blurred.png"", mask2)
cv2.imwrite(""lena_dft_numpy_roundtrip.png"", img_back)
cv2.imwrite(""lena_dft_numpy_lowpass_filtered1.png"", img_filtered)
cv2.imwrite(""lena_dft_numpy_lowpass_filtered2.png"", img_filtered2)
</code></pre>

<p><br>
Sharp Mask:</p>

<p><a href=""https://i.stack.imgur.com/lKUuq.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/lKUuq.png"" alt=""enter image description here""></a></p>

<p>Blurred Mask:</p>

<p><a href=""https://i.stack.imgur.com/nBCji.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/nBCji.png"" alt=""enter image description here""></a></p>

<p>Simple Round Trip:</p>

<p><a href=""https://i.stack.imgur.com/m2HEr.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/m2HEr.png"" alt=""enter image description here""></a></p>

<p>Low Pass Filtered Result from sharp mask (ringing obvious):</p>

<p><a href=""https://i.stack.imgur.com/imN7I.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/imN7I.png"" alt=""enter image description here""></a></p>

<p>Low Pass Filtered Result from blurred mask (ringing mitigated):</p>

<p><a href=""https://i.stack.imgur.com/Jwh0H.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/Jwh0H.png"" alt=""enter image description here""></a></p>
","1","2","26665","2157","177","2926","60477377","60481431"
"60481431","<p>The problem happens here:</p>

<pre><code>def imgRadius(img, radius):
    result = np.zeros(img.shape,np.float64)
</code></pre>

<p>You are creating a real-valued array, and copying over the complex values. Likely either the real component or the magnitude is written to the array. In any case, the complex-valued frequency domain data becomes real-valued. The inverse transform is a symmetric matrix.</p>

<p>To solve the problem, initialize <code>result</code> as a complex-valued array.</p>

<p>After this, make sure to use the real component of the inverse transform, not the magnitude, as <a href=""https://stackoverflow.com/a/60477770/7328782"">Gianluca already suggested in their answer</a>.</p>
","2","3","42543","6046","915","6722","60477377","60481431"
"60478060","<p>You could do something like</p>

<pre class=""lang-py prettyprint-override""><code>class Contact:
    def __init__(self, first_name, last_name, phone_num, email):
        self.first_name = first_name
        self.last_name = last_name
        self.phone_num = phone_num
        self.email = email

    def __str__(self):
        return ""~"".join([self.first_name, self.last_name, self.phone_num, self.email])

address_book = []
try:
    with open(""save.txt"") as save_file:
        for contact in save_file:
            address_book.append(Contact(*contact.rstrip().split(""~"")))
except FileNotFoundError as fefe:
    pass

print(""Hello I am an addressbook! What do you want to do?\n1.Add contact"")
print(""2.Print out contacts\n3.Search for and edit a contact\n4.Exit\n"")
while True:
    choice = int(input(""Choice: ""))
    if choice == 1:
        address_book.append(Contact(input(""First name?""), input(""Last name?""), input(""Phone number?""), input(""Email?"")))
    elif choice == 2:
        print(*[contact for contact in address_book], sep=""\n"")
    elif choice == 3:
        pass
    elif choice == 4:
        with open(""save.txt"", ""w"") as save_file:
            for contact in address_book:
                save_file.write(str(contact) + ""\n"")
            break
</code></pre>
","7","0","7789","823","247","820","60477378","60478060"
"60477561","<p>It looks like it might be an import issue or you need to define method for <code>show_grid(x,y)</code>. Let me know if this helps!</p>
","0","1","1444","3","8","195","60477495","60477561"
"60477826","<p>You just need to refresh the window.<br>
I've added a colour toggle so it will toggle between grey and white on a click.</p>

<pre><code>import wx
import wx.grid as gridlib
class MyForm(wx.Frame):

    def __init__(self):
        wx.Frame.__init__(self, None, wx.ID_ANY, ""Sample grid"")

        self.grid = gridlib.Grid(self)
        self.grid.CreateGrid(5,4)
        self.grid.SetCellSize(4,1,1,2)

        self.grid.SetDefaultCellAlignment(wx.ALIGN_CENTRE, wx.ALIGN_CENTRE)

        self.grid.SetColLabelSize(0)            # eliminates spreadsheet-style row &amp; col headers
        self.grid.SetRowLabelSize(0)

        self.grid.SetCellBackgroundColour(4, 3, wx.LIGHT_GREY)

        rowHeight = 50
        colWidth  = 50
        for i in range(1,5):
            self.grid.SetRowSize(i, rowHeight)
        for i in range(0,4):
            self.grid.SetColSize(i, colWidth)

        self.grid.Bind(gridlib.EVT_GRID_CELL_LEFT_CLICK, self.GridLeftClick, self.grid)

    def GridLeftClick(self, event):
        col = event.GetCol()
        row = event.GetRow()
        clr = self.grid.GetCellBackgroundColour(row, col)
        if clr != wx.LIGHT_GREY:
            self.grid.SetCellBackgroundColour(row, col, wx.LIGHT_GREY)
        else:
            self.grid.SetCellBackgroundColour(row, col, wx.WHITE)
        self.Refresh()

app = wx.App()
frame = MyForm().Show()
app.MainLoop()
</code></pre>

<p><a href=""https://i.stack.imgur.com/qictb.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/qictb.png"" alt=""enter image description here""></a></p>
","0","2","16833","416","37","1242","60477525","60477826"
"60477569","<p>You are looking for <a href=""https://docs.python.org/3/library/functions.html#input"" rel=""nofollow noreferrer"">input()</a> function, <a href=""https://docs.python.org/2/tutorial/datastructures.html"" rel=""nofollow noreferrer"">append()</a> method of list. See <a href=""https://stackoverflow.com/a/3940137/5735010"">this</a> answer to know how to reverse a list.</p>

<p>Try this:</p>

<pre><code>array = []
num = int(input(""Enter the length of array: "")) # You need to convert str returned by input to an int using int() constructor
for i in range(num):
    array.append(input(""Enter a number: "")) # You need to use append() method of list
print(array)
print(array[::-1])
</code></pre>

<p>Or </p>

<p>Using <a href=""https://docs.python.org/3/tutorial/datastructures.html#list-comprehensions"" rel=""nofollow noreferrer"">list comprehension</a>:</p>

<pre><code>array = [input(""Enter a number: "") for i in range(int(input(""Enter the length of array: "")))]
</code></pre>

<p>To reverse a list, use</p>

<pre><code>print(array[::-1])
</code></pre>
","0","1","7385","7807","4","901","60477533","60477569"
"60477592","<p>To add an element at the end of the list you have to use <code>.append</code> method.</p>

<p>try this.</p>

<pre><code>array=[]
for _ in range(5):
    array.append(input())  # use int(input()) to so that you have int type elements

print(array[::-1])  # to print array in reverse order.
</code></pre>

<hr>

<p>You can use list comprehension here.</p>

<pre><code>[input() for _ in range(5)][::-1]  # use int(input()) to so that you have int type elements
</code></pre>
","0","2","14733","1831","61","1931","60477533","60477569"
"60478222","<p>""tooltipstered"" class is added by javascript and is not available in the plain html document returned by the server.
You can see that when you open the ""source"" of the page not using browser inspector.</p>

<p>As you can see ""tooltipster"" is some jquery plugin, you will need to use some other tool to scrape this page (eg.: selenium).</p>

<pre><code>&lt;script type=""text/javascript"" src=""https://tmssl.akamaized.net//assets/e17e6900/js/jquery.tooltipster.js?lm=1574952016""&gt;&lt;/script&gt;
</code></pre>
","2","0","324","23","0","8","60477574","60478222"
"60477683","<p>Convert the list to a set, which automatically gets rid of duplicates. Then compare their size:</p>

<pre class=""lang-py prettyprint-override""><code>l = [1,2,3,4,5,6,7,7,6,5,4]
print(len(l) - len(set(l)))
</code></pre>
","0","1","3674","7445","142","610","60477597","60477812"
"60477736","<p>If your intention is to find out the duplicates across the 10 lists, you can try the following - </p>

<pre class=""lang-py prettyprint-override""><code># Import Counter from collections 
In [11]: from collections import Counter

# Your definition of my_random_list
In [12]: def my_random_list(l: list):
    ...:     return sorted(random.sample(list(set(l)), 6))
    ...:

# Copying your version of creating 10 lists into a lists variable (calling the sorted() here is superfluous in my opinion)
In [13]: lists = [sorted(my_random_list([i for i in range(1, 43)])) for _ in range(10)]

# Count all the entries across all the 10 lists
In [14]: counter = Counter([])

# You can add multiple Counter instances to produce a ""merged"" Counter
In [15]: for l in lists:
    ...:     counter += Counter(l)

# Find the entries whose value exists more than once
In [16]: duplicates = [k for k,v in counter.items() if v &gt; 1]

# Printing all the duplicate entries across the lists
In [17]: duplicates
Out[17]: [6, 16, 20, 37, 38, 2, 9, 29, 1, 18, 33, 3, 17, 19, 31, 15, 21, 42, 41, 11]

# Length of the duplicate list
In [18]: len(duplicates)
Out[18]: 20
</code></pre>

<p>You can read-up on <code>Counter</code> <a href=""https://docs.python.org/2/library/collections.html#collections.Counter"" rel=""nofollow noreferrer"">here</a></p>
","0","1","5228","3106","0","384","60477597","60477812"
"60477812","<p>You can use:</p>

<pre><code>import random
from collections import defaultdict

def my_random_list(l: list):
    return sorted(random.sample(list(set(l)), 6))

repeated = defaultdict(int)
for _ in range(10):
    rl = my_random_list([i for i in range(1, 43)])
    for x in rl:
        repeated[x] += 1
    print(sorted(rl))

repeated = {k:v for k,v in repeated.items() if v &gt; 1}
print(repeated)
# {2: 2, 5: 3, 19: 4, 21: 4, 4: 3, 8: 2, 14: 2, 38: 3, 9: 3, 24: 2, 40: 3, 42: 2, 10: 2, 22: 3, 32: 2, 18: 3, 34: 2, 30: 2, 31: 3}
print(len(repeated.keys())) # how many duplicates
</code></pre>

<p><a href=""https://trinket.io/python3/baca95387b"" rel=""nofollow noreferrer"">Demo</a></p>
","0","1","74108","5063","858","7248","60477597","60477812"
"60477875","<p>A statement of problem is not clear, I assume you want to calculate duplicates in concatenation of these 10 arrays. In this case you could use advantages of <code>numpy.unique</code>:</p>

<pre><code>import random
import numpy as np
collection = [my_random_list(list(range(1, 43))) for i in range(10)]
conc = np.concatenate(collection) # concatenated list
items, cnt = np.unique(conc, return_counts=True) # sorted set of unique items and their counts
output = items[cnt&gt;1] # items that appears more than once
</code></pre>
","0","1","3747","281","19","426","60477597","60477812"
"60477883","<p><code>collections.Counter</code> and <code>itertools.chain</code> will be helpful.</p>

<pre class=""lang-py prettyprint-override""><code>import random

source = [i for i in range(1, 43)]


def my_random_list():
    return sorted(random.sample(source, 6))


random_lists = [my_random_list() for _ in range(10)]
print(random_lists)
</code></pre>

<p>Here are 10 random lists(6 length for each).</p>

<pre><code>&gt;&gt;&gt; [[2, 4, 10, 18, 20, 30], [4, 12, 13, 19, 21, 27], [10, 11, 18, 26, 32, 33], [4, 11, 12, 17, 38, 42], [12, 22, 28, 38, 40, 41], [2, 11, 22, 30, 35, 36], [4, 6, 22, 24, 32, 34], [1, 3, 5, 25, 31, 33], [25, 29, 31, 32, 33, 35], [12, 16, 28, 31, 37, 41]]
</code></pre>

<p>Then you can count it.</p>

<pre class=""lang-py prettyprint-override""><code>from collections import Counter
from itertools import chain


counter = Counter(chain(*random_lists))
print(counter)
</code></pre>

<pre><code>&gt;&gt;&gt; Counter({4: 4, 12: 4, 11: 3, 32: 3, 33: 3, 22: 3, 31: 3, 2: 2, 10: 2, 18: 2, 30: 2, 38: 2, 28: 2, 41: 2, 35: 2, 25: 2, 20: 1, 13: 1, 19: 1, 21: 1, 27: 1, 26: 1, 17: 1, 42: 1, 40: 1, 36: 1, 6: 1, 24: 1, 34: 1, 1: 1, 3: 1, 5: 1, 29: 1, 16: 1, 37: 1})
</code></pre>

<p>And filter the counter with comprehension.</p>

<pre class=""lang-py prettyprint-override""><code>results = [k for k, v in counter.items() if v &gt;= 2]
print(results)
</code></pre>

<pre><code>&gt;&gt;&gt; [2, 4, 10, 18, 30, 12, 11, 32, 33, 38, 22, 28, 41, 35, 25, 31]
</code></pre>
","0","1","2217","279","150","156","60477597","60477812"
"60477782","<p>Use <code>explode</code> and <code>map</code>, then you can do a little grouping to get your output:</p>

<pre><code>(df.set_index('Student ID')['Subjects']
   .str.split(', ')
   .explode()
   .map(df2.set_index('Subjects')['Subject ID'])
   .reset_index()
   .groupby('Subjects')['Student ID']
   .agg(list))

Subjects
Bio13                            [S1, S4]
Che13                    [S1, S2, S3, S4]
Eco13                                [S6]
EngLit13                         [S5, S9]
FMat13                               [S7]
Geo13                                [S6]
His13                                [S5]
Mat13       [S1, S2, S3, S4, S6, S7, S10]
Phy13                            [S1, S7]
Name: Student ID, dtype: object
</code></pre>

<p>From here, call <code>.to_dict()</code> if you want the result in a dictionary.</p>
","0","1","266035","10142","8528","64481","60477626","60477782"
"60478142","<p>Not pythonic but simple</p>

<pre><code>{row['Subject ID'] : 
      df1[df1.Subjects.str.contains(row['Subjects'])]['Student ID'].to_list() 
      for _, row in df2.iterrows()}
</code></pre>

<p>What are we doing :</p>

<p>Iterate over all the Subjects and check if the Subject string lies in the subjects taken by a student. If so, get the students ID. </p>
","0","0","12487","27","13","826","60477626","60477782"
"65602375","<p>The answer is to make a function (I called it «camera_enemy ») that returns the value of <code>enemy.pos.x+background.pos.x</code>. Then, when blitting the enemy, write <code>win.blit(enemy_img, (camera_enemy, enemy.pos.y))</code></p>
","0","1","134","3","1","21","60477678","65602375"
"60477804","<p>Here's your answer: <a href=""https://stackoverflow.com/questions/24108507/beautiful-soup-resultset-object-has-no-attribute-find-all"">Beautiful Soup: &#39;ResultSet&#39; object has no attribute &#39;find_all&#39;?</a></p>

<p>However, I tried running your script and was running into a different issue. The ""table"" element didn't even exist. </p>
","0","0","1588","202","71","228","60477682","60478613"
"60478613","<p>The table you're trying to scrape is in an iframe, so it's better to get the iframe source html instead of the page html</p>

<pre><code>URL = 'https://dailyfantasyrankings.com.au/resources/nba/htm/projections/mballproj.htm'
</code></pre>

<p>Get the table with CSS selector instead of class name because there is an issue with how HTML is formatted on the source page:</p>

<pre><code>table = soup.select(""#Finish_20945 &gt; table"")[0]
</code></pre>

<p>Working code. Change are marked with code comments:</p>

<pre><code>import requests
from bs4 import BeautifulSoup
import pandas as pd
#CHANGED LINE BELOW
URL = 'https://dailyfantasyrankings.com.au/resources/nba/htm/projections/mballproj.htm'
response = requests.get(URL)
soup = BeautifulSoup(response.content, 'html.parser')
#CHANGED LINE BELOW
table = soup.select(""#Finish_20945 &gt; table"")[0]
columns = ['#', 'PLAYER', 'POS', '@', 'TEAM', 'OPP', 'M-UP', 'PACE', 'REST', 'PRICE', 'PROJ', 'VALUE', 'AVE']
df = pd.DataFrame(columns=columns)
trs = table.find_all('tr')
for tr in trs:
    tds = tr.find_all('td')
    row = [td.text.replace('\n', '') for td in tds]
    print(row)
    # df = df.append(pd.Series(row, index=columns), ignore_index=True)

df.to_csv('dfr_proj.csv', index=False)
</code></pre>

<p>Output:</p>

<pre><code>['', '', '', '', '', '', '', '', '', '', '', '↓', '↓', '', '\xa0', '\xa0', '\xa0', '\xa0', '\xa0']
['#', 'Player', '\xa0', 'Pos', '@', 'Team', 'Opp', 'M-UP', 'Pace', 'Rest', 'Price', 'Proj', 'Value', 'Ave', 'Last 5 Games']
['1', 'A. Davis', '\xa0', 'PF', 'A', 'LAL', 'NOP', '18', '3.5', 'B2B', '$10,800', '61', '5.6', '51', '70', '52', '61', '41', '37']
['2', 'B. Beal', '\xa0', 'SG', 'A', 'WAS', 'GSW', '5', '0.3', '1', '$9,600', '57', '5.9', '46', '34', '67', '53', '51', '67']
['3', 'L. James', '\xa0', 'SF', 'A', 'LAL', 'NOP', '3', '3.5', 'B2B', '$10,400', '53', '5.1', '51', '51', '50', '55', '\xa0', '45']
['4', 'N. Jokic', '\xa0', 'C', 'H', 'DEN', 'TOR', '19', '0.4', '1', '$10,100', '47', '4.7', '45', '53', '52', '50', '35', '35']
['5', 'P. Siakam', '\xa0', 'SF', 'A', 'TOR', 'DEN', '26', '-3.0', '1', '$8,400', '45', '5.4', '41', '34', '63', '28', '33', '50']
['6', 'K. Lowry', '\xa0', 'PG', 'A', 'TOR', 'DEN', '11', '-3.0', '1', '$7,600', '44', '5.8', '38', '43', '31', '57', '23', '47']
['7', 'A. Wiggins', '\xa0', 'SF', 'H', 'GSW', 'WAS', '11', '3.0', 'B2B', '$7,700', '42', '5.5', '36', '34', '34', '16', '\xa0', '46']
['8', 'B. Ingram', '\xa0', 'SF', 'H', 'NOP', 'LAL', '16', '0.5', '1', '$7,900', '40', '5.1', '40', '\xa0', '26', '32', '47', '47']
['9', 'C. Wood', 'GTD', 'PF', 'A', 'DET', 'SAC', '26', '-2.0', '1', '$7,900', '39', '4.9', '23', '48', '35', '44', '36', '48']
['10', 'D. Fox', 'GTD', 'PG', 'H', 'SAC', 'DET', '3', '-2.4', '1', '$7,500', '38', '5.1', '37', '34', '35', '36', '\xa0', '42']
['11', 'J. Holiday', '\xa0', 'SG', 'H', 'NOP', 'LAL', '24', '0.5', '1', '$8,900', '38', '4.3', '40', '35', '44', '52', '33', '40']
['12', 'D. Rose', '\xa0', 'PG', 'A', 'DET', 'SAC', '18', '-2.0', '1', '$6,000', '36', '6.0', '30', '11', '19', '17', '32', '47']
['13', 'Z. Williamson', '\xa0', 'PF', 'H', 'NOP', 'LAL', '16', '0.5', '1', '$8,300', '36', '4.3', '33', '41', '37', '41', '41', '33']
['14', 'D. Lee', '\xa0', 'SG', 'H', 'GSW', 'WAS', '7', '3.0', 'B2B', '$6,100', '34', '5.7', '24', '26', '36', '32', '25', '41']
['15', 'M. Chriss', '\xa0', 'C', 'H', 'GSW', 'WAS', '21', '3.0', 'B2B', '$6,400', '34', '5.3', '22', '21', '\xa0', '37', '20', '36']
['16', 'O. Anunoby', '\xa0', 'SF', 'A', 'TOR', 'DEN', '27', '-3.0', '1', '$5,000', '33', '6.7', '24', '12', '31', '19', '29', '49']
['17', 'J. Murray', '\xa0', 'PG', 'H', 'DEN', 'TOR', '15', '0.4', '1', '$7,200', '32', '4.4', '33', '49', '35', '29', '39', '17']
['18', 'L. Ball', '\xa0', 'PG', 'H', 'NOP', 'LAL', '30', '0.5', '1', '$6,900', '32', '4.6', '32', '33', '32', '33', '30', '46']
['19', 'E. Paschall', '\xa0', 'PF', 'H', 'GSW', 'WAS', '21', '3.0', 'B2B', '$4,600', '30', '6.5', '23', '21', '20', '20', '30', '34']
['20', 'N. Powell', '\xa0', 'SG', 'A', 'TOR', 'DEN', '10', '-3.0', '1', '$4,500', '28', '6.2', '26', '\xa0', '\xa0', '\xa0', '\xa0', '27']
['21', 'R. Hachimura', '\xa0', 'PF', 'A', 'WAS', 'GSW', '15', '0.3', '1', '$5,100', '28', '5.4', '25', '36', '25', '22', '20', '31']
['22', 'B. Hield', '\xa0', 'SG', 'H', 'SAC', 'DET', '26', '-2.4', '1', '$6,000', '27', '4.4', '32', '39', '12', '32', '24', '24']
['23', 'W. Barton', '\xa0', 'SF', 'H', 'DEN', 'TOR', '11', '0.4', '1', '$5,800', '26', '4.5', '31', '\xa0', '35', '25', '16', '25']
['24', 'H. Giles III', '\xa0', 'PF', 'H', 'SAC', 'DET', '7', '-2.4', '1', '$5,100', '26', '5.1', '15', '15', '33', '33', '29', '30']
['25', 'N. Bjelica', '\xa0', 'PF', 'H', 'SAC', 'DET', '11', '-2.4', '1', '$5,100', '26', '5.1', '27', '26', '24', '10', '31', '31']
['26', 'J. Grant', '\xa0', 'PF', 'H', 'DEN', 'TOR', '23', '0.4', '1', '$4,500', '25', '5.5', '21', '26', '8', '17', '35', '35']
['27', 'S. Napier', '\xa0', 'PG', 'A', 'WAS', 'GSW', '6', '0.3', '1', '$5,000', '24', '4.7', '22', '18', '17', '46', '22', '13']
['28', 'D. Bender', '\xa0', 'PF', 'H', 'GSW', 'WAS', '21', '3.0', 'B2B', '$3,900', '23', '5.9', '12', '\xa0', '20', '8', '13', '39']
['29', 'D. Favors', '\xa0', 'C', 'H', 'NOP', 'LAL', '30', '0.5', '1', '$5,400', '23', '4.3', '27', '21', '27', '24', '18', '37']
['30', 'K. Bazemore', '\xa0', 'SF', 'H', 'SAC', 'DET', '26', '-2.4', '1', '$5,400', '23', '4.2', '19', '25', '47', '28', '18', '26']
['31', 'D. Bertans', '\xa0', 'PF', 'A', 'WAS', 'GSW', '24', '0.3', '1', '$5,100', '23', '4.5', '26', '26', '25', '\xa0', '23', '19']
['32', 'H. Barnes', '\xa0', 'SF', 'H', 'SAC', 'DET', '29', '-2.4', '1', '$5,200', '23', '4.4', '25', '35', '36', '24', '29', '15']
['33', 'T. Bryant', '\xa0', 'C', 'A', 'WAS', 'GSW', '11', '0.3', '1', '$4,100', '23', '5.5', '25', '20', '13', '\xa0', '15', '22']
['34', 'B. Knight', '\xa0', 'PG', 'A', 'DET', 'SAC', '23', '-2.0', '1', '$3,900', '22', '5.8', '11', '\xa0', '1', '22', '25', '28']
['35', 'R.\r  Hollis-Jefferson', '\xa0', 'PF', 'A', 'TOR', 'DEN', '26', '-3.0', '1', '$4,000', '22', '5.4', '19', '12', '22', '18', '25', '15']
['36', 'I. Smith', '\xa0', 'PG', 'A', 'WAS', 'GSW', '8', '0.3', '1', '$5,000', '22', '4.3', '24', '26', '29', '30', '12', '16']
['37', 'R. Rondo', '\xa0', 'PG', 'A', 'LAL', 'NOP', '4', '3.5', 'B2B', '$4,300', '21', '4.9', '19', '14', '28', '7', '30', '10']
['38', 'A. Len', '\xa0', 'C', 'H', 'SAC', 'DET', '7', '-2.4', '1', '$4,000', '21', '5.2', '20', '\xa0', '16', '11', '26', '24']
['39', 'B. Bogdanovic', '\xa0', 'SG', 'H', 'SAC', 'DET', '25', '-2.4', '1', '$5,100', '20', '4.0', '24', '16', '32', '28', '23', '24']
['40', 'D. Howard', '\xa0', 'C', 'A', 'LAL', 'NOP', '29', '3.5', 'B2B', '$4,400', '20', '4.6', '22', '12', '20', '15', '36', '20']
['41', 'M. Mulder', '\xa0', '-', 'H', 'GSW', 'WAS', '7', '3.0', 'B2B', '-', '20', '-', '-', '\xa0', '\xa0', '\xa0', '7', '21']
['42', 'M. Morris', '\xa0', 'PG', 'H', 'DEN', 'TOR', '15', '0.4', '1', '$4,600', '19', '4.2', '19', '26', '12', '34', '29', '18']
['43', 'J. Henson', '\xa0', 'C', 'A', 'DET', 'SAC', '21', '-2.0', '1', '$4,500', '19', '4.3', '17', '4', '12', '31', '14', '21']
['44', 'N. Melli', '\xa0', 'PF', 'H', 'NOP', 'LAL', '30', '0.5', '1', '$4,100', '19', '4.7', '14', '17', '24', '30', '22', '20']
['45', 'K. Caldwell-Pope', '\xa0', 'SG', 'A', 'LAL', 'NOP', '2', '3.5', 'B2B', '$4,200', '19', '4.5', '17', '19', '16', '22', '20', '16']
['46', 'T. Brown Jr.', '\xa0', 'SF', 'A', 'WAS', 'GSW', '24', '0.3', '1', '$4,400', '19', '4.3', '23', '24', '17', '9', '12', '24']
['47', 'K. Looney', '\xa0', 'C', 'H', 'GSW', 'WAS', '15', '3.0', 'B2B', '$3,500', '19', '5.3', '10', '12', '15', '14', '16', '22']
['48', 'S. Mykhailiuk', '\xa0', 'SG', 'A', 'DET', 'SAC', '23', '-2.0', '1', '$3,500', '18', '5.2', '15', '13', '16', '8', '10', '27']
['49', 'L. Galloway', '\xa0', 'SG', 'A', 'DET', 'SAC', '18', '-2.0', '1', '$4,100', '18', '4.4', '17', '17', '13', '26', '14', '12']
['50', 'J. Toscano-Anderson', '\xa0', 'SF', 'H', 'GSW', 'WAS', '11', '3.0', 'B2B', '$4,300', '18', '4.2', '18', '32', '38', '13', '10', '15']
['51', 'A. Bradley', '\xa0', 'SG', 'A', 'LAL', 'NOP', '3', '3.5', 'B2B', '$4,000', '18', '4.4', '15', '33', '10', '8', '19', '8']
['52', 'P. Millsap', 'GTD', 'PF', 'H', 'DEN', 'TOR', '23', '0.4', '1', '$5,400', '17', '3.2', '25', '27', '11', '41', '17', '8']
['53', 'C. Boucher', '\xa0', 'PF', 'A', 'TOR', 'DEN', '25', '-3.0', '1', '$4,200', '17', '3.9', '16', '4', '21', '37', '20', '8']
['54', 'T. Snell', '\xa0', 'SG', 'A', 'DET', 'SAC', '23', '-2.0', '1', '$3,900', '17', '4.2', '15', '30', '15', '9', '28', '13']
['55', 'K. Kuzma', '\xa0', 'PF', 'A', 'LAL', 'NOP', '18', '3.5', 'B2B', '$4,400', '17', '3.8', '20', '17', '22', '13', '25', '16']
['56', 'A. Caruso', '\xa0', 'PG', 'A', 'LAL', 'NOP', '4', '3.5', 'B2B', '$4,000', '16', '4.1', '14', '18', '9', '32', '14', '14']
['57', 'M. Plumlee', '\xa0', 'C', 'H', 'DEN', 'TOR', '19', '0.4', '1', '$4,200', '16', '3.8', '19', '\xa0', '12', '17', '21', '16']
['58', 'T. Davis', '\xa0', 'SG', 'A', 'TOR', 'DEN', '10', '-3.0', '1', '$4,600', '16', '3.4', '16', '3', '19', '21', '20', '8']
['59', 'J. Hart', '\xa0', 'SG', 'H', 'NOP', 'LAL', '22', '0.5', '1', '$4,900', '15', '3.2', '24', '20', '33', '20', '17', '13']
['60', 'J. Robinson', '\xa0', 'PG', 'A', 'WAS', 'GSW', '19', '0.3', '1', '$3,900', '14', '3.6', '8', '14', '10', '10', '22', '18']
['61', 'G. Harris', '\xa0', 'SG', 'H', 'DEN', 'TOR', '21', '0.4', '1', '$4,300', '14', '3.3', '20', '18', '10', '24', '19', '10']
['62', 'C. Joseph', 'GTD', 'PG', 'H', 'SAC', 'DET', '3', '-2.4', '1', '$3,900', '14', '3.6', '17', '17', '5', '19', '33', '14']
['63', 'S. Doumbouya', '\xa0', 'PF', 'A', 'DET', 'SAC', '23', '-2.0', '1', '$3,500', '14', '4.0', '12', '10', '18', '14', '3', '14']
['64', 'M. Porter Jr.', '\xa0', 'PF', 'H', 'DEN', 'TOR', '23', '0.4', '1', '$3,900', '13', '3.4', '16', '\xa0', '5', '6', '22', '15']
['65', 'J. McGee', '\xa0', 'C', 'A', 'LAL', 'NOP', '29', '3.5', 'B2B', '$3,900', '12', '3.0', '20', '10', '14', '13', '21', '7']
['66', 'T. Maker', 'GTD', 'C', 'A', 'DET', 'SAC', '21', '-2.0', '1', '$4,600', '11', '2.5', '11', '25', '25', '16', '9', '6']
['67', 'I. Mahinmi', '\xa0', 'C', 'A', 'WAS', 'GSW', '11', '0.3', '1', '$4,100', '11', '2.6', '20', '18', '6', '21', '15', '14']
['68', 'M. Morris', '\xa0', 'SF', 'A', 'LAL', 'NOP', '18', '3.5', 'B2B', '$4,200', '10', '2.4', '19', '\xa0', '\xa0', '8', '13', '13']
['69', 'E. Moore', '\xa0', 'SF', 'H', 'NOP', 'LAL', '24', '0.5', '1', '$3,500', '9', '2.7', '16', '15', '10', '6', '3', '19']
['70', 'I. Bonga', '\xa0', 'SF', 'A', 'WAS', 'GSW', '19', '0.3', '1', '$3,500', '9', '2.7', '12', '8', '3', '13', '14', '7']
['71', 'T. Craig', '\xa0', 'SG', 'H', 'DEN', 'TOR', '21', '0.4', '1', '$3,900', '9', '2.3', '12', '20', '7', '6', '\xa0', '12']
['72', 'M. Wagner', '\xa0', 'C', 'A', 'WAS', 'GSW', '11', '0.3', '1', '$4,000', '8', '2.1', '20', '11', '12', '28', '8', '4']
['73', 'P. McCaw', '\xa0', 'SG', 'A', 'TOR', 'DEN', '10', '-3.0', '1', '$3,500', '8', '2.3', '13', '9', '\xa0', '\xa0', '\xa0', '7']
['74', 'M. Thomas', '\xa0', 'SG', 'A', 'TOR', 'DEN', '10', '-3.0', '1', '$3,500', '7', '2.0', '8', '1', '1', '18', '14', '4']
['75', 'J. Hayes', '\xa0', 'C', 'H', 'NOP', 'LAL', '30', '0.5', '1', '$3,500', '3', '0.9', '17', '11', '9', '0', '\xa0', '10']
['76', 'P. Dozier', '\xa0', 'SG', 'H', 'DEN', 'TOR', '15', '0.4', '1', '$3,500', '3', '0.7', '10', '6', '\xa0', '0', '3', '6']
['77', 'J. McRae', '\xa0', 'SG', 'H', 'DEN', 'TOR', '11', '0.4', '1', '$4,100', '2', '0.6', '20', '6', '\xa0', '0', '\xa0', '3']
['78', 'J. Okafor', '\xa0', 'C', 'H', 'NOP', 'LAL', '30', '0.5', '1', '$3,500', '2', '0.6', '16', '\xa0', '\xa0', '\xa0', '2', '\xa0']
['79', 'F. Jackson', '\xa0', 'PG', 'H', 'NOP', 'LAL', '30', '0.5', '1', '$3,500', '1', '0.2', '9', '7', '0', '\xa0', '\xa0', '4']
</code></pre>
","4","0","1541","222","23","129","60477682","60478613"
"60485517","<p>Another option is just use Pandas to read in the table (it uses Beautifulsoup under the hood)</p>

<pre><code>import pandas as pd

URL = 'https://dailyfantasyrankings.com.au/resources/nba/htm/projections/mballproj.htm'
df = pd.read_html(URL)[0]
df.columns = df.iloc[1,:]
df = df.iloc[2:,:]

df.to_csv('dfr_proj.csv', index=False)
</code></pre>

<p><strong>Output:</strong></p>

<pre><code>print(df.to_string())
1      #              Player  NaN Pos  @ Team  Opp M-UP  Pace Rest    Price Proj Value Ave Last 5 Games Last 5 Games Last 5 Games Last 5 Games Last 5 Games
2      1            A. Davis  GTD  PF  A  LAL  NOP   18   3.5  B2B  $10,800   59   5.5  51           70           52           61           41           37
3      2             B. Beal  NaN  SG  A  WAS  GSW    5   0.3    1   $9,600   57   5.9  46           34           67           53           51           67
4      3            L. James  NaN  SF  A  LAL  NOP    3   3.5  B2B  $10,400   53   5.1  51           51           50           55          NaN           45
5      4            N. Jokic  NaN   C  H  DEN  TOR   19   0.4    1  $10,100   51   5.1  45           53           52           50           35           35
6      5           P. Siakam  NaN  SF  A  TOR  DEN   26  -3.0    1   $8,400   45   5.4  41           34           63           28           33           50
7      6            K. Lowry  NaN  PG  A  TOR  DEN   11  -3.0    1   $7,600   45   5.9  38           43           31           57           23           47
8      7          A. Wiggins  NaN  SF  H  GSW  WAS   11   3.0  B2B   $7,700   42   5.5  36           34           34           16          NaN           46
9      8             C. Wood  NaN  PF  A  DET  SAC   26  -2.0    1   $7,900   42   5.3  23           48           35           44           36           48
10     9           B. Ingram  NaN  SF  H  NOP  LAL   16   0.5    1   $7,900   40   5.1  40          NaN           26           32           47           47
11    10              D. Fox  NaN  PG  H  SAC  DET    3  -2.4    1   $7,500   38   5.1  37           34           35           36          NaN           42
12    11          J. Holiday  NaN  SG  H  NOP  LAL   24   0.5    1   $8,900   38   4.3  40           35           44           52           33           40
13    12             D. Rose  NaN  PG  A  DET  SAC   18  -2.0    1   $6,000   36   6.0  30           11           19           17           32           47
14    13       Z. Williamson  NaN  PF  H  NOP  LAL   16   0.5    1   $8,300   36   4.3  33           41           37           41           41           33
15    14           M. Chriss  NaN   C  H  GSW  WAS   21   3.0  B2B   $6,400   34   5.3  22           21          NaN           37           20           36
16    15          O. Anunoby  NaN  SF  A  TOR  DEN   27  -3.0    1   $5,000   33   6.7  24           12           31           19           29           49
17    16              D. Lee  NaN  SG  H  GSW  WAS    7   3.0  B2B   $6,100   32   5.3  24           26           36           32           25           41
18    17           J. Murray  NaN  PG  H  DEN  TOR   15   0.4    1   $7,200   32   4.4  33           49           35           29           39           17
19    18             L. Ball  NaN  PG  H  NOP  LAL   30   0.5    1   $6,900   32   4.6  32           33           32           33           30           46
20    19           N. Powell  NaN  SG  A  TOR  DEN   10  -3.0    1   $4,500   30   6.7  26          NaN          NaN          NaN          NaN           27
21    20         E. Paschall  NaN  PF  H  GSW  WAS   21   3.0  B2B   $4,600   30   6.5  23           21           20           20           30           34
22    21            J. Grant  NaN  PF  H  DEN  TOR   23   0.4    1   $4,500   30   6.6  21           26            8           17           35           35
23    22        R. Hachimura  NaN  PF  A  WAS  GSW   15   0.3    1   $5,100   28   5.4  25           36           25           22           20           31
24    23            B. Hield  NaN  SG  H  SAC  DET   26  -2.4    1   $6,000   27   4.4  32           39           12           32           24           24
25    24           W. Barton  NaN  SF  H  DEN  TOR   11   0.4    1   $5,800   26   4.5  31          NaN           35           25           16           25
26    25        H. Giles III  NaN  PF  H  SAC  DET    7  -2.4    1   $5,100   26   5.1  15           15           33           33           29           30
27    26          N. Bjelica  NaN  PF  H  SAC  DET   11  -2.4    1   $5,100   26   5.1  27           26           24           10           31           31
28    27           S. Napier  NaN  PG  A  WAS  GSW    6   0.3    1   $5,000   24   4.7  22           18           17           46           22           13
29    28       M. Porter Jr.  NaN  PF  H  DEN  TOR   23   0.4    1   $3,900   23   6.0  16          NaN            5            6           22           15
30    29           D. Bender  NaN  PF  H  GSW  WAS   21   3.0  B2B   $3,900   23   5.9  12          NaN           20            8           13           39
31    30           D. Favors  NaN   C  H  NOP  LAL   30   0.5    1   $5,400   23   4.3  27           21           27           24           18           37
32    31         K. Bazemore  NaN  SF  H  SAC  DET   26  -2.4    1   $5,400   23   4.2  19           25           47           28           18           26
33    32          D. Bertans  NaN  PF  A  WAS  GSW   24   0.3    1   $5,100   23   4.5  26           26           25          NaN           23           19
34    33           H. Barnes  NaN  SF  H  SAC  DET   29  -2.4    1   $5,200   23   4.4  25           35           36           24           29           15
35    34           T. Bryant  NaN   C  A  WAS  GSW   11   0.3    1   $4,100   23   5.5  25           20           13          NaN           15           22
36    35           B. Knight  NaN  PG  A  DET  SAC   23  -2.0    1   $3,900   22   5.8  11          NaN            1           22           25           28
37    36           J. Henson  NaN   C  A  DET  SAC   21  -2.0    1   $4,500   22   5.0  17            4           12           31           14           21
38    37  R.  Hollis-Jeffers  NaN  PF  A  TOR  DEN   26  -3.0    1   $4,000   22   5.4  19           12           22           18           25           15
39    38            I. Smith  NaN  PG  A  WAS  GSW    8   0.3    1   $5,000   22   4.3  24           26           29           30           12           16
40    39              A. Len  NaN   C  H  SAC  DET    7  -2.4    1   $4,000   21   5.2  20          NaN           16           11           26           24
41    40       B. Bogdanovic  NaN  SG  H  SAC  DET   25  -2.4    1   $5,100   20   4.0  24           16           32           28           23           24
42    41           D. Howard  NaN   C  A  LAL  NOP   29   3.5  B2B   $4,400   20   4.6  22           12           20           15           36           20
43    42             J. Hart  NaN  SG  H  NOP  LAL   22   0.5    1   $4,900   19   4.0  24           20           33           20           17           13
44    43           M. Morris  NaN  PG  H  DEN  TOR   15   0.4    1   $4,600   19   4.2  19           26           12           34           29           18
45    44            R. Rondo  NaN  PG  A  LAL  NOP    4   3.5  B2B   $4,300   19   4.5  19           14           28            7           30           10
46    45        T. Brown Jr.  NaN  SF  A  WAS  GSW   24   0.3    1   $4,400   19   4.3  23           24           17            9           12           24
47    46            T. Davis  NaN  SG  A  TOR  DEN   10  -3.0    1   $4,600   19   4.1  16            3           19           21           20            8
48    47          C. Boucher  NaN  PF  A  TOR  DEN   25  -3.0    1   $4,200   19   4.4  16            4           21           37           20            8
49    48       S. Mykhailiuk  NaN  SG  A  DET  SAC   23  -2.0    1   $3,500   18   5.2  15           13           16            8           10           27
50    49     K. Caldwell-Pop  NaN  SG  A  LAL  NOP    2   3.5  B2B   $4,200   18   4.3  17           19           16           22           20           16
51    50         L. Galloway  NaN  SG  A  DET  SAC   18  -2.0    1   $4,100   18   4.4  17           17           13           26           14           12
52    51      J. Toscano-And  NaN  SF  H  GSW  WAS   11   3.0  B2B   $4,300   18   4.2  18           32           38           13           10           15
53    52            J. Poole  GTD  SG  H  GSW  WAS   18   3.0  B2B   $4,900   18   3.6  15           27           27           20           25          NaN
54    53           K. Looney  NaN   C  H  GSW  WAS   15   3.0  B2B   $3,500   18   5.1  10           12           15           14           16           22
55    54          A. Bradley  NaN  SG  A  LAL  NOP    3   3.5  B2B   $4,000   18   4.4  15           33           10            8           19            8
56    55            T. Snell  NaN  SG  A  DET  SAC   23  -2.0    1   $3,900   17   4.2  15           30           15            9           28           13
...
</code></pre>
","0","0","16881","862","128","1314","60477682","60478613"
"60496218","<p>Here is a solution using np.r_, slicing and skimage.util.view_as_windows.</p>

<p>For simplicity, I just take np.arange as data. In your case of more than one Series of Data, you could repeat this for all rows for which you would like this backward averaging:</p>

<pre><code>from skimage.util import view_as_windows

numberOfDataItems=500
sumwindow=100
data=np.arange(numberOfDataItems)
</code></pre>

<p>Using np.r_, I can roll that data stepwise to make it array-shaped with dimension len(data)xlen(data)</p>

<pre><code>b = np.r_[data,np.full(len(data)-1,data[:-1])]
c=view_as_windows(b,len(data))
c
Out[]: 
array([[ 0,  1,  2, ..., 47, 48, 49],
       [ 1,  2,  3, ..., 48, 49,  0],
       [ 2,  3,  4, ..., 49,  0,  1],
       ...,
       [47, 48, 49, ..., 44, 45, 46],
       [48, 49,  0, ..., 45, 46, 47],
       [49,  0,  1, ..., 46, 47, 48]])
</code></pre>

<p>Basically that is np.roll(data) with stepsize i in column i, but without a loop.
Now I could sum the first, say 10 elements in column 0 as the values to work with for column 10, and so on for the further columns.</p>

<pre><code>d=c[:sumwindow,:-sumwindow].sum(axis=0)/sumwindow
Out[]: 
array([ 4.5,  5.5,  6.5,  7.5,  8.5,  9.5, 10.5, 11.5, 12.5, 13.5, 14.5,
       15.5, 16.5, 17.5, 18.5, 19.5, 20.5, 21.5, 22.5, 23.5, 24.5, 25.5,
       26.5, 27.5, 28.5, 29.5, 30.5, 31.5, 32.5, 33.5, 34.5, 35.5, 36.5,
       37.5, 38.5, 39.5, 40.5, 41.5, 42.5, 43.5])
</code></pre>

<p>Easy to see now, that if we wanted to take the mean of the last 10 elements in every column, then 4.5 would be the value for row 10, and the value would of course increase by 1 every column. </p>

<pre><code>e=np.array([data,data],dtype=float)
e[1,sumwindow:]=d
Out[]: 
array([[ 0. ,  1. ,  2. ,  3. ,  4. ,  5. ,  6. ,  7. ,  8. ,  9. , 10. ,
        11. , 12. , 13. , 14. , 15. , 16. , 17. , 18. , 19. , 20. , 21. ,
        22. , 23. , 24. , 25. , 26. , 27. , 28. , 29. , 30. , 31. , 32. ,
        33. , 34. , 35. , 36. , 37. , 38. , 39. , 40. , 41. , 42. , 43. ,
        44. , 45. , 46. , 47. , 48. , 49. ],
       [ 0. ,  1. ,  2. ,  3. ,  4. ,  5. ,  6. ,  7. ,  8. ,  9. ,  4.5,
         5.5,  6.5,  7.5,  8.5,  9.5, 10.5, 11.5, 12.5, 13.5, 14.5, 15.5,
        16.5, 17.5, 18.5, 19.5, 20.5, 21.5, 22.5, 23.5, 24.5, 25.5, 26.5,
        27.5, 28.5, 29.5, 30.5, 31.5, 32.5, 33.5, 34.5, 35.5, 36.5, 37.5,
        38.5, 39.5, 40.5, 41.5, 42.5, 43.5]])
</code></pre>

<p>Viewing initial data and result together, the first (sumwindow) values are the same, and from then it is always the avg of the (sumwindow) values before, just as you had for window 200 in your example.</p>

<p>I hope, that solution fits your needs.</p>
","0","1","346","347","9","27","60477684","60496218"
"60477765","<p>The <a href=""https://docs.python.org/3/library/functions.html#input"" rel=""nofollow noreferrer"">input()</a> returns a string not an int and if you multiply a string in Python with an integer <code>num</code>, then you will get a string repeated num times. For example,</p>

<pre><code>s = ""stack""
print(s * 3) # Returns ""stackstackstack""
</code></pre>

<p>You need to use <code>int()</code> constructor to cast the input from str to int.</p>

<pre><code>d =  int(input(""Enter the no. you want ""))
</code></pre>

<p>Try this:</p>

<pre><code>d = int(input(""Enter the no. you want ""))
for i in range(1,11):
    print(i * d)
</code></pre>

<p>In the above code, I have replaced your <code>while</code> loop construct with <a href=""https://wiki.python.org/moin/ForLoop"" rel=""nofollow noreferrer"">for loop</a> and <a href=""https://docs.python.org/3/library/functions.html#func-range"" rel=""nofollow noreferrer"">range()</a> to get sequence of numbers.</p>

<p><strong>BONUS:</strong></p>

<p>To print/display the table in a nice and better way, try the below code:</p>

<pre><code>for i in range(1,11):
    print(""%d X %d = %d"" % (d, i, i * d))
</code></pre>

<p>Outputs:</p>

<pre><code>Enter the no. you want 2
2 X 1 = 2
2 X 2 = 4
2 X 3 = 6
2 X 4 = 8
2 X 5 = 10
2 X 6 = 12
2 X 7 = 14
2 X 8 = 16
2 X 9 = 18
2 X 10 = 20
</code></pre>
","0","3","7385","7807","4","901","60477739","60477765"
"60485481","<p><strong>table_areas</strong> (not table_area) keyword argument works well and should be used (I use Camelot 0.7.3).</p>

<pre><code>tables = camelot.read_pdf('12s0324.pdf', flavor='stream', strip_text='\n', table_areas=['35,591,385,343'], pages = '1')
</code></pre>

<p>returns:</p>

<p><a href=""https://i.stack.imgur.com/Kio75.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/Kio75.png"" alt=""enter image description here""></a></p>

<p>which seems to be right.</p>
","1","1","1730","120","4","120","60477763","60485481"
"60480249","<p><strong>Cause of your error:</strong><br>
The vdim should be the name of the column you want to have on the y-axis, but the column name 'Fraction' doesn't exist, so you get the error.<br>
<br></p>

<p><strong>Here's a possible solution:</strong><br>
When you set hour as the index, you could specify: <code>kdim='hour'</code> and <code>vdim='blocked_driveway'</code>, but in this case you don't really need them and can leave them out:<br></p>

<pre><code># import libraries
import numpy as np
import pandas as pd
import holoviews as hv
hv.extension('bokeh')

# create sample data
data = {'hour': ['00', '01', '02'],
        'blocked_driveway': np.random.uniform(size=3),
        'illegal_parking': np.random.uniform(size=3),
        'street_condition': np.random.uniform(size=3),}

# create dataframe and set hour as index
df = pd.DataFrame(data).set_index('hour')

# create curves: 
# in this case the index is automatically taken as kdim
# and the series variable, e.g. blocked_driveway is taken as vdim
plot1 = hv.Curve(df['blocked_driveway'], label='blocked_driveway')
plot2 = hv.Curve(df['illegal_parking'], label='illegal_parking')
plot3 = hv.Curve(df['street_condition'], label='street_condition')

# put plots together
(plot1 * plot2 * plot3).opts(legend_position='top', width=600, height=400)
</code></pre>

<p><br>
<strong>Alternative and shorter solution:</strong><br>
In this case however I would use library <a href=""https://hvplot.holoviz.org/"" rel=""nofollow noreferrer"">hvplot</a> which is built on top of holoviews.<br>
It has even easier syntax and you need a lot less code to get the plot you want:</p>

<pre><code>import hvplot.pandas

# you don't have to set hour as index this time, but you could if you'd want to.
df.hvplot.line(
    x='hour', 
    y=['blocked_driveway', 
       'illegal_parking',
       'street_condition'],
)
</code></pre>

<p><br>
<strong>Resulting plot:</strong>
<a href=""https://i.stack.imgur.com/dr7gd.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/dr7gd.png"" alt=""multiple curves overlay with hvplot""></a></p>
","1","2","6228","628","11","411","60477838","60480249"
"60478680","<p>The issue is that you don't draw complete triangles. Comment out <code>draw_hexagon()</code> and <code>draw_squares()</code> and inspect the result:</p>

<p><a href=""https://i.stack.imgur.com/zs4ON.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/zs4ON.png"" alt=""enter image description here""></a></p>

<p>At some point you have to draw a complete triangle. e.g.:</p>

<pre class=""lang-py prettyprint-override""><code>begin_fill()
forward(side_length)
right(120)
forward(side_length)
right(120)
forward(side_length)
end_fill()
</code></pre>

<p>Draw the  triangle in case of <code>i%2==0:</code></p>

<pre class=""lang-py prettyprint-override""><code>def draw_triangles():

    color('black','yellow')  
    seth(180)#these 3 lines position the turtle at the starting place to start drawing the triangles
    back(50)
    left(60)
    for i in range(12):#these lines draw the 12 sides of the triangles
        if i%2==0:
            color('black','yellow')

            # draw filled triangle
            begin_fill()
            forward(side_length)
            right(120)
            forward(side_length)
            right(120)
            forward(side_length)
            end_fill()

            right(120)
            forward(side_length)
            right(30) 
        else:
            forward(side_length)
            right(30)
</code></pre>

<p><a href=""https://i.stack.imgur.com/Y0Z89.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/Y0Z89.png"" alt=""""></a>
<a href=""https://i.stack.imgur.com/9RFXM.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/9RFXM.png"" alt=""""></a></p>
","0","0","136140","16645","626","8521","60477868","60478680"
"60528411","<p>IUUC Here you have two options: a loop or convert your df from wide to long and use <code>plotly.express</code></p>

<pre class=""lang-py prettyprint-override""><code>import pandas as pd
import plotly.graph_objs as go
import plotly.express as px

from io import StringIO
df = """"""   200    300    400    500
0   1.2    2.2   12.3    4.2
1   2.7   13.1    9.8    3.3
2   1.8    1.5    5.1    9.8
3   3.9    3.3   12.1   12.2""""""

df = pd.read_csv(StringIO(df), delim_whitespace=True)

# as you want columns on x axis
df = df.T
</code></pre>

<h1>loop</h1>

<pre class=""lang-py prettyprint-override""><code>fig = go.Figure()
for col in df.columns:
    fig.add_trace(go.Line(x=df.index, y=df[col]))
fig.show()
</code></pre>

<p><a href=""https://i.stack.imgur.com/MenFl.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/MenFl.png"" alt=""enter image description here""></a></p>

<h1><code>plotly.express</code></h1>

<pre class=""lang-py prettyprint-override""><code>df['x'] = df.index
df_melt = pd.melt(df, id_vars=""x"", value_vars=df.columns[:-1])
px.line(df_melt, x=""x"", y=""value"",color=""variable"")
</code></pre>

<p><a href=""https://i.stack.imgur.com/FegN8.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/FegN8.png"" alt=""enter image description here""></a></p>
","0","1","8483","1815","10","970","60477982","60528411"
"60478033","<p>You definitely <em>can</em> update, since there is no difference in the object constructed. The problem here is that all keys refer to the <em>same</em> dictionary object as values, not different objects with (possibly) the same data.</p>

<p>You thus can make copies of the dictionary with:</p>

<pre><code>def calendar_init(year, month, habits):
    date_list = dates_in_month(year, month)
    merged_dict = {**dict.fromkeys(habits, None), **{'mood': None}}
    calendar_init = {mydate: <b>dict(</b>merged_dict<b>)</b> for mydate in date_list}
    return calendar_init</code></pre>
","1","1","312807","16628","2518","41861","60477997","60478033"
"60478135","<p>Is this what you're looking for?</p>

<pre><code>data = [
    {k: v} 
    for k, v in df.groupby('source')['tables'].agg(
        lambda x: {v: {} for v in x}).items()
]

with open('data.json', 'w') as f:
    json.dump(data, f, indent=2)  
</code></pre>

<p>There are two layers to the answer here. To group the tables by source, use <code>groupby</code> first with an inner comprehension. You can use a list comprehension to assemble your data in this specific format overall.</p>

<pre><code>[
  {
    ""src1"": {
      ""table1"": {},
      ""table2"": {},
      ""table3"": {}
    }
  },
  {
    ""src2"": {
      ""table1"": {},
      ""table2"": {}
    }
  }
]
</code></pre>

<hr>

<p><strong>Example using <code>.apply</code> with arbitrary data</strong></p>

<pre><code>df['tables2'] = 'abc'

def func(g): 
    return {x: y for x, y in zip(g['tables'], g['tables2'])}

data = [{k: v} for k, v in df.groupby('source').apply(func).items()]
data
# [{'src1': {'table1': 'abc', 'table2': 'abc', 'table3': 'abc'}},
#  {'src2': {'table1': 'abc', 'table2': 'abc'}}]
</code></pre>

<p>Note that this will not work with pandas 1.0 (probably because of a bug)</p>
","6","1","266035","10142","8528","64481","60478009","60478135"
"60479050","<p>For example, let's say your Python file is called <code>hello.py</code> and looks like this:</p>

<pre><code>print('Hello', input())
</code></pre>

<p>You can run it from the command line like this:</p>

<pre class=""lang-none prettyprint-override""><code>$ python3 hello.py
William
Hello William
</code></pre>

<p>Now say you have your name stored in <code>name.txt</code>. You can have the shell read it into your script's standard input (stdin) with <code>&lt;</code> like this:</p>

<pre class=""lang-none prettyprint-override""><code>$ python3 hello.py &lt; name.txt
Hello William
</code></pre>
","0","0","15300","3115","1510","3211","60478048","60479050"
"60478302","<p>If your data is a list of dicts then </p>

<pre><code>mpg = [ {'mpg' : 12,  'model': 'ford',  'year' : 2015 }, 
  {'mpg' : 13,  'model': 'amc',  'year' : 2016 }, 
  {'mpg' : 14,  'model': 'toyota',  'year' : 2014 }, 
  {'mpg' : 15,  'model': 'ford',  'year' : 2013 },
]

list(map(lambda x: (x['model'], x['mpg']), mpg))
</code></pre>
","0","0","12487","27","13","826","60478147","60480627"
"60480627","<p>Not sure if this is what you mean, but you can get the desired output with</p>

<pre><code>result = [(i['model'], i['mpg']) for i in mpg]
</code></pre>
","0","0","1342","35","17","63","60478147","60480627"
"60478228","<p>You can try this:</p>

<pre><code>L = ['8', 'K' , '&amp;' ,'2', '$' , '3' , 'T','R', 5.4, ""3.2""]
number_count = 0

for data in L:
    if isinstance(data,int) or isinstance(data, float) or data.replace('.','',1).isdigit():
        number_count += 1

print(""Number Count:"", number_count)
</code></pre>

<p>Output: <code>Number Count: 5</code></p>

<p>Code above will find for number / float in string, int, or float.</p>
","1","0","3385","25","8","162","60478181","60478228"
"60478281","<p>You can use:</p>

<pre><code>import string
from collections import defaultdict
letters = string.ascii_letters
digits = string.digits

L = ['8', 'K' , '&amp;' ,'2', '$' , '3' , 'T','R']

results = defaultdict(int)
for x in L:
    if x in letters:
        results[""letters""] += 1
    elif x in digits:
        results[""digits""] += 1
    else:
        results[""special""] += 1

print(dict(results))
# {'digits': 3, 'letters': 3, 'special': 2}
</code></pre>

<p><a href=""https://trinket.io/python3/3513b9b65b"" rel=""nofollow noreferrer"">Demo</a></p>
","1","2","74108","5063","858","7248","60478181","60478228"
"60478282","<p>You can use <code>string</code> module:</p>

<pre><code>&gt;&gt;&gt; from string import ascii_letters, digits, punctuation
&gt;&gt;&gt; L = ['8', 'K' , '&amp;' ,'2', '$' , '3' , 'T','R']
&gt;&gt;&gt; def categorical_counter(lst, category):
...     if category == 'letters':
...             return sum(1 for char in lst if char in ascii_letters)
...     elif category == 'numbers':
...             return sum(1 for char in lst if char in digits)
...     else:
...             return sum(1 for char in lst if char in punctuation)
...
&gt;&gt;&gt; categorical_counter(L, 'numbers')
3
</code></pre>
","2","1","12268","1175","288","837","60478181","60478228"
"60478318","<p>You can use <code>str.isdigit()</code> and <code>str.isalpha()</code> to check if characters/strings are numbers or letters, for example</p>

<pre><code>L = ['8', 'K' , '&amp;' ,'2', '$' , '3' , 'T','R']
number_count = 0
letter_count = 0
symbol_count = 0

for i in L:
    if i.isdigit(): # If string is only numeric digits
        number_count += 1
    elif i.isalpha(): # If string is only alphabetical characters
        letter_count += 1
    else: # Assume the rest are symbols
        symbol_count += 1
</code></pre>

<p>There are many other functions you can use to check what the string contains: <a href=""https://docs.python.org/3/library/stdtypes.html#str.isalnum"" rel=""nofollow noreferrer"">https://docs.python.org/3/library/stdtypes.html#str.isalnum</a></p>
","0","0","26","43","0","1","60478181","60478228"
"60478754","<p>try this :D</p>

<pre><code>l=[""wael"", ""dd"", "";D""]
l.clear()
print(""Input the list size"")
n=(int(input()))
for i in range(1,n+1):
 print(""fill spot"",i,""of the list with"")
 l.append(input())
d=0
for data in l:
    if data.isnumeric():
     d=d+1
print(""number="",d)
</code></pre>
","0","0","1","0","0","6","60478181","60478228"
"60478767","<pre class=""lang-py prettyprint-override""><code>file = ID3(""file.mp3"") # Load the file
file.delall(""APIC"") # Delete every APIC tag (Cover art)
file.save() # Save the file
</code></pre>
","0","3","391","64","7","40","60478235","60478767"
"60478330","<p>You chose a poor example. <code>int.__isub__</code> isn't defined, so <code>a -= 5</code> is exactly equal to <code>a = a - 5</code>, with no in-place modification of the original value.</p>

<p>Try with a set, which does implement <code>__isub__</code>.</p>

<pre><code>&gt;&gt;&gt; s = {1,2,3}
&gt;&gt;&gt; operator.isub(s, {2})
&gt;&gt;&gt; s
{1, 3}
</code></pre>

<p><code>a -= b</code> is implemented as <code>a.__isub__(b)</code> <em>if</em> <code>a.__isub__</code> is defined. Otherwise, it is equivalent to <code>a = a - b</code>, which is implemented as <code>a = a.__sub__(b)</code>. Thus, <code>isub(a, b)</code> is the same as <code>a -= b</code>, but that <em>doesn't</em> mean <code>isub(a, b)</code> can or does modify <code>a</code> in-place.</p>
","2","5","383179","18330","5892","20227","60478284","60478330"
"60479408","<p>Your <code>select</code> tag needs a name. Replace: </p>

<pre class=""lang-html prettyprint-override""><code>&lt;select class=""form-control"" id=""continent_selector""&gt;
</code></pre>

<p>With: </p>

<pre class=""lang-html prettyprint-override""><code>&lt;select class=""form-control"" id=""continent_selector"" name=""select""&gt;
</code></pre>
","1","1","943","82","16","40","60478309","60479408"
"60478429","<pre><code>data =  'Emma', 'F', '20799\nOlivia', 'F', '19674\nSophia', 'F', '18490\nIsabella', 'F', '16950\nAva','Emma', 'F', '20799\nOlivia', 'F', '19674\nSophia', 'F', '18490\nIsabella', 'F', '16950\nAva'
sum((s.split('\n') for s in data), [])
</code></pre>

<p>['Emma', 'F', '20799', 'Olivia', 'F', '19674', 'Sophia', 'F', '18490', 'Isabella', 'F', '16950', 'Ava', 'Emma', 'F', '20799', 'Olivia', 'F', '19674', 'Sophia', 'F', '18490', 'Isabella', 'F', '16950', 'Ava']</p>

<p>or if it is a string like this below:</p>

<p>data =  ""'Emma', 'F', '20799\nOlivia', 'F', '19674\nSophia', 'F', '18490\nIsabella', 'F', '16950\nAva','Emma', 'F', '20799\nOlivia', 'F', '19674\nSophia', 'F', '18490\nIsabella', 'F', '16950\nAva'""</p>

<pre><code>import re
re.findall(r""[\w]+"", data)
</code></pre>

<p>['Emma', 'F', '20799', 'Olivia', 'F', '19674', 'Sophia', 'F', '18490', 'Isabella', 'F', '16950', 'Ava', 'Emma', 'F', '20799', 'Olivia', 'F', '19674', 'Sophia', 'F', '18490', 'Isabella', 'F', '16950', 'Ava']</p>
","5","-1","416","78","1","43","60478368","60478447"
"60478447","<p>I think you are trying to replace the ""\n"" characters with a delimiter rather than removing them:</p>

<pre><code>def files_to_dict(folder_name):
    list_of_files = os.listdir(""./""+folder_name) #read file names of current dir in list
    newDict=dict()
    for year in (list_of_files):
        if(year!="".ipynb_checkpoints""):
            with open(""./""+folder_name+""/""+year,""r"") as ofile:
                data = ofile.read().replace('\n', ',').split(',')
                return data
</code></pre>
","1","1","26","43","0","1","60478368","60478447"
"60478509","<p>I don't know what your files look like, but I see you're never using newDict so you just return the last file what was processed</p>

<p>Try seeing if the following is closer to what you want </p>

<pre><code>with open(""./""+folder_name+""/""+year) as ofile:
    data_lines = [s.rstrip() for s in ofile.readlines()] 
    # would be better if you used csv module 
    data = [s.split(',') for s in data_lines]
    print(data)
</code></pre>
","0","0","124322","2234","5803","53684","60478368","60478447"
"60479214","<p>It's  very simple ,use split() instead of split(',') in your code.I modified  your code and it is shown below:-</p>

<pre><code>def files_to_dict(folder_name):
list_of_files = os.listdir(""./""+folder_name) #read file names of current dir in list
newDict=dict()
for year in (list_of_files):
    if(year!="".ipynb_checkpoints""):
        ofile = open(""./""+folder_name+""/""+year,""r"")
        data = ofile.read().split()

return data
</code></pre>

<p>Please refer to the following code and output if any more confusion is there.To understand easily i executed the below code based on your input</p>

<p><strong>code:</strong></p>

<pre><code>fh=open(""trystack.txt"",'r')
for line in fh:
    lines=fh.read().split()
    print(lines)  
fh.close() 
</code></pre>

<p><strong>output:</strong></p>

<p>['Olivia', 'F', '19674', 'Sophia', 'F', '18490', 'Isabella', 'F', '16950']</p>

<p>My text file <strong>trystack.txt</strong>  contains:</p>

<p>Emma F 20799</p>

<p>Olivia F 19674</p>

<p>Sophia F 18490</p>

<p>Isabella F 16950</p>

<p>This will help you in achieving what you need i.e removing '\n'</p>

<p>ThankYou</p>
","3","0","22","4","0","3","60478368","60478447"
"60498356","<p>Use <code>data.strip()</code> to remove ‘\n’ from a string</p>
","0","0","1508","486","108","140","60478368","60478447"
"60479850","<p>With libraries like <code>pyinput</code> you can only emulate mouse events in the window that is in focus/foreground and only if it is in the same process. If you want to generally inject or monitor mouse or keyboard events also in processes different from the calling process (like in your case) you have to establish a <em>mouse hook</em> or <em>keyboard hook</em> in windows.</p>

<p><a href=""https://docs.microsoft.com/en-us/windows/win32/winmsg/about-hooks"" rel=""nofollow noreferrer"">https://docs.microsoft.com/en-us/windows/win32/winmsg/about-hooks</a>
<a href=""https://www.codeproject.com/Articles/19858/Global-Windows-Hooks"" rel=""nofollow noreferrer"">https://www.codeproject.com/Articles/19858/Global-Windows-Hooks</a></p>

<p>In linux is the <code>evdev</code> system and <code>xdotool</code></p>

<p>In java on windows you have to invoke JNI like in this library : <a href=""https://github.com/kwhat/jnativehook"" rel=""nofollow noreferrer"">https://github.com/kwhat/jnativehook</a></p>

<p>Also see this <strong><a href=""https://stackoverflow.com/questions/10355286/programmatically-mouse-click-in-another-window"">programmatically mouse click in another window</a></strong> and this git <strong><a href=""https://github.com/boppreh/mouse"" rel=""nofollow noreferrer"">https://github.com/boppreh/mouse</a></strong></p>
","0","1","8021","737","2","567","60478419","60514532"
"60514532","<p>Even the Windows hooks didn't work with the game. We ended up opening the game on a remote desktop server and running the automation code over it, which worked.</p>
","0","0","75","347","0","271","60478419","60514532"
"60479261","<p>The element ('//span[contains(@data-bind, ""text: formatCurrency"")]') can't be scrapped because it's in a collapsed accordion.</p>

<p>The best solution I could come up with is to scroll to an element below the ""Fuel and Service Rates"" button and then click on it and then scrape the price. </p>

<p>I'm sure someone else can come up with a better solution with fewer lines of code.</p>

<p>Explanation in code comment.</p>

<pre><code>from selenium import webdriver
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.common.by import By
from selenium.webdriver.common.action_chains import ActionChains

driver = webdriver.Chrome('./chromedriver')

driver.get(""https://www.signatureflight.com/locations/acy"")
# Get an element below the fees section to scroll to, so the Fuel &amp; Service Rate will be visible
scroll_to = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.ID, ""skyvector-heading"")))
actions = ActionChains(driver)
# Scroll to that element
actions.move_to_element(scroll_to).perform()
# Find the Fuel &amp; Service Rate link and click on it
btn = driver.find_element_by_css_selector(""a[href='#fees']"")
btn.click()
# Get the price
price = driver.find_element_by_xpath('//span[contains(@data-bind, ""text: formatCurrency"")]').text
print(price)
</code></pre>

<p>Output:</p>

<pre><code>$5.83
</code></pre>
","0","2","1541","222","23","129","60478467","60479261"
"60478593","<p>You can use <code>sorted(iterable,key)</code>.</p>

<pre><code>&gt;&gt;&gt;sorted(list1,key=lambda x: (x[1],x[2],x[0])
#[(5, 3, 2), (2, 3, 4), (3, 4, 5)]
</code></pre>

<hr>

<p>If you don't want to use <code>lambda</code> you can use <code>itemgetter</code>.</p>

<pre><code>from operator import itemgetter
sorted(list1,key=itemgetter(1,2,0))
#[(5, 3, 2), (2, 3, 4), (3, 4, 5)]
</code></pre>
","2","2","14733","1831","61","1931","60478559","60478593"
"60478737","<p>You can create samples where two features are independent of each other and a third feature is a linear combination of the other two. </p>

<p>For example: </p>

<pre><code>import numpy as np
from numpy.random import random

N_SAMPLES = 1000

samples = random((N_SAMPLES, 3))

# Let us suppose that the column `1` will have the dependent feature, the other two being independent

samples[:, 1] = 3 * samples[:, 0] - 2 * samples[:, 2]
</code></pre>

<p>Now if you run PCA to find two principal components on that sample, the ""explained variance"" should be equal to 1. </p>

<p>For example:</p>

<pre><code>from sklearn.decomposition import PCA

pca2 = PCA(2)
pca2.fit(samples)

assert sum(pca2.explained_variance_ratio_) == 1.0 # this should be true

</code></pre>
","2","0","3349","277","19","129","60478562","60478737"
"60479216","<p>You should always try to click on the element that can receive the click, in this case on the <code>button</code>  </p>

<p>xpath: <code>//div[@class='MEAGs']/button</code></p>
","2","1","3998","61","76","447","60478655","60479216"
"60478712","<p>We can make a utility function that filters out the <code>None</code>s. For example:</p>

<pre><code>from django.db.models import Q

def filter_without_none(**kwargs):
    return Q(**{k: v for k, v in kwargs.items() if v is not None and v != ''})</code></pre>

<p>Now we can filter with:</p>

<pre><code>Ingredient.objects.filter(
    <b>filter_without_none(</b>account=account, brand=brand, name=name, cost=cost<b>)</b>
)</code></pre>

<p>If one (or multiple) of the values like <code>account</code>, <code>brand</code> and/or <code>name</code> are <code>None</code>, these will <em>not</em> be taken into account for filtering.</p>
","4","2","312807","16628","2518","41861","60478689","60478712"
"60497298","<p>Turns out the environment variable was wrongly reading a double-quote a la <a href=""https://github.com/docker/compose/issues/3702"" rel=""nofollow noreferrer"">https://github.com/docker/compose/issues/3702</a></p>
","0","0","1404","119","9","203","60478724","60497298"
"60479496","<p>I found it:</p>

<p>kernel.json file was pointing to wrong python:</p>

<pre><code>{
 ""argv"": [
  ""/home/****/anaconda3/bin/python"",
  ""-m"",
  ""ipykernel_launcher"",
  ""-f"",
  ""{connection_file}""
 ],
 ""display_name"": ""myvirtenv"",
 ""language"": ""python""
}
</code></pre>

<p>Changed it to:</p>

<pre><code>{
 ""argv"": [
  ""/home/****/anaconda3/envs/myvirtenv/bin/python"",
  ""-m"",
  ""ipykernel_launcher"",
  ""-f"",
  ""{connection_file}""
 ],
 ""display_name"": ""myvirtenv"",
 ""language"": ""python""
}
</code></pre>
","0","0","179","7","0","7","60478729","60479496"
"60544413","<p>Yes you can use <a href=""https://www.tensorflow.org/api_docs/python/tf/GradientTape"" rel=""nofollow noreferrer"">GradientTape</a>. The purpose of <code>tf.GradientTape</code> is to record operations for automatic differentiation or for computing the gradient of an operation or computation with respect to its input variables.</p>

<p>According to <a href=""https://rads.stackoverflow.com/amzn/click/com/B07VWGN8NB"" rel=""nofollow noreferrer"" rel=""nofollow noreferrer"">What's New in TensorFlow 2.0</a>, to first implement the simple training of a model with tf.GradientTape, call the forward pass on the input tensor inside the tf.GradentTape context manager and then compute the loss function. <strong>This ensures that all of the computations will be recorded on the gradient tape.</strong></p>

<p>Then, compute the gradients with regard to all of the trainable variables in the model. Once the gradients are computed, any desired gradient clipping, normalization, or transformation can be performed before passing them to the optimizer to apply them to the model variables. Take a look at the following example:</p>

<pre><code>NUM_EXAMPLES = 2000

input_x = tf.random.normal([NUM_EXAMPLES])
noise = tf.random.normal([NUM_EXAMPLES])
input_y = input_x * 5 + 2 + noise

def loss_fn(model, inputs, targets):
  error = model(inputs) - targets
  return tf.reduce_mean(tf.square(error))

def gradients(model, inputs, targets):
  with tf.GradientTape() as tape:
    loss_value = loss_fn(model, inputs, targets)
  return tape.gradient(loss_value, model.trainable_variables)

model = tf.keras.Sequential(tf.keras.layers.Dense(1))
optimizer = tf.keras.optimizers.Adam(learning_rate=0.01)
print(""Initial loss: {:.3f}"".format(loss_fn(model, input_x, input_y)))
for i in range(500):
  grads = gradients(model, input_x, input_y)
  optimizer.apply_gradients(zip(grads, model.trainable_variables))
  if i % 20 == 0:
    print(""Loss at step {:03d}: {:.3f}"".format(i, loss_fn(model, input_x, input_y)))
print(""Final loss: {:.3f}"".format(loss(model, input_x, input_y)))
print(""W = {}, B = {}"".format(*model.trainable_variables))
</code></pre>
","4","2","8788","8668","329","2107","60478749","60567742"
"60567742","<p>Ok, so one answer that I finally found is hidden here: <a href=""https://stackoverflow.com/a/56567364/4750170"">https://stackoverflow.com/a/56567364/4750170</a>. I can even use subclassed model with this.</p>

<p>Additionally problem with AttributeError is strange, because when I used Sequential instead of subclassing Model, AttributeError magically disappeared, maybe it's connected with this issue <a href=""https://github.com/tensorflow/tensorflow/issues/34834"" rel=""nofollow noreferrer"">https://github.com/tensorflow/tensorflow/issues/34834</a>? </p>

<p>Still, I'd like to know why I can't just pass the layer's output as a second argument to tape.gradient.</p>
","4","2","143","2","0","16","60478749","60567742"
"60479278","<p>first you have to use sheet_name as a string not an object and another thing is last for loop is not needed as we loop through sheet names.</p>

<pre><code>from pandas import ExcelWriter
import glob
import pandas as pd
import openpyxl


writer = ExcelWriter(""output.xlsx"")
for filename in glob.glob (r""C:\path\*.xlsx""):
    wb = openpyxl.load_workbook(filename)
    for ws in wb.sheetnames:
        ws1 = wb[ws]
        data = ws1.values
        columns = next(data)[0:]
        df= pd.DataFrame(data, columns=columns)
        df.to_excel(writer,sheet_name=ws,index = False)

writer.save()
</code></pre>
","6","0","413","773","4","74","60478752","60479278"
"60479355","<p>You are getting GET parameters in your request so you need to pass that GET parameter in your url like this:</p>

<pre><code>https://url?parameter=2
</code></pre>

<p>so set the <code>cat=i</code> in your <code>bikes_all</code> url:</p>

<pre><code>{% url 'core:bikes_all' %}?cat=i
</code></pre>
","0","2","680","178","6","67","60478833","60479355"
"60485719","<p>It was possible to avoid this error by downgrading to python 3.7.6</p>

<p>Remark: Unfortunately, the first step of the overall processing (run time 3 days on my GPU) creates intermediate results with pickel format 5, which is new in Python 3.8. Therefore, I either have to re-run the first step for 3 days or find another solution. The files with the intermediate results cannot be used with python 3.7.6</p>
","0","0","605","156","1","68","60478862","60909819"
"60909819","<p>Try this workground: run the following code after import torch (should be fixed in 1.5):</p>

<pre><code>import ctypes
ctypes.cdll.LoadLibrary('caffe2_nvrtc.dll')
</code></pre>
","1","4","309","53","1","15","60478862","60909819"
"60478934","<p>I am really not sure about my solution, but!!! If I remember correctly, you
can only serialize dictionaries in json, so maybe try this out:</p>

<pre class=""lang-py prettyprint-override""><code>def save(filename, budgets):
   """"""Saves the changes made into the accounts""""""

   with open(filename, 'w') as f_obj: 
       budgets2 = [budget.__dict__ for budget in budgets]
       json.dump(budgets2, f_obj)
</code></pre>
","1","0","312","10","3","16","60478879","60478934"
"60479916","<p>I believe this code will achieve the result you are looking for (note that call to grid_columnconfigure is on win, which is the parent of your frame widget):</p>

<pre><code>import tkinter
import tkinter.ttk

win = tkinter.Tk()
win.geometry('600x600')

frame = tkinter.Frame(win, bg='red', height=300)
frame.grid(row=0, column=0, sticky='ew')
win.grid_columnconfigure(0,weight=1)

win.mainloop()
</code></pre>
","1","3","337","5","0","111","60478892","60479916"
"60479012","<p>You can try this.</p>

<pre><code>for lst in my_list:
    lst[2:]=[0,0,0,0]
print(my_list)
#[[1, 2, 0, 0, 0, 0], [2, 4, 0, 0, 0, 0], [10, 11, 0, 0, 0, 0]]
</code></pre>

<p>If you have different sizes of lists in list and you want to change only last 4 items to <em>0</em> try this.</p>

<pre><code>for lst in my_list:
    lst[-4:]=[0,0,0,0]
</code></pre>

<hr>

<p><strong>EDIT:</strong></p>

<p><em>I want to keep the first x elements, and change the rest to 0.</em></p>

<p>Try this.</p>

<pre><code>lst[x-len(lst):]=[0 for i in range(len(lst)-x)] #suggested by dcg
</code></pre>

<p>Or</p>

<pre><code>lst[x:]=[0]*(len(lst)-x)
</code></pre>
","3","4","14733","1831","61","1931","60478978","60479012"
"60479113","<p>The following code is what you need:</p>

<pre><code>if __name__ == ""__main__"":
    # list modification with zeros
    alist = [[1,2,3,4,5,6], [2,4,6,8,9,10], [10, 11, 12, 13, 14, 15]]

    for x in alist: 
        x[2:] = [0]*4

    print(alist)
</code></pre>

<p>Output:</p>

<pre><code>[[1, 2, 0, 0, 0, 0], [2, 4, 0, 0, 0, 0], [10, 11, 0, 0, 0, 0]]
</code></pre>
","4","0","413","32","0","12","60478978","60479012"
"60479076","<p>use <code>sum</code> method in pandas</p>

<pre><code>df.groupby('Length')['Duration'].sum()
</code></pre>

<p>Let me know if this helps!!</p>
","0","2","1444","3","8","195","60479008","60479076"
"60515381","<p>As already discussed in the comments, you don't want to add an extra new line with the print statement.
Instead you want to use the position argument in tqdm.
The use case for different threads is even mentioned in the <a href=""https://tqdm.github.io/docs/tqdm/"" rel=""nofollow noreferrer"">docs</a>.</p>

<pre><code>position : int, optional
  Specify the line offset to print this bar (starting from 0)
  Automatic if unspecified. Useful to manage multiple bars at once (eg, from threads).
</code></pre>

<p>Currently, this argument is set to 0, so it will start the progress bar each time new. Instead you want to use the number of the thread. Because of simplicity, you can convert the given text to an integer and use this. But this is not recommended for production.</p>

<pre class=""lang-py prettyprint-override""><code>import multiprocessing
import time

from tqdm import tqdm
from joblib import Parallel, delayed


def run_file_analysis(text):
    cool = []
    for i in tqdm(range(0, 10), position=int(text), leave=True, desc = f'Text : {text}'):
        cool.append(i)
        time.sleep(1)

num_cores = multiprocessing.cpu_count()
ls = ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10']

if __name__ == ""__main__"":
    processed_list = Parallel(n_jobs=num_cores)(delayed(run_file_analysis)(i) for i in ls)

</code></pre>

<p>If the text's can not directly converted to integer, 'enumerate' can be used an the index can be passed to the function.</p>

<pre class=""lang-py prettyprint-override""><code>import multiprocessing
import time

from tqdm import tqdm
from joblib import Parallel, delayed


def run_file_analysis(text, job_number):
    cool = []
    for i in tqdm(range(0, 10), position=job_number, leave=True, desc = f'Text : {text}'):
        cool.append(i)
        time.sleep(1)

num_cores = multiprocessing.cpu_count()
ls = ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10']

if __name__ == ""__main__"":
    processed_list = Parallel(n_jobs=num_cores)(delayed(run_file_analysis)(text, i) for i, text in enumerate(ls))
</code></pre>

<p><strong>Edit:</strong></p>

<p>Some raceconditions can be reduced by setting <code>prefer='threads'</code> to the Parallel constructor:</p>

<pre class=""lang-py prettyprint-override""><code>if __name__ == ""__main__"":
    processed_list = Parallel(n_jobs=num_cores, prefer=""threads"")(delayed(run_file_analysis)(text, i) for i, text in enumerate(ls))
</code></pre>
","7","3","1890","89","67","84","60479039","60515381"
"60479312","<p>I am not familiar with this class but after looking at the source code it seems fairly straightforward to achieve this. Keep in mind that it picks the <em>next</em> closest business day meaning Saturday turns into Monday as opposed to Friday. Also making your index be non-unique will <a href=""https://stackoverflow.com/questions/16626058/what-is-the-performance-impact-of-non-unique-indexes-in-pandas"">decrease performance</a> on your DataFrame, so I suggest assigning these values to a new column.</p>

<p>The one prerequisite is you have to make sure your index is any of these three types, <a href=""https://github.com/pandas-dev/pandas/blob/v1.0.1/pandas/tseries/offsets.py#L1064"" rel=""nofollow noreferrer"">datetime</a>, <a href=""https://github.com/pandas-dev/pandas/blob/v1.0.1/pandas/tseries/offsets.py#L1079"" rel=""nofollow noreferrer"">timedelta, pd.tseries.offsets.Tick</a>.</p>

<pre><code>offset = pd.tseries.offsets.CustomBusinessDay(n=0)

df.assign(
    closest_business_day=df.index.to_series().apply(offset)
)

            V1  V2  V3  V4  V5 closest_business_day
2008-01-12   4  15  11   7   1           2008-01-14
2008-01-13   5   2   8   7   1           2008-01-14
2008-01-14  13  13   9   6   4           2008-01-14
2008-01-15  14  15  12   9   3           2008-01-15
2008-01-16   1  10   2  12  15           2008-01-16
2008-01-17  10   5   9   9   1           2008-01-17
2008-01-18  13  11   5   7   2           2008-01-18
2008-01-19   2   6   7   9   6           2008-01-21
2008-01-20   5   4  14   3   7           2008-01-21
2008-01-21  11  11   4   7  15           2008-01-21
2008-01-22   9   4  15  10   3           2008-01-22
2008-01-23   2  13  13  10   3           2008-01-23
2008-01-24  12  15  14  12   8           2008-01-24
2008-01-25   1   4   2   6  15           2008-01-25
</code></pre>
","0","1","8935","225","249","1619","60479081","60479312"
"60479188","<p>The full signature of the <a href=""https://docs.python.org/3/library/functions.html#print"" rel=""nofollow noreferrer"">print</a> function is:</p>

<pre><code>print(*objects, sep=' ', end='\n', file=sys.stdout, flush=False)
</code></pre>

<p>The ""end"" paramter is the suffix appened to each print.
The default value is '\n' which is a new line.</p>

<pre><code>def fib(n):
    a = 0
    b = 1
    while a &lt; n :
        print(a)
        a = b
        b = a+b

fib(5)
</code></pre>
","0","1","784","99","4","65","60479100","60479188"
"60479298","<p>When you are encountering unknown Python construct, it can be often explained by built-in Python <code>help</code>. Simply launch python console and do <code>help(print)</code> to get description of <code>print</code>, which is as follows:</p>

<pre><code>Help on built-in function print in module builtins:

print(...)
    print(value, ..., sep=' ', end='\n', file=sys.stdout, flush=False)

    Prints the values to a stream, or to sys.stdout by default.
    Optional keyword arguments:
    file:  a file-like object (stream); defaults to the current sys.stdout.
    sep:   string inserted between values, default a space.
    end:   string appended after the last value, default a newline.
    flush: whether to forcibly flush the stream.
</code></pre>
","0","1","8910","0","0","376","60479100","60479188"
"60479352","<p>Can't you just <a href=""https://pandas.pydata.org/pandas-docs/stable/user_guide/groupby.html"" rel=""nofollow noreferrer"">group by</a> the year and month and then proceed from there?</p>

<pre><code>for _, v in df.groupby(['year', 'month'])['open']:
    tempOpenDF = v
    # do stuff
</code></pre>
","3","1","8935","225","249","1619","60479144","60479352"
"60479436","<p>Sample data frame:</p>

<pre><code>     0     1  2
0  123  2020  1
1  234  2020  2
2  543  2020  1
</code></pre>

<pre class=""lang-py prettyprint-override""><code># For all unique years
for y in df[1].unique():
    # For all unique months
    for m in df[2].unique():
        # Get the row based on the month
        row = df.loc[df[2] == m]
            # Print only the desired column
            print(row[0])
</code></pre>

<p>Output:</p>

<pre><code>0    123
2    543
Name: 0, dtype: int64
1    234
Name: 0, dtype: int64
</code></pre>
","0","0","203","2009","0","27","60479144","60479352"
"60479749","<pre><code>for month in range(1,13):
    tempOpenDF = tempYearDF.loc[tempYearDF['month'] == month, 'open']
</code></pre>

<p><code>loc</code> = location, or ""named"" items</p>

<p>You might want <code>iloc</code>, but also, isn't <code>tempYearDF['month']</code> an entire column?<br>
You might want to refer to <code>tempYearDF['month'].value</code> or <code>tempYearDF['month'].the_name_of_this_column</code> (or whatever the appropriate method/attribute is).</p>

<hr>

<p><code>df[df[""month""] ==1]</code> is a slice with 21 rows and all the columns
<code>df.loc[df[""month""] ==1]</code> is also a slice with 21 rows and all the columns
'<code>df.loc[df[""month""] ==1, ""open""</code> does return the 21 rows just in the <code>open</code> column when month equals <strong>1</strong>.</p>

<p>Where are you saving this too? <code>tempOpenDF</code> is <strong>within</strong> the <code>for</code> loop. Its value will just change with every index of the loop.</p>

<p>I would have to see more of where this is passed to. As it stands you filter correctly, but sending that filtered data to nowhere.</p>

<p>What you have works otherwise.</p>

<pre><code>import pandas as pd
df = pd.read_csv(""sample_data.csv"",sep='\t',parse_dates=[""date""])
# sample data is what you provided above, using tab separation
#

some_year = 2020
print(df.loc[df[""month""] == 1, 'open'],'\n')
print(df.loc[df[""year""] == 2020, 'open'],'\n')
# print(df.loc[(df[""month""] == 1 and df[""year""] == 2020), 'open'])

for i in range(1,13):
    dfy = df.loc[df[""year""] == 2020]
    mondata = dfy.loc[dfy[""month""] == i, ""open""]
    print(""Month: "",i,'\n',mondata,""\n"")
</code></pre>

<p><code>&gt;&gt;&gt; df.head()</code><br>
<code>some_index        open  year  month  day       date</code><br>
<code>0        2516  296.239990  2020      1    2 2020-01-02</code><br>
<code>1        2517  297.149994  2020      1    3 2020-01-03</code><br>
<code>2        2518  293.790009  2020      1    6 2020-01-06</code><br>
<code>3        2519  299.839996  2020      1    7 2020-01-07</code><br>
<code>4        2520  297.160004  2020      1    8 2020-01-08</code><br>
true index is 0,1, etc. <code>some_index</code> came from your data.</p>
","0","0","1560","210","2","417","60479144","60479352"
"60479253","<p>regex101.com finds the match <code>21.0*2</code> in the string <code>2+21.0*2*2</code>. <code>re.match</code> doesn't because <code>match</code> always has to include the start of the string. Using <code>re.search</code> instead works.</p>
","0","0","31087","446","113","2216","60479178","60479253"
"60479255","<p>As <a href=""https://docs.python.org/3/library/re.html"" rel=""nofollow noreferrer"">docs</a> says regarding <code>re.match</code>:</p>

<blockquote>
  <p>If zero or more characters at the beginning of string match the
  regular expression pattern, return a corresponding match object.
  Return None if the string does not match the pattern</p>
</blockquote>

<p>regex101 show that there is match starting at first digit of 21. You should use <code>re.search</code> instead:</p>

<pre><code>import re
m = re.search(r""((\d+)?(\.?)\d+)\*((\d+)?(\.?)\d+)"", ""2+21.0*2*2"")
print(m is None)  # False
</code></pre>
","0","0","8910","0","0","376","60479178","60479253"
"60479281","<p>It seems like you want to get the gradient of the loss function with respect to the input (not the weights, as is usually the case). You can use <code>tf.GradientTape()</code> to achieve this particular task. Here is a sample implementation I referenced from a <a href=""https://www.tensorflow.org/tutorials/generative/adversarial_fgsm"" rel=""nofollow noreferrer"">TensorFlow tutorial</a>, with minimal edits to code to suit your situation:</p>

<pre class=""lang-py prettyprint-override""><code>loss_object = tf.keras.losses.CategoricalCrossentropy() # Can be any loss function

model = tf. keras.applications.MobileNetV2(include_top=True, weights='imagenet') # Can be any model

def compute_gradient(input, input_label):
  with tf.GradientTape() as tape:
    tape.watch(input)
    prediction = model(input)
    loss = loss_object(input_label, prediction)
  gradient = tape.gradient(loss, input)
  return gradient
</code></pre>

<p>For more information on how to use <code>tf.GradientTape()</code>, refer to the <a href=""https://www.tensorflow.org/api_docs/python/tf/GradientTape"" rel=""nofollow noreferrer"">official documentation</a>.</p>
","0","0","1396","8","14","79","60479230","60479281"
"60479493","<p>I was not exactly sure what you wanted to do, but I modified your function to determine if num entry is ''.  If not then convert value fetched to int and compare to 56.  If larger, then insert entry ""Excellent"" in remark entry, otherwise put ""Done"" in remark entry.</p>

<p>As you enter each digit, the comparison to 56 will take place so the first digit will always result in ""Done"" appearing.  Once you exceed 56 (which will require a minimum of 2 digits) it will continue to remain ""Excellent"".</p>

<p>Again, I did the best I could with the logic provided.  Here's the full code:</p>

<pre><code>from tkinter import *

root = Tk()

num = StringVar()
entry1 = Entry(root, textvariable=num).pack()

remark = StringVar()
entry2 = Entry(root, textvariable=remark).pack()

def set_label(name, index, mode):
    result = num.get()
    if result == '':
        pass # not sure what rule should be here
    else:
        result = int(result)
        if result &gt; 56:
            remark.set(""Excellent"")
        else:
            remark.set(""Done"")

num.trace('w', set_label)
num.set('')

root.mainloop
</code></pre>
","2","0","337","5","0","111","60479237","60479493"
"60479829","<p>Welcome to StackOverflow.</p>

<p>There could be two causes for your problem. </p>

<p>1) It could be that you modified the dataset. For this, I would check the dataset and see if you made any changes to the data itself. Because your code works on other examples and will not change from day to day because there are no random elements to it. </p>

<p>2) The second issue could be your use of <code>df.description</code> when you call a dataframe column in this line:</p>

<pre><code>sent = nltk.word_tokenize(str(df.description))
</code></pre>

<p>you get a truncated output. Look at the type of <code>df.description</code> and it is a <code>Series</code> object.</p>

<p>I created another example and it is as follows:</p>

<pre><code>from nltk.tokenize import word_tokenize
import pandas as pd

df = pd.DataFrame({'description' : ['The OP is asking a question and I referred him to the Minimum Verifible Example page which states: When asking a question, people will be better able to provide help if you provide code that they can easily understand and use to reproduce the problem. This is referred to by community members as creating a minimal, reproducible example (reprex), a minimal, complete and verifiable example (mcve), or a minimal, workable example (mwe). Regardless of how it\'s communicated to you, it boils down to ensuring your code that reproduces the problem follows the following guidelines:']})


print(df.description)

0    The OP is asking a question and I referred him...
Name: description, dtype: object
</code></pre>

<p>As you see above, it is truncated and it is not the full text in the <code>description</code> column.</p>

<p>My recommendation to your code is to look into this line of code and find a different way of doing it:</p>

<pre><code>sent = nltk.word_tokenize(str(df.description))
</code></pre>

<p>Note that the method that you used in your code will include the index number (which I understand you filtered by <code>isalpha</code>) and also this <code>Name: description, dtype: object</code> in the data that you are processing.</p>

<p>One way would be to use <code>map</code> to process your data. An example is:</p>

<pre><code>pd.set_option('display.max_colwidth', -1)
df['tokenized'] = df['description'].map(str).map(nltk.word_tokenize)
</code></pre>

<p>Proceed to do this for other operations as well. An easy way to do it would be to build a preprocessing function that applies all the pre-processing operations (that you want to use) on your dataframe.</p>

<p>I hope this helps.</p>
","2","0","1710","112","5","196","60479331","60479829"
"60479363","<p>No, that gets evaluated like this:</p>

<p><code>a[1:3][1]</code> -> <code>[[8, 3], [22, 80]][1]</code> -> <code>[22, 80]</code></p>

<p>Note that <code>:3</code> means <em>up to</em> index 3 (not including it), so really your slice should be <code>a[1:4]</code>, but where you want the <em>last three</em> sublists, and not the <em>second to fourth</em> sublists, you should use a negative slice: <code>a[-3:]</code>. Even if the list can only ever be 4-long, this is clearer.</p>

<p>So you want <code>[x[1] for x in a[-3:]]</code></p>

<p>If you want to print them like in your example output:</p>

<pre><code>&gt;&gt;&gt; for x in a[-3:]:
...     print(x[1])
... 
3
80
9
</code></pre>
","1","0","15300","3115","1510","3211","60479341","60479396"
"60479373","<p>You can use <em>negative slicing</em> here.</p>

<pre><code>print(*[x[1] for x in a[-3:]],sep='\n') #a[-3:] gives last 3 elements
</code></pre>
","0","1","14733","1831","61","1931","60479341","60479396"
"60479396","<p>My 2c:</p>

<pre><code>[x[1] for x in a[-3:]]
</code></pre>

<hr>

<pre><code>[3, 80, 9]
</code></pre>

<p><a href=""https://trinket.io/python3/d1dc7e25e6"" rel=""nofollow noreferrer"">Demo</a></p>
","0","3","74108","5063","858","7248","60479341","60479396"
"60479504","<p>Possibly the easiest way to do this as most of the other answers have suggested is:</p>

<pre><code>[x[1] for x in a[-3:]]
</code></pre>

<p>However, for practice and for getting used to other ways of solving problems involving lists (and others), it is good to read up on what <code>map</code>, <code>filter</code> and <code>reduce</code> do (assuming that it is not known already). A small description is <a href=""https://book.pythontips.com/en/latest/map_filter.html"" rel=""nofollow noreferrer"">here</a>. </p>

<p>I thought I'd leave this answer here to add to the other answers. This is another way to do it using <code>map</code>. </p>

<pre><code>[*map(lambda x: x[1], a[-3:])]

Output: [3, 80, 9]
</code></pre>

<p>Hope this helps.</p>
","1","0","1710","112","5","196","60479341","60479396"
"60479490","<p>By default, kafka python start from last offset, ie will only read new mesages.
One approach is to read from beginning or the alternative approach is to keep polling topic in an infinite loop as shown in below code:</p>

<pre><code>while True:
    try:
        records = consumer.poll(60 * 1000) # timeout in millis , here set to 1 min

        record_list = []
        for tp, consumer_records in records.items():
            for consumer_record in consumer_records:
                record_list.append(consumer_record.value)
        print(record_list) # record_list will be list of dictionaries
</code></pre>

<h2>Edit</h2>

<p>To read from the beginning, we need to add <code>auto_offset_reset=earliest</code> earlies while making consumer object</p>

<pre><code>consumer = KafkaConsumer(
    ""my-topic"",
    bootstrap_servers=""localhost:9092""),
    value_deserializer=lambda v: json.dumps(v).encode(""utf-8""),
    auto_offset_reset='earliest')
</code></pre>

<p>Let me know if this helps!!</p>
","2","1","1444","3","8","195","60479348","60479490"
"60479999","<p>Why <code>+=</code> works and <code>+</code> doesn't work is ""that's how its coded"". But I haven't figured out any good reason for it. Lets focus simply on list addition</p>

<pre><code>operator         magic method   list equiv
--------         ------------   ----------
+= (inplace add) __iadd__       list_inplace_concat
+  (add)         __add__        list_concat
</code></pre>

<p>Inplace Add / list_inplace_concat works on any sequence. Under the covers, python simply calls <code>list.extend</code> which turns the right hand side into an iterator and so works with all sequences</p>

<pre><code>&gt;&gt;&gt; test = []
&gt;&gt;&gt; test += 'abc'
&gt;&gt;&gt; test
['a', 'b', 'c']
</code></pre>

<p>Add / list_concat is hardcoded to work only with other lists. The underlying C code uses the internal data structure of the list to copy its elements.</p>

<pre><code>&gt;&gt;&gt; test + 'abc'
Traceback (most recent call last):
  File ""&lt;stdin&gt;"", line 1, in &lt;module&gt;
TypeError: can only concatenate list (not ""str"") to list
</code></pre>

<p>Change the right hand side to a list and it works</p>

<pre><code>&gt;&gt;&gt; test + list('abc')
['a', 'b', 'c', 'a', 'b', 'c']
&gt;&gt;&gt; 
</code></pre>

<p><code>list_concat</code> is optimized to use the size of the two lists to know exactly how large the new list needs to be. Then it does member copy at the C structure level. What puzzles me is why there isn't a fallback when the ""not a list"" condition is detected. The list could be copied and extended.</p>
","0","1","55035","2176","130","4224","60479354","60479999"
"60480411","<p>Django is framework designed to build web applicattions. So it means that when the web-browser sends a request to a server, server processes the request and produces a response with adequate data, data gets send and displayed in the browser. This also means that most of processing that is done in Django happens in request context, while the applications is running.</p>

<p>Now if Django is not running and you try to use it scripts it crashes because it does not have its configuration loaded. So what you are really trying to do is using Django database layer outside of Django. To achieve this you load the settings and setup Django before you use its models.</p>

<p>Question how to use Django ORM outside of Django has already been answered here 
<a href=""https://stackoverflow.com/questions/2180415/using-django-database-layer-outside-of-django"">Using Django database layer outside of Django?</a>
and here 
<a href=""https://stackoverflow.com/questions/55247878/how-to-use-django-models-outside-of-django"">How to use Django models outside of Django?</a></p>

<p>For the sake of making your code work, if we supposedly if we have application 'football' and an app called 'list' in it with model 'Player' in its models module, and your script is in folder with manage.py. Than your code could look like the following:</p>

<pre><code>import requests
import urllib3
from bs4 import BeautifulSoup
import os
import django

os.environ['DJANGO_SETTINGS_MODULE'] = 'football.settings'
django.setup()

from list.models import Player

urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)
session = requests.Session()
session.headers = {""User-Agent"": ""Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/79.0.3945.117 Safari/537.36""}
url = 'https://www.smitegame.com/'
content = session.get(url, verify=False).content
soup = BeautifulSoup(content, 'html.parser')
allgods = soup.find_all('div', {'class': 'god'})

allitem = []

for god in allgods:
    godName = god.find('p')
    godFoto = god.find('img').get('src')
    allitem.append((godName, godFoto))
    Player.objects.create(name=godName.text)
</code></pre>

<p>Now what the bit of code that was added tells Django where its settings module, and then imports the models. </p>

<blockquote>
  <p>When you use Django, you have to tell it which settings you’re using. Do this by using an environment variable, </p>
</blockquote>

<p>Check the documentation
<a href=""https://docs.djangoproject.com/en/3.0/topics/settings/#designating-the-settings"" rel=""nofollow noreferrer"">https://docs.djangoproject.com/en/3.0/topics/settings/#designating-the-settings</a></p>
","1","1","86","22","0","6","60479411","60480411"
"60479735","<p>I recommend you scan the text as a whole and not the individual lines. Also you can use groups in your pattern to capture and contain data. I would read the data as follows:</p>

<pre class=""lang-py prettyprint-override""><code>with open('test_subtitle.srt', 'r') as f:
    subtitles = f.read()
</code></pre>

<p>Then using the following code I would match the single sections and extract the data:</p>

<pre class=""lang-py prettyprint-override""><code>import re

num_pat = r'(\d+)'
time_pat = r'(\d{2,}:\d{2}:\d{2},\d{3}) --&gt; (\d{2,}:\d{2}:\d{2},\d{3})'
sentence_pat = r'([^\n]*)\n'

data_pattern = re.compile(r'\n'.join([num_pat, time_pat, sentence_pat]))
print('data_pattern:', data_pattern)

for i in re.finditer(data_pattern, subtitles):
    print('-'*20)
    print(i.group(1))
    print(f'time: {i.group(2)} --&gt; {i.group(3)}')
    print('text:', repr(i.group(4)))
    print()
</code></pre>

<p>A problem I also noticed in your code is that when defining your patterns you were using normal strings instead of raw strings and you weren't escaping your backslashes. If you want to use backslashes without escaping you should use a raw string. Hope this helped.</p>
","5","0","266","7","4","21","60479444","60479735"
"60479573","<p>Since you have multiple levels of grouping here, I'd recommend just using a for loop to iterate over your data.</p>

<pre><code>from collections import defaultdict  

def make_nested(df): 
    f = lambda: defaultdict(f)   
    data = f()  

    for row in df.to_numpy().tolist():
        t = data
        for r in row[:-1]:
            t = t[r]
        t[row[-1]] = {}

    return data
</code></pre>

<p></p>

<pre><code>print(json.dumps(make_nested(df), indent=2))
{
  ""src1"": {
    ""table1"": {
      ""col1"": {},
      ""col2"": {}
    },
    ""table2"": {
      ""col1"": {}
    }
  },
  ""src2"": {
    ""table1"": {
      ""col1"": {},
      ""col2"": {}
    }
  }
}
</code></pre>

<p></p>

<p>This assumes your columns are arranged from left to right: outermost keys to innermost key.</p>
","3","2","266035","10142","8528","64481","60479452","60479573"
"60486167","<p>I guess you only need the <code>review</code> part of the data? If so, and <code>dt</code> is that part of the json, you can use </p>

<pre><code>data=dt.to_dict('records'),
</code></pre>

<p>because your structure is <code>[{column -&gt; value}, … , {column -&gt; value}]</code>, see <a href=""https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.to_dict.html"" rel=""nofollow noreferrer"">pandas reference</a></p>
","0","1","1920","33","39","141","60479516","60486167"
"60480022","<p>Decorator is a function that takes as input the function (or class) to decorate, and makes some changes to it. I would go for a two method option, in which if the first method is true then they're genuine teacher, else they're not and in such case give them a valid output.</p>

<pre><code>def teacher_required(function=None, redirect_field_name=REDIRECT_FIELD_NAME, login_url='login'):
    '''
    Decorator for views that checks that the logged in user is a teacher,
    redirects to the log-in page if necessary.
    '''
    actual_decorator = user_passes_test(
        lambda u: u.is_active and u.is_teacher,
        login_url=login_url,
        redirect_field_name=redirect_field_name
    )
</code></pre>

<p>We can simply make a use case for the decorator <code>user_passes_test</code> </p>

<pre><code>from django.contrib.auth.decorators import user_passes_test

def teacher_required(function=None):
    def is_teacher(u):
        return Shopkeeper.objects.filter(user=u).exists()
    actual_decorator = user_passes_test(is_teacher)
    if function:
        return actual_decorator(function)
    else:
        return actual_decorator

</code></pre>

<p>You can then for example implement it as:</p>

<pre><code>@login_required
@teacher_required
def teacher_view(request):
    # ...
    pass

@login_required
def not_teacher_view(request):
    # ...
    pass

</code></pre>

<p>I hope you get the idea, for clarity see <a href=""https://stackoverflow.com/a/51127599/6505847"">this</a></p>
","0","1","5568","358","9","686","60479527","60480657"
"60480543","<p>Django comes with build in messages framework. <a href=""https://docs.djangoproject.com/en/3.0/ref/contrib/messages/"" rel=""nofollow noreferrer"">https://docs.djangoproject.com/en/3.0/ref/contrib/messages/</a></p>

<p>To use if you have to follow the steps:</p>

<p>Make sure you have django messages added in installed apps in your settings.py.</p>

<pre><code>INSTALLED_APPS = [
    ...

    'django.contrib.messages',

    ...
]
</code></pre>

<p>Configure the messages storage by adding the following line into your settings.py:</p>

<pre><code>MESSAGE_STORAGE = 'django.contrib.messages.storage.session.SessionStorage'
</code></pre>

<p>Add message in your decorator before returning the actual_decorator:</p>

<pre><code>messages.warning(request, 'Access restricted, for teachers only')
</code></pre>

<p>and than if you use bootstrap you could display alters in your template in following way:</p>

<pre><code>{% if messages %}
    {% for message in messages %}
    &lt;div class=""alert alert-warning""&gt;
    {{ message }}
    &lt;/div&gt;
    {% endfor %}
{% endif %}
</code></pre>

<p>the documentation for bootstrap alerts can be found here: <a href=""https://getbootstrap.com/docs/4.0/components/alerts/"" rel=""nofollow noreferrer"">https://getbootstrap.com/docs/4.0/components/alerts/</a></p>
","0","0","86","22","0","6","60479527","60480657"
"60480657","<p>You can use the build-in <a href=""https://docs.djangoproject.com/en/3.0/ref/contrib/messages/"" rel=""nofollow noreferrer"">messages</a> from Django with a custom decorator.</p>

<p>For this, Django provides full support for cookie- and session-based messaging, for both anonymous and authenticated users.</p>

<p>In your case, an example would be the following:</p>

<p>decorators.py</p>

<pre><code># Import Django messages
from django.contrib import messages

# Custom Decorator
def teacher_required(function):
    def _function(request, *args, **kwargs):
        if not request.user.is_teacher:
            messages.info(request, 'Custom message to user')
            return HttpResponseRedirect(reverse('app:url_name'))
        return function(request, *args, **kwargs)

    return _function
</code></pre>

<p>views.py</p>

<pre><code>from django.utils.decorators import method_decorator
from django.contrib.auth.decorators import login_required
from foo.decorators import teacher_required

@method_decorator([login_required, teacher_required], name='dispatch')
class MyView(TemplateView):
    template_name = 'template.html'
</code></pre>

<p>In this case you have to call the decorator with <code>@method_decorator()</code>, and pass the <code>login_required</code> first, to ensure that the user is logged in before checking if he is a teacher.</p>

<p>If you want to implement a more elegant system, I have found an example on <a href=""https://gist.github.com/edwinlunando/3af8f1eae9bbd67cb647"" rel=""nofollow noreferrer"">github</a>.</p>
","0","1","675","143","17","71","60479527","60480657"
"60479584","<p>You can do for example:</p>

<pre><code>matching_shakes = list(filter(lambda line: re.match(regex, line), shakes))
</code></pre>
","3","0","701","18","5","37","60479529","60479584"
"60479634","<p>You've opened <code>out</code> twice: once for the <code>f</code> variable and a second time for the <code>for line in open(out):</code> loop. Each <code>file</code> object has its own position, and you've only been reading from the second one (which hasn't been assigned to a variable so you can't get the position). The position of <code>f</code> is still at the beginning, since you never read from it.</p>

<p>You should use</p>

<pre><code>for line in f:
</code></pre>

<p>and not call <code>open(out)</code> a second time. You can then call <code>f.readline()</code> inside the loop to read more lines of the file.</p>
","0","1","586865","7069","3864","89361","60479599","60481686"
"60479673","<p>How about this (note: untested so there's bound to be bugs - think of this as a sketch of a solution):</p>

<pre><code>def read_xyz_out(self,out):
    atoms = []
    x = []
    y = []
    z = []
    f = open(out, ""r"")

    # Read until you get to the data
    for line in f:
        if re.match(r'{}'.format(r'CARTESIAN COORDINATES \(ANGSTROEM\)'), line):
            # skip the next line too
            f.readline()
            break

     # Now you're into the data - the loop here picks up where the previous
     # one left off
     for line in f:
             data = line.split()
             atoms.append(data[0])
             x.append(float(data[1]))
             y.append(float(data[2]))
             z.append(float(data[3]))
    f.close()
</code></pre>
","0","1","8115","76","8","296","60479599","60481686"
"60481686","<p>Suppose you read your file into this string:</p>

<pre><code>My dog has fleas.
CARTESIAN COORDINATES (ANGSTROEM)
---------------------------------
  C     -0.283576   -0.776740   -0.312605
  H     -0.177080   -0.046256   -1.140653
  Cl    -0.166557    0.025928    1.189976

----------------------------

My cat too.
</code></pre>

<p>You can then extract lines 4, 5 and 6 with the regular expression</p>

<pre><code>/CARTESIAN COORDINATES \(ANGSTROEM\)\r?\n---------------------------------\r?\n(.+?)(?=\r?\n\r?\n)/s
</code></pre>

<p><a href=""https://regex101.com/r/gOwkCf/3/"" rel=""nofollow noreferrer"">demo</a></p>

<p>This expression reads, ""match the string 'CARTENSION...---\r?\n' followed by matching 1+ chars, greedily, in capture group 1, followed by an empty line, with the flag '/s' to enable '.' to match the ends of lines"".</p>

<p>The desired information can then be extracted with the regular expression</p>

<pre><code>/ *([A-Z][a-z]*) +(-?\d+.\d{6}) +(-?\d+.\d{6}) +(-?\d+.\d{6})\r?\n/
</code></pre>

<p><a href=""https://regex101.com/r/AU4WTR/3/"" rel=""nofollow noreferrer"">demo</a></p>

<p>The first step can be skipped if it is sufficient to look for a line that look like this:</p>

<pre><code>C     -0.283576   -0.776740   -0.312605
</code></pre>

<p>without having to confirm it is preceded by ""CARTESIAN...---"".</p>

<p><a href=""https://regex101.com/r/AU4WTR/5/"" rel=""nofollow noreferrer"">demo</a></p>
","0","1","93421","7912","102","9185","60479599","60481686"
"60479760","<p>The solution is provided below:</p>

<pre><code>NPVDict = sum([cash_flow/(1.1**year) for year,cash_flow in
cash_flow_dictionary.items()]) # Note items function to iterate over dictionary
print(""Present Value = "" , (f""{NPVDict:9,.2f}""))
</code></pre>

<p>Let me know if it helps!!</p>
","2","1","1444","3","8","195","60479657","60479760"
"60524489","<blockquote>
  <p>Each image has one object that I want to classify. But in total I have images of 10 different objects. I am confused, how can I prepare my mask input? Is it considered as multi-label segmentation or only for one class?</p>
</blockquote>

<p>If your dataset has N different labels (i.e: 0 - background, 1 - dogs, 2 -cats...), you have a multi class problem, even if your images contain only kind of object.</p>

<blockquote>
  <p>Should I convert my input to one hot encoded? Should I use to_categorical?</p>
</blockquote>

<p>Yes, you should one-hot encode your labels. Using to_categorical boils down to the source format of your labels. Say you have N classes and your labels are (height, width, 1), where each pixel has a value in range [0,N). In that case <strong>keras.utils.to_categorical(label, N)</strong> will provide a float (height,width,N) label, where each pixel is 0 or 1. And you don't have to divide by 255.</p>

<p>if your source format is different, you may have to use a custom function to get the same output format.</p>

<p>Check out this repo (not my work): <a href=""https://github.com/karolzak/keras-unet"" rel=""nofollow noreferrer"">keras-unet</a>. The notebooks folder contain two examples to train a u-net on small datasets. They are not multiclass, but it is easy to go step by step to use your own dataset. Star by loading your labels as:</p>

<pre><code>im = Image.open(mask).resize((512,512))
im = to_categorical(im,NCLASSES)
</code></pre>

<p>reshape and normalize like this:</p>

<pre><code>x = np.asarray(imgs_np, dtype=np.float32)/255
y = np.asarray(masks_np, dtype=np.float32)
y = y.reshape(y.shape[0], y.shape[1], y.shape[2], NCLASSES)
x = x.reshape(x.shape[0], x.shape[1], x.shape[2], 3)
</code></pre>

<p>adapt your model to NCLASSES</p>

<pre><code>model = custom_unet(
input_shape,
use_batch_norm=False,
num_classes=NCLASSES,
filters=64,
dropout=0.2,
output_activation='softmax')
</code></pre>

<p>select the correct loss:</p>

<pre><code>from keras.losses import categorical_crossentropy
model.compile(    
   optimizer=SGD(lr=0.01, momentum=0.99),
   loss='categorical_crossentropy',    
   metrics=[iou, iou_thresholded])
</code></pre>

<p>Hope it helps</p>
","1","1","327","13","0","27","60479659","60524489"
"60479855","<blockquote>
  <p>I'm relying on the fact that <code>./</code> is (in effect) on the PYTHONPATH.</p>
</blockquote>

<p>It's not. It's not on <code>PYTHONPATH</code>, and it's not on <code>sys.path</code>. When you run a script by file path, it's the <em>script's</em> directory that gets added to <code>sys.path</code>. You can see what gets added to <code>sys.path</code> for each way of specifying a program to run in the <a href=""https://docs.python.org/3/using/cmdline.html"" rel=""nofollow noreferrer"">Python command line docs</a>.</p>
","0","1","212283","3259","18958","29736","60479777","60479855"
"60484475","<p>I have not used pandas dataframes before. I'm sure you could also use those, but I find it easier to use the builtin structures.<br>
What I recommended in the comments was using a list of characters. That could look like this:  </p>

<pre class=""lang-py prettyprint-override""><code>mylist = [ 'a', 'b', 'c' ]
print(mylist[1])
# outputs 'b', because that's at position 1 in the list
</code></pre>

<p>However, since you already have a dict of the numbers and characters in your code, we can just as well use that <code>code</code> dict:</p>

<pre class=""lang-py prettyprint-override""><code>import string, random

def make_a_guess(solution):
    print(""Make a guess..."")
    letter = input(""What letter: "").lower()
    number = int(input(""What number: ""))

    # the -1 is a default value to be returned if no valid number was provided. None would work just as well, if not better.
    if solution.get(number, -1) == letter:
        print(""Correct, {} = {}"".format(letter, number))
    else:
        print(""Wrong, {} != {}"".format(letter, number))

#User Input
title = input(""Please Enter A Title For This Puzzle: "")
if len(title) == 0:
    print(""String is empty"")
    quit()

phrase = input(""Please Enter A Phrase To Be Encoded: "")
if len(phrase) == 0:
    print(""String is empty"")
    quit()


if not  phrase.islower():
    print(""Please use lowercase for the phrase"")
    quit()

#Numbers get assigned to the letters
nums = random.sample(range(1, 27), 26)
code = dict(zip(nums, string.ascii_lowercase))

print('')

while True:
    make_a_guess(code)

</code></pre>

<p>Of course, you'll still have to add a stopping condition and a way to allow the user to enter the correct phrase as numbers. But the <code>make_a_guess</code> function should be what I think you were looking for.</p>

<hr>

<h3>Bonus Question</h3>

<p>As you asked in a comment if I have an idea why the numbers from my code are off by one compared to the pandas indexing.
That is likely simply due to this line here, which samples from a minimum of <code>1</code> instead of <code>0</code> up to but exclusive <code>27</code>.</p>

<pre class=""lang-py prettyprint-override""><code>nums = random.sample(range(1, 27), 26)
</code></pre>

<p>If you change that to the following, it will also start at 0.</p>

<pre class=""lang-py prettyprint-override""><code>nums = random.sample(range(0, 26), 26)
</code></pre>

<p>Normally, arrays count from <code>0</code>, not from <code>1</code>, and it seems pandas keeps to this convention.</p>
","3","2","3674","7445","142","610","60479809","60484475"
"60479900","<p>We can split the y before the <code>rolling</code> and <code>reindex</code> fill the value with 0 </p>

<pre><code>y1 = y[df.COL3 == 'A']
y1 = y1.rolling(window).apply(lambda x: np.max(x) if len(x)&gt;0 else 0).fillna('drop')
y = y1.reindex(y.index, fill_value = 0).loc[lambda x : x!='drop']
</code></pre>
","2","0","252249","5881","962","22297","60479828","60479900"
"60486172","<p>You can merge every two contours that applies the following condition:  </p>

<ul>
<li>Area of <strong>convex hull</strong> of the merged contours is close to the sum of areas of the two contours.  </li>
</ul>

<p>The following solution uses a kind of ""brute force"" approach that tries merging every contour with all other contours (not very efficient).  </p>

<p>Here is a working code sample (please read the comments):  </p>

<pre><code>from skimage.feature import peak_local_max
from skimage.segmentation import watershed
import matplotlib.pyplot as plt
from scipy import ndimage
import cv2 as cv
import imutils
import numpy as np

img = cv.imread(""image.jpg"");
blur = cv.GaussianBlur(img,(7,7),0)


#color space change
mSource_Hsv = cv.cvtColor(blur,cv.COLOR_BGR2HSV);
mMask = cv.inRange(mSource_Hsv,np.array([0,0,0]),np.array([80,255,255]));
output = cv.bitwise_and(img, img, mask=mMask)

#grayscale
img_grey = cv.cvtColor(output, cv.COLOR_BGR2GRAY)

#thresholding
ret,th1 = cv.threshold(img_grey,0,255,cv.THRESH_BINARY + cv.THRESH_OTSU)

#dist transform
D = ndimage.distance_transform_edt(th1)

#markers
localMax = peak_local_max(D, indices=False, min_distance=20, labels=th1)
markers = ndimage.label(localMax, structure=np.ones((3, 3)))[0]

#apply watershed
labels = watershed(-D, markers, mask=th1)
print(""[INFO] {} unique segments found"".format(len(np.unique(labels)) - 1))


contours = []

# loop over the unique labels, and append contours to all_cnts
for label in np.unique(labels):
    if label == 0:
        continue

    # draw label on the mask
    mask = np.zeros(img_grey.shape, dtype=""uint8"")
    mask[labels == label] = 255

    # detect contours in the mask and grab the largest one
    cnts = cv.findContours(mask.copy(), cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)
    cnts = imutils.grab_contours(cnts)
    c = max(cnts, key=cv.contourArea)

    ## Ignore small contours
    #if c.shape[0] &lt; 20:
    #    continue

    # Get convex hull of contour - it' going to help when merging contours
    hull = cv.convexHull(c)

    #cv.drawContours(img, c, -1, (0, 255, 0), 2)
    cv.drawContours(img, [hull], -1, (0, 255, 0), 2, 1)

    # Append hull to contours list
    contours.append(hull)


# Merge the contours that does not increase the convex hull by much.
# Note: The solution is kind of ""brute force"" solution, and can be better.
################################################################################
for i in range(len(contours)):
    c = contours[i]

    area = cv.contourArea(c)

    # Iterate all contours from i+1 to end of list
    for j in range(i+1, len(contours)):
        c2 = contours[j]

        area2 = cv.contourArea(c2)

        area_sum = area + area2

        # Merge contours together
        tmp = np.vstack((c, c2))
        merged_c = cv.convexHull(tmp)

        merged_area = cv.contourArea(merged_c)

        # Replace contours c and c2 by the convex hull of merged c and c2, if total area is increased by no more then 10%
        if merged_area &lt; area_sum*1.1:
            # Replace contour with merged one.
            contours[i] = merged_c
            contours[j] = merged_c
            c = merged_c
            area = merged_area
################################################################################


# Draw new contours in red color
for c in contours:
    #Ignore small contours
    if cv.contourArea(c) &gt; 100:
        cv.drawContours(img, [c], -1, (0, 0, 255), 2, 1)


cv.imshow(""segmented"",img)
cv.waitKey(0)
cv.destroyAllWindows()
</code></pre>

<hr>

<p>Result:<br>
<a href=""https://i.stack.imgur.com/sOZhT.jpg"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/sOZhT.jpg"" alt=""enter image description here""></a></p>
","0","1","11911","1803","123","963","60479830","60486172"
"60479998","<p>The error might be that <code>json_data</code> is a string and not a dict type as <code>json.dumps(str(soup))</code> returns a string.Since <code>json_data</code> is string, we cannot do <code>json_data['Results']</code> and to access any element of string, we need to pass the index and hence the error.</p>

<h2>EDIT</h2>

<p>To get <code>Results</code> from the response, the code is shown below:</p>

<pre><code>json_data = json.loads(str(soup.text))
print(json_data['Results'])
</code></pre>

<p>Let me know if this helps!!</p>
","2","2","1444","3","8","195","60479854","60479998"
"60479993","<p>Use a <a href=""https://docs.python.org/3/glossary.html#term-generator-expression"" rel=""nofollow noreferrer"">generator expression</a> instead of a <code>map</code>.</p>

<pre><code>(fun(x, **kwargs) for x in elements)
</code></pre>

<p>e.g.</p>

<pre><code>reduce(fun(x, **kwargs) for x in elements)
</code></pre>

<p>Or if you're going straight to a list, use a <a href=""https://docs.python.org/3/glossary.html#term-list-comprehension"" rel=""nofollow noreferrer"">list comprehension</a> instead:</p>

<pre><code>[fun(x, **kwargs) for x in elements]
</code></pre>
","0","4","15300","3115","1510","3211","60479968","60479993"
"60480014","<p>The question is already answered at <a href=""https://stackoverflow.com/questions/16874244/python-map-and-arguments-unpacking"">Python `map` and arguments unpacking</a></p>

<p>The map does not exactly support named variable, though can handle multiple variable based on position. </p>

<p>Since Python 3 the standard map can list arguments of multi-argument separately</p>

<pre><code>map(fun, listx, listy, listz)
</code></pre>

<p>It is though less convenient for variable length list of named variables, especially in presence of <code>**kwargs</code> in the function signature. You can, though,
introduce some intermediate function to pack separately positional and named arguments. For one line solution with lambda see <a href=""https://stackoverflow.com/questions/16874244/python-map-and-arguments-unpacking"">Python `map` and arguments unpacking</a>
If you are not proficient with lambda, you can go as below</p>

<pre><code>def foldarg(param): 
    return f(param[0], **param[1])
list(map(foldarg, elements))
</code></pre>

<p>where <code>elements</code> is something like</p>

<pre><code>[[[1,2], dict(x=3, y=4)],
[[-2,-2], dict(w=3, z=4)]]
</code></pre>

<p>For unnamed variables list you can also use itertools.starmap </p>
","1","2","2617","151","9","275","60479968","60479993"
"60480123","<p>Looks like the problem is that you want the program to remember the player's health between screens?</p>

<p>If so, I think you'll need some kind of variable outside of the function to store the player's health in between attacks. Since right now it looks like the function resets the health to 10 every time.</p>

<p>Also, I'd recommend using another argument to the function to pass in your current health, and a return value to calculate what your new health should be after the attack.</p>

<p>If that's the approach you're going for, I think your top level function would look kind of like this --</p>

<pre class=""lang-py prettyprint-override""><code># Starting Health
my_health = 10
...
# Main loop
while(not_quit):
    ...
    # Update health
    my_health = healthSystem(enemy_attack, my_health)
    ...
</code></pre>
","0","3","731","442","15","39","60480049","60480123"
"60480124","<p>The root problem is that you're not tracking health at all. <code>current_health</code> is defined in the function but not returned or saved to a global or anything. Ultimately a class is going to be the best solution (probably - I've never built a game myself), but the bare minimum fix would be to take <code>current_health</code> as a parameter, modify it in the function, <code>return current_health</code> at the end, and track it outside the function until the next loop.</p>
","0","0","15300","3115","1510","3211","60480049","60480123"
"60480189","<p>The return type is an instance of <code>sympy.core.add.Add</code>. You can convert it to float by doing:</p>

<pre><code>&gt;&gt;&gt; integral
1/8 - exp(-4)/8
&gt;&gt;&gt; float(integral)
0.12271054513890822
</code></pre>
","0","0","10203","195","80","596","60480054","60480189"
"60482765","<p>Just so you know, I don't know much about the transip api.</p>

<p>I took a look at their code where the error is being thrown in <a href=""https://github.com/benkonrath/transip-api/blob/master/transip/service/objects.py#L52"" rel=""nofollow noreferrer"">transip/service/objects.py</a>, and it looks like they have a bug:</p>

<pre class=""lang-py prettyprint-override""><code>def __eq__(self, other): 
    # other can be a list. This check ensures that other is a DnsEntry. 
    if not hasattr(self, 'name') or not hasattr(self, 'type') or not hasattr(self, 'content'): 
        return False 

    # expire is intentionally not used for equality. 
    return self.name == other.name and self.type == other.type and self.content == other.content

</code></pre>

<p>The comment says that <code>other</code> can be a list so they're ensuring that it's a DNSEntry, but they're actually not checking that at all. If <code>self</code> has the attributes <code>name</code>, <code>type</code>, and <code>content</code>, and <code>other</code> does not, this will break. In your case, <code>other</code> is a list so it doesn't have the <code>name</code> attribute.</p>

<p>Something like changing the first if statement to check <code>other</code> instead of <code>self</code> may solve it:</p>

<pre class=""lang-py prettyprint-override""><code>if not hasattr(other, 'name') or not hasattr(other, 'type') or not hasattr(other, 'content'): 
        return False 
</code></pre>

<p>It would actually probably be better to just check if <code>other</code> is a list:</p>

<pre class=""lang-py prettyprint-override""><code>if isinstance(other, list):
   return False
</code></pre>

<p>If I were you, I'd either open an issue in transip API GitHub repo, or do a quick fix yourself and submit a pull request.</p>
","0","1","1337","2625","1","61","60480069","60482765"
"60480182","<p>For example:</p>

<pre><code>while all((row[2] != 2 for row in list)):
</code></pre>

<p>or:</p>

<pre><code>while any((row[2] != 2 for row in list)):
</code></pre>

<p>depending on what you really want.</p>
","0","2","701","18","5","37","60480149","60480182"
"60480831","<p>I wrote a function that could get the job done, depending on the size of the file. Explanation in code comments.</p>

<pre><code>def split_file(file_name, lines_per_file=100000):
    # Open large file to be read in UTF-8
    with open(file_name, 'r', encoding='utf-8') as rf:
        # Read all lines in file
        lines = rf.readlines()
        print ( str(len(lines)) + ' LINES READ.')
        # Set variables to count file number and count of lines written
        file_no = 0
        wlines_count = 0
        # For x from 0 to length of lines read stepping by number of lines that will be written in each file
        for x in range(0, len(lines), lines_per_file):
            # Open new ""split"" file for writing in UTF-8
            with open( 'data' + '-' + str(file_no) + '.txt', 'w', encoding='utf-8') as wf:
                # Write lines
                wf.writelines(lines[x:x+lines_per_file])
                # Update the written lines count
                wlines_count += (len(lines[x:x + lines_per_file]))
                # Update new ""split"" file count mainly for naming
                file_no+=1
        print(str(wlines_count) + "" LINES WRITTEN IN "" + str(file_no) + "" FILES."")

# Split data.txt into files containing 100000 lines
split_file('data.txt',100000)
</code></pre>
","0","0","1541","222","23","129","60480172","60480831"
"60480247","<p>If you're looking for how to use a builtin Python module (the <code>csv</code> module, for example), I would recommend looking at the official Python documentation.</p>

<p>You can find the documentation for the csv module <a href=""https://docs.python.org/3/library/csv.html"" rel=""nofollow noreferrer"">here</a>.</p>

<p>Here's the first example they give of reading a csv file (see <a href=""https://docs.python.org/3/library/csv.html#examples"" rel=""nofollow noreferrer"">https://docs.python.org/3/library/csv.html#examples</a>):</p>

<pre class=""lang-py prettyprint-override""><code>with open('some.csv', newline='') as f:
    reader = csv.reader(f)
    for row in reader:
        print(row)
</code></pre>

<p>In the loop, you can access <code>row</code> to store it in whatever data structure you prefer.</p>

<p>For example, to put it in all in a list:</p>

<pre class=""lang-py prettyprint-override""><code>with open('some.csv', newline='') as f:
    reader = csv.reader(f)
    data = [row for row in reader]
print(data)
</code></pre>
","0","1","1337","2625","1","61","60480197","60480251"
"60480251","<p>The beauty of using pandas' read_csv is that it automatically and most importantly <strong>quickly</strong> converts said csv into a usable dataframe.</p>

<p>using csv.reader simply refers to the csv in question but you would have to call an iterator to get a result.</p>

<p>i.e.: (from <a href=""https://docs.python.org/3/library/csv.html"" rel=""nofollow noreferrer"">https://docs.python.org/3/library/csv.html</a>)</p>

<pre><code>&gt;&gt;&gt; import csv
&gt;&gt;&gt; with open('eggs.csv', newline='') as csvfile:
...     spamreader = csv.reader(csvfile, delimiter=' ', quotechar='|')
...     for row in spamreader:
...         print(', '.join(row))
Spam, Spam, Spam, Spam, Spam, Baked Beans
Spam, Lovely Spam, Wonderful Spam
</code></pre>
","1","0","505","25","7","54","60480197","60480251"
"60480389","<p>As you can see from the <code>insert(self, data)</code> method's content, the <code>right</code> and <code>left</code> instance attributes are meant to hold objects of type <code>Node</code>, which are references to the two child nodes of the <code>self</code> node. The lines you quoted call the methods defined in this very class, but instead of calling them on the <code>self</code> instance, they call them on the child nodes, so they'll be working with different data.</p>
","1","1","88","29","0","22","60480265","60480389"
"60480460","<p>You can get a specified version of a file without checking out the corresponding commit using <code>git show</code>. For example:</p>

<pre><code>git show git_hash:./file.py
</code></pre>

<p>will print the contents of <code>file.py</code> as of the specified commit to standard output. (Presumably the Git Python interface, which I haven't used, provides similar functionality.) The leading <code>./</code> avoids path resolution problems in some cases (I don't remember the details).</p>

<p>I've written a Perl script that does this kind of thing for several different version control systems (most of which I no longer use): <a href=""https://github.com/Keith-S-Thompson/get-versions"" rel=""nofollow noreferrer"">https://github.com/Keith-S-Thompson/get-versions</a> (no warranties).</p>

<p>As requested, here's an example of running <code>get-versions</code> on a copy of its own repo:</p>

<pre><code>$ ls -l
total 56
-rw-r--r-- 1 kst kst 18092 Aug  9  2015 COPYING
-rw-r--r-- 1 kst kst  6234 Apr 16  2018 README.md
-rw-r--r-- 1 kst kst   940 Apr 25  2018 TODO.md
-rwxr-xr-x 1 kst kst 20977 Apr 16  2018 get-versions
$ get-versions -pad 3 -last 3 get-versions 
$ ls -l
total 128
-rw-r--r-- 1 kst kst 18092 Aug  9  2015 COPYING
-rw-r--r-- 1 kst kst  6234 Apr 16  2018 README.md
-rw-r--r-- 1 kst kst   940 Apr 25  2018 TODO.md
-rwxr-xr-x 1 kst kst 20977 Apr 16  2018 get-versions
-r--r--r-- 1 kst kst 20752 Mar  2 10:54 get-versions,012
-r--r--r-- 1 kst kst 20766 Mar  2 10:54 get-versions,013
-r--r--r-- 1 kst kst 20977 Mar  2 10:54 get-versions,014
$ 
</code></pre>

<p><code>get-versions -help</code> prints an entirely too verbose usage message. (Adding a man page is on my TODO list, as is preserving execute permissions.)</p>
","1","0","228253","1538","626","50273","60480287","60480966"
"60480960","<p>Use git rev-list to get the list of commits, and git show to output the file:</p>

<pre><code>i=0; git rev-list --abbrev-commit HEAD | 
while read sha; do
    git show $sha:./file.py &gt; $((i++))_${sha}_file.py
done
</code></pre>

<p>This version might avoid problems with <code>i++</code> being executed in a subshell and not affecting the parent:</p>

<pre><code>i=0; git rev-list --abbrev-commit HEAD |
while read sha; do
    git show $sha:./file.py &gt; ${i}_${sha}_file.py
    ((i++))
done
</code></pre>
","13","0","171867","3675","1562","10640","60480287","60480966"
"60480966","<pre><code>n=0
git log --pretty= --diff-filter=d --raw -- $file | 
while read m1 m2 h1 h2 rest; do
        eval git show $h2 &gt; $((n++))_${h2}.$file
done
</code></pre>

<p>or</p>

<pre><code>n=0
git log --pretty=%h --diff-filter=d -- $file |
while read; do
        eval git show $REPLY:$file &gt; $((n++))_$REPLY.$file
done
</code></pre>

<p>depending on whether you want the blob's or the commit's hash in the resulting file name.</p>
","4","2","42001","1728","671","1888","60480287","60480966"
"60481244","<p>You: I wanted to apply k-mean to remove any anomalies. </p>

<p>Actually, KMeas will detect anomalies and include them in the nearest cluster.  The loss function is the minimum sum of squared distances from each point to its assigned cluster centroid.  If you want to kick out outliers, consider using a z-score methodology.  </p>

<pre><code>import numpy as np
import pandas as pd

# import your data
df = pd.read_csv('C:\\Users\\your_file.csv)

# get only numerics
numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']
newdf = df.select_dtypes(include=numerics)

df = newdf

# count rows in DF before kicking out records with z-score over 3
df.shape

# handle NANs
df = df.fillna(0)


from scipy import stats
df = df[(np.abs(stats.zscore(df)) &lt; 3).all(axis=1)]
df.shape


df = pd.DataFrame(np.random.randn(100, 3))
from scipy import stats
df[(np.abs(stats.zscore(df)) &lt; 3).all(axis=1)]

# count rows in DF before kicking out records with z-score over 3
df.shape
</code></pre>

<p>In addition, take a look at these links when you have some free time.</p>

<p><a href=""https://medium.com/analytics-vidhya/effect-of-outliers-on-k-means-algorithm-using-python-7ba85821ea23"" rel=""nofollow noreferrer"">https://medium.com/analytics-vidhya/effect-of-outliers-on-k-means-algorithm-using-python-7ba85821ea23</a></p>

<p><a href=""https://statisticsbyjim.com/basics/outliers/"" rel=""nofollow noreferrer"">https://statisticsbyjim.com/basics/outliers/</a></p>
","3","1","14971","13653","10","2256","60480314","60482019"
"60482019","<p>Here is a follow up answer for your last question.</p>

<pre><code>import seaborn as sns
import pandas as pd
titanic = sns.load_dataset('titanic')
titanic = titanic.copy()
titanic = titanic.dropna()
titanic['age'].plot.hist(
  bins = 50,
  title = ""Histogram of the age variable""
)


from scipy.stats import zscore
titanic[""age_zscore""] = zscore(titanic[""age""])
titanic[""is_outlier""] = titanic[""age_zscore""].apply(
  lambda x: x &lt;= -2.5 or x &gt;= 2.5
)
titanic[titanic[""is_outlier""]]


ageAndFare = titanic[[""age"", ""fare""]]
ageAndFare.plot.scatter(x = ""age"", y = ""fare"")


from sklearn.preprocessing import MinMaxScaler
scaler = MinMaxScaler()
ageAndFare = scaler.fit_transform(ageAndFare)
ageAndFare = pd.DataFrame(ageAndFare, columns = [""age"", ""fare""])
ageAndFare.plot.scatter(x = ""age"", y = ""fare"")


from sklearn.cluster import DBSCAN
outlier_detection = DBSCAN(
  eps = 0.5,
  metric=""euclidean"",
  min_samples = 3,
  n_jobs = -1)
clusters = outlier_detection.fit_predict(ageAndFare)

clusters


from matplotlib import cm
cmap = cm.get_cmap('Accent')
ageAndFare.plot.scatter(
  x = ""age"",
  y = ""fare"",
  c = clusters,
  cmap = cmap,
  colorbar = False
)
</code></pre>

<p><a href=""https://i.stack.imgur.com/iuhct.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/iuhct.png"" alt=""enter image description here""></a></p>

<p>See this link for all details.</p>

<p><a href=""https://www.mikulskibartosz.name/outlier-detection-with-scikit-learn/"" rel=""nofollow noreferrer"">https://www.mikulskibartosz.name/outlier-detection-with-scikit-learn/</a></p>

<p>I have never heard of 'Local Outlier Factor' before today.  When I Googled it, I got some information that seems to indicate that it is a derivative of DBSCAN.  Finally, I think my first answer is actually the best way to detect outliers.  DBSCAN is clustering algo that happens to find outliers, which are really considered 'noise'.  I don't think the primary purpose of DBSCAN is anomaly detection, but rather clustering.  In conclusion, it takes a bit of skill to choose hyper-parameters correctly.  Also, DBSCAN can be slow on very large datasets, as it implicitly needs to compute the empirical density for each sample point, leading  to  a  quadratic  worst-case  time  complexity, which is quite slow on large datasets. </p>
","0","1","14971","13653","10","2256","60480314","60482019"
"60480344","<p>From <a href=""https://stackoverflow.com/a/7397195/1675501"">https://stackoverflow.com/a/7397195/1675501</a></p>

<p>First, you need to strip the 0b prefix, and left-zero-pad the string so it's length is divisible by 8, to make dividing the bitstring up into characters easy:</p>

<pre><code>bitstring = bitstring[2:]
bitstring = -len(bitstring) % 8 * '0' + bitstring
</code></pre>

<p>Then you divide the string up into blocks of eight binary digits, convert them to ASCII characters, and join them back into a string:</p>

<pre><code>string_blocks = (bitstring[i:i+8] for i in range(0, len(bitstring), 8))
string = ''.join(chr(int(char, 2)) for char in string_blocks)
</code></pre>

<p>If you actually want to treat it as a number, you still have to account for the fact that the leftmost character will be at most seven digits long if you want to go left-to-right instead of right-to-left.</p>
","0","0","1082","116","16","81","60480316","60480344"
"60480448","<p>You have two issues:</p>

<ul>
<li>You are not sending JSON data, you forgot to encode your data to JSON. Encoding the string value <code>test connection</code> to JSON becomes <code>""test connection""</code>, but <em>quotes have meaning in your shell too</em>, so you need to add <em>extra</em> quoting or escapes.</li>
<li>You can't set multiple headers with a single <code>-H</code> entry. Use multiple, one per header set. Headers don't need quotes, only the shell needs quoting to prevent argument splitting on spaces.</li>
</ul>

<p>This would be equivalent:</p>

<pre class=""lang-sh prettyprint-override""><code>curl -X POST \
  --data '""test connection""' \
  -H 'Content-type: application/json' \
  -H 'Authorization: Basic asdfasdf' \
  dns.com/end
</code></pre>

<p>Demo using <a href=""https://httpbin.org"" rel=""nofollow noreferrer"">https://httpbin.org</a>:</p>

<pre class=""lang-sh prettyprint-override""><code>$ curl -X POST \
&gt;   --data '""test connection""' \
&gt;   -H 'Content-type: application/json' \
&gt;   -H 'Authorization: Basic asdfasdf' \
&gt;   https://httpbin.org/post

{
  ""args"": {},
  ""data"": ""\""test connection\"""",
  ""files"": {},
  ""form"": {},
  ""headers"": {
    ""Accept"": ""*/*"",
    ""Authorization"": ""Basic asdfasdf"",
    ""Content-Length"": ""17"",
    ""Content-Type"": ""application/json"",
    ""Host"": ""httpbin.org"",
    ""User-Agent"": ""curl/7.54.0"",
    ""X-Amzn-Trace-Id"": ""Root=1-5e5c399c-201cc8007165873084d4cf38""
  },
  ""json"": ""test connection"",
  ""origin"": ""&lt;ip address&gt;"",
  ""url"": ""https://httpbin.org/post""
}
</code></pre>

<p>which matches the Python equivalent:</p>

<pre class=""lang-py prettyprint-override""><code>&gt;&gt;&gt; import requests
&gt;&gt;&gt; url = 'https://httpbin.org/post'
&gt;&gt;&gt; msg = ""test connection""
&gt;&gt;&gt; headers = {""Content-type"": ""application/json"",
...             ""Authorization"": ""Basic asdfasdf""}
&gt;&gt;&gt; response = requests.post(url, json=msg, headers=headers)
&gt;&gt;&gt; print(response.text)
{
  ""args"": {},
  ""data"": ""\""test connection\"""",
  ""files"": {},
  ""form"": {},
  ""headers"": {
    ""Accept"": ""*/*"",
    ""Accept-Encoding"": ""gzip, deflate"",
    ""Authorization"": ""Basic asdfasdf"",
    ""Content-Length"": ""17"",
    ""Content-Type"": ""application/json"",
    ""Host"": ""httpbin.org"",
    ""User-Agent"": ""python-requests/2.22.0"",
    ""X-Amzn-Trace-Id"": ""Root=1-5e5c3a25-50c9db19a78512606a42b6ec""
  },
  ""json"": ""test connection"",
  ""origin"": ""&lt;ip address&gt;"",
  ""url"": ""https://httpbin.org/post""
}
</code></pre>
","0","1","879075","5816","21692","293021","60480388","60480448"
"60498093","<p>You can remove some of the noise using contour area filtering with <a href=""https://docs.opencv.org/2.4/modules/imgproc/doc/structural_analysis_and_shape_descriptors.html#contourarea"" rel=""nofollow noreferrer""><code>cv2.contourArea</code></a>. The idea is to filter using some threshold area. If a contour passes this filter then we can remove the noise by filling in the contour with <a href=""https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_imgproc/py_contours/py_contours_begin/py_contours_begin.html#how-to-draw-the-contours"" rel=""nofollow noreferrer""><code>cv2.drawContours</code></a>. Using your binary image as input:</p>

<p><a href=""https://i.stack.imgur.com/BL55h.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/BL55h.png"" alt=""enter image description here""></a></p>

<p>Detected contours to remove highlighted in green</p>

<p><a href=""https://i.stack.imgur.com/4IR5n.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/4IR5n.png"" alt=""enter image description here""></a></p>

<p>Result</p>

<p><a href=""https://i.stack.imgur.com/xkGlL.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/xkGlL.png"" alt=""enter image description here""></a></p>

<p>Depending on how much noise you want to remove, you can adjust the threshold area value</p>

<p>Code</p>

<pre><code>import numpy as np
import cv2

# Load image, grayscale, Otsu's threshold
image = cv2.imread(""1.png"")
gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]

# Find contours and filter using contour area
cnts = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)
cnts = cnts[0] if len(cnts) == 2 else cnts[1]
for c in cnts:
    area = cv2.contourArea(c)
    if area &lt; 50:
        cv2.drawContours(thresh, [c], -1, 0, -1)
        cv2.drawContours(image, [c], -1, (36,255,12), -1)

result = 255 - thresh
cv2.imshow(""image"", image) 
cv2.imshow(""thresh"", thresh) 
cv2.imshow(""result"", result) 
cv2.waitKey()
</code></pre>
","0","2","25600","1364","21","7558","60480473","60498093"
"60482931","<p>You can compare text of revision directly, or look for the revisions that have the same sha1 hash:</p>

<pre><code>&gt;&gt;&gt; rev = next(revs)
&gt;&gt;&gt; rev.sha1
'1b02fc4cbcfd1298770b16f85afe0224fad4b3ca'
</code></pre>

<p>If two revision have the same text/hash it means that the newer one is a revert to the older one. Of-course there are some special cases like <a href=""https://www.mediawiki.org/wiki/API:Revisions"" rel=""nofollow noreferrer""><code>sha1hidden</code></a>, or how to handle multiple reverts to the same revision that one needs to consider.</p>
","1","3","5471","4461","28","216","60480535","60483214"
"60483214","<p>""Revert"" is not a well-defined concept so it depends on how you define it. (See <a href=""https://phabricator.wikimedia.org/T152434"" rel=""nofollow noreferrer"">https://phabricator.wikimedia.org/T152434</a> for some relevant discussion.) The most capable revert detection tool today is probably <a href=""https://pythonhosted.org/mwreverts/"" rel=""nofollow noreferrer"">mwrevert</a>.</p>
","0","4","25311","465","58","1995","60480535","60483214"
"60480819","<p>With the most recent versions of Matplotlib, this is pretty straightforward.</p>

<pre><code>def add_twin(ax, **kwargs):
    twin = ax.twinx()
    twin.yaxis.tick_left()
    twin.tick_params(axis='y', direction='in', **kwargs)
    for tick in twin.get_yticklabels():
        tick.set_horizontalalignment('right')
    return twin


fig, ax = plt.subplots()
twin = add_twin(ax)
twin.set_yticks((0.1, 0.5, 0.9))
</code></pre>

<p>The horizontal alignment part is key, and you'll probably need to tweak the pad for your purposes, using the <code>kwargs</code>. But you should get something like this:</p>

<p><a href=""https://i.stack.imgur.com/G0alw.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/G0alw.png"" alt=""enter image description here""></a></p>
","0","1","5064","271","12","584","60480567","60480819"
"60480732","<p>Each line of data you read from the file already has a newline character at the end of it. If you append something to the line, it will go after the newline, and therefore appear on the next line.</p>

<p><a href=""https://stackoverflow.com/questions/60480613/mysterious-new-line-character-when-writing-to-a-text-file#comment106994109_60480613"">Source</a></p>
","0","0","10360","1639","11617","4786","60480613","60480732"
"60537191","<p>Here's a temporary hack that I found:<br>
I changed line 753 in djongo/sql2mongo/query.py from this:</p>

<pre class=""lang-py prettyprint-override""><code>        self.parse()
</code></pre>

<p>to this:</p>

<pre class=""lang-py prettyprint-override""><code>        try:
            self.parse()
        except:
            if (self._sql.strip().endswith(""subquery"")):
                self._sql = self._sql.strip()[:-8]
</code></pre>
","1","1","147","5","0","14","60480692","60537191"
"60481078","<p>Easiest way is to use ImageDataGenerator.flow from directory. Documentation is 
at <a href=""https://keras.io/preprocessing/image/"" rel=""nofollow noreferrer"">https://keras.io/preprocessing/image/</a>. images will be an array of shape (batch_size, 200, 200, 3)
Note: each time you run this it will put batch_size more images in the 
save_to_dir so you may not want to include that parameter.
You can access the individual images as img1=images[0], img2=images[1] etc
Set up your generator as follows    </p>

<pre><code>datagen = ImageDataGenerator(rotation_range = 30, width_shift_range = 0.2,
                             height_shift_range = 0.2,
                             shear_range = 0.2, 
                             zoom_range = 0.2,
                             rescale=1/255,
                             horizontal_flip = True,
                             fill_mode = ""nearest"")
data=datagen.flow_from_directory(your_dir, target_size=(200, 200),
                                 batch_size=your_file_count, shuffle=False,
                                 save_to_dir=your_save_dir,save_format='png',
                                 interpolation='nearest')
images,labels=data.next()

</code></pre>
","4","0","3888","52","11","321","60480693","60481078"
"60481033","<p>If you check the <a href=""https://github.com/scikit-learn/scikit-learn/blob/b194674c4/sklearn/metrics/_plot/confusion_matrix.py#L119"" rel=""nofollow noreferrer"">source</a> for <code>sklearn.metrics.plot_confusion_matrix</code>, you can see how the data is processed to create the plot. Then you can reuse the constructor <code>ConfusionMatrixDisplay</code> and plot your own confusion matrix.</p>

<pre><code>import matplotlib.pyplot as plt
from sklearn.metrics import ConfusionMatrixDisplay

cm = [0.612, 0.388, 0.228, 0.772] # your confusion matrix
ls = [0, 1] # your y labels
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=ls)
disp.plot(include_values=include_values, cmap=cmap, ax=ax, xticks_rotation=xticks_rotation)
plt.show()
</code></pre>
","0","3","2342","130","56","174","60480777","60481033"
"65865549","<p>I saw that someone already answered this question, but I'm adding a new one that can be useful for the author or even for other users.</p>
<p>It is possible to <strong>plot</strong> in <strong>Python</strong> an already <strong>Confusion Matrix</strong> computed through <code>mlxtend</code> package:</p>
<blockquote>
<p>Mlxtend (machine learning extensions) is a Python library of useful
tools for the day-to-day data science tasks.</p>
</blockquote>
<p><strong>Snippet code:</strong></p>
<pre><code># Imports
from mlxtend.plotting import plot_confusion_matrix
import matplotlib.pyplot as plt
import numpy as np

# Your Confusion Matrix
cm = np.array([[0.612, 0.388],
               [0.228, 0.772]])

# Classes
classes = ['class A', 'class B']

figure, ax = plot_confusion_matrix(conf_mat = cm,
                                   class_names = classes,
                                   show_absolute = False,
                                   show_normed = True,
                                   colorbar = True)

plt.show()
</code></pre>
<p><strong>The output will be:</strong></p>
<p><a href=""https://i.stack.imgur.com/b2HL4.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/b2HL4.png"" alt=""enter image description here"" /></a></p>
","0","1","540","907","1","230","60480777","60481033"
"60481442","<p><a href=""https://matplotlib.org/tutorials/introductory/customizing.html#matplotlibrc-sample"" rel=""nofollow noreferrer""><code>matplotlib.rcParams</code></a> contains the plot parameters for <code>matplotlib</code>, stored in <em>matplotlibrc</em> file. You can change the parameters either directly in the matplotlibrc file (as explained <a href=""https://matplotlib.org/tutorials/introductory/customizing.html#the-matplotlibrc-file"" rel=""nofollow noreferrer"">here</a>), or in your code, just before plotting. Here is an example to change the figure background color as you requested:</p>

<pre><code>import matplotlib as mpl
import matplotlib.plot as plt

plt.plot(play_num_2019[g], home_prob_2019[g], color = getColor(home_teams_2019[g]))
plt.plot(play_num_2019[g], away_prob_2019[g], color = getColor(away_teams_2019[g]))
plt.xlabel(""Play Number"")
plt.ylabel(""Win Probability"")
mpl.rcParams['figure.facecolor'] = 'r' # &lt;--- here is the line for changing the background to red
plt.legend([home_teams_2019[g], away_teams_2019[g]])
fig = plt.figure()
fig.patch.set_facecolor('xkcd:white')
</code></pre>

<p>If you want to change it only when the figure is saved, change the following parameter instead.</p>

<pre><code>mpl.rcParams['savefig.facecolor'] = 'r'
</code></pre>
","0","1","2342","130","56","174","60480832","60481442"
"60485077","<p>If you want to set the facecolor for a figure you can either use <code>matplotlib.rcParams</code> to set the a facecolcolor globally - for all figures - or for a single figure you can specify the facecolor in calling <code>plt.savefig()</code>. If you want to set the facecolor using <code>fig.patch.set_facecolor()</code> you can then simply use <code>fig.get_facecolor()</code> in <code>savefig()</code>. For example:</p>

<pre class=""lang-py prettyprint-override""><code>import matplotlib.pyplot as plt
import numpy as np

x = np.linspace(0, np.pi*4, 100)

fig = plt.figure()
plt.plot(x, np.sin(x))
plt.plot(x, np.cos(np.sin(x)))
fig.patch.set_facecolor((0.68, 0.78, 0.91))

plt.savefig('/path/to/output.png', facecolor = fig.get_facecolor())
</code></pre>

<p>Output</p>

<p><a href=""https://i.stack.imgur.com/8pKZP.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/8pKZP.png"" alt=""enter image description here""></a></p>

<p>If you want this color applied behind the plot area as well then you must pass <code>transparent=True</code> in <code>plt.savefig()</code> which will give you</p>

<p><a href=""https://i.stack.imgur.com/hpCUr.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/hpCUr.png"" alt=""enter image description here""></a></p>

<p>Or - as I prefer - you can set the alpha of the axes patch like so</p>

<pre class=""lang-py prettyprint-override""><code>plt.gca().patch.set_alpha(0.7)
</code></pre>

<p>or the like. This will produce</p>

<p><a href=""https://i.stack.imgur.com/otAcb.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/otAcb.png"" alt=""enter image description here""></a></p>

<hr>

<p><strong>Note</strong> &ensp; - &ensp;  Setting the facecolor to <code>'xkcd:white'</code> won't have any effect because the corresponding RGB values are <code>(1.0, 1.0, 1.0)</code> - identical to the default facecolor.</p>
","0","0","8010","2376","172","1219","60480832","60481442"
"60491341","<p>In Python 2.7 (which has been deprecated since 2015 and has officially reached End of Life per Januari 1, 2020), <a href=""https://docs.python.org/2.7/reference/simple_stmts.html#print"" rel=""nofollow noreferrer""><code>print</code> used to be a statement</a>, just like a couple of other keywords such as <code>break</code> and <code>continue</code>. In newer versions of Python since 3.0 onwards, <a href=""https://docs.python.org/3/whatsnew/3.0.html#print-is-a-function"" rel=""nofollow noreferrer""><code>print</code> is a function</a>, and that is why you may see examples of your callback that use <code>print</code> itself.</p>

<p>So you get a SyntaxError because you are applying a modern construction (post-2015 v.3) to an old and officially obsolete version of Python.</p>

<p>If you want to keep on using 2.7, you can work around it by creating a wrapper <em>function</em> for just the <code>print</code> statement:</p>

<pre class=""lang-py prettyprint-override""><code>def my_print (text):
  print text

def event_loop (handle_key):
  handle_key('hello!')

event_loop(my_print)
</code></pre>

<p>where replacing the last line with your original line</p>

<pre class=""lang-py prettyprint-override""><code>event_loop(print)
</code></pre>

<p>will show that SyntaxError again. But it would be better to upgrade.</p>
","1","0","20908","7958","28090","11460","60480901","60491341"
"60480994","<p>The source of your problem is that the path variable you are adding to ROUTES is a reference to the same object that you are using to control the traversal.  This same object is added every time you find a destination so, when the process is over (and path is empty again), your ROUTE list contains multiple references to the (now empty) path object.</p>

<p>Your correction <code>ROUTES.append([i for i in path])</code> creates a new instance of the path variable to store in the ROUTES list.  That's why it works.</p>

<p>It is a common mistake in Python to store lists in variables assuming that you are holding a copy when in fact it is only a reference and the content may be modified by other parts of the program that change the original.</p>

<p>Note that you could also use <code>ROUTES.append(path.copy())</code> or <code>ROUTES.append(list(path))</code> or <code>ROUTES.append([*path])</code></p>
","0","1","24359","14","17","1310","60480903","60480994"
"60499012","<p>Of the unsupported operations, it’s only interrupt that you <em>should</em> want; Java has long deprecated the others as being <a href=""https://stackoverflow.com/q/16504140/8586227"">impossible to use safely in general</a>.  Since Python lacks even the generic interrupt interface (except that an interrupt produces a <code>KeyboardInterrupt</code> on the <em>main</em> thread only, which is not very useful), you have to avoid basic functions like <a href=""https://stackoverflow.com/a/49877671/8586227""><code>time.sleep</code></a> in favor of versions that also detect an inter-thread signal.  (In general, successful methods of <em>killing</em> a thread are also able to <em>control</em> it, since they involve getting the thread’s attention and then having <em>it</em> exit.)</p>

<p>Details:</p>

<ul>
<li>Dropping references to a <code>Thread</code> object can’t kill it: threads are the <strong>roots</strong> for garbage collection.</li>
<li><strong>All</strong> objects are shared between threads: that’s what distinguishes them from processes.  (That’s not to say that threads typically <em>use</em> their theoretical access to a large number of objects, nor to say that they shouldn’t <em>minimize</em> the number of shared objects for simplicity.)</li>
<li>Libraries that you call may or may not provide an interface to interrupt their long-running operations; for example, some will gracefully return control to you upon receipt of an “ignored” signal like <code>SIGPIPE</code>.</li>
</ul>
","2","0","22977","1407","171","2296","60480944","60499012"